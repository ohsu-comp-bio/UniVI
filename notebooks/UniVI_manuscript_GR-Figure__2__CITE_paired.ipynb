{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e79c80",
   "metadata": {},
   "source": [
    "# UniVI manuscript - Figure 2 generation reproducible workflow\n",
    "### CITE-seq embeddings before/after integration; modality mixing statistics; label-transfer confusion matrices and per-class performance.\n",
    "\n",
    "Andrew Ashford, Pathways + Omics Group, Oregon Health & Science University, Portland, OR - 12/6/2025\n",
    "\n",
    "This Jupyter Notebook will house the end-to-end workflow to generate the panels in Figure 2 of our manuscript, \"Unifying multimodal single-cell data with a mixture-of-experts β-variational autoencoder framework\" which is currently being revised for Genome Research and is available currently on bioRxiv at the following link: https://www.biorxiv.org/content/10.1101/2025.02.28.640429v1.full\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4493641",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import non-UniVI modules\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01af9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required UniVI modules\n",
    "from univi import (\n",
    "    ModalityConfig,\n",
    "    UniVIConfig,\n",
    "    TrainingConfig,\n",
    "    UniVIMultiModalVAE,\n",
    "    matching,\n",
    "    UniVITrainer,\n",
    "    write_univi_latent,\n",
    "    MultiModalDataset,\n",
    ")\n",
    "\n",
    "import univi as uv\n",
    "import univi.evaluation as ue\n",
    "import univi.plotting as up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check UniVI module version\n",
    "print(\"Installed version is univi v\" + str(uv.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dedadc6",
   "metadata": {},
   "source": [
    "### Specify device to use for model\n",
    "\n",
    "Set \"device\" - preferably device should be \"cuda\" for speedier model implementation/training (NOTE: can use \"mps\" on MacBook M1 chips to use their GPU). Requires GPU and the correct packages/versions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de30da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af0ce95",
   "metadata": {},
   "source": [
    "### Specify file paths\n",
    "\n",
    "Where data lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c47391",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/home/groups/precepts/ashforda/UniVI_v2/UniVI_older-non_git/data/Hao_CITE-seq_data\")\n",
    "\n",
    "RNA_PATH = DATA_ROOT / \"Hao_RNA_data.h5ad\"\n",
    "ADT_PATH = DATA_ROOT / \"Hao_ADT_data.h5ad\"\n",
    "\n",
    "print(\"RNA file:\", RNA_PATH)\n",
    "print(\"ADT file:\", ADT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3c39c",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "Read data into AnnData objects using the paths in the code chunk above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3aa18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = sc.read_h5ad(RNA_PATH)\n",
    "adt = sc.read_h5ad(ADT_PATH)\n",
    "\n",
    "print(rna)\n",
    "print(adt)\n",
    "\n",
    "print(\"RNA obs names head:\", rna.obs_names[:5].tolist())\n",
    "print(\"ADT obs names head:\", adt.obs_names[:5].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2621eea",
   "metadata": {},
   "source": [
    "### Align cells between RNA and ADT\n",
    "\n",
    "Make sure the cell indices are aligned so UniVI knows which samples are paired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersect barcodes\n",
    "common_cells = rna.obs_names.intersection(adt.obs_names)\n",
    "print(\"Common cells:\", len(common_cells))\n",
    "\n",
    "rna = rna[common_cells].copy()\n",
    "adt = adt[common_cells].copy()\n",
    "\n",
    "# Make sure order matches\n",
    "adt = adt[rna.obs_names].copy()\n",
    "\n",
    "assert np.array_equal(rna.obs_names.values, adt.obs_names.values)\n",
    "print(\"obs_names aligned between RNA and ADT.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45146ae4",
   "metadata": {},
   "source": [
    "### Stratify the data by celltype so that we train a balanced/generalizeable model\n",
    "\n",
    "Also specifying all the data preprocessing functions below, will be used in their own respective sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2aebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Stratified split with cap\n",
    "# -----------------------------\n",
    "def stratified_split(\n",
    "    idx,\n",
    "    labels,\n",
    "    frac_train=0.8,\n",
    "    frac_val=0.1,\n",
    "    seed=0,\n",
    "    max_per_label=None,\n",
    "    unused_to_test=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each label:\n",
    "      - shuffle its indices\n",
    "      - keep up to max_per_label as \"used\"\n",
    "      - split used -> train/val/test by fractions\n",
    "      - leftover beyond max_per_label -> unused\n",
    "    If unused_to_test=True, unused is appended into test and not returned separately.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.asarray(idx)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    train_idx, val_idx, test_idx, unused_idx = [], [], [], []\n",
    "\n",
    "    # stable label order (preserves category order if categorical, else sorted unique)\n",
    "    uniq = pd.unique(labels)\n",
    "\n",
    "    for lab in uniq:\n",
    "        m = idx[labels == lab]\n",
    "        rng.shuffle(m)\n",
    "\n",
    "        if max_per_label is not None:\n",
    "            used = m[:max_per_label]\n",
    "            leftover = m[max_per_label:]\n",
    "            if leftover.size:\n",
    "                unused_idx.append(leftover)\n",
    "        else:\n",
    "            used = m\n",
    "\n",
    "        n = used.size\n",
    "        if n == 0:\n",
    "            continue\n",
    "\n",
    "        n_train = int(frac_train * n)\n",
    "        n_val   = int(frac_val * n)\n",
    "        # remainder -> test\n",
    "        train_idx.append(used[:n_train])\n",
    "        val_idx.append(used[n_train:n_train + n_val])\n",
    "        test_idx.append(used[n_train + n_val:])\n",
    "\n",
    "    train_idx = np.concatenate(train_idx) if train_idx else np.array([], dtype=int)\n",
    "    val_idx   = np.concatenate(val_idx)   if val_idx   else np.array([], dtype=int)\n",
    "    test_idx  = np.concatenate(test_idx)  if test_idx  else np.array([], dtype=int)\n",
    "    unused_idx = np.concatenate(unused_idx) if unused_idx else np.array([], dtype=int)\n",
    "\n",
    "    if unused_to_test and unused_idx.size:\n",
    "        test_idx = np.concatenate([test_idx, unused_idx])\n",
    "        unused_idx = np.array([], dtype=int)\n",
    "\n",
    "    return train_idx, val_idx, test_idx, unused_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Small helper functions\n",
    "# -----------------------------\n",
    "def _ensure_counts_layer(adata, layer_name=\"counts\"):\n",
    "    if layer_name in adata.layers:\n",
    "        return\n",
    "    # Fall back to X as counts if needed (only if X is actually raw counts!)\n",
    "    adata.layers[layer_name] = adata.X.copy()\n",
    "\n",
    "def _subset_by_idx_pair(rna, adt, idx):\n",
    "    # Assumes rna/adt are already paired in the same order\n",
    "    return rna[idx].copy(), adt[idx].copy()\n",
    "\n",
    "def _clr_normalize_dense(X, eps=1e-8):\n",
    "    \"\"\"\n",
    "    CLR per cell: log1p(x) - mean(log1p(x)) across features.\n",
    "    Works for dense or sparse; returns dense float32 array.\n",
    "    \"\"\"\n",
    "    if sp.issparse(X):\n",
    "        X = X.toarray()\n",
    "    X = X.astype(np.float32, copy=False)\n",
    "    X = np.log1p(X)\n",
    "    X = X - X.mean(axis=1, keepdims=True)\n",
    "    return X\n",
    "\n",
    "def preprocess_citeseq_splits(\n",
    "    rna_train, adt_train,\n",
    "    rna_val, adt_val,\n",
    "    rna_test, adt_test,\n",
    "    *,\n",
    "    rna_counts_layer=\"counts\",\n",
    "    adt_counts_layer=\"counts\",\n",
    "    n_hvg=2000,\n",
    "    target_sum=1e4,\n",
    "    rna_make_log1p=True,\n",
    "    adt_make_clr=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train-fit, then transform val/test the same way.\n",
    "\n",
    "    RNA:\n",
    "      - ensures counts layer\n",
    "      - HVGs learned on train only (Seurat v3 if possible)\n",
    "      - normalize_total + log1p (applied to all splits)\n",
    "      - subsets to HVGs for all splits\n",
    "\n",
    "    ADT:\n",
    "      - ensures counts layer\n",
    "      - CLR per cell (applied to all splits) -> stored in .X (dense float32)\n",
    "    \"\"\"\n",
    "    # ensure counts layers exist\n",
    "    for a in (rna_train, rna_val, rna_test):\n",
    "        _ensure_counts_layer(a, rna_counts_layer)\n",
    "    for a in (adt_train, adt_val, adt_test):\n",
    "        _ensure_counts_layer(a, adt_counts_layer)\n",
    "\n",
    "    # ---- RNA: pick HVGs on TRAIN only\n",
    "    rna_train_tmp = rna_train.copy()\n",
    "    rna_train_tmp.X = rna_train_tmp.layers[rna_counts_layer]\n",
    "\n",
    "    try:\n",
    "        sc.pp.highly_variable_genes(\n",
    "            rna_train_tmp,\n",
    "            n_top_genes=int(n_hvg),\n",
    "            flavor=\"seurat_v3\",\n",
    "            layer=None,   # we set .X already\n",
    "        )\n",
    "    except Exception:\n",
    "        sc.pp.highly_variable_genes(\n",
    "            rna_train_tmp,\n",
    "            n_top_genes=int(n_hvg),\n",
    "            flavor=\"seurat\",\n",
    "            layer=None,\n",
    "        )\n",
    "\n",
    "    hvg_mask = rna_train_tmp.var[\"highly_variable\"].to_numpy()\n",
    "    hvg_genes = rna_train_tmp.var_names[hvg_mask].tolist()\n",
    "\n",
    "    # ---- RNA: normalize/log1p + subset to HVGs (train/val/test)\n",
    "    def _rna_transform(adata):\n",
    "        # subset genes first to minimize memory\n",
    "        ad = adata[:, hvg_genes].copy()\n",
    "        X = ad.layers[rna_counts_layer]\n",
    "\n",
    "        # normalize_total on counts\n",
    "        if sp.issparse(X):\n",
    "            cell_sums = np.asarray(X.sum(axis=1)).ravel()\n",
    "            scale = (float(target_sum) / np.maximum(cell_sums, 1e-12)).astype(np.float32)\n",
    "            Xn = X.multiply(scale[:, None])\n",
    "        else:\n",
    "            cell_sums = X.sum(axis=1, keepdims=True)\n",
    "            Xn = (X / np.maximum(cell_sums, 1e-12)) * float(target_sum)\n",
    "\n",
    "        if rna_make_log1p:\n",
    "            if sp.issparse(Xn):\n",
    "                Xn = Xn.tocsr(copy=True)\n",
    "                Xn.data = np.log1p(Xn.data).astype(np.float32, copy=False)\n",
    "            else:\n",
    "                Xn = np.log1p(Xn).astype(np.float32, copy=False)\n",
    "\n",
    "        ad.X = Xn\n",
    "        # keep original counts too (still subsetted)\n",
    "        ad.layers[rna_counts_layer] = ad.layers[rna_counts_layer]\n",
    "        return ad\n",
    "\n",
    "    rna_train_pp = _rna_transform(rna_train)\n",
    "    rna_val_pp   = _rna_transform(rna_val)\n",
    "    rna_test_pp  = _rna_transform(rna_test)\n",
    "\n",
    "    # ---- ADT: CLR into .X (train/val/test)\n",
    "    def _adt_transform(adata):\n",
    "        ad = adata.copy()\n",
    "        Xc = ad.layers[adt_counts_layer]\n",
    "        if adt_make_clr:\n",
    "            ad.X = _clr_normalize_dense(Xc)\n",
    "        else:\n",
    "            # keep counts as X (dense float32)\n",
    "            ad.X = Xc.toarray().astype(np.float32) if sp.issparse(Xc) else Xc.astype(np.float32)\n",
    "        return ad\n",
    "\n",
    "    adt_train_pp = _adt_transform(adt_train)\n",
    "    adt_val_pp   = _adt_transform(adt_val)\n",
    "    adt_test_pp  = _adt_transform(adt_test)\n",
    "\n",
    "    return (rna_train_pp, adt_train_pp,\n",
    "            rna_val_pp,   adt_val_pp,\n",
    "            rna_test_pp,  adt_test_pp,\n",
    "            hvg_genes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df6d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the counts of each celltype.l1 in the data\n",
    "print(rna.obs[\"celltype.l1\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff37651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the counts of each celltype.l2 in the data\n",
    "print(rna.obs[\"celltype.l2\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b989592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the counts of each celltype.l3 in the data\n",
    "print(rna.obs[\"celltype.l3\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac538c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Use it on Hao CITE-seq\n",
    "# -----------------------------\n",
    "\n",
    "labels = rna.obs[\"celltype.l1\"].astype(str).to_numpy()\n",
    "idx = np.arange(rna.n_obs)\n",
    "\n",
    "train_idx, val_idx, test_idx, unused_idx = stratified_split(\n",
    "    idx, labels,\n",
    "    frac_train=0.8, frac_val=0.1, seed=0,\n",
    "    max_per_label=2000,\n",
    "    unused_to_test=True,      # set True if you want unused merged into test\n",
    ")\n",
    "\n",
    "# paired splits\n",
    "rna_train, adt_train = _subset_by_idx_pair(rna, adt, train_idx)\n",
    "rna_val,   adt_val   = _subset_by_idx_pair(rna, adt, val_idx)\n",
    "rna_test,  adt_test  = _subset_by_idx_pair(rna, adt, test_idx)\n",
    "\n",
    "if unused_idx.size:\n",
    "    rna_unused, adt_unused = _subset_by_idx_pair(rna, adt, unused_idx)\n",
    "else:\n",
    "    rna_unused, adt_unused = None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1815694",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "* RNA preprocessing (log1p + HVG + scale → Gaussian decoder)\n",
    "\n",
    "* ADT preprocessing (CLR + scale → Gaussian decoder)\n",
    "\n",
    "Running the preprocessing functions specified above. Of note, we're performing the preprocessing per-train/val/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f249100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "# preprocessing (fit on train, apply to val/test)\n",
    "(rna_train_pp, adt_train_pp,\n",
    " rna_val_pp,   adt_val_pp,\n",
    " rna_test_pp,  adt_test_pp,\n",
    " hvg_genes) = preprocess_citeseq_splits(\n",
    "    rna_train, adt_train,\n",
    "    rna_val,   adt_val,\n",
    "    rna_test,  adt_test,\n",
    "    n_hvg=2000,\n",
    "    target_sum=1e4,\n",
    "    rna_make_log1p=True,\n",
    "    adt_make_clr=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da2027",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# optionally preprocess \"unused\" with same HVGs + same transforms (no refit)\n",
    "if rna_unused is not None:\n",
    "    # reuse the same transform logic by treating unused as \"test\"\n",
    "    (rna_unused_pp, adt_unused_pp,\n",
    "     _, _, _, _, _) = preprocess_citeseq_splits(\n",
    "        rna_train, adt_train,     # only used to learn HVGs (already learned here, but fine)\n",
    "        rna_unused, adt_unused,\n",
    "        rna_unused, adt_unused,\n",
    "        n_hvg=len(hvg_genes),\n",
    "        target_sum=1e4,\n",
    "        rna_make_log1p=True,\n",
    "        adt_make_clr=True,\n",
    "    )\n",
    "    # the function returns in (train,val,test) slots; we passed unused into val/test\n",
    "    # so grab one of them:\n",
    "    # rna_unused_pp == rna_train_pp from that call; use the \"val\" one instead:\n",
    "    # Instead, do a tiny manual transform with the already-computed hvg_genes:\n",
    "    # (If you want this cleaned up, I can give you a one-liner helper.)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa3c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check above preprocessed data objects - start with RNA\n",
    "print(rna_train_pp)\n",
    "print(rna_val_pp)\n",
    "print(rna_test_pp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now sanity check ADT data objects\n",
    "print(adt_train_pp)\n",
    "print(adt_val_pp)\n",
    "print(adt_test_pp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ac0d5",
   "metadata": {},
   "source": [
    "### Wrap into MultiModalDataset & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from univi.data import align_paired_obs_names\n",
    "\n",
    "pin_memory = (device == \"cuda\")\n",
    "\n",
    "# Make sure each split is paired and ordered the same across modalities\n",
    "# This was erroring out due to a function bug, fixed it and should be fixed by manuscript publication\n",
    "#train_dict = align_paired_obs_names({\"rna\": rna_train_pp, \"adt\": adt_train_pp})\n",
    "#val_dict   = align_paired_obs_names({\"rna\": rna_val_pp,   \"adt\": adt_val_pp})\n",
    "#test_dict  = align_paired_obs_names({\"rna\": rna_test_pp,  \"adt\": adt_test_pp})\n",
    "\n",
    "# Using this instead for now since we know the data are already paired from above code\n",
    "assert (rna_train_pp.obs_names == adt_train_pp.obs_names).all()\n",
    "assert (rna_val_pp.obs_names   == adt_val_pp.obs_names).all()\n",
    "assert (rna_test_pp.obs_names  == adt_test_pp.obs_names).all()\n",
    "\n",
    "train_dict = {\"rna\": rna_train_pp, \"adt\": adt_train_pp}\n",
    "val_dict   = {\"rna\": rna_val_pp,   \"adt\": adt_val_pp}\n",
    "test_dict  = {\"rna\": rna_test_pp,  \"adt\": adt_test_pp}\n",
    "\n",
    "# Build datasets (CPU tensors; trainer/model moves to GPU)\n",
    "train_ds = MultiModalDataset(adata_dict=train_dict, X_key=\"X\", device=None)\n",
    "val_ds   = MultiModalDataset(adata_dict=val_dict,   X_key=\"X\", device=None)\n",
    "test_ds  = MultiModalDataset(adata_dict=test_dict,  X_key=\"X\", device=None)\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 0\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "print(\"n_train / n_val / n_test:\", train_ds.n_cells, val_ds.n_cells, test_ds.n_cells)\n",
    "print(\"batches:\", len(train_loader), len(val_loader), len(test_loader))\n",
    "\n",
    "# sanity check one batch\n",
    "x = next(iter(train_loader))\n",
    "print({k: v.shape for k, v in x.items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ee05d",
   "metadata": {},
   "source": [
    "### UniVI configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c14dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "univi_cfg = UniVIConfig(\n",
    "    latent_dim=30,\n",
    "    beta=1.5,\n",
    "    gamma=5.0,\n",
    "    encoder_dropout=0.1,\n",
    "    decoder_dropout=0.0,\n",
    "    encoder_batchnorm=True,\n",
    "    decoder_batchnorm=False,\n",
    "    kl_anneal_start=0,\n",
    "    kl_anneal_end=0,\n",
    "    align_anneal_start=0,\n",
    "    align_anneal_end=0,\n",
    "    modalities=[\n",
    "        ModalityConfig(\n",
    "            name=\"rna\",\n",
    "            input_dim=rna_train_pp.n_vars,\n",
    "            encoder_hidden=[512, 256, 128],\n",
    "            decoder_hidden=[128, 256, 512],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "        ModalityConfig(\n",
    "            name=\"adt\",\n",
    "            input_dim=adt_train_pp.n_vars,\n",
    "            encoder_hidden=[128, 64],\n",
    "            decoder_hidden=[64, 128],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f71acd",
   "metadata": {},
   "source": [
    "If you want raw-count NB/ZINB instead, you’d:\n",
    "* Put raw counts in .layers[\"counts\"]\n",
    "* Set X_key=\"counts\" in the dataset\n",
    "* Use likelihood=\"nb\" or \"zinb\" above\n",
    "\n",
    "But for this \"Figure 2\" notebook, the scaled Gaussian setup is nicely stable and good for the best-integrated latent space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635d784",
   "metadata": {},
   "source": [
    "### Instantiate model and model objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccffde4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UniVIMultiModalVAE(\n",
    "    univi_cfg,\n",
    "    loss_mode=\"v1\",      # cross-recon + cross-posterior alignment - \"lite\"/\"v2\" just use single joint latent and L2 norm latent means for alignment,\n",
    "                         # leads to weaker alignment but depends less on paired feature reconstruction in training.\n",
    "    #v1_recon=\"cross\",   # full k→j cross-recon\n",
    "    v1_recon=\"avg\",      # average of cross-and self- recon\n",
    "    #v1_recon_mix=0.5,\n",
    "    normalize_v1_terms=True,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e1f35",
   "metadata": {},
   "source": [
    "### Instantiate TrainingConfig & trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da20ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg = TrainingConfig(\n",
    "    n_epochs=3000,\n",
    "    batch_size=batch_size,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    device=device,\n",
    "    log_every=20,\n",
    "    grad_clip=5.0,\n",
    "    num_workers=0,\n",
    "    seed=42,\n",
    "    early_stopping=True,\n",
    "    patience=50,\n",
    "    min_delta=0.0,\n",
    ")\n",
    "\n",
    "print(train_cfg)\n",
    "print(univi_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8681668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = UniVITrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    train_cfg=train_cfg,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(trainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8447f944",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.fit()\n",
    "\n",
    "# history is a dict with keys like \"train_loss\", \"val_loss\", \"beta\", \"gamma\"\n",
    "print(\"Training finished.\")\n",
    "print(\"Best val loss:\", np.min(history[\"val_loss\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01098c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"train_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_loss\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"UniVI training (CITE-seq)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92b2bd",
   "metadata": {},
   "source": [
    "### Write latent z back to AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d47db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test batches:\", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db679c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure adata_dict has the *same ordering* as during training\n",
    "adata_dict = {\n",
    "    \"rna\": rna_test_pp,\n",
    "    \"adt\": adt_test_pp,\n",
    "}\n",
    "\n",
    "Z = write_univi_latent(\n",
    "    model,\n",
    "    adata_dict,\n",
    "    obsm_key=\"X_univi\",    # will be added to each AnnData in adata_dict\n",
    "    batch_size=512,\n",
    "    device=device,\n",
    "    use_mean=True,         # deterministic: use encoder means instead of noisy samples\n",
    "    #use_mean=False,       # Stochastic\n",
    ")\n",
    "\n",
    "print(\"UniVI latent shape:\",  Z.shape)\n",
    "print(\"rna.obsm keys:\",       rna_test_pp.obsm.keys())\n",
    "print(\"adt.obsm keys:\",       adt_test_pp.obsm.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ef92f",
   "metadata": {},
   "source": [
    "Now both rna and adt have a shared latent:\n",
    "\n",
    "* rna_test_pp.obsm[\"X_univi\"]\n",
    "\n",
    "* adt_test_pp.obsm[\"X_univi\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9531530b",
   "metadata": {},
   "source": [
    "### Quick UMAP + visualization\n",
    "\n",
    "You can now treat X_univi like any other embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out many of each cell type are in the test set for level 2 cell annotations\n",
    "print(rna_test_pp.obs[\"celltype.l2\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f925231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RNA AnnData just to get a UMAP; ADT has matching .obsm[\"X_univi\"]\n",
    "rna_univi = rna_test_pp.copy()\n",
    "rna_univi.obsm[\"X_univi\"] = rna_test_pp.obsm[\"X_univi\"]\n",
    "\n",
    "# wipe any stale neighbors artifacts\n",
    "rna_univi.uns.pop(\"neighbors\", None)\n",
    "rna_univi.obsp.pop(\"connectivities\", None)\n",
    "rna_univi.obsp.pop(\"distances\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(rna_univi, use_rep=\"X_univi\", n_neighbors=15, key_added=\"univi\")\n",
    "sc.tl.umap(rna_univi, neighbors_key=\"univi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy back UMAP to ADT so they share coords\n",
    "adt_test_pp.obsm[\"X_univi_umap\"] = rna_univi.obsm[\"X_umap\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scanpy defaults (affects sc.pl.*)\n",
    "sc.set_figure_params(\n",
    "    figsize=(10, 8),   # bigger canvas\n",
    "    dpi=100,            # on-screen sharpness\n",
    "    dpi_save=300,       # saved file sharpness\n",
    "    fontsize=10,\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "# Matplotlib defaults (affects plt.*)\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (10, 8),\n",
    "    \"figure.dpi\": 100,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"savefig.pad_inches\": 0.1,\n",
    "    \"axes.titlesize\": 12,\n",
    "    \"axes.labelsize\": 8,\n",
    "    \"legend.fontsize\": 10,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc036034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: color by cell type and modality (if you have those obs fields)\n",
    "sc.pl.umap(\n",
    "    rna_univi,\n",
    "    color=[\"celltype.l1\"],\n",
    "    frameon=False,\n",
    "    size=3.0,\n",
    "    wspace=0.4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed19d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure X_univi exists in both\n",
    "assert \"X_univi\" in rna_test_pp.obsm and \"X_univi\" in adt_test_pp.obsm\n",
    "assert rna_test_pp.obsm[\"X_univi\"].shape == adt_test_pp.obsm[\"X_univi\"].shape  # paired case\n",
    "\n",
    "rna_u = rna_test_pp.copy()\n",
    "adt_u = adt_test_pp.copy()\n",
    "rna_u.obs[\"modality\"] = \"rna\"\n",
    "adt_u.obs[\"modality\"] = \"adt\"\n",
    "\n",
    "# concatenate (keeps obs, stacks cells)\n",
    "combo = ad.concat([rna_u, adt_u], join=\"outer\", label=\"modality\", keys=[\"rna\",\"adt\"], index_unique=\"-\")\n",
    "\n",
    "# IMPORTANT: carry over the latent explicitly (concat won't always merge obsm how you want)\n",
    "combo.obsm[\"X_univi\"] = np.vstack([rna_u.obsm[\"X_univi\"], adt_u.obsm[\"X_univi\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbors on the latent\n",
    "sc.pp.neighbors(combo, use_rep=\"X_univi\", n_neighbors=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02911f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# umap on the latent using the neighbors\n",
    "sc.tl.umap(combo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    combo,\n",
    "    color=[\"modality\"],\n",
    "    frameon=False,\n",
    "    size=3.0,\n",
    "    wspace=0.4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15bea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    combo,\n",
    "    color=[\"celltype.l1\"],\n",
    "    frameon=False,\n",
    "    size=3.0,\n",
    "    wspace=0.4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd61c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    combo,\n",
    "    color=[\"celltype.l2\"],\n",
    "    frameon=False,\n",
    "    size=3.0,\n",
    "    wspace=0.4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbe202",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    combo,\n",
    "    color=[\"celltype.l3\"],\n",
    "    frameon=False,\n",
    "    size=3.0,\n",
    "    wspace=0.4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec5e3a",
   "metadata": {},
   "source": [
    "### All evaluation metrics beyond just the UMAP embeddings of the shared test set latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# ----------------------------\n",
    "# User settings\n",
    "# ----------------------------\n",
    "outdir = \"figures/Figure2_CITEseq_metrics_reproducibility\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "celltype_key = \"celltype.l2\"   # change to celltype.l1 / celltype.l3 as needed\n",
    "k_mix = 20                     # k for modality mixing\n",
    "k_lt  = 15                     # k for label transfer kNN\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c05cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# ----------------------------\n",
    "# Metrics helpers\n",
    "# ----------------------------\n",
    "def foscttm_chunked(Z1, Z2, block=512):\n",
    "    \"\"\"\n",
    "    Exact FOSCTTM computed in blocks to avoid NxN memory blowups.\n",
    "    Assumes 1:1 pairing between rows i in Z1 and Z2.\n",
    "    \"\"\"\n",
    "    Z1 = np.asarray(Z1, dtype=np.float32)\n",
    "    Z2 = np.asarray(Z2, dtype=np.float32)\n",
    "    assert Z1.shape == Z2.shape\n",
    "    n = Z1.shape[0]\n",
    "\n",
    "    Z2_T = Z2.T\n",
    "    n2 = np.sum(Z2 * Z2, axis=1)  # (n,)\n",
    "\n",
    "    fos = np.empty(n, dtype=np.float32)\n",
    "\n",
    "    for i0 in range(0, n, block):\n",
    "        i1 = min(i0 + block, n)\n",
    "        A = Z1[i0:i1]  # (b, d)\n",
    "        n1 = np.sum(A * A, axis=1)[:, None]  # (b,1)\n",
    "\n",
    "        d2 = n1 + n2[None, :] - 2.0 * (A @ Z2_T)  # (b,n)\n",
    "\n",
    "        true = d2[np.arange(i1 - i0), np.arange(i0, i1)]\n",
    "        fos[i0:i1] = (d2 < true[:, None]).sum(axis=1) / (n - 1)\n",
    "\n",
    "    return float(fos.mean()), float(fos.std(ddof=1) / np.sqrt(n))\n",
    "\n",
    "\n",
    "def modality_mixing_score(Z, modality_labels, k=20, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Vanilla modality mixing:\n",
    "    Mean fraction of kNN neighbors that differ in modality.\n",
    "    Use this for *non-duplicated* sets (e.g., concatenated modality-specific embeddings).\n",
    "    \"\"\"\n",
    "    Z = np.asarray(Z, dtype=np.float32)\n",
    "    modality_labels = np.asarray(modality_labels)\n",
    "\n",
    "    n = Z.shape[0]\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    k_eff = int(min(max(int(k), 1), n - 1))\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff + 1, metric=metric)\n",
    "    nn.fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]  # drop self\n",
    "\n",
    "    same = (modality_labels[nbrs] == modality_labels[:, None])\n",
    "    return float((~same).mean())\n",
    "\n",
    "\n",
    "def modality_mixing_score_excluding_pairs(Z, modality_labels, cell_ids, k=20, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Pair-aware modality mixing for 'combo' style stacked data (same cell appears twice: RNA + ADT),\n",
    "    where the fused embedding may be identical (or extremely close) for the paired duplicates.\n",
    "\n",
    "    Computes: for each row, the fraction of neighbors from the other modality,\n",
    "    AFTER removing the paired duplicate (same cell_id) from its neighbor list.\n",
    "\n",
    "    cell_ids must map each row to a shared cell identifier (same for RNA+ADT copy).\n",
    "    \"\"\"\n",
    "    Z = np.asarray(Z, dtype=np.float32)\n",
    "    modality_labels = np.asarray(modality_labels)\n",
    "    cell_ids = np.asarray(cell_ids).astype(str)\n",
    "\n",
    "    n = Z.shape[0]\n",
    "    if n <= 2:\n",
    "        return 0.0\n",
    "\n",
    "    # Need enough neighbors so we can drop self + paired duplicate and still have k\n",
    "    k_eff = int(min(max(int(k), 1), n - 2))\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff + 2, metric=metric)\n",
    "    nn.fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]  # drop self\n",
    "\n",
    "    # Build \"pair index\": for each row i, pair[i] is the index of the other modality copy\n",
    "    first = {}\n",
    "    pair = np.full(n, -1, dtype=np.int64)\n",
    "    for i, cid in enumerate(cell_ids):\n",
    "        if cid in first:\n",
    "            j = first[cid]\n",
    "            pair[i] = j\n",
    "            pair[j] = i\n",
    "        else:\n",
    "            first[cid] = i\n",
    "\n",
    "    frac_other = np.empty(n, dtype=np.float32)\n",
    "    for i in range(n):\n",
    "        neigh = nbrs[i]\n",
    "\n",
    "        # remove paired duplicate if present\n",
    "        pj = pair[i]\n",
    "        if pj != -1:\n",
    "            neigh = neigh[neigh != pj]\n",
    "\n",
    "        neigh = neigh[:k_eff]\n",
    "        frac_other[i] = (modality_labels[neigh] != modality_labels[i]).mean()\n",
    "\n",
    "    return float(frac_other.mean())\n",
    "\n",
    "\n",
    "def knn_label_transfer(Z_source, y_source, Z_target, y_target, k=15, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    kNN label transfer: predict y_target from neighbors in Z_source.\n",
    "    Returns predictions, accuracy, macro-F1, confusion matrix.\n",
    "    \"\"\"\n",
    "    Z_source = np.asarray(Z_source, dtype=np.float32)\n",
    "    Z_target = np.asarray(Z_target, dtype=np.float32)\n",
    "    y_source = np.asarray(y_source, dtype=str)\n",
    "    y_target = np.asarray(y_target, dtype=str)\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=k, metric=metric)\n",
    "    nn.fit(Z_source)\n",
    "    nbrs = nn.kneighbors(Z_target, return_distance=False)\n",
    "\n",
    "    preds = []\n",
    "    for inds in nbrs:\n",
    "        votes = y_source[inds]\n",
    "        vals, cnts = np.unique(votes, return_counts=True)\n",
    "        preds.append(vals[np.argmax(cnts)])\n",
    "    preds = np.asarray(preds, dtype=str)\n",
    "\n",
    "    acc = float(accuracy_score(y_target, preds))\n",
    "    macro_f1 = float(f1_score(y_target, preds, average=\"macro\"))\n",
    "    classes = np.unique(np.concatenate([y_source, y_target]))\n",
    "    cm = confusion_matrix(y_target, preds, labels=classes)\n",
    "    return preds, acc, macro_f1, cm, classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9472652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from univi.evaluation import encode_adata\n",
    "\n",
    "Z_rna = encode_adata(model, rna_test_pp, modality=\"rna\",\n",
    "                     latent=\"modality_mean\", device=device, batch_size=1024)\n",
    "Z_adt = encode_adata(model, adt_test_pp, modality=\"adt\",\n",
    "                     latent=\"modality_mean\", device=device, batch_size=1024)\n",
    "\n",
    "key_rna = \"encode_adata(modality_mean)\"\n",
    "key_adt = \"encode_adata(modality_mean)\"\n",
    "\n",
    "rna_test_pp.obsm[\"X_univi_rna\"] = Z_rna\n",
    "adt_test_pp.obsm[\"X_univi_adt\"] = Z_adt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8072352",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max|Z_rna-Z_adt|:\", float(np.max(np.abs(Z_rna - Z_adt))))\n",
    "print(\"mean L2(Z_rna-Z_adt):\", float(np.mean(np.linalg.norm(Z_rna - Z_adt, axis=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PRE-FLIGHT CHECK + FIX (run once right before metrics/plots) ----------\n",
    "def _preflight_align_for_metrics(\n",
    "    rna_test_pp, adt_test_pp, Z_rna, Z_adt, celltype_key=\"celltype.l2\"\n",
    "):\n",
    "    import numpy as np\n",
    "\n",
    "    # 1) basic shape checks\n",
    "    print(\"rna_test_pp n_obs:\", rna_test_pp.n_obs)\n",
    "    print(\"adt_test_pp n_obs:\", adt_test_pp.n_obs)\n",
    "    print(\"Z_rna shape:\", np.asarray(Z_rna).shape)\n",
    "    print(\"Z_adt shape:\", np.asarray(Z_adt).shape)\n",
    "\n",
    "    # 2) enforce pairing by obs_names intersection (preserves RNA order)\n",
    "    common = rna_test_pp.obs_names.intersection(adt_test_pp.obs_names)\n",
    "    if len(common) != rna_test_pp.n_obs or len(common) != adt_test_pp.n_obs:\n",
    "        print(f\"[preflight] restricting to common paired cells: {len(common)}\")\n",
    "\n",
    "    rna_al = rna_test_pp[common].copy()\n",
    "    adt_al = adt_test_pp[common].copy()\n",
    "    adt_al = adt_al[rna_al.obs_names].copy()  # force identical order\n",
    "\n",
    "    # 3) slice Z arrays to match aligned AnnData order (assumes Z were computed in the same order)\n",
    "    # If your Z were computed from rna_test_pp/adt_test_pp directly, this is safe.\n",
    "    # If not, you *must* recompute Z after alignment.\n",
    "    if np.asarray(Z_rna).shape[0] != rna_al.n_obs or np.asarray(Z_adt).shape[0] != adt_al.n_obs:\n",
    "        raise ValueError(\n",
    "            \"[preflight] Z arrays do not match aligned AnnData n_obs. \"\n",
    "            \"Recompute Z_rna/Z_adt from rna_al/adt_al.\"\n",
    "        )\n",
    "\n",
    "    # 4) labels must come from the SAME objects you predict on\n",
    "    labels_rna = rna_al.obs[celltype_key].astype(str).to_numpy()\n",
    "    labels_adt = adt_al.obs[celltype_key].astype(str).to_numpy()\n",
    "\n",
    "    # 5) final asserts (this prevents your exact error)\n",
    "    assert rna_al.n_obs == adt_al.n_obs\n",
    "    assert (rna_al.obs_names == adt_al.obs_names).all()\n",
    "    assert len(labels_rna) == np.asarray(Z_rna).shape[0]\n",
    "    assert len(labels_adt) == np.asarray(Z_adt).shape[0]\n",
    "\n",
    "    print(\"[preflight] OK: paired, aligned, and lengths match.\")\n",
    "    return rna_al, adt_al, labels_rna, labels_adt\n",
    "\n",
    "\n",
    "# run it:\n",
    "rna_test_pp, adt_test_pp, labels_rna, labels_adt = _preflight_align_for_metrics(\n",
    "    rna_test_pp, adt_test_pp, Z_rna, Z_adt, celltype_key=celltype_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078dd5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Compute metrics (Figure 2)\n",
    "# ----------------------------\n",
    "\n",
    "# 0) Fused latent (if you truly want it)\n",
    "Z_fused = np.asarray(combo.obsm[\"X_univi\"])\n",
    "mods_fused = combo.obs[\"modality\"].to_numpy()\n",
    "\n",
    "# derive cell_ids that are identical for RNA+ADT copies\n",
    "# works with index_unique=\"-\" that produces \"<orig>-rna\" / \"<orig>-adt\"\n",
    "cell_ids = combo.obs_names.to_series().str.rsplit(\"-\", n=1).str[0].to_numpy()\n",
    "\n",
    "mix_fused = modality_mixing_score_excluding_pairs(Z_fused, mods_fused, cell_ids, k=k_mix)\n",
    "\n",
    "# 1) Modality-specific latents (Z_rna, Z_adt) already computed above\n",
    "\n",
    "# 2) FOSCTTM on modality-specific latents (subsample ok)\n",
    "n_total = int(rna_test_pp.n_obs)\n",
    "n_fos = int(min(20000, n_total))     # subsample size for FOSCTTM eval\n",
    "rng = np.random.default_rng(seed)\n",
    "sub = rng.choice(n_total, size=n_fos, replace=False)\n",
    "\n",
    "fos_rna_adt, fos_sem = foscttm_chunked(Z_rna[sub], Z_adt[sub], block=512)\n",
    "\n",
    "# 3) Modality mixing on modality-specific latents\n",
    "Z_concat = np.vstack([Z_rna, Z_adt])\n",
    "mods = np.array([\"rna\"] * Z_rna.shape[0] + [\"adt\"] * Z_adt.shape[0], dtype=object)\n",
    "mix_modality_specific = modality_mixing_score(Z_concat, mods, k=k_mix)\n",
    "\n",
    "# 4) Label transfer (modality-specific)\n",
    "# Make labels that match each embedding 1:1\n",
    "labels_rna = rna_test_pp.obs[celltype_key].astype(str).to_numpy()\n",
    "labels_adt = adt_test_pp.obs[celltype_key].astype(str).to_numpy()\n",
    "\n",
    "assert Z_rna.shape[0] == labels_rna.shape[0], (Z_rna.shape, labels_rna.shape)\n",
    "assert Z_adt.shape[0] == labels_adt.shape[0], (Z_adt.shape, labels_adt.shape)\n",
    "\n",
    "pred_adt, acc_r2a, f1_r2a, cm_r2a, classes = knn_label_transfer(\n",
    "    Z_source=Z_rna, y_source=labels_rna,\n",
    "    Z_target=Z_adt, y_target=labels_adt,\n",
    "    k=k_lt\n",
    ")\n",
    "pred_rna, acc_a2r, f1_a2r, cm_a2r, _ = knn_label_transfer(\n",
    "    Z_source=Z_adt, y_source=labels_adt,\n",
    "    Z_target=Z_rna, y_target=labels_rna,\n",
    "    k=k_lt\n",
    ")\n",
    "\n",
    "metrics = {\n",
    "    \"embedding_keys\": {\"rna\": key_rna, \"adt\": key_adt, \"fused\": \"combo.obsm['X_univi']\"},\n",
    "    \"n_test\": n_total,\n",
    "    \"celltype_key\": celltype_key,\n",
    "\n",
    "    \"FOSCTTM_metric\": \"euclidean_sq\",\n",
    "    \"FOSCTTM_subsample_n\": n_fos,\n",
    "    \"FOSCTTM_rna_vs_adt_mean\": float(fos_rna_adt),\n",
    "    \"FOSCTTM_rna_vs_adt_sem\": float(fos_sem),\n",
    "\n",
    "    \"modality_mixing_k\": int(k_mix),\n",
    "    \"modality_mixing_fused\": float(mix_fused),\n",
    "    \"modality_mixing_modality_specific\": float(mix_modality_specific),\n",
    "\n",
    "    \"label_transfer_k\": int(k_lt),\n",
    "    \"label_transfer_rna_to_adt_acc\": float(acc_r2a),\n",
    "    \"label_transfer_rna_to_adt_macroF1\": float(f1_r2a),\n",
    "    \"label_transfer_adt_to_rna_acc\": float(acc_a2r),\n",
    "    \"label_transfer_adt_to_rna_macroF1\": float(f1_a2r),\n",
    "}\n",
    "\n",
    "print(json.dumps(metrics, indent=2))\n",
    "with open(os.path.join(outdir, \"figure2_reproducibility_metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "pd.DataFrame([metrics]).to_csv(os.path.join(outdir, \"figure2_reproducibility_metrics.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5552024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# If plots ever don't show in classic notebook, run once:\n",
    "# %matplotlib inline\n",
    "\n",
    "# -------------------------\n",
    "# show-or-save helper\n",
    "# -------------------------\n",
    "def _finish(fig=None, outpath=None, dpi=200, show=True, close=True):\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath, dpi=dpi, bbox_inches=\"tight\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if close:\n",
    "        plt.close(fig if fig is not None else plt.gcf())\n",
    "\n",
    "# -------------------------\n",
    "# plots\n",
    "# -------------------------\n",
    "def plot_metrics_bar(\n",
    "    metrics,\n",
    "    keys,\n",
    "    title=\"Figure 2 reproducibility summary metrics\",\n",
    "    outpath=None,\n",
    "    err_keys=None,          # dict: metric_key -> error_metric_key\n",
    "    default_err=np.nan,     # np.nan = no error bar drawn; 0.0 = zero-length\n",
    "    capsize=4,\n",
    "):\n",
    "    vals = np.array([float(metrics[k]) for k in keys], dtype=float)\n",
    "\n",
    "    if err_keys is None:\n",
    "        yerr = np.full_like(vals, default_err, dtype=float)\n",
    "    else:\n",
    "        yerr = np.array(\n",
    "            [float(metrics[err_keys[k]]) if k in err_keys and err_keys[k] in metrics else default_err\n",
    "             for k in keys],\n",
    "            dtype=float\n",
    "        )\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.bar(keys, vals, yerr=yerr, capsize=capsize)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # inline “finish” behavior\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_confusion(cm, classes, title, normalize=\"true\", outpath=None, cmap=\"viridis\"):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    cm = np.asarray(cm, dtype=float)\n",
    "    if normalize == \"true\":\n",
    "        cm = cm / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
    "        subtitle = \"Row-normalized\"\n",
    "    elif normalize == \"pred\":\n",
    "        cm = cm / (cm.sum(axis=0, keepdims=True) + 1e-12)\n",
    "        subtitle = \"Col-normalized\"\n",
    "    elif normalize == \"all\":\n",
    "        cm = cm / (cm.sum() + 1e-12)\n",
    "        subtitle = \"Global-normalized\"\n",
    "    else:\n",
    "        subtitle = \"Counts\"\n",
    "\n",
    "    classes = np.asarray(classes, dtype=str)\n",
    "    n = len(classes)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\", cmap=cmap, aspect=\"auto\")\n",
    "\n",
    "    # kill any gridlines (including ones from styles)\n",
    "    ax.grid(False)\n",
    "    ax.minorticks_off()\n",
    "\n",
    "    ax.set_title(f\"{title}\\n({subtitle})\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "\n",
    "    ax.set_xticks(np.arange(n))\n",
    "    ax.set_yticks(np.arange(n))\n",
    "    ax.set_xticklabels(classes, rotation=90)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label(\"value\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if outpath is not None:\n",
    "        fig.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_per_class_f1(y_true, y_pred, title=\"Per-class F1\", outpath=None, top_n=None):\n",
    "    y_true = np.asarray(y_true).astype(str)\n",
    "    y_pred = np.asarray(y_pred).astype(str)\n",
    "    classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "\n",
    "    _, _, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=classes, zero_division=0\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame({\"class\": classes, \"f1\": f1, \"support\": support})\n",
    "    df = df.sort_values([\"f1\", \"support\"], ascending=[True, False])\n",
    "\n",
    "    if top_n is not None:\n",
    "        df = df.head(int(top_n))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 0.35 * len(df) + 2.0))\n",
    "    plt.barh(df[\"class\"], df[\"f1\"])\n",
    "    plt.xlabel(\"F1\")\n",
    "    plt.title(title)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n",
    "    return df\n",
    "\n",
    "def plot_modality_mixing_hist(Z, mods, k=20, metric=\"euclidean\", title=\"Modality mixing\", outpath=None):\n",
    "    Z = np.asarray(Z, dtype=np.float32)\n",
    "    mods = np.asarray(mods)\n",
    "\n",
    "    n = Z.shape[0]\n",
    "    k_eff = int(min(max(int(k), 1), n - 1))\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff + 1, metric=metric)\n",
    "    nn.fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]\n",
    "    frac_other = (mods[nbrs] != mods[:, None]).mean(axis=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(7, 4.5))\n",
    "    plt.hist(frac_other, bins=60)\n",
    "    plt.xlabel(\"Fraction of kNN from other modality\")\n",
    "    plt.ylabel(\"# cells\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n",
    "    return frac_other\n",
    "\n",
    "def plot_foscttm_sanity(Z1, Z2, idx, title=\"FOSCTTM sanity\", outpath=None):\n",
    "    Z1s = np.asarray(Z1[idx], dtype=np.float32)\n",
    "    Z2s = np.asarray(Z2[idx], dtype=np.float32)\n",
    "\n",
    "    d_true = np.sum((Z1s - Z2s) ** 2, axis=1)\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=51, metric=\"euclidean\")\n",
    "    nn.fit(np.asarray(Z2, dtype=np.float32))\n",
    "    dist, _ = nn.kneighbors(Z1s)\n",
    "    d_min = dist[:, 0] ** 2\n",
    "\n",
    "    fig = plt.figure(figsize=(5.5, 5.5))\n",
    "    plt.scatter(d_true, d_min, s=8, alpha=0.4)\n",
    "    mx = np.percentile(np.concatenate([d_true, d_min]), 99)\n",
    "    plt.plot([0, mx], [0, mx], linewidth=1)\n",
    "    plt.xlim(0, mx); plt.ylim(0, mx)\n",
    "    plt.xlabel(\"d(true match)^2\")\n",
    "    plt.ylabel(\"d(nearest neighbor)^2\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n",
    "\n",
    "def plot_paired_distance_hist(Z_rna, Z_adt, idx, title=\"Paired latent distance (subset)\", outpath=None):\n",
    "    d_pair = np.sqrt(np.sum((Z_rna[idx] - Z_adt[idx]) ** 2, axis=1))\n",
    "    fig = plt.figure(figsize=(7, 4.5))\n",
    "    plt.hist(d_pair, bins=80)\n",
    "    plt.xlabel(\"||z_rna - z_adt||\")\n",
    "    plt.ylabel(\"# cells\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Summary metric bar\n",
    "plot_metrics_bar(\n",
    "    metrics,\n",
    "    keys=[\n",
    "        \"FOSCTTM_rna_vs_adt_mean\",\n",
    "        \"modality_mixing_fused\",\n",
    "        \"modality_mixing_modality_specific\",\n",
    "        \"label_transfer_rna_to_adt_acc\",\n",
    "        \"label_transfer_rna_to_adt_macroF1\",\n",
    "    ],\n",
    "    err_keys={\n",
    "        #\"FOSCTTM_rna_vs_adt_mean\": \"FOSCTTM_rna_vs_adt_sem\",\n",
    "        # add more here if you compute SEM/CI for them later\n",
    "    },\n",
    "    default_err=np.nan,   # no error bars for the others\n",
    "    outpath=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ef494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Confusion matrices (row-normalized)\n",
    "plot_confusion(cm_r2a, classes, title=f\"Label transfer (RNA → ADT), k={k_lt}\", normalize=\"true\", outpath=None)\n",
    "plot_confusion(cm_a2r, classes, title=f\"Label transfer (ADT → RNA), k={k_lt}\", normalize=\"true\", outpath=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b69c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Per-class F1\n",
    "_ = plot_per_class_f1(labels_adt, pred_adt, title=\"RNA → ADT: per-class F1\", top_n=100, outpath=None)\n",
    "_ = plot_per_class_f1(labels_rna, pred_rna, title=\"ADT → RNA: per-class F1\", top_n=100, outpath=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89cb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Modality-mixing distributions\n",
    "_ = plot_modality_mixing_hist(Z_fused, mods_fused, k=k_mix, title=f\"Mixing (fused latent), k={k_mix}\", outpath=None)\n",
    "\n",
    "Z_concat = np.vstack([Z_rna, Z_adt])\n",
    "mods_concat = np.array([\"rna\"] * Z_rna.shape[0] + [\"adt\"] * Z_adt.shape[0], dtype=object)\n",
    "_ = plot_modality_mixing_hist(Z_concat, mods_concat, k=k_mix, title=f\"Mixing (modality-specific latents), k={k_mix}\", outpath=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c795a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) FOSCTTM sanity + paired distance hist\n",
    "sub_sanity = np.asarray(sub)[:min(5000, len(sub))]\n",
    "plot_foscttm_sanity(Z_rna, Z_adt, sub_sanity, outpath=None)\n",
    "\n",
    "sub_dist = np.asarray(sub)[:min(50000, len(sub))]\n",
    "plot_paired_distance_hist(Z_rna, Z_adt, sub_dist, outpath=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a825b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) UMAPs (Scanpy already shows inline)\n",
    "# (these are heavy at 294k cells; feel free to set size=1.5)\n",
    "#sc.pl.umap(combo, color=[\"modality\"], frameon=False, size=2.0)\n",
    "#sc.pl.umap(combo, color=[celltype_key], frameon=False, size=2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a8a3e",
   "metadata": {},
   "source": [
    "#### Interactive 3-D UMAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584392b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_umap3d_interactive(\n",
    "    combo,\n",
    "    umap_key=\"X_umap_3d\",         # <- default for your CITE-seq object\n",
    "    color_by=\"celltype.l2\",\n",
    "    symbol_by=\"modality\",\n",
    "    hover_cols=(\"cell_id\", \"modality\"),\n",
    "\n",
    "    point_size=3,\n",
    "    opacity=0.85,\n",
    "\n",
    "    # paired lines between modalities (optional)\n",
    "    draw_pair_lines=True,         # <- default False for typical CITE-seq (often not stacked)\n",
    "    id_key=\"cell_id\",             # will auto-create from obs_names if missing\n",
    "    modality_key=\"modality\",\n",
    "    mod_a=None,                   # if None, infer from available modalities\n",
    "    mod_b=None,\n",
    "    line_sample=None,             # None = all\n",
    "    random_state=0,\n",
    "    line_width=2.5,\n",
    "    line_opacity=0.35,\n",
    "    line_color=\"rgba(0,0,0,0.25)\",\n",
    "\n",
    "    width=900,\n",
    "    height=700,\n",
    "):\n",
    "    # --- embedding checks ---\n",
    "    assert umap_key in combo.obsm, f\"combo.obsm['{umap_key}'] missing.\"\n",
    "    assert combo.obsm[umap_key].shape[1] == 3, f\"combo.obsm['{umap_key}'] must be 3D.\"\n",
    "\n",
    "    coords = combo.obsm[umap_key]\n",
    "    df = combo.obs.copy()\n",
    "\n",
    "    # --- ensure an ID column exists (use obs_names if not) ---\n",
    "    if id_key not in df.columns:\n",
    "        df[id_key] = combo.obs_names.astype(str)\n",
    "\n",
    "    # coords\n",
    "    df = df.assign(u1=coords[:, 0], u2=coords[:, 1], u3=coords[:, 2])\n",
    "\n",
    "    # --- validations ---\n",
    "    if color_by is not None and color_by not in df.columns:\n",
    "        raise KeyError(f\"color_by='{color_by}' not found in combo.obs.\")\n",
    "    if symbol_by is not None and symbol_by not in df.columns:\n",
    "        raise KeyError(f\"symbol_by='{symbol_by}' not found in combo.obs.\")\n",
    "    if draw_pair_lines and modality_key not in df.columns:\n",
    "        raise KeyError(f\"Need '{modality_key}' in combo.obs to draw pair lines.\")\n",
    "\n",
    "    hover_data = {c: True for c in hover_cols if c in df.columns}\n",
    "    if color_by is not None:\n",
    "        hover_data[color_by] = True\n",
    "\n",
    "    fig = px.scatter_3d(\n",
    "        df,\n",
    "        x=\"u1\", y=\"u2\", z=\"u3\",\n",
    "        color=color_by if color_by is not None else None,\n",
    "        symbol=symbol_by if symbol_by is not None else None,\n",
    "        hover_data=hover_data,\n",
    "        opacity=opacity,\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=point_size))\n",
    "\n",
    "    # --- paired lines (only works if you have stacked modalities: same cell_id appears multiple times) ---\n",
    "    if draw_pair_lines:\n",
    "        vc = df[id_key].value_counts()\n",
    "        has_pairs = (vc >= 2).any()\n",
    "        if not has_pairs:\n",
    "            # Nothing to connect; skip gracefully\n",
    "            draw_pair_lines = False\n",
    "        else:\n",
    "            d2 = df[[id_key, modality_key, \"u1\", \"u2\", \"u3\"]].copy()\n",
    "\n",
    "            # infer modalities to link if not provided\n",
    "            mods = list(pd.unique(d2[modality_key].astype(str)))\n",
    "            if mod_a is None or mod_b is None:\n",
    "                if len(mods) < 2:\n",
    "                    raise ValueError(f\"Not enough modalities in '{modality_key}' to link: {mods}\")\n",
    "                mod_a, mod_b = mods[0], mods[1]\n",
    "\n",
    "            wide = d2.pivot(index=id_key, columns=modality_key, values=[\"u1\", \"u2\", \"u3\"])\n",
    "            needed = [((\"u1\", mod_a), (\"u1\", mod_b)),\n",
    "                      ((\"u2\", mod_a), (\"u2\", mod_b)),\n",
    "                      ((\"u3\", mod_a), (\"u3\", mod_b))]\n",
    "            if not all(a in wide.columns and b in wide.columns for a, b in needed):\n",
    "                raise KeyError(\n",
    "                    f\"Could not find both modalities '{mod_a}' and '{mod_b}' for paired links. \"\n",
    "                    f\"Available modalities: {mods}\"\n",
    "                )\n",
    "\n",
    "            wide = wide.dropna(subset=[(c, m) for c in (\"u1\", \"u2\", \"u3\") for m in (mod_a, mod_b)], how=\"any\")\n",
    "\n",
    "            if line_sample is not None and wide.shape[0] > line_sample:\n",
    "                wide = wide.sample(n=line_sample, random_state=random_state)\n",
    "\n",
    "            x = np.empty(wide.shape[0] * 3)\n",
    "            y = np.empty(wide.shape[0] * 3)\n",
    "            z = np.empty(wide.shape[0] * 3)\n",
    "\n",
    "            x[0::3] = wide[(\"u1\", mod_a)].to_numpy()\n",
    "            y[0::3] = wide[(\"u2\", mod_a)].to_numpy()\n",
    "            z[0::3] = wide[(\"u3\", mod_a)].to_numpy()\n",
    "\n",
    "            x[1::3] = wide[(\"u1\", mod_b)].to_numpy()\n",
    "            y[1::3] = wide[(\"u2\", mod_b)].to_numpy()\n",
    "            z[1::3] = wide[(\"u3\", mod_b)].to_numpy()\n",
    "\n",
    "            x[2::3] = np.nan\n",
    "            y[2::3] = np.nan\n",
    "            z[2::3] = np.nan\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=x, y=y, z=z,\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(width=line_width, color=line_color),\n",
    "                    opacity=line_opacity,\n",
    "                    hoverinfo=\"skip\",\n",
    "                    showlegend=False,\n",
    "                    name=f\"paired links ({mod_a}↔{mod_b})\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=width,\n",
    "        height=height,\n",
    "        margin=dict(l=10, r=10, t=40, b=10),\n",
    "        scene=dict(xaxis_title=\"UMAP1\", yaxis_title=\"UMAP2\", zaxis_title=\"UMAP3\"),\n",
    "        title=f\"Interactive 3D UMAP (key={umap_key}, color={color_by}, symbol={symbol_by})\",\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6270330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scanpy writes to combo.obsm[\"X_umap\"] (now 3D). If you want to preserve 2D:\n",
    "# Compute 2D first (done), copy it\n",
    "combo.obsm[\"X_umap_2d\"] = combo.obsm[\"X_umap\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then compute 3D UMAP - might take a bit since we're using, like, 150k cells for the test set for the figures\n",
    "sc.tl.umap(combo, n_components=3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccc3053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then add 2d back to .obsm['X_umap'] and 3d to .obsm['X_umap_3d']\n",
    "combo.obsm[\"X_umap_3d\"] = combo.obsm[\"X_umap\"].copy()\n",
    "combo.obsm[\"X_umap\"] = combo.obsm[\"X_umap_2d\"]  # restore default 2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4fcfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "#pio.renderers.default\n",
    "\n",
    "# Classic Jupyter Notebook:\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "# JupyterLab:\n",
    "#pio.renderers.default = \"jupyterlab\"\n",
    "\n",
    "# VS Code notebooks:\n",
    "#pio.renderers.default = \"vscode\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you’ve created your 3D UMAP via function and added it to combo:\n",
    "threedee_umap_fig = plot_umap3d_interactive(\n",
    "    combo,\n",
    "    color_by=label_key,\n",
    "    symbol_by=\"modality\",\n",
    "    draw_pair_lines=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threedee_umap_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51637855",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f198706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb3ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac772588",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049154db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c90778",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb969c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5605479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38092ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3546cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (UniVI v0.2.3)",
   "language": "python",
   "name": "univi_v0.2.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
