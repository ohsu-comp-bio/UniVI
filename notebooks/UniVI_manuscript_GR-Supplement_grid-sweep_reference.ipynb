{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0833a536-cdda-49eb-bb95-12e428ef6b47",
   "metadata": {},
   "source": [
    "# UniVI – Model parameter grid sweep supplemental figure analysis (robust v1, no leakage)\n",
    "\n",
    "This notebook builds the UniVI hyperameter grid sweep supplemental figures  **without train–test leakage** and with **loss_mode='v1'**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c37e35-c1fb-430f-b238-9e86878a993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 0) Imports / versions / globals ----\n",
    "# =============================================================================\n",
    "import os, gc, time, math, copy, inspect\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, Iterable, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    silhouette_score,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "# UniVI\n",
    "import univi as uv\n",
    "from univi import UniVIMultiModalVAE, ModalityConfig, UniVIConfig, TrainingConfig\n",
    "from univi.trainer import UniVITrainer\n",
    "from univi.data import MultiModalDataset, align_paired_obs_names\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"scanpy:\", sc.__version__)\n",
    "print(\"univi:\", uv.__version__)\n",
    "\n",
    "GLOBAL_SEED = 0\n",
    "\n",
    "def seed_all(seed: int):\n",
    "    seed = int(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_all(GLOBAL_SEED)\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "print(\"device:\", device)\n",
    "\n",
    "DTYPE = np.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5dd9b9-0878-4051-8cda-a7b5047419f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 1) Load data (paths match your Figure 8 notebook) ----\n",
    "# =============================================================================\n",
    "RNA_PATH  = \"./data/10x_Genomics_Multiome_data/10x-Multiome-Pbmc10k-RNA.h5ad\"\n",
    "ATAC_PATH = \"./data/10x_Genomics_Multiome_data/10x-Multiome-Pbmc10k-ATAC.h5ad\"\n",
    "\n",
    "rna_raw  = sc.read_h5ad(RNA_PATH)\n",
    "atac_raw = sc.read_h5ad(ATAC_PATH)\n",
    "\n",
    "def ensure_counts_layer(a: ad.AnnData, layer: str = \"counts\"):\n",
    "    if layer not in a.layers:\n",
    "        a.layers[layer] = a.X.copy()\n",
    "    return a\n",
    "\n",
    "rna_raw  = ensure_counts_layer(rna_raw, \"counts\")\n",
    "atac_raw = ensure_counts_layer(atac_raw, \"counts\")\n",
    "\n",
    "print(\"RNA:\", rna_raw)\n",
    "print(\"ATAC:\", atac_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac32fb6-1df5-4186-a9dd-0cc181ed71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 2) Align paired obs_names ----\n",
    "# =============================================================================\n",
    "adata_dict_raw = {\"rna\": rna_raw, \"atac\": atac_raw}\n",
    "adata_dict_raw = align_paired_obs_names(adata_dict_raw)\n",
    "\n",
    "rna_raw  = adata_dict_raw[\"rna\"]\n",
    "atac_raw = adata_dict_raw[\"atac\"]\n",
    "\n",
    "if not (rna_raw.obs_names == atac_raw.obs_names).all():\n",
    "    raise RuntimeError(\"obs_names mismatch after align_paired_obs_names()\")\n",
    "print(\"Aligned n_obs:\", rna_raw.n_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585828f-94e3-49f7-855f-de24f14b549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 3) Train/val/test split ----\n",
    "# =============================================================================\n",
    "N = int(rna_raw.n_obs)\n",
    "rng = np.random.default_rng(GLOBAL_SEED)\n",
    "perm = rng.permutation(N)\n",
    "\n",
    "frac_train = 0.75\n",
    "frac_val   = 0.10\n",
    "\n",
    "n_tr = int(round(frac_train * N))\n",
    "n_va = int(round(frac_val   * N))\n",
    "n_te = int(N - n_tr - n_va)\n",
    "\n",
    "idx_tr = perm[:n_tr]\n",
    "idx_va = perm[n_tr:n_tr + n_va]\n",
    "idx_te = perm[n_tr + n_va:]\n",
    "\n",
    "rna_tr  = rna_raw[idx_tr].copy()\n",
    "rna_va  = rna_raw[idx_va].copy()\n",
    "rna_te  = rna_raw[idx_te].copy()\n",
    "\n",
    "atac_tr = atac_raw[idx_tr].copy()\n",
    "atac_va = atac_raw[idx_va].copy()\n",
    "atac_te = atac_raw[idx_te].copy()\n",
    "\n",
    "print(\"Splits:\", rna_tr.n_obs, rna_va.n_obs, rna_te.n_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea098dcb-58b0-42d6-982c-4ba7a87d253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 4) RNA preprocessing (fit on train, apply to val/test) ----\n",
    "# =============================================================================\n",
    "def _get_layer_X(a: ad.AnnData, layer: str) -> Any:\n",
    "    if layer not in a.layers:\n",
    "        raise KeyError(f\"Layer '{layer}' not found. Available layers: {list(a.layers.keys())}\")\n",
    "    X = a.layers[layer]\n",
    "    return X.tocsr() if sp.issparse(X) else X\n",
    "\n",
    "def _normalize_log1p_dense_inplace(a: ad.AnnData, *, target_sum: float, out_dtype=DTYPE):\n",
    "    sc.pp.normalize_total(a, target_sum=float(target_sum))\n",
    "    sc.pp.log1p(a)\n",
    "    if sp.issparse(a.X):\n",
    "        a.X = a.X.toarray()\n",
    "    a.X = np.asarray(a.X, dtype=out_dtype)\n",
    "\n",
    "def _apply_zscore_clip_inplace(a: ad.AnnData, mean: np.ndarray, std: np.ndarray, *, clip: float = 10.0):\n",
    "    X = np.asarray(a.X, dtype=DTYPE)\n",
    "    X = (X - mean) / std\n",
    "    if clip is not None:\n",
    "        X = np.clip(X, -float(clip), float(clip))\n",
    "    a.X = X\n",
    "\n",
    "def preprocess_rna_train(\n",
    "    adata: ad.AnnData,\n",
    "    *,\n",
    "    counts_layer: str = \"counts\",\n",
    "    n_hvg: int = 2000,\n",
    "    target_sum: float = 1e4,\n",
    "    flavor: str = \"seurat_v3\",\n",
    "    out_dtype=DTYPE,\n",
    ") -> Tuple[ad.AnnData, list, np.ndarray, np.ndarray]:\n",
    "    a = adata.copy()\n",
    "    a.X = _get_layer_X(a, counts_layer)\n",
    "\n",
    "    sc.pp.highly_variable_genes(a, n_top_genes=int(n_hvg), flavor=str(flavor))\n",
    "    hvg = a.var_names[a.var[\"highly_variable\"]].tolist()\n",
    "    if len(hvg) == 0:\n",
    "        raise RuntimeError(\"No HVGs selected. Check your RNA AnnData .X/.layers['counts'].\")\n",
    "\n",
    "    a = a[:, hvg].copy()\n",
    "    _normalize_log1p_dense_inplace(a, target_sum=target_sum, out_dtype=out_dtype)\n",
    "\n",
    "    mean = a.X.mean(axis=0).astype(out_dtype, copy=False)\n",
    "    std  = a.X.std(axis=0, ddof=0).astype(out_dtype, copy=False)\n",
    "    std  = np.where(std == 0, 1.0, std).astype(out_dtype, copy=False)\n",
    "\n",
    "    _apply_zscore_clip_inplace(a, mean, std, clip=10.0)\n",
    "    return a, hvg, mean, std\n",
    "\n",
    "def preprocess_rna_apply(\n",
    "    adata: ad.AnnData,\n",
    "    hvg: list,\n",
    "    mean: np.ndarray,\n",
    "    std: np.ndarray,\n",
    "    *,\n",
    "    counts_layer: str = \"counts\",\n",
    "    target_sum: float = 1e4,\n",
    "    out_dtype=DTYPE,\n",
    ") -> ad.AnnData:\n",
    "    a = adata.copy()\n",
    "    a.X = _get_layer_X(a, counts_layer)\n",
    "\n",
    "    # align genes to training HVG order; fill missing with zeros\n",
    "    hvg = list(hvg)\n",
    "    present = [g for g in hvg if g in a.var_names]\n",
    "    a_sub = a[:, present].copy()\n",
    "\n",
    "    _normalize_log1p_dense_inplace(a_sub, target_sum=target_sum, out_dtype=out_dtype)\n",
    "\n",
    "    X_full = np.zeros((a_sub.n_obs, len(hvg)), dtype=out_dtype)\n",
    "    col_map = {g: j for j, g in enumerate(a_sub.var_names.tolist())}\n",
    "    for j, g in enumerate(hvg):\n",
    "        jj = col_map.get(g, None)\n",
    "        if jj is not None:\n",
    "            X_full[:, j] = a_sub.X[:, jj]\n",
    "\n",
    "    out = ad.AnnData(X=X_full, obs=a_sub.obs.copy())\n",
    "    out.obs_names = a_sub.obs_names.copy()\n",
    "    out.var_names = np.array(hvg, dtype=str)\n",
    "\n",
    "    _apply_zscore_clip_inplace(out, mean, std, clip=10.0)\n",
    "    out.X = np.asarray(out.X, dtype=out_dtype)\n",
    "    return out\n",
    "\n",
    "# ---- run ----\n",
    "rna_tr_pp, hvg, rna_mean, rna_std = preprocess_rna_train(rna_tr, n_hvg=2000, target_sum=1e4)\n",
    "rna_va_pp = preprocess_rna_apply(rna_va, hvg, rna_mean, rna_std, target_sum=1e4)\n",
    "rna_te_pp = preprocess_rna_apply(rna_te, hvg, rna_mean, rna_std, target_sum=1e4)\n",
    "\n",
    "print(\"RNA dims:\", rna_tr_pp.shape, \"|\", rna_va_pp.shape, \"|\", rna_te_pp.shape)\n",
    "assert list(rna_va_pp.var_names) == list(hvg)\n",
    "assert list(rna_te_pp.var_names) == list(hvg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75439a91-ffe8-4f2f-8e3b-3ee5701e351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 5) ATAC preprocessing (TF-IDF + LSI) ----\n",
    "# =============================================================================\n",
    "def _get_counts_csr(a: ad.AnnData, counts_layer: str = \"counts\") -> sp.csr_matrix:\n",
    "    X = _get_layer_X(a, counts_layer)\n",
    "    return X.tocsr() if sp.issparse(X) else sp.csr_matrix(X)\n",
    "\n",
    "def preprocess_atac_lsi_train(\n",
    "    adata: ad.AnnData,\n",
    "    *,\n",
    "    counts_layer: str = \"counts\",\n",
    "    n_lsi: int = 101,\n",
    "    drop_first: bool = True,\n",
    "    binarize: bool = False,\n",
    "    seed: int = 0,\n",
    "    out_dtype=DTYPE,\n",
    "):\n",
    "    a = adata.copy()\n",
    "    X = _get_counts_csr(a, counts_layer)\n",
    "\n",
    "    if binarize:\n",
    "        X = X.copy()\n",
    "        X.data[:] = 1.0\n",
    "\n",
    "    tfidf = TfidfTransformer(norm=\"l2\", use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "    X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "    svd = TruncatedSVD(n_components=int(n_lsi), random_state=int(seed))\n",
    "    X_lsi = svd.fit_transform(X_tfidf)\n",
    "\n",
    "    if drop_first:\n",
    "        if X_lsi.shape[1] < 2:\n",
    "            raise RuntimeError(f\"Cannot drop_first with n_lsi={n_lsi} (need >=2).\")\n",
    "        X_lsi = X_lsi[:, 1:]\n",
    "\n",
    "    X_lsi = normalize(X_lsi, norm=\"l2\")\n",
    "    X_lsi = np.asarray(X_lsi, dtype=out_dtype)\n",
    "\n",
    "    out = ad.AnnData(X=X_lsi, obs=a.obs.copy())\n",
    "    out.obs_names = a.obs_names.copy()\n",
    "    return out, tfidf, svd\n",
    "\n",
    "def preprocess_atac_lsi_apply(\n",
    "    adata: ad.AnnData,\n",
    "    tfidf: TfidfTransformer,\n",
    "    svd: TruncatedSVD,\n",
    "    *,\n",
    "    counts_layer: str = \"counts\",\n",
    "    drop_first: bool = True,\n",
    "    binarize: bool = False,\n",
    "    out_dtype=DTYPE,\n",
    ") -> ad.AnnData:\n",
    "    a = adata.copy()\n",
    "    X = _get_counts_csr(a, counts_layer)\n",
    "\n",
    "    if binarize:\n",
    "        X = X.copy()\n",
    "        X.data[:] = 1.0\n",
    "\n",
    "    X_tfidf = tfidf.transform(X)\n",
    "    X_lsi = svd.transform(X_tfidf)\n",
    "\n",
    "    if drop_first:\n",
    "        X_lsi = X_lsi[:, 1:]\n",
    "\n",
    "    X_lsi = normalize(X_lsi, norm=\"l2\")\n",
    "    X_lsi = np.asarray(X_lsi, dtype=out_dtype)\n",
    "\n",
    "    out = ad.AnnData(X=X_lsi, obs=a.obs.copy())\n",
    "    out.obs_names = a.obs_names.copy()\n",
    "    return out\n",
    "\n",
    "# ---- run ----\n",
    "atac_tr_lsi, tfidf_atac, svd_atac = preprocess_atac_lsi_train(\n",
    "    atac_tr, n_lsi=101, drop_first=True, seed=GLOBAL_SEED\n",
    ")\n",
    "atac_va_lsi = preprocess_atac_lsi_apply(atac_va, tfidf_atac, svd_atac, drop_first=True)\n",
    "atac_te_lsi = preprocess_atac_lsi_apply(atac_te, tfidf_atac, svd_atac, drop_first=True)\n",
    "\n",
    "print(\"ATAC dims:\", atac_tr_lsi.shape, \"|\", atac_va_lsi.shape, \"|\", atac_te_lsi.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e6dc85-b185-4d76-bdb2-d84492ee1e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 6) Build MultiModalDataset ----\n",
    "# =============================================================================\n",
    "def _concat_three(a1: ad.AnnData, a2: ad.AnnData, a3: ad.AnnData) -> ad.AnnData:\n",
    "    # Use scanpy concat to avoid deprecated AnnData.concatenate behavior differences\n",
    "    return sc.concat([a1, a2, a3], axis=0, join=\"outer\", merge=\"same\", label=None, index_unique=None)\n",
    "\n",
    "adata_dict = {\n",
    "    \"rna\":  _concat_three(rna_tr_pp, rna_va_pp, rna_te_pp),\n",
    "    \"atac\": _concat_three(atac_tr_lsi, atac_va_lsi, atac_te_lsi),\n",
    "}\n",
    "adata_dict = align_paired_obs_names(adata_dict)\n",
    "\n",
    "dataset = MultiModalDataset(adata_dict=adata_dict, X_key=\"X\", device=None)\n",
    "\n",
    "n_tr = int(rna_tr_pp.n_obs)\n",
    "n_va = int(rna_va_pp.n_obs)\n",
    "n_te = int(rna_te_pp.n_obs)\n",
    "\n",
    "train_idx = np.arange(0, n_tr, dtype=np.int64)\n",
    "val_idx   = np.arange(n_tr, n_tr + n_va, dtype=np.int64)\n",
    "test_idx  = np.arange(n_tr + n_va, n_tr + n_va + n_te, dtype=np.int64)\n",
    "\n",
    "label_key = \"cell_type\"  # adjust if needed\n",
    "if label_key not in adata_dict[\"rna\"].obs.columns:\n",
    "    print(\"Available RNA obs columns:\", list(adata_dict[\"rna\"].obs.columns)[:50])\n",
    "    raise KeyError(f\"label_key='{label_key}' not found in RNA obs\")\n",
    "\n",
    "y_all = adata_dict[\"rna\"].obs[label_key].astype(str).to_numpy()\n",
    "\n",
    "print(\"dataset n:\", len(dataset), \"train/val/test:\", n_tr, n_va, n_te)\n",
    "print(pd.Series(y_all).value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275ec1ca-cf12-4541-a216-f84d20d5d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 7) Overlap loaders with homogeneous batches ----\n",
    "# =============================================================================\n",
    "class IndexedDataset(Dataset):\n",
    "    \"\"\"Wrap base_dataset + a list of global indices, returning (x_dict, global_id).\"\"\"\n",
    "    def __init__(self, base_dataset: Dataset, indices: np.ndarray):\n",
    "        self.base = base_dataset\n",
    "        self.indices = np.asarray(indices, dtype=np.int64)\n",
    "        if self.indices.ndim != 1:\n",
    "            raise ValueError(\"indices must be 1D\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(self.indices.shape[0])\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        gi = int(self.indices[int(i)])\n",
    "        item = self.base[gi]\n",
    "        if isinstance(item, dict):\n",
    "            x = item\n",
    "        elif isinstance(item, (tuple, list)) and len(item) >= 1 and isinstance(item[0], dict):\n",
    "            x = item[0]\n",
    "        else:\n",
    "            raise TypeError(f\"Expected base_dataset to yield dict or (dict,...); got {type(item)}\")\n",
    "        return dict(x), gi\n",
    "\n",
    "class DeterministicMaskDataset(Dataset):\n",
    "    \"\"\"\n",
    "    groups==0: paired (keep both)\n",
    "    groups!=0: unpaired (DROP drop_modality key)\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ds: Dataset, groups: np.ndarray, *, drop_modality: str):\n",
    "        self.base = base_ds\n",
    "        self.groups = np.asarray(groups, dtype=np.int64)\n",
    "        self.drop_modality = str(drop_modality)\n",
    "        if len(self.base) != len(self.groups):\n",
    "            raise ValueError(f\"len(base)={len(self.base)} != len(groups)={len(self.groups)}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        x, gid = self.base[i]\n",
    "        g = int(self.groups[int(i)])\n",
    "        x = dict(x)\n",
    "        if g != 0:\n",
    "            x.pop(self.drop_modality, None)\n",
    "        return x, gid\n",
    "\n",
    "def collate_xdict_with_idx(batch):\n",
    "    if len(batch) == 0:\n",
    "        raise ValueError(\"Empty batch\")\n",
    "    gids = torch.as_tensor([b[1] for b in batch], dtype=torch.long)\n",
    "\n",
    "    keys0 = set(batch[0][0].keys())\n",
    "    for x, _ in batch[1:]:\n",
    "        if set(x.keys()) != keys0:\n",
    "            raise RuntimeError(\n",
    "                \"Non-homogeneous batch (mixed modality keys inside batch). \"\n",
    "                \"Fix grouping/sampler.\"\n",
    "            )\n",
    "\n",
    "    out = {}\n",
    "    for k in keys0:\n",
    "        out[k] = torch.stack([x[k] for x, _ in batch], dim=0)\n",
    "    return out, gids\n",
    "\n",
    "class InterleavedGroupedBatchSampler(Sampler):\n",
    "    \"\"\"Yield homogeneous batches: all paired (group==0) or all unpaired (group!=0).\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        groups: np.ndarray,\n",
    "        batch_size: int,\n",
    "        *,\n",
    "        seed: int = 0,\n",
    "        unpaired_per_paired: float = 1.0,\n",
    "        oversample_paired: bool = True,\n",
    "        oversample_unpaired: bool = True,\n",
    "    ):\n",
    "        self.groups = np.asarray(groups, dtype=np.int64)\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.seed = int(seed)\n",
    "\n",
    "        upp = float(unpaired_per_paired)\n",
    "        if not np.isfinite(upp) or upp < 0:\n",
    "            raise ValueError(f\"unpaired_per_paired must be finite and >=0, got {upp}\")\n",
    "        self.unpaired_per_paired = upp\n",
    "\n",
    "        self.oversample_paired = bool(oversample_paired)\n",
    "        self.oversample_unpaired = bool(oversample_unpaired)\n",
    "\n",
    "        self.paired_idx = np.where(self.groups == 0)[0].astype(np.int64)\n",
    "        self.unpaired_idx = np.where(self.groups != 0)[0].astype(np.int64)\n",
    "        if len(self.paired_idx) == 0:\n",
    "            raise ValueError(\"No paired samples (group==0). Need at least one anchor.\")\n",
    "\n",
    "        self.only_paired = (len(self.unpaired_idx) == 0)\n",
    "\n",
    "        # Paired-driven epoch length (in batches)\n",
    "        if len(self.paired_idx) >= self.batch_size:\n",
    "            self.n_paired_batches = len(self.paired_idx) // self.batch_size\n",
    "        else:\n",
    "            self.n_paired_batches = 1 if self.oversample_paired else 0\n",
    "\n",
    "        self.n_unpaired_expected = 0 if self.only_paired else int(round(self.n_paired_batches * self.unpaired_per_paired))\n",
    "        self.n_batches = max(int(self.n_paired_batches + self.n_unpaired_expected), 1)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(self.n_batches)\n",
    "\n",
    "    def __iter__(self):\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "\n",
    "        paired_pool = self.paired_idx.copy()\n",
    "        rng.shuffle(paired_pool)\n",
    "        p_ptr = 0\n",
    "\n",
    "        unpaired_pool = self.unpaired_idx.copy()\n",
    "        if len(unpaired_pool) > 0:\n",
    "            rng.shuffle(unpaired_pool)\n",
    "        u_ptr = 0\n",
    "\n",
    "        def sample_with_replacement(pool):\n",
    "            sel = rng.integers(0, len(pool), size=self.batch_size)\n",
    "            return pool[sel]\n",
    "\n",
    "        def next_batch(pool, ptr, oversample):\n",
    "            end = ptr + self.batch_size\n",
    "            if end <= len(pool):\n",
    "                return pool[ptr:end], end\n",
    "            if not oversample:\n",
    "                return None, ptr\n",
    "            rng.shuffle(pool)\n",
    "            ptr = 0\n",
    "            end = ptr + self.batch_size\n",
    "            if end <= len(pool):\n",
    "                return pool[ptr:end], end\n",
    "            return sample_with_replacement(pool), ptr\n",
    "\n",
    "        carry = 0.0\n",
    "        for _ in range(self.n_paired_batches):\n",
    "            if len(paired_pool) < self.batch_size:\n",
    "                if not self.oversample_paired:\n",
    "                    break\n",
    "                pb = sample_with_replacement(paired_pool)\n",
    "            else:\n",
    "                pb, p_ptr = next_batch(paired_pool, p_ptr, self.oversample_paired)\n",
    "                if pb is None:\n",
    "                    break\n",
    "            yield pb.tolist()\n",
    "\n",
    "            if self.only_paired:\n",
    "                continue\n",
    "\n",
    "            carry += self.unpaired_per_paired\n",
    "            while carry >= 1.0 and len(unpaired_pool) > 0:\n",
    "                carry -= 1.0\n",
    "                if len(unpaired_pool) < self.batch_size:\n",
    "                    if not self.oversample_unpaired:\n",
    "                        break\n",
    "                    ub = sample_with_replacement(unpaired_pool)\n",
    "                else:\n",
    "                    ub, u_ptr = next_batch(unpaired_pool, u_ptr, self.oversample_unpaired)\n",
    "                    if ub is None:\n",
    "                        break\n",
    "                yield ub.tolist()\n",
    "\n",
    "def make_loaders_with_overlap_v1(\n",
    "    base_dataset,\n",
    "    train_idx,\n",
    "    val_idx,\n",
    "    test_idx,\n",
    "    *,\n",
    "    overlap_fraction: float,\n",
    "    drop_modality: str,\n",
    "    seed: int,\n",
    "    batch_size: int = 256,\n",
    "    num_workers: int = 0,\n",
    "    oversample_paired: bool = True,\n",
    "):\n",
    "    \"\"\"overlap_fraction applies ONLY to training. val/test remain paired.\"\"\"\n",
    "    p = float(overlap_fraction)\n",
    "    if not (0.0 <= p <= 1.0):\n",
    "        raise ValueError(f\"overlap_fraction must be in [0,1], got {p}\")\n",
    "\n",
    "    rng = np.random.default_rng(int(seed))\n",
    "\n",
    "    train_indexed = IndexedDataset(base_dataset, indices=train_idx)\n",
    "    N = len(train_indexed)\n",
    "    if N == 0:\n",
    "        raise ValueError(\"Empty train split\")\n",
    "\n",
    "    n_paired = int(round(p * N))\n",
    "    n_paired = max(min(n_paired, N), 0)\n",
    "\n",
    "    perm = rng.permutation(N)\n",
    "    paired_local = perm[:n_paired]\n",
    "\n",
    "    groups = np.ones(N, dtype=np.int64)\n",
    "    groups[paired_local] = 0\n",
    "\n",
    "    train_masked = DeterministicMaskDataset(train_indexed, groups=groups, drop_modality=str(drop_modality))\n",
    "\n",
    "    n_paired_real = int((groups == 0).sum())\n",
    "    n_unpaired_real = int((groups != 0).sum())\n",
    "    upp_sampling = float(n_unpaired_real / max(n_paired_real, 1))\n",
    "\n",
    "    print(\n",
    "        f\"[overlap={p:g}] batch_size={int(batch_size)} \"\n",
    "        f\"train_paired={n_paired_real} train_unpaired={n_unpaired_real} \"\n",
    "        f\"(sampler_upp={upp_sampling:.6f}) drop_modality={drop_modality}\"\n",
    "    )\n",
    "\n",
    "    if n_unpaired_real == 0:\n",
    "        train_loader = DataLoader(\n",
    "            train_masked,\n",
    "            batch_size=int(batch_size),\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            num_workers=int(num_workers),\n",
    "            collate_fn=collate_xdict_with_idx,\n",
    "        )\n",
    "    else:\n",
    "        batch_sampler = InterleavedGroupedBatchSampler(\n",
    "            groups=groups,\n",
    "            batch_size=int(batch_size),\n",
    "            seed=int(seed),\n",
    "            unpaired_per_paired=upp_sampling,\n",
    "            oversample_paired=bool(oversample_paired),\n",
    "            oversample_unpaired=True,\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_masked,\n",
    "            batch_sampler=batch_sampler,\n",
    "            num_workers=int(num_workers),\n",
    "            collate_fn=collate_xdict_with_idx,\n",
    "        )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        IndexedDataset(base_dataset, indices=val_idx),\n",
    "        batch_size=int(batch_size),\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=int(num_workers),\n",
    "        collate_fn=collate_xdict_with_idx,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        IndexedDataset(base_dataset, indices=test_idx),\n",
    "        batch_size=int(batch_size),\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=int(num_workers),\n",
    "        collate_fn=collate_xdict_with_idx,\n",
    "    )\n",
    "\n",
    "    info = {\n",
    "        \"train_paired\": n_paired_real,\n",
    "        \"train_unpaired\": n_unpaired_real,\n",
    "        \"sampler_unpaired_per_paired\": float(upp_sampling),\n",
    "        \"overlap_fraction\": float(p),\n",
    "        \"drop_modality\": str(drop_modality),\n",
    "    }\n",
    "    return train_loader, val_loader, test_loader, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add4c1ef-d181-4e30-bb44-7680f359c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 8) UniVI config + trainer compat + training wrapper (ES-gated, seed-fixed) ----\n",
    "# =============================================================================\n",
    "def make_univi_cfg(\n",
    "    rna_dim: int,\n",
    "    atac_dim: int,\n",
    "    *,\n",
    "    latent_dim: int = 30,\n",
    "    beta: float = 1.25,\n",
    "    gamma: float = 4.35,\n",
    "    kl_anneal_start: int = 0,\n",
    "    kl_anneal_end: int = 60,\n",
    "    align_anneal_start: int = 25,\n",
    "    align_anneal_end: int = 85,\n",
    "    encoder_dropout: float = 0.10,\n",
    "    decoder_dropout: float = 0.05,\n",
    ") -> UniVIConfig:\n",
    "    return UniVIConfig(\n",
    "        latent_dim=int(latent_dim),\n",
    "        beta=float(beta),\n",
    "        gamma=float(gamma),\n",
    "        encoder_dropout=float(encoder_dropout),\n",
    "        decoder_dropout=float(decoder_dropout),\n",
    "        encoder_batchnorm=True,\n",
    "        decoder_batchnorm=False,\n",
    "        kl_anneal_start=int(kl_anneal_start),\n",
    "        kl_anneal_end=int(kl_anneal_end),\n",
    "        align_anneal_start=int(align_anneal_start),\n",
    "        align_anneal_end=int(align_anneal_end),\n",
    "        modalities=[\n",
    "            ModalityConfig(\n",
    "                name=\"rna\",\n",
    "                input_dim=int(rna_dim),\n",
    "                encoder_hidden=[512, 256, 128],\n",
    "                decoder_hidden=[128, 256, 512],\n",
    "                likelihood=\"gaussian\",\n",
    "            ),\n",
    "            ModalityConfig(\n",
    "                name=\"atac\",\n",
    "                input_dim=int(atac_dim),\n",
    "                encoder_hidden=[128, 64],\n",
    "                decoder_hidden=[64, 128],\n",
    "                likelihood=\"gaussian\",\n",
    "            ),\n",
    "        ],\n",
    "        class_heads=[],\n",
    "    )\n",
    "\n",
    "def make_train_cfg(\n",
    "    device,\n",
    "    *,\n",
    "    seed: int,\n",
    "    n_epochs: int = 5000,\n",
    "    batch_size: int = 256,\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 1e-4,\n",
    "    log_every: int = 25,\n",
    "    grad_clip: float = 5.0,\n",
    "    early_stopping: bool = True,\n",
    "    patience: int = 100,\n",
    "    min_delta: float = 0.0,\n",
    "    num_workers: int = 0,\n",
    ") -> TrainingConfig:\n",
    "    return TrainingConfig(\n",
    "        n_epochs=int(n_epochs),\n",
    "        batch_size=int(batch_size),\n",
    "        lr=float(lr),\n",
    "        weight_decay=float(weight_decay),\n",
    "        device=device,\n",
    "        log_every=int(log_every),\n",
    "        grad_clip=float(grad_clip),\n",
    "        num_workers=int(num_workers),\n",
    "        seed=int(seed),\n",
    "        early_stopping=bool(early_stopping),\n",
    "        patience=int(patience),\n",
    "        min_delta=float(min_delta),\n",
    "    )\n",
    "\n",
    "def _build_univi_trainer_compat(*, model, train_cfg, train_loader, val_loader):\n",
    "    sig = inspect.signature(UniVITrainer.__init__)\n",
    "    params = sig.parameters\n",
    "    kwargs = {}\n",
    "\n",
    "    if \"model\" in params: kwargs[\"model\"] = model\n",
    "    if \"train_loader\" in params: kwargs[\"train_loader\"] = train_loader\n",
    "    if \"val_loader\" in params: kwargs[\"val_loader\"] = val_loader\n",
    "\n",
    "    for cand in (\"train_cfg\", \"training_cfg\", \"cfg_train\", \"config\", \"cfg\"):\n",
    "        if cand in params:\n",
    "            kwargs[cand] = train_cfg\n",
    "            return UniVITrainer(**kwargs)\n",
    "\n",
    "    for k, v in vars(train_cfg).items():\n",
    "        if k in params:\n",
    "            kwargs[k] = v\n",
    "\n",
    "    return UniVITrainer(**kwargs)\n",
    "\n",
    "def _trainer_fit_compat(trainer, train_loader, val_loader):\n",
    "    try:\n",
    "        return trainer.fit()\n",
    "    except TypeError:\n",
    "        pass\n",
    "    try:\n",
    "        return trainer.fit(train_loader=train_loader, val_loader=val_loader)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return trainer.fit(train_loader, val_loader)\n",
    "\n",
    "@dataclass\n",
    "class TrainResult:\n",
    "    model: torch.nn.Module\n",
    "    best_epoch: Optional[int]\n",
    "    best_val: Optional[float]\n",
    "    wall_seconds: float\n",
    "    peak_mem_mb: Optional[float]\n",
    "\n",
    "def _filter_kwargs_for_init(cls_or_fn, kwargs: dict, *, tag: str = \"\") -> dict:\n",
    "    if not kwargs:\n",
    "        return {}\n",
    "    sig = inspect.signature(cls_or_fn)\n",
    "    params = sig.parameters\n",
    "    if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in params.values()):\n",
    "        return dict(kwargs)\n",
    "    keep, dropped = {}, []\n",
    "    for k, v in kwargs.items():\n",
    "        if k in params:\n",
    "            keep[k] = v\n",
    "        else:\n",
    "            dropped.append(k)\n",
    "    if dropped:\n",
    "        prefix = f\"[{tag}] \" if tag else \"\"\n",
    "        print(f\"{prefix}dropping unsupported kwargs: {dropped}\")\n",
    "    return keep\n",
    "\n",
    "def train_one(\n",
    "    *,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    univi_cfg: UniVIConfig,\n",
    "    seed: int,\n",
    "    device,\n",
    "    loss_mode: str = \"v1\",\n",
    "    v1_recon: str = \"moe\",\n",
    "    batch_size: int = 256,\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 1e-4,\n",
    "    n_epochs: int = 5000,\n",
    "    early_stopping: bool = True,\n",
    "    patience: int = 100,\n",
    "    min_delta: float = 0.0,\n",
    "    min_epochs: int = 0,\n",
    "    grad_clip: float = 5.0,\n",
    "    log_every: int = 25,\n",
    "    num_workers: int = 0,\n",
    "    extra_model_kwargs: Optional[dict] = None,\n",
    "):\n",
    "    seed_all(int(seed))\n",
    "\n",
    "    model_kwargs = _filter_kwargs_for_init(\n",
    "        UniVIMultiModalVAE.__init__,\n",
    "        dict(extra_model_kwargs or {}),\n",
    "        tag=\"model\",\n",
    "    )\n",
    "\n",
    "    model = UniVIMultiModalVAE(\n",
    "        univi_cfg,\n",
    "        loss_mode=str(loss_mode),\n",
    "        v1_recon=str(v1_recon),\n",
    "        **model_kwargs,\n",
    "    ).to(device)\n",
    "\n",
    "    # ---- FIX: real early-stopping gate\n",
    "    # If trainer uses patience as \"epochs since best\", increase patience by min_epochs\n",
    "    # so it cannot trip before min_epochs has elapsed.\n",
    "    min_epochs = int(max(min_epochs, 0))\n",
    "    patience = int(patience)\n",
    "    patience_eff = patience + min_epochs if bool(early_stopping) else patience\n",
    "\n",
    "    train_cfg = make_train_cfg(\n",
    "        device=device,\n",
    "        seed=int(seed),\n",
    "        n_epochs=int(n_epochs),\n",
    "        batch_size=int(batch_size),\n",
    "        lr=float(lr),\n",
    "        weight_decay=float(weight_decay),\n",
    "        log_every=int(log_every),\n",
    "        grad_clip=float(grad_clip),\n",
    "        early_stopping=bool(early_stopping),\n",
    "        patience=int(patience_eff),\n",
    "        min_delta=float(min_delta),\n",
    "        num_workers=int(num_workers),\n",
    "    )\n",
    "\n",
    "    trainer = _build_univi_trainer_compat(\n",
    "        model=model,\n",
    "        train_cfg=train_cfg,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "    )\n",
    "\n",
    "    if not hasattr(trainer, \"train_loader\"):\n",
    "        trainer.train_loader = train_loader\n",
    "    if not hasattr(trainer, \"val_loader\"):\n",
    "        trainer.val_loader = val_loader\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    _trainer_fit_compat(trainer, train_loader=train_loader, val_loader=val_loader)\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    peak_mem_mb = getattr(trainer, \"peak_mem_mb\", None)\n",
    "    best_epoch = getattr(trainer, \"best_epoch\", None)\n",
    "    best_val = getattr(trainer, \"best_val_loss\", None)\n",
    "    if best_val is None:\n",
    "        best_val = getattr(trainer, \"best_val\", None)\n",
    "\n",
    "    if hasattr(trainer, \"restore_best\"):\n",
    "        try:\n",
    "            trainer.restore_best()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return TrainResult(\n",
    "        model=model,\n",
    "        best_epoch=(int(best_epoch) if best_epoch is not None else None),\n",
    "        best_val=(float(best_val) if best_val is not None else None),\n",
    "        wall_seconds=float(t1 - t0),\n",
    "        peak_mem_mb=(float(peak_mem_mb) if peak_mem_mb is not None else None),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbc080-340b-4a37-ae97-50c6be757b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 9) Robust per-modality latent extraction (FIXED for mu_dict outputs) ----\n",
    "# =============================================================================\n",
    "def _to_numpy(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    if torch.is_tensor(x):\n",
    "        return x.detach().cpu().numpy()\n",
    "    return np.asarray(x)\n",
    "\n",
    "def _pick_tensor(obj):\n",
    "    if torch.is_tensor(obj):\n",
    "        return obj\n",
    "    if isinstance(obj, (tuple, list)):\n",
    "        for x in obj[::-1]:\n",
    "            if torch.is_tensor(x):\n",
    "                return x\n",
    "        return None\n",
    "    if isinstance(obj, dict):\n",
    "        for k in (\"z\", \"latent\", \"mu\", \"z_shared\", \"emb\", \"repr\"):\n",
    "            if k in obj and torch.is_tensor(obj[k]):\n",
    "                return obj[k]\n",
    "        for v in obj.values():\n",
    "            if torch.is_tensor(v):\n",
    "                return v\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def _extract_modality_latent(out: Any, mod: str) -> Optional[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Handles UniVI outputs like the ones you showed:\n",
    "      keys include: 'mu_dict', 'logvar_dict', 'z', ...\n",
    "    Prefer mu_dict[mod] as a stable modality-specific representation.\n",
    "    \"\"\"\n",
    "    if not isinstance(out, dict):\n",
    "        return None\n",
    "\n",
    "    # 1) Your current UniVI version: mu_dict / logvar_dict\n",
    "    if \"mu_dict\" in out and isinstance(out[\"mu_dict\"], dict) and mod in out[\"mu_dict\"]:\n",
    "        t = out[\"mu_dict\"][mod]\n",
    "        return t if torch.is_tensor(t) else None\n",
    "\n",
    "    # 2) Common alternatives in other versions\n",
    "    for key in (f\"mu_{mod}\", f\"z_{mod}\", mod):\n",
    "        if key in out:\n",
    "            t = _pick_tensor(out[key])\n",
    "            if t is not None:\n",
    "                return t\n",
    "\n",
    "    if \"latents\" in out and isinstance(out[\"latents\"], dict):\n",
    "        t = _pick_tensor(out[\"latents\"].get(mod, None))\n",
    "        if t is not None:\n",
    "            return t\n",
    "\n",
    "    if \"z_dict\" in out and isinstance(out[\"z_dict\"], dict) and mod in out[\"z_dict\"]:\n",
    "        t = out[\"z_dict\"][mod]\n",
    "        return t if torch.is_tensor(t) else None\n",
    "\n",
    "    return None\n",
    "\n",
    "def _extract_fused_latent(out: Any) -> Optional[torch.Tensor]:\n",
    "    if not isinstance(out, dict):\n",
    "        return _pick_tensor(out)\n",
    "    for k in (\"z\", \"z_shared\", \"latent\", \"mu\", \"mu_z\"):\n",
    "        if k in out:\n",
    "            t = _pick_tensor(out[k])\n",
    "            if t is not None:\n",
    "                return t\n",
    "    return _pick_tensor(out)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _model_call_any(model, xb: dict):\n",
    "    # Prefer inference/encode if present; otherwise forward\n",
    "    if hasattr(model, \"inference\"):\n",
    "        try:\n",
    "            return model.inference(xb)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(model, \"encode\"):\n",
    "        try:\n",
    "            return model.encode(xb)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return model(xb)\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_modality_mu(model, xb: dict, *, device, mod: str) -> torch.Tensor:\n",
    "    if mod not in xb:\n",
    "        raise KeyError(f\"Batch missing modality '{mod}'. Keys: {list(xb.keys())}\")\n",
    "    xb_mod = {mod: xb[mod].to(device)}\n",
    "    out = _model_call_any(model, xb_mod)\n",
    "    z = _extract_modality_latent(out, mod)\n",
    "    if z is None:\n",
    "        keys = list(out.keys()) if isinstance(out, dict) else None\n",
    "        raise RuntimeError(\n",
    "            f\"Could not extract modality latent for mod='{mod}'. \"\n",
    "            f\"out_type={type(out)} keys={keys}\"\n",
    "        )\n",
    "    return z.detach().cpu()\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_fused_z(model, xb: dict, *, device) -> torch.Tensor:\n",
    "    xb2 = {k: v.to(device) for k, v in xb.items()}\n",
    "    out = _model_call_any(model, xb2)\n",
    "    z = _extract_fused_latent(out)\n",
    "    if z is None:\n",
    "        keys = list(out.keys()) if isinstance(out, dict) else None\n",
    "        raise RuntimeError(f\"Could not extract fused latent. out_type={type(out)} keys={keys}\")\n",
    "    return z.detach().cpu()\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_test_latents(model, loader, *, device):\n",
    "    \"\"\"\n",
    "    For paired loader (xb has 'rna' and 'atac'):\n",
    "      returns Z_fused, Z_rna(mu), Z_atac(mu), gids\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    Zf, Zr, Za, G = [], [], [], []\n",
    "\n",
    "    for xb, gids in loader:\n",
    "        if \"rna\" not in xb or \"atac\" not in xb:\n",
    "            raise RuntimeError(f\"Expected paired xb keys ['rna','atac']; got {list(xb.keys())}\")\n",
    "\n",
    "        zf = encode_fused_z(model, xb, device=device)\n",
    "        zr = encode_modality_mu(model, xb, device=device, mod=\"rna\")\n",
    "        za = encode_modality_mu(model, xb, device=device, mod=\"atac\")\n",
    "\n",
    "        Zf.append(zf); Zr.append(zr); Za.append(za)\n",
    "        G.append(gids.detach().cpu())\n",
    "\n",
    "    return torch.cat(Zf, 0), torch.cat(Zr, 0), torch.cat(Za, 0), torch.cat(G, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5397607-5404-4467-8e3e-6a540bbf1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 10) Eval helpers (kNN, clustering, mixing) ----\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    silhouette_score,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def _to_numpy(x):\n",
    "    \"\"\"Torch tensor -> numpy, otherwise np.asarray.\"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.detach().cpu().numpy()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.asarray(x)\n",
    "\n",
    "\n",
    "def l2_normalize_rows(X, eps=1e-12):\n",
    "    X = _to_numpy(X).astype(np.float32, copy=False)\n",
    "    n = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    return X / np.maximum(n, eps)\n",
    "\n",
    "\n",
    "def knn_majority_vote_predict(y_neighbors):\n",
    "    \"\"\"\n",
    "    y_neighbors: (n, k) int labels\n",
    "    Returns: (n,) predicted labels by majority vote; ties -> smallest label id.\n",
    "    \"\"\"\n",
    "    y_neighbors = np.asarray(y_neighbors)\n",
    "    pred = np.empty(y_neighbors.shape[0], dtype=y_neighbors.dtype)\n",
    "    for i in range(y_neighbors.shape[0]):\n",
    "        vals, cnts = np.unique(y_neighbors[i], return_counts=True)\n",
    "        pred[i] = vals[np.argmax(cnts)]\n",
    "    return pred\n",
    "\n",
    "\n",
    "def knn_label_transfer(Z_src, y_src, Z_tgt, *, k=5, metric=\"cosine\", normalize=True):\n",
    "    \"\"\"\n",
    "    Predict labels for target points using kNN in source space (source->target).\n",
    "    This is true \"transfer\": y_src are labels for the Z_src points.\n",
    "\n",
    "    Returns: pred_tgt labels (len = n_tgt)\n",
    "    \"\"\"\n",
    "    Z_src = _to_numpy(Z_src).astype(np.float32, copy=False)\n",
    "    Z_tgt = _to_numpy(Z_tgt).astype(np.float32, copy=False)\n",
    "    y_src = np.asarray(y_src, dtype=np.int64)\n",
    "\n",
    "    if normalize:\n",
    "        Z_src = l2_normalize_rows(Z_src)\n",
    "        Z_tgt = l2_normalize_rows(Z_tgt)\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=int(k), metric=str(metric))\n",
    "    nn.fit(Z_src)\n",
    "    idx = nn.kneighbors(Z_tgt, return_distance=False)\n",
    "    votes = y_src[idx]\n",
    "    return knn_majority_vote_predict(votes)\n",
    "\n",
    "\n",
    "def knn_loo_accuracy(Z, y, *, k=5, metric=\"cosine\", normalize=True):\n",
    "    \"\"\"\n",
    "    Leave-one-out kNN accuracy within a single embedding space.\n",
    "    Uses k+1 neighbors and drops self.\n",
    "    \"\"\"\n",
    "    Z = _to_numpy(Z).astype(np.float32, copy=False)\n",
    "    y = np.asarray(y, dtype=np.int64)\n",
    "\n",
    "    if normalize:\n",
    "        Z = l2_normalize_rows(Z)\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=int(k) + 1, metric=str(metric))\n",
    "    nn.fit(Z)\n",
    "    idx = nn.kneighbors(Z, return_distance=False)[:, 1:]  # drop self\n",
    "    pred = knn_majority_vote_predict(y[idx])\n",
    "    return float(accuracy_score(y, pred)), float(f1_score(y, pred, average=\"macro\")), float(balanced_accuracy_score(y, pred))\n",
    "\n",
    "\n",
    "def clustering_metrics(Z, y_true, *, kmeans_k, seed=0):\n",
    "    \"\"\"\n",
    "    KMeans clusters on Z, compare to y_true.\n",
    "    Returns: ARI, NMI, SIL_kmeans, CH_kmeans, DB_kmeans, SIL_true (silhouette by true labels).\n",
    "    \"\"\"\n",
    "    Z = _to_numpy(Z).astype(np.float32, copy=False)\n",
    "    y_true = np.asarray(y_true, dtype=np.int64)\n",
    "\n",
    "    out = {\"kmeans_k\": int(kmeans_k)}\n",
    "\n",
    "    if int(kmeans_k) < 2:\n",
    "        out.update({\"ARI\": np.nan, \"NMI\": np.nan, \"SIL_kmeans\": np.nan, \"CH_kmeans\": np.nan, \"DB_kmeans\": np.nan})\n",
    "        out[\"SIL_true\"] = np.nan\n",
    "        return out\n",
    "\n",
    "    km = KMeans(n_clusters=int(kmeans_k), random_state=int(seed), n_init=10)\n",
    "    y_km = km.fit_predict(Z)\n",
    "\n",
    "    out[\"ARI\"] = float(adjusted_rand_score(y_true, y_km))\n",
    "    out[\"NMI\"] = float(normalized_mutual_info_score(y_true, y_km))\n",
    "\n",
    "    if len(np.unique(y_km)) > 1 and Z.shape[0] > int(kmeans_k):\n",
    "        out[\"SIL_kmeans\"] = float(silhouette_score(Z, y_km, metric=\"euclidean\"))\n",
    "        out[\"CH_kmeans\"]  = float(calinski_harabasz_score(Z, y_km))\n",
    "        out[\"DB_kmeans\"]  = float(davies_bouldin_score(Z, y_km))\n",
    "    else:\n",
    "        out[\"SIL_kmeans\"] = np.nan\n",
    "        out[\"CH_kmeans\"]  = np.nan\n",
    "        out[\"DB_kmeans\"]  = np.nan\n",
    "\n",
    "    if len(np.unique(y_true)) > 1 and Z.shape[0] > len(np.unique(y_true)):\n",
    "        out[\"SIL_true\"] = float(silhouette_score(Z, y_true, metric=\"euclidean\"))\n",
    "    else:\n",
    "        out[\"SIL_true\"] = np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def modality_mixing_score(Z, modality_labels, *, k=15, metric=\"cosine\", normalize=True):\n",
    "    \"\"\"\n",
    "    1 - mean(frac of same-modality neighbors). Higher is better mixing.\n",
    "    \"\"\"\n",
    "    Z = _to_numpy(Z).astype(np.float32, copy=False)\n",
    "    m = np.asarray(modality_labels, dtype=np.int64)\n",
    "\n",
    "    if normalize:\n",
    "        Z = l2_normalize_rows(Z)\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=int(k) + 1, metric=str(metric))\n",
    "    nn.fit(Z)\n",
    "    idx = nn.kneighbors(Z, return_distance=False)[:, 1:]\n",
    "    same = (m[idx] == m[:, None]).mean(axis=1)\n",
    "    return float(1.0 - same.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f9d3e-002b-45c8-9c23-5b0d629a9c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 11) Paired eval metrics (FOSCTTM + recall@k + evaluate_on_test) ----\n",
    "# =============================================================================\n",
    "def foscttm_rank_fraction(Za, Zb):\n",
    "    \"\"\"\n",
    "    Classic FOSCTTM (lower is better): for each i, fraction of non-match pairs\n",
    "    that are closer than the true match, averaged across i.\n",
    "    Uses cosine similarity via L2-normalized dot product.\n",
    "    \"\"\"\n",
    "    A = l2_normalize_rows(Za)\n",
    "    B = l2_normalize_rows(Zb)\n",
    "    S = A @ B.T  # cosine sim\n",
    "    D = 1.0 - S  # cosine distance proxy\n",
    "\n",
    "    d_true = np.diag(D)  # true pair distance\n",
    "    n = D.shape[0]\n",
    "    mask = ~np.eye(n, dtype=bool)\n",
    "\n",
    "    frac = (D < d_true[:, None]) & mask\n",
    "    return float(frac.sum(axis=1).mean() / max(1, (n - 1)))\n",
    "\n",
    "\n",
    "def recall_at_k(Za, Zb, *, ks=(1, 5, 10, 25, 50, 100), symmetric=True):\n",
    "    \"\"\"\n",
    "    Recall@k retrieval in cosine space after L2 normalization.\n",
    "    recall_A2B@k: true match in top-k when querying A against B\n",
    "    recall_B2A@k: reverse\n",
    "    recall_sym@k: average of the two\n",
    "    \"\"\"\n",
    "    A = l2_normalize_rows(Za)\n",
    "    B = l2_normalize_rows(Zb)\n",
    "    S = A @ B.T\n",
    "\n",
    "    n = S.shape[0]\n",
    "    true = np.arange(n)[:, None]\n",
    "    out = {}\n",
    "\n",
    "    order = np.argsort(-S, axis=1)\n",
    "    for k in ks:\n",
    "        out[f\"recall_A2B@{int(k)}\"] = float((order[:, :int(k)] == true).any(axis=1).mean())\n",
    "\n",
    "    if symmetric:\n",
    "        order2 = np.argsort(-S.T, axis=1)\n",
    "        for k in ks:\n",
    "            out[f\"recall_B2A@{int(k)}\"] = float((order2[:, :int(k)] == true).any(axis=1).mean())\n",
    "        for k in ks:\n",
    "            out[f\"recall_sym@{int(k)}\"] = float(0.5 * (out[f\"recall_A2B@{int(k)}\"] + out[f\"recall_B2A@{int(k)}\"]))\n",
    "    return out\n",
    "\n",
    "\n",
    "def foscttm_at_k(Za, Zb, *, ks=(1, 5, 10, 25, 50, 100)):\n",
    "    \"\"\"\n",
    "    \"FOSCTTM@k\" as an error-rate derived from symmetric recall@k:\n",
    "        FOSCTTM@k = 1 - recall_sym@k\n",
    "    Lower is better, consistent with classic FOSCTTM.\n",
    "    \"\"\"\n",
    "    rec = recall_at_k(Za, Zb, ks=tuple(int(x) for x in ks), symmetric=True)\n",
    "    out = {}\n",
    "    for k in ks:\n",
    "        out[f\"FOSCTTM@{int(k)}\"] = float(1.0 - rec[f\"recall_sym@{int(k)}\"])\n",
    "    # back-compat: FOSCTTM means classic rank fraction (keep both!)\n",
    "    return out, rec\n",
    "\n",
    "\n",
    "def make_label_codes(y_all):\n",
    "    \"\"\"\n",
    "    Robust label encoding. Keeps deterministic mapping via sorted unique strings.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y_all, dtype=str)\n",
    "    uniq = np.unique(y)\n",
    "    mapping = {lab: i for i, lab in enumerate(uniq.tolist())}\n",
    "    y_int = np.array([mapping[v] for v in y], dtype=np.int64)\n",
    "    return y_int, mapping\n",
    "\n",
    "\n",
    "def evaluate_on_test(\n",
    "    model,\n",
    "    test_loader,\n",
    "    *,\n",
    "    device,\n",
    "    y_all,\n",
    "    k_knn=3,\n",
    "    seed=0,\n",
    "    fos_ks=(1, 5, 10, 25, 50, 100),\n",
    "    mix_k=15,\n",
    "):\n",
    "    \"\"\"\n",
    "    Paired-only evaluation:\n",
    "      - Requires collect_test_latents() returning (Zf, Zr, Za, gids).\n",
    "      - y_all indexed by gids gives per-cell labels (strings or ints).\n",
    "\n",
    "    Outputs include:\n",
    "      - classic FOSCTTM (rank fraction)\n",
    "      - recall@k (A2B, B2A, sym)\n",
    "      - FOSCTTM@k = 1 - recall_sym@k\n",
    "      - within-embedding LOO kNN acc/macroF1/bal_acc for Zr, Za, Zf\n",
    "      - KMeans ARI/NMI + SIL/CH/DB + SIL_true on Zf\n",
    "      - modality mixing score on stacked [Zr; Za]\n",
    "    \"\"\"\n",
    "    Zf_t, Zr_t, Za_t, gids_t = collect_test_latents(model, test_loader, device=device)\n",
    "\n",
    "    Zf = _to_numpy(Zf_t)\n",
    "    Zr = _to_numpy(Zr_t)\n",
    "    Za = _to_numpy(Za_t)\n",
    "    gids = _to_numpy(gids_t).astype(np.int64)\n",
    "\n",
    "    y_int_all, _ = make_label_codes(y_all)\n",
    "    y_true = y_int_all[gids]\n",
    "\n",
    "    out = {}\n",
    "    out[\"n_test\"] = int(len(gids))\n",
    "    out[\"latent_dim\"] = int(Zf.shape[1]) if Zf is not None else -1\n",
    "    out[\"k_knn\"] = int(k_knn)\n",
    "\n",
    "    # ---- Paired retrieval metrics (RNA vs ATAC latents) ----\n",
    "    out[\"FOSCTTM_rankfrac\"] = foscttm_rank_fraction(Zr, Za)\n",
    "\n",
    "    fosk, rec = foscttm_at_k(Zr, Za, ks=tuple(int(x) for x in fos_ks))\n",
    "    out.update(fosk)      # FOSCTTM@{...}\n",
    "    out.update(rec)       # recall_*@k\n",
    "\n",
    "    # keep legacy key if you want it:\n",
    "    out[\"FOSCTTM\"] = out[\"FOSCTTM_rankfrac\"]\n",
    "\n",
    "    # ---- kNN accuracy within each space (LOO) ----\n",
    "    # (This is the clean \"kNN ACC\" people usually mean.)\n",
    "    acc_r, f1_r, bal_r = knn_loo_accuracy(Zr, y_true, k=int(k_knn), metric=\"cosine\", normalize=True)\n",
    "    acc_a, f1_a, bal_a = knn_loo_accuracy(Za, y_true, k=int(k_knn), metric=\"cosine\", normalize=True)\n",
    "    acc_f, f1_f, bal_f = knn_loo_accuracy(Zf, y_true, k=int(k_knn), metric=\"cosine\", normalize=True)\n",
    "\n",
    "    out[\"kNN_LOO_acc_rna\"] = float(acc_r)\n",
    "    out[\"kNN_LOO_macroF1_rna\"] = float(f1_r)\n",
    "    out[\"kNN_LOO_balacc_rna\"] = float(bal_r)\n",
    "\n",
    "    out[\"kNN_LOO_acc_atac\"] = float(acc_a)\n",
    "    out[\"kNN_LOO_macroF1_atac\"] = float(f1_a)\n",
    "    out[\"kNN_LOO_balacc_atac\"] = float(bal_a)\n",
    "\n",
    "    out[\"kNN_LOO_acc_fused\"] = float(acc_f)\n",
    "    out[\"kNN_LOO_macroF1_fused\"] = float(f1_f)\n",
    "    out[\"kNN_LOO_balacc_fused\"] = float(bal_f)\n",
    "\n",
    "    # ---- Optional: cross-space \"transfer\" (source labels must come from SOURCE set) ----\n",
    "    # In paired-only, the \"source\" and \"target\" are the same cells, so this becomes\n",
    "    # more of a neighborhood-consistency score than true transfer.\n",
    "    # We keep it anyway since you had it.\n",
    "    pred_r2a = knn_label_transfer(Z_src=Zr, y_src=y_true, Z_tgt=Za, k=int(k_knn), metric=\"cosine\", normalize=True)\n",
    "    pred_a2r = knn_label_transfer(Z_src=Za, y_src=y_true, Z_tgt=Zr, k=int(k_knn), metric=\"cosine\", normalize=True)\n",
    "\n",
    "    out[\"LT_RNA2ATAC_acc\"] = float(accuracy_score(y_true, pred_r2a))\n",
    "    out[\"LT_ATAC2RNA_acc\"] = float(accuracy_score(y_true, pred_a2r))\n",
    "    out[\"LT_RNA2ATAC_macroF1\"] = float(f1_score(y_true, pred_r2a, average=\"macro\"))\n",
    "    out[\"LT_ATAC2RNA_macroF1\"] = float(f1_score(y_true, pred_a2r, average=\"macro\"))\n",
    "\n",
    "    # ---- Clustering + silhouette on fused ----\n",
    "    kmeans_k = int(len(np.unique(y_true)))\n",
    "    out.update(clustering_metrics(Zf, y_true, kmeans_k=kmeans_k, seed=int(seed)))\n",
    "\n",
    "    # ---- Mixing score: stack rna + atac and measure neighbor modality purity ----\n",
    "    Z_mix = np.vstack([Zr, Za])\n",
    "    m_lab = np.array([0] * Zr.shape[0] + [1] * Za.shape[0], dtype=np.int64)\n",
    "    out[f\"mixing_1minus_samefrac_k{int(mix_k)}\"] = modality_mixing_score(\n",
    "        Z_mix, m_lab, k=int(mix_k), metric=\"cosine\", normalize=True\n",
    "    )\n",
    "\n",
    "    # handy counts\n",
    "    out[\"n_labels\"] = int(len(np.unique(y_true)))\n",
    "    out[\"kmeans_k\"] = int(kmeans_k)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b27f2-c221-4786-9004-29a231d748fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 12) Param sweep spec ----\n",
    "# =============================================================================\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class SweepPoint:\n",
    "    name: str\n",
    "    cfg_patch: dict\n",
    "    model_kwargs: dict\n",
    "    loss_mode: str = \"v1\"\n",
    "    v1_recon: str = \"moe\"\n",
    "\n",
    "def _fmt(x: float) -> str:\n",
    "    # 0.25 -> \"0p25\", -1.0 -> \"m1p0\"\n",
    "    #return str(float(x)).replace(\".\", \"p\").replace(\"-\", \"m\")\n",
    "    return str(float(x)).replace(\"p\", \".\").replace(\"m\", \"-\")\n",
    "\n",
    "def _sp(\n",
    "    name: str,\n",
    "    *,\n",
    "    cfg_patch: Optional[dict] = None,\n",
    "    model_kwargs: Optional[dict] = None,\n",
    "    loss_mode: str = \"v1\",\n",
    "    v1_recon: str = \"moe\",\n",
    ") -> SweepPoint:\n",
    "    return SweepPoint(\n",
    "        name=name,\n",
    "        cfg_patch={} if cfg_patch is None else dict(cfg_patch),\n",
    "        model_kwargs={} if model_kwargs is None else dict(model_kwargs),\n",
    "        loss_mode=str(loss_mode),\n",
    "        v1_recon=str(v1_recon),\n",
    "    )\n",
    "\n",
    "def _filter_cfg_patch(cfg_patch: dict, *, allowed_keys: Optional[set[str]] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Optional safety: if you pass allowed_keys (e.g. from UniVIConfig.__dataclass_fields__),\n",
    "    we drop unknown keys so sweeps don't crash on older config versions.\n",
    "    \"\"\"\n",
    "    if not cfg_patch:\n",
    "        return {}\n",
    "    if allowed_keys is None:\n",
    "        return dict(cfg_patch)\n",
    "    out = {}\n",
    "    for k, v in cfg_patch.items():\n",
    "        if k in allowed_keys:\n",
    "            out[k] = v\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Value grids (easy to edit)\n",
    "# -----------------------------------------------------------------------------\n",
    "BETA_GRID   = [0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 2.0, 3.0, 4.0, 4.35, 6.0, 8.0, 12.0, 18.0, 24.0, 48.0, 64.0, 128.0]\n",
    "GAMMA_GRID  = [0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 2.0, 3.0, 4.0, 4.35, 6.0, 8.0, 12.0, 18.0, 24.0, 48.0, 64.0, 128.0]\n",
    "LATENT_DIMS = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 24, 30, 36, 48, 64, 128]\n",
    "\n",
    "# Dropout grids\n",
    "ENC_DROPOUT_GRID = [0.0, 0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.35, 0.50]\n",
    "DEC_DROPOUT_GRID = [0.0, 0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.35, 0.50]\n",
    "ENCDEC_COUPLED   = [0.0, 0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.35, 0.50]\n",
    "\n",
    "\n",
    "def make_sweep_points(*, cfg_allowed_keys: Optional[set[str]] = None) -> list[SweepPoint]:\n",
    "    \"\"\"\n",
    "    If you pass cfg_allowed_keys, cfg_patch keys will be filtered (nice for backward compatibility).\n",
    "    Example:\n",
    "        cfg_allowed_keys = set(UniVIConfig.__dataclass_fields__.keys())\n",
    "        SWEEP_POINTS = make_sweep_points(cfg_allowed_keys=cfg_allowed_keys)\n",
    "    \"\"\"\n",
    "    pts: list[SweepPoint] = []\n",
    "\n",
    "    # --- baselines ---\n",
    "    pts += [\n",
    "        _sp(\"baseline\", v1_recon=\"moe\"),\n",
    "        _sp(\"no_moe_agg\", v1_recon=\"avg\"),\n",
    "    ]\n",
    "\n",
    "    # --- alignment off ---\n",
    "    # In this UniVI version there is no symmetric_align model kwarg.\n",
    "    # So \"no alignment\" is gamma=0.\n",
    "    pts.append(_sp(\"no_align\", cfg_patch=_filter_cfg_patch({\"gamma\": 0.0}, allowed_keys=cfg_allowed_keys), v1_recon=\"moe\"))\n",
    "    '''\n",
    "    # --- beta sweep ---\n",
    "    for b in BETA_GRID:\n",
    "        pts.append(_sp(\n",
    "            f\"beta_{_fmt(b)}\",\n",
    "            cfg_patch=_filter_cfg_patch({\"beta\": float(b)}, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\",\n",
    "        ))\n",
    "\n",
    "    # --- gamma sweep ---\n",
    "    for g in GAMMA_GRID:\n",
    "        pts.append(_sp(\n",
    "            f\"gamma_{_fmt(g)}\",\n",
    "            cfg_patch=_filter_cfg_patch({\"gamma\": float(g)}, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\",\n",
    "        ))\n",
    "    '''\n",
    "    \n",
    "    # --- beta x gamma grid (ALL combos) ---\n",
    "    # Optionally skip the (baseline beta, baseline gamma) combo to avoid duplicating \"baseline\"\n",
    "    BASE_BETA = float(getattr(UniVIConfig, \"__dummy__\", 0.0) or 1.25)   # optional: just for naming logic\n",
    "    BASE_GAMMA = float(getattr(UniVIConfig, \"__dummy__\", 0.0) or 4.35) # optional: just for naming logic\n",
    "\n",
    "    SKIP_BASELINE_COMBO = False  # set True if you want to not include baseline beta/gamma combos\n",
    "\n",
    "    for b in BETA_GRID:\n",
    "        for g in GAMMA_GRID:\n",
    "            if SKIP_BASELINE_COMBO and (float(b) == float(BASE_BETA)) and (float(g) == float(BASE_GAMMA)):\n",
    "                continue\n",
    "\n",
    "            pts.append(_sp(\n",
    "                f\"bg_beta_{_fmt(b)}__gamma_{_fmt(g)}\",\n",
    "                cfg_patch=_filter_cfg_patch({\"beta\": float(b), \"gamma\": float(g)}, allowed_keys=cfg_allowed_keys),\n",
    "                v1_recon=\"moe\",\n",
    "            ))\n",
    "\n",
    "\n",
    "    # --- annealing variants ---\n",
    "    pts += [\n",
    "        _sp(\"no_prior_anneal\",\n",
    "            cfg_patch=_filter_cfg_patch({\"kl_anneal_start\": 0, \"kl_anneal_end\": 0}, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\"),\n",
    "        _sp(\"no_align_anneal\",\n",
    "            cfg_patch=_filter_cfg_patch({\"align_anneal_start\": 0, \"align_anneal_end\": 0}, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\"),\n",
    "        _sp(\"very_early_anneal\",\n",
    "            cfg_patch=_filter_cfg_patch({\n",
    "                \"kl_anneal_start\": 0, \"kl_anneal_end\": 25,\n",
    "                \"align_anneal_start\": 10, \"align_anneal_end\": 35,\n",
    "            }, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\"),\n",
    "        _sp(\"early_anneal\",\n",
    "            cfg_patch=_filter_cfg_patch({\n",
    "                \"kl_anneal_start\": 0, \"kl_anneal_end\": 55,\n",
    "                \"align_anneal_start\": 25, \"align_anneal_end\": 90,\n",
    "            }, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\"),\n",
    "        _sp(\"late_anneal\",\n",
    "            cfg_patch=_filter_cfg_patch({\n",
    "                \"kl_anneal_start\": 50, \"kl_anneal_end\": 105,\n",
    "                \"align_anneal_start\": 75, \"align_anneal_end\": 140,\n",
    "            }, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\"),\n",
    "        _sp(\"very_late_anneal\",\n",
    "            cfg_patch=_filter_cfg_patch({\n",
    "                \"kl_anneal_start\": 100, \"kl_anneal_end\": 155,\n",
    "                \"align_anneal_start\": 125, \"align_anneal_end\": 190,\n",
    "            }, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\"),\n",
    "    ]\n",
    "\n",
    "    # --- latent dim sweep ---\n",
    "    for d in LATENT_DIMS:\n",
    "        pts.append(_sp(\n",
    "            f\"latent_{d}\",\n",
    "            cfg_patch=_filter_cfg_patch({\"latent_dim\": int(d)}, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\",\n",
    "        ))\n",
    "\n",
    "    # --- dropout sweeps ---\n",
    "    # NOTE: key names must match UniVIConfig. Common possibilities:\n",
    "    #   encoder_dropout / decoder_dropout\n",
    "    #   enc_dropout / dec_dropout\n",
    "    # Adjust the keys below to match your config.\n",
    "    ENC_KEY = \"encoder_dropout\"\n",
    "    DEC_KEY = \"decoder_dropout\"\n",
    "\n",
    "    for p in ENC_DROPOUT_GRID:\n",
    "        pts.append(_sp(\n",
    "            f\"drop_enc_{_fmt(p)}\",\n",
    "            cfg_patch=_filter_cfg_patch({ENC_KEY: float(p)}, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\",\n",
    "        ))\n",
    "\n",
    "    for p in DEC_DROPOUT_GRID:\n",
    "        pts.append(_sp(\n",
    "            f\"drop_dec_{_fmt(p)}\",\n",
    "            cfg_patch=_filter_cfg_patch({DEC_KEY: float(p)}, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\",\n",
    "        ))\n",
    "\n",
    "    for p in ENCDEC_COUPLED:\n",
    "        pts.append(_sp(\n",
    "            f\"drop_encdec_{_fmt(p)}\",\n",
    "            cfg_patch=_filter_cfg_patch({ENC_KEY: float(p), DEC_KEY: float(p)}, allowed_keys=cfg_allowed_keys),\n",
    "            v1_recon=\"moe\",\n",
    "        ))\n",
    "\n",
    "    # --- sanity check: unique names ---\n",
    "    names = [p.name for p in pts]\n",
    "    if len(names) != len(set(names)):\n",
    "        dupes = sorted({n for n in names if names.count(n) > 1})\n",
    "        raise ValueError(f\"Duplicate sweep point names: {dupes}\")\n",
    "\n",
    "    return pts\n",
    "\n",
    "\n",
    "# Usage (recommended):\n",
    "# cfg_allowed = set(UniVIConfig.__dataclass_fields__.keys())\n",
    "# SWEEP_POINTS = make_sweep_points(cfg_allowed_keys=cfg_allowed)\n",
    "SWEEP_POINTS = make_sweep_points(cfg_allowed_keys=None)\n",
    "\n",
    "print(\"n sweep points:\", len(SWEEP_POINTS))\n",
    "print(\"example:\", SWEEP_POINTS[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f0d8d-7ae9-46bf-b81b-f5e201e01b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 13) Grid runner (paired-only) + outputs (uses min_epochs ES gating) ----\n",
    "# =============================================================================\n",
    "OUTDIR = \"./results/fig10_ablation_scaling_all_combos\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "def apply_cfg_patch(cfg: UniVIConfig, patch: dict) -> UniVIConfig:\n",
    "    cfg2 = copy.deepcopy(cfg)\n",
    "    for k, v in (patch or {}).items():\n",
    "        if hasattr(cfg2, k):\n",
    "            setattr(cfg2, k, v)\n",
    "        else:\n",
    "            print(f\"[warn] UniVIConfig has no attribute '{k}' (skipping patch)\")\n",
    "    return cfg2\n",
    "\n",
    "def save_tsv(df: pd.DataFrame, path: str):\n",
    "    df.to_csv(path, sep=\"\\t\", index=False)\n",
    "    print(\"[wrote]\", path)\n",
    "\n",
    "def make_paired_loaders(*, base_dataset, train_idx, val_idx, test_idx, batch_size: int = 256, num_workers: int = 0):\n",
    "    train_ds = IndexedDataset(base_dataset, indices=train_idx)\n",
    "    val_ds   = IndexedDataset(base_dataset, indices=val_idx)\n",
    "    test_ds  = IndexedDataset(base_dataset, indices=test_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=int(batch_size), shuffle=True,  drop_last=True,\n",
    "                              num_workers=int(num_workers), collate_fn=collate_xdict_with_idx)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=int(batch_size), shuffle=False, drop_last=False,\n",
    "                              num_workers=int(num_workers), collate_fn=collate_xdict_with_idx)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=int(batch_size), shuffle=False, drop_last=False,\n",
    "                              num_workers=int(num_workers), collate_fn=collate_xdict_with_idx)\n",
    "\n",
    "    info = {\"train_paired\": int(len(train_ds)), \"train_unpaired\": 0, \"overlap_fraction\": 1.0, \"drop_modality\": \"none\"}\n",
    "    return train_loader, val_loader, test_loader, info\n",
    "\n",
    "def _infer_min_epochs_from_cfg(cfg: UniVIConfig) -> int:\n",
    "    kl_end = getattr(cfg, \"kl_anneal_end\", 0)\n",
    "    al_end = getattr(cfg, \"align_anneal_end\", 0)\n",
    "    try:\n",
    "        return int(max(int(kl_end), int(al_end), 0))\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "def run_grid_paired_only(\n",
    "    *,\n",
    "    sweep_points,\n",
    "    seed=0,\n",
    "    batch_size=256,\n",
    "    patience=100,\n",
    "    min_delta=0.0,\n",
    "    k_knn=5,\n",
    "    fuse_mode=\"avg\",\n",
    "    num_workers=0,\n",
    "    gate_es_by_anneal_end: bool = True,\n",
    "    extra_min_epochs: int = 0,\n",
    "):\n",
    "    rna_dim  = int(rna_tr_pp.n_vars)\n",
    "    atac_dim = int(atac_tr_lsi.n_vars)\n",
    "\n",
    "    train_loader, val_loader, test_loader, info = make_paired_loaders(\n",
    "        base_dataset=dataset,\n",
    "        train_idx=train_idx,\n",
    "        val_idx=val_idx,\n",
    "        test_idx=test_idx,\n",
    "        batch_size=int(batch_size),\n",
    "        num_workers=int(num_workers),\n",
    "    )\n",
    "\n",
    "    xb0, _ = next(iter(val_loader))\n",
    "    if not (\"rna\" in xb0 and \"atac\" in xb0):\n",
    "        raise RuntimeError(f\"Expected paired batches with keys ['rna','atac']; got {list(xb0.keys())}\")\n",
    "\n",
    "    rows = []\n",
    "    for spoint in sweep_points:\n",
    "        cfg0 = make_univi_cfg(rna_dim=rna_dim, atac_dim=atac_dim)\n",
    "        cfg  = apply_cfg_patch(cfg0, spoint.cfg_patch)\n",
    "\n",
    "        min_epochs = _infer_min_epochs_from_cfg(cfg) if gate_es_by_anneal_end else 0\n",
    "        min_epochs = int(max(min_epochs + int(extra_min_epochs), 0))\n",
    "\n",
    "        tr = train_one(\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            univi_cfg=cfg,\n",
    "            seed=int(seed),\n",
    "            device=device,\n",
    "            loss_mode=str(spoint.loss_mode),\n",
    "            v1_recon=str(spoint.v1_recon),\n",
    "            batch_size=int(batch_size),\n",
    "            patience=int(patience),\n",
    "            min_delta=float(min_delta),\n",
    "            min_epochs=int(min_epochs),\n",
    "            extra_model_kwargs=dict(spoint.model_kwargs),\n",
    "        )\n",
    "\n",
    "        met = evaluate_on_test(\n",
    "            tr.model,\n",
    "            test_loader,\n",
    "            device=device,\n",
    "            y_all=y_all,\n",
    "            k_knn=int(k_knn),\n",
    "            seed=int(seed),\n",
    "        )\n",
    "\n",
    "        row = {\n",
    "            \"sweep\": spoint.name,\n",
    "            \"loss_mode\": spoint.loss_mode,\n",
    "            \"v1_recon\": spoint.v1_recon,\n",
    "            \"seed\": int(seed),\n",
    "            \"batch_size\": int(batch_size),\n",
    "            \"patience\": int(patience),\n",
    "            \"min_delta\": float(min_delta),\n",
    "            \"min_epochs_gate\": int(min_epochs),\n",
    "            \"k_knn\": int(k_knn),\n",
    "            \"fuse_mode\": str(fuse_mode),\n",
    "            \"best_epoch\": tr.best_epoch,\n",
    "            \"best_val\": tr.best_val,\n",
    "            \"wall_seconds\": tr.wall_seconds,\n",
    "            \"gpu_peak_mem_mb\": tr.peak_mem_mb,\n",
    "            \"latent_dim\": int(getattr(cfg, \"latent_dim\", -1)),\n",
    "            \"beta\": float(getattr(cfg, \"beta\", np.nan)),\n",
    "            \"gamma\": float(getattr(cfg, \"gamma\", np.nan)),\n",
    "            \"kl_anneal_start\": int(getattr(cfg, \"kl_anneal_start\", -1)),\n",
    "            \"kl_anneal_end\": int(getattr(cfg, \"kl_anneal_end\", -1)),\n",
    "            \"align_anneal_start\": int(getattr(cfg, \"align_anneal_start\", -1)),\n",
    "            \"align_anneal_end\": int(getattr(cfg, \"align_anneal_end\", -1)),\n",
    "        }\n",
    "        row.update(info)\n",
    "        row.update(met)\n",
    "        rows.append(row)\n",
    "\n",
    "        fos = row.get(\"FOSCTTM\", np.nan)\n",
    "        fos_str = \"nan\" if (fos is None or (isinstance(fos, float) and np.isnan(fos))) else f\"{fos:.4f}\"\n",
    "        print(f\"[done] sweep={spoint.name:>20}  min_epochs={min_epochs:>4}  FOSCTTM={fos_str}  wall={tr.wall_seconds:.1f}s\")\n",
    "\n",
    "        del tr\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_grid = run_grid_paired_only(\n",
    "    sweep_points=SWEEP_POINTS,\n",
    "    seed=0,\n",
    "    batch_size=256,\n",
    "    patience=50,\n",
    "    min_delta=0.0,\n",
    "    k_knn=3,\n",
    "    fuse_mode=\"moe\",\n",
    "    num_workers=0,\n",
    "    gate_es_by_anneal_end=True,\n",
    "    extra_min_epochs=0,\n",
    ")\n",
    "\n",
    "save_tsv(df_grid, os.path.join(OUTDIR, \"param_grid_paired_only.tsv\"))\n",
    "df_grid.to_csv(os.path.join(OUTDIR, \"param_grid_paired_only.csv\"), index=False)\n",
    "df_grid.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce281a-2bc9-49bd-b50d-9de04a1a0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SWEEP_POINTS[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184929c9-8223-4ab3-9140-ea4d0cbc410e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 14) Scaling curve (paired-only; uses min_epochs ES gating)\n",
    "#      Self-contained utilities + optional oversampling beyond available train cells.\n",
    "#      - MPS: torch.mps current_allocated_memory + driver_allocated_memory (if available)\n",
    "#      - CUDA: sampled allocated/reserved + true peak stats\n",
    "#      - CPU: RSS + CPU% via psutil (optional)\n",
    "# =============================================================================\n",
    "import os, time, gc, threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# --- psutil (optional, but recommended) ---\n",
    "try:\n",
    "    import psutil\n",
    "    _proc = psutil.Process(os.getpid())\n",
    "except Exception:\n",
    "    psutil = None\n",
    "    _proc = None\n",
    "\n",
    "def get_cpu_rss_mb():\n",
    "    if _proc is None:\n",
    "        return None\n",
    "    try:\n",
    "        return float(_proc.memory_info().rss / (1024**2))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _prime_cpu_percent():\n",
    "    if psutil is None or _proc is None:\n",
    "        return\n",
    "    try:\n",
    "        _proc.cpu_percent(interval=None)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def resolve_device(device=None):\n",
    "    \"\"\"\n",
    "    Supports: None, 'mps', 'cpu', 'cuda', 'cuda:0', torch.device(...)\n",
    "    Default preference: MPS (if available) -> CUDA -> CPU\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "            device = torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda:0\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "    elif isinstance(device, str):\n",
    "        device = torch.device(device)\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        idx = 0 if device.index is None else int(device.index)\n",
    "        try:\n",
    "            torch.cuda.set_device(idx)\n",
    "        except Exception:\n",
    "            pass\n",
    "        device = torch.device(f\"cuda:{idx}\")\n",
    "\n",
    "    return device\n",
    "\n",
    "def _mps_mem_mb():\n",
    "    \"\"\"\n",
    "    Returns (allocated_mb, driver_allocated_mb) for MPS if available else (None, None)\n",
    "    \"\"\"\n",
    "    if not (hasattr(torch, \"mps\") and hasattr(torch.mps, \"current_allocated_memory\")):\n",
    "        return (None, None)\n",
    "    try:\n",
    "        a = float(torch.mps.current_allocated_memory() / (1024**2))\n",
    "        d = float(torch.mps.driver_allocated_memory() / (1024**2)) if hasattr(torch.mps, \"driver_allocated_memory\") else None\n",
    "        return (a, d)\n",
    "    except Exception:\n",
    "        return (None, None)\n",
    "\n",
    "def _cuda_reset_peaks(device):\n",
    "    if device.type != \"cuda\" or not torch.cuda.is_available():\n",
    "        return\n",
    "    try:\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def _cuda_peaks_mb(device):\n",
    "    \"\"\"\n",
    "    Returns (peak_alloc_mb, peak_reserved_mb) for CUDA else (None, None)\n",
    "    \"\"\"\n",
    "    if device.type != \"cuda\" or not torch.cuda.is_available():\n",
    "        return (None, None)\n",
    "    try:\n",
    "        alloc = float(torch.cuda.max_memory_allocated(device) / (1024**2))\n",
    "        reserv = float(torch.cuda.max_memory_reserved(device) / (1024**2))\n",
    "        return (alloc, reserv)\n",
    "    except Exception:\n",
    "        return (None, None)\n",
    "\n",
    "class ResourceMonitor:\n",
    "    \"\"\"\n",
    "    Samples CPU% + RSS, and (if possible) GPU memory.\n",
    "    - MPS: samples torch.mps current_allocated_memory + driver_allocated_memory\n",
    "    - CUDA: samples torch.cuda memory_allocated + memory_reserved\n",
    "    \"\"\"\n",
    "    def __init__(self, device, sample_every_s: float = 0.2):\n",
    "        self.device = device\n",
    "        self.sample_every_s = float(sample_every_s)\n",
    "\n",
    "        self._stop = threading.Event()\n",
    "        self._thr = None\n",
    "\n",
    "        # CPU samples\n",
    "        self.cpu_percent = []\n",
    "        self.rss_mb = []\n",
    "\n",
    "        # GPU samples (backend-dependent)\n",
    "        self.gpu_alloc_mb = []     # MPS allocated / CUDA allocated\n",
    "        self.gpu_driver_mb = []    # MPS driver_allocated (None on CUDA)\n",
    "        self.gpu_reserved_mb = []  # CUDA reserved (None on MPS)\n",
    "\n",
    "        _prime_cpu_percent()\n",
    "\n",
    "    def start(self):\n",
    "        self._thr = threading.Thread(target=self._run, daemon=True)\n",
    "        self._thr.start()\n",
    "        return self\n",
    "\n",
    "    def stop(self):\n",
    "        self._stop.set()\n",
    "        if self._thr is not None:\n",
    "            self._thr.join(timeout=2.0)\n",
    "\n",
    "    def _run(self):\n",
    "        while not self._stop.is_set():\n",
    "            # CPU\n",
    "            if psutil is not None and _proc is not None:\n",
    "                try:\n",
    "                    self.cpu_percent.append(float(_proc.cpu_percent(interval=None)))\n",
    "                    self.rss_mb.append(get_cpu_rss_mb())\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # GPU\n",
    "            if self.device.type == \"mps\":\n",
    "                a, d = _mps_mem_mb()\n",
    "                self.gpu_alloc_mb.append(a)\n",
    "                self.gpu_driver_mb.append(d)\n",
    "            elif self.device.type == \"cuda\" and torch.cuda.is_available():\n",
    "                try:\n",
    "                    self.gpu_alloc_mb.append(float(torch.cuda.memory_allocated(self.device) / (1024**2)))\n",
    "                    self.gpu_reserved_mb.append(float(torch.cuda.memory_reserved(self.device) / (1024**2)))\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            time.sleep(self.sample_every_s)\n",
    "\n",
    "    @staticmethod\n",
    "    def _clean(xs):\n",
    "        return [x for x in xs if x is not None and not (isinstance(x, float) and np.isnan(x))]\n",
    "\n",
    "    def summary(self):\n",
    "        def _mean(xs):\n",
    "            xs = self._clean(xs)\n",
    "            return float(np.mean(xs)) if xs else None\n",
    "\n",
    "        def _max(xs):\n",
    "            xs = self._clean(xs)\n",
    "            return float(np.max(xs)) if xs else None\n",
    "\n",
    "        return {\n",
    "            \"cpu_percent_mean\": _mean(self.cpu_percent),\n",
    "            \"cpu_percent_max\": _max(self.cpu_percent),\n",
    "            \"cpu_rss_peak_mb\": _max(self.rss_mb),\n",
    "\n",
    "            \"gpu_alloc_mean_mb\": _mean(self.gpu_alloc_mb),\n",
    "            \"gpu_alloc_peak_mb\": _max(self.gpu_alloc_mb),\n",
    "\n",
    "            # MPS-only\n",
    "            \"mps_driver_mean_mb\": _mean(self.gpu_driver_mb),\n",
    "            \"mps_driver_peak_mb\": _max(self.gpu_driver_mb),\n",
    "\n",
    "            # CUDA-only (sampled)\n",
    "            \"cuda_reserved_mean_mb_sampled\": _mean(self.gpu_reserved_mb),\n",
    "            \"cuda_reserved_peak_mb_sampled\": _max(self.gpu_reserved_mb),\n",
    "        }\n",
    "\n",
    "def sample_train_indices(idx, n_target, seed=0, allow_oversample=True):\n",
    "    \"\"\"\n",
    "    Returns indices of length n_target.\n",
    "    - If n_target <= len(idx): sample without replacement.\n",
    "    - If n_target >  len(idx): if allow_oversample, sample WITH replacement; else return idx (cap).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(int(seed))\n",
    "    idx = np.asarray(idx, dtype=np.int64)\n",
    "    n_target = int(n_target)\n",
    "\n",
    "    if n_target <= 0:\n",
    "        return idx[:0]\n",
    "\n",
    "    if n_target <= len(idx):\n",
    "        out = rng.choice(idx, size=n_target, replace=False)\n",
    "        return out.astype(np.int64)\n",
    "\n",
    "    # n_target > len(idx)\n",
    "    if not allow_oversample:\n",
    "        return idx.astype(np.int64)\n",
    "\n",
    "    out = rng.choice(idx, size=n_target, replace=True)\n",
    "    return out.astype(np.int64)\n",
    "\n",
    "def _empty_backend_cache(device):\n",
    "    if device.type == \"cuda\" and torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    elif device.type == \"mps\" and hasattr(torch, \"mps\") and hasattr(torch.mps, \"empty_cache\"):\n",
    "        try:\n",
    "            torch.mps.empty_cache()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def run_scaling_paired_only(\n",
    "    *,\n",
    "    n_cells_grid=(50, 100, 250, 500, 1000, 2000, 4000, 6000, 8000, 10000),\n",
    "    seed=0,\n",
    "    batch_size=256,\n",
    "    spoint=None,\n",
    "    patience=100,\n",
    "    min_delta=0.0,\n",
    "    num_workers=0,\n",
    "    gate_es_by_anneal_end: bool = True,\n",
    "    extra_min_epochs: int = 0,\n",
    "    device=None,\n",
    "    sample_every_s: float = 0.2,\n",
    "    allow_oversample: bool = True,\n",
    "):\n",
    "    if spoint is None:\n",
    "        spoint = SweepPoint(name=\"baseline\", cfg_patch={}, model_kwargs={}, loss_mode=\"v1\", v1_recon=\"moe\")\n",
    "\n",
    "    device = resolve_device(device)\n",
    "\n",
    "    rna_dim  = int(rna_tr_pp.n_vars)\n",
    "    atac_dim = int(atac_tr_lsi.n_vars)\n",
    "\n",
    "    rows = []\n",
    "    for n_cells in n_cells_grid:\n",
    "        # --- choose training indices (possibly oversampled) ---\n",
    "        tr_idx2 = sample_train_indices(\n",
    "            train_idx,\n",
    "            n_target=int(n_cells),\n",
    "            seed=int(seed),\n",
    "            allow_oversample=bool(allow_oversample),\n",
    "        )\n",
    "        n_eff = int(len(tr_idx2))\n",
    "        n_unique = int(np.unique(tr_idx2).size)\n",
    "        oversample_factor = float(n_eff / max(n_unique, 1))\n",
    "\n",
    "        train_loader, val_loader, test_loader, _info = make_paired_loaders(\n",
    "            base_dataset=dataset,\n",
    "            train_idx=tr_idx2,\n",
    "            val_idx=val_idx,\n",
    "            test_idx=test_idx,\n",
    "            batch_size=int(batch_size),\n",
    "            num_workers=int(num_workers),\n",
    "        )\n",
    "\n",
    "        cfg0 = make_univi_cfg(rna_dim=rna_dim, atac_dim=atac_dim)\n",
    "        cfg  = apply_cfg_patch(cfg0, spoint.cfg_patch)\n",
    "\n",
    "        min_epochs = _infer_min_epochs_from_cfg(cfg) if gate_es_by_anneal_end else 0\n",
    "        min_epochs = int(max(min_epochs + int(extra_min_epochs), 0))\n",
    "\n",
    "        cpu_before = get_cpu_rss_mb()\n",
    "\n",
    "        # Reset CUDA peaks if on CUDA (no-op on MPS/CPU)\n",
    "        _cuda_reset_peaks(device)\n",
    "\n",
    "        # Start monitor thread\n",
    "        mon = ResourceMonitor(device=device, sample_every_s=sample_every_s).start()\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        tr = train_one(\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            univi_cfg=cfg,\n",
    "            seed=int(seed),\n",
    "            device=device,\n",
    "            loss_mode=str(spoint.loss_mode),\n",
    "            v1_recon=str(spoint.v1_recon),\n",
    "            batch_size=int(batch_size),\n",
    "            patience=int(patience),\n",
    "            min_delta=float(min_delta),\n",
    "            min_epochs=int(min_epochs),\n",
    "            extra_model_kwargs=dict(spoint.model_kwargs),\n",
    "        )\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        mon.stop()\n",
    "        mon_s = mon.summary()\n",
    "\n",
    "        cpu_after = get_cpu_rss_mb()\n",
    "\n",
    "        # CUDA-only peaks (None on MPS/CPU)\n",
    "        cuda_peak_alloc_mb, cuda_peak_reserved_mb = _cuda_peaks_mb(device)\n",
    "\n",
    "        # MPS \"snapshot\" after run (helpful if sampling missed a spike)\n",
    "        mps_alloc_after_mb, mps_driver_after_mb = _mps_mem_mb() if device.type == \"mps\" else (None, None)\n",
    "\n",
    "        tr_peak = getattr(tr, \"peak_mem_mb\", None)  # optional field from your trainer\n",
    "\n",
    "        rows.append({\n",
    "            # --- scaling axes ---\n",
    "            \"n_train_cells_eff\": n_eff,          # may include duplicates\n",
    "            \"n_train_cells_unique\": n_unique,    # unique cells\n",
    "            \"oversample_factor\": oversample_factor,\n",
    "            \"allow_oversample\": bool(allow_oversample),\n",
    "\n",
    "            # --- sweep/config ---\n",
    "            \"sweep\": spoint.name,\n",
    "            \"loss_mode\": spoint.loss_mode,\n",
    "            \"v1_recon\": spoint.v1_recon,\n",
    "            \"seed\": int(seed),\n",
    "            \"batch_size\": int(batch_size),\n",
    "            \"patience\": int(patience),\n",
    "            \"min_delta\": float(min_delta),\n",
    "            \"min_epochs_gate\": int(min_epochs),\n",
    "\n",
    "            # --- timing ---\n",
    "            \"wall_seconds\": float(t1 - t0),\n",
    "\n",
    "            # --- device/backend ---\n",
    "            \"device\": str(device),\n",
    "            \"backend\": device.type,\n",
    "\n",
    "            # --- GPU mem (backend-aware; sampled) ---\n",
    "            \"gpu_alloc_peak_mb_sampled\": mon_s[\"gpu_alloc_peak_mb\"],  # CUDA allocated / MPS allocated\n",
    "            \"gpu_alloc_mean_mb_sampled\": mon_s[\"gpu_alloc_mean_mb\"],\n",
    "            \"mps_driver_peak_mb_sampled\": mon_s[\"mps_driver_peak_mb\"],  # MPS only\n",
    "            \"mps_driver_mean_mb_sampled\": mon_s[\"mps_driver_mean_mb\"],\n",
    "            \"mps_alloc_after_mb\": mps_alloc_after_mb,   # MPS only\n",
    "            \"mps_driver_after_mb\": mps_driver_after_mb, # MPS only\n",
    "\n",
    "            # --- CUDA-only peaks/stats ---\n",
    "            \"cuda_peak_alloc_mb\": cuda_peak_alloc_mb,\n",
    "            \"cuda_peak_reserved_mb\": cuda_peak_reserved_mb,\n",
    "            \"cuda_reserved_peak_mb_sampled\": mon_s[\"cuda_reserved_peak_mb_sampled\"],\n",
    "            \"cuda_reserved_mean_mb_sampled\": mon_s[\"cuda_reserved_mean_mb_sampled\"],\n",
    "\n",
    "            # --- optional trainer-reported value ---\n",
    "            \"gpu_peak_mem_mb_trainone\": tr_peak,\n",
    "\n",
    "            # --- CPU metrics ---\n",
    "            \"cpu_rss_mb_before\": cpu_before,\n",
    "            \"cpu_rss_mb_after\": cpu_after,\n",
    "            \"cpu_rss_mb_delta\": (None if (cpu_before is None or cpu_after is None) else float(cpu_after - cpu_before)),\n",
    "            \"cpu_rss_peak_mb_sampled\": mon_s[\"cpu_rss_peak_mb\"],\n",
    "            \"cpu_percent_mean\": mon_s[\"cpu_percent_mean\"],\n",
    "            \"cpu_percent_max\": mon_s[\"cpu_percent_max\"],\n",
    "\n",
    "            # --- training outputs ---\n",
    "            \"best_epoch\": getattr(tr, \"best_epoch\", None),\n",
    "            \"best_val\": getattr(tr, \"best_val\", None),\n",
    "\n",
    "            # --- bookkeeping ---\n",
    "            \"train_paired\": int(n_eff),\n",
    "            \"train_unpaired\": 0,\n",
    "            \"overlap_fraction\": 1.0,\n",
    "            \"drop_modality\": \"none\",\n",
    "            \"latent_dim\": int(getattr(cfg, \"latent_dim\", -1)),\n",
    "            \"beta\": float(getattr(cfg, \"beta\", np.nan)),\n",
    "            \"gamma\": float(getattr(cfg, \"gamma\", np.nan)),\n",
    "            \"kl_anneal_start\": int(getattr(cfg, \"kl_anneal_start\", -1)),\n",
    "            \"kl_anneal_end\": int(getattr(cfg, \"kl_anneal_end\", -1)),\n",
    "            \"align_anneal_start\": int(getattr(cfg, \"align_anneal_start\", -1)),\n",
    "            \"align_anneal_end\": int(getattr(cfg, \"align_anneal_end\", -1)),\n",
    "        })\n",
    "\n",
    "        print(\n",
    "            f\"[scale] n_eff={n_eff:>6} n_unique={n_unique:>6} x{oversample_factor:>4.1f} \"\n",
    "            f\"min_epochs={min_epochs:>4} wall={t1-t0:>7.1f}s backend={device.type} \"\n",
    "            f\"gpu_alloc_peak={mon_s['gpu_alloc_peak_mb']}MB mps_driver_peak={mon_s['mps_driver_peak_mb']}MB \"\n",
    "            f\"cpu_rss_peak={mon_s['cpu_rss_peak_mb']}MB\"\n",
    "        )\n",
    "\n",
    "        # cleanup\n",
    "        del tr\n",
    "        gc.collect()\n",
    "        _empty_backend_cache(device)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --- example call ---\n",
    "df_scale = run_scaling_paired_only(\n",
    "    n_cells_grid=(10, 25, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1500, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 15000, 20000, 30000, 40000, 50000, 100000, 500000),\n",
    "    #n_cells_grid=(50000, 100000),\n",
    "    seed=0,\n",
    "    batch_size=256,\n",
    "    spoint=SWEEP_POINTS[0],\n",
    "    patience=50,\n",
    "    min_delta=0.0,\n",
    "    num_workers=0,\n",
    "    gate_es_by_anneal_end=True,\n",
    "    extra_min_epochs=0,\n",
    "    device=\"mps\",\n",
    "    sample_every_s=0.2,\n",
    "    allow_oversample=True,   # <- set False to keep the original \"cap at max unique\" behavior\n",
    ")\n",
    "\n",
    "save_tsv(df_scale, os.path.join(OUTDIR, \"scaling_curve.tsv\"))\n",
    "df_scale.to_csv(os.path.join(OUTDIR, \"scaling_curve.csv\"), index=False)\n",
    "df_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8e2b1-0a0a-47aa-8c60-225541528ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 15) Plotting (paired-only) ----\n",
    "# =============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# ---- global defaults ----\n",
    "mpl.rcParams[\"figure.figsize\"] = (14.0, 12.0)     # default size for plt.figure()\n",
    "mpl.rcParams[\"figure.dpi\"] = 300                  # DPI for on-screen display\n",
    "mpl.rcParams[\"savefig.dpi\"] = 300                 # default DPI for saved files (if you don't override)\n",
    "mpl.rcParams[\"savefig.bbox\"] = \"tight\"            # nice default cropping\n",
    "\n",
    "def _savefig(savepath):\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=300)\n",
    "        print(\"[wrote]\", savepath)\n",
    "\n",
    "def barplot_best(df, metric, *, top_n=30, ascending=None, savepath=None, title=None):\n",
    "    if metric not in df.columns:\n",
    "        print(f\"[skip] missing metric: {metric}\")\n",
    "        return\n",
    "    d = df.copy()\n",
    "    d[metric] = pd.to_numeric(d[metric], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[metric])\n",
    "\n",
    "    if ascending is None:\n",
    "        m = metric.lower()\n",
    "        ascending = any(s in m for s in [\"loss\", \"error\", \"dist\", \"foscttm\", \"rmse\", \"mae\"])\n",
    "\n",
    "    d = d.sort_values(metric, ascending=bool(ascending)).head(int(top_n))\n",
    "\n",
    "    # ---- plot ----\n",
    "    fig, ax = plt.subplots(figsize=(10, 0.32 * len(d) + 2))\n",
    "\n",
    "    y = d[\"sweep\"].astype(str).to_numpy()\n",
    "    x = d[metric].astype(float).to_numpy()\n",
    "\n",
    "    ax.barh(y, x, height=0.9)  # slightly thicker bars (optional but looks nicer)\n",
    "\n",
    "    ax.set_xlabel(metric)\n",
    "    ax.set_ylabel(\"sweep\")\n",
    "    ax.set_title(title if title is not None else f\"Top {top_n}: {metric}\")\n",
    "\n",
    "    # ---- remove the big top/bottom gap ----\n",
    "    ax.margins(y=0)                 # kill categorical padding\n",
    "    ax.set_ylim(-0.5, len(d) - 0.5) # clamp to first/last bar\n",
    "\n",
    "    # If you want labels in the same order as your sorted rows (best at top):\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    _savefig(savepath)\n",
    "    plt.show()\n",
    "\n",
    "def scatter_tradeoff(df, x, y, *, annotate_top=0, savepath=None, title=None):\n",
    "    if x not in df.columns or y not in df.columns:\n",
    "        print(f\"[skip] missing: {x} or {y}\")\n",
    "        return\n",
    "\n",
    "    d = df[[\"sweep\", x, y]].copy()\n",
    "    d[x] = pd.to_numeric(d[x], errors=\"coerce\")\n",
    "    d[y] = pd.to_numeric(d[y], errors=\"coerce\")\n",
    "    d = d.dropna()\n",
    "\n",
    "    plt.figure(figsize=(6.5, 5))\n",
    "    plt.scatter(d[x].astype(float), d[y].astype(float))\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.title(title if title is not None else f\"{y} vs {x}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if int(annotate_top) > 0:\n",
    "        y_asc = any(s in y.lower() for s in [\"loss\", \"error\", \"dist\", \"foscttm\", \"rmse\", \"mae\"])\n",
    "        dd = d.sort_values(y, ascending=bool(y_asc)).head(int(annotate_top))\n",
    "        for _, r in dd.iterrows():\n",
    "            plt.annotate(str(r[\"sweep\"]), (float(r[x]), float(r[y])), fontsize=8)\n",
    "\n",
    "    _savefig(savepath)\n",
    "    plt.show()\n",
    "\n",
    "def heatmap_hparams_vs_metric(df, metric, hp_x=\"beta\", hp_y=\"gamma\", *, agg=\"median\", savepath=None, title=None):\n",
    "    needed = [metric, hp_x, hp_y]\n",
    "    for c in needed:\n",
    "        if c not in df.columns:\n",
    "            print(f\"[skip] missing col: {c}\")\n",
    "            return\n",
    "\n",
    "    d = df[[hp_x, hp_y, metric]].copy()\n",
    "    d[hp_x] = pd.to_numeric(d[hp_x], errors=\"coerce\")\n",
    "    d[hp_y] = pd.to_numeric(d[hp_y], errors=\"coerce\")\n",
    "    d[metric] = pd.to_numeric(d[metric], errors=\"coerce\")\n",
    "    d = d.dropna()\n",
    "\n",
    "    if agg == \"mean\":\n",
    "        pv = d.groupby([hp_y, hp_x])[metric].mean().unstack(hp_x)\n",
    "    elif agg == \"min\":\n",
    "        pv = d.groupby([hp_y, hp_x])[metric].min().unstack(hp_x)\n",
    "    elif agg == \"max\":\n",
    "        pv = d.groupby([hp_y, hp_x])[metric].max().unstack(hp_x)\n",
    "    else:\n",
    "        pv = d.groupby([hp_y, hp_x])[metric].median().unstack(hp_x)\n",
    "\n",
    "    plt.figure(figsize=(1.2*max(6, pv.shape[1]), 1.0*max(4, pv.shape[0])))\n",
    "    plt.imshow(pv.values, aspect=\"auto\")\n",
    "    plt.xticks(range(pv.shape[1]), [str(x) for x in pv.columns], rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(pv.shape[0]), [str(y) for y in pv.index])\n",
    "    plt.xlabel(hp_x)\n",
    "    plt.ylabel(hp_y)\n",
    "    plt.title(title if title is not None else f\"{metric} heatmap ({agg})\")\n",
    "    plt.colorbar(label=metric)\n",
    "    plt.tight_layout()\n",
    "    _savefig(savepath)\n",
    "    plt.show()\n",
    "\n",
    "def plot_scaling_multi(df, *, saveprefix=None):\n",
    "    if \"n_train_cells\" in df.columns and \"wall_seconds\" in df.columns:\n",
    "        d = df.sort_values(\"n_train_cells\")\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(d[\"n_train_cells\"], d[\"wall_seconds\"], marker=\"o\")\n",
    "        plt.xlabel(\"# train cells\")\n",
    "        plt.ylabel(\"wall seconds (train)\")\n",
    "        plt.title(\"Scaling: runtime vs #cells\")\n",
    "        plt.tight_layout()\n",
    "        _savefig(None if saveprefix is None else f\"{saveprefix}_runtime.png\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(6,4))\n",
    "        thr = d[\"n_train_cells\"].astype(float) / np.maximum(d[\"wall_seconds\"].astype(float), 1e-9)\n",
    "        plt.plot(d[\"n_train_cells\"], thr, marker=\"o\")\n",
    "        plt.xlabel(\"# train cells\")\n",
    "        plt.ylabel(\"train throughput (cells/sec)\")\n",
    "        plt.title(\"Scaling: throughput vs #cells\")\n",
    "        plt.tight_layout()\n",
    "        _savefig(None if saveprefix is None else f\"{saveprefix}_throughput.png\")\n",
    "        plt.show()\n",
    "\n",
    "    if \"n_train_cells\" in df.columns and \"gpu_peak_mem_mb\" in df.columns:\n",
    "        d = df.sort_values(\"n_train_cells\")\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(d[\"n_train_cells\"], d[\"gpu_peak_mem_mb\"], marker=\"o\")\n",
    "        plt.xlabel(\"# train cells\")\n",
    "        plt.ylabel(\"GPU peak mem (MB)\")\n",
    "        plt.title(\"Scaling: GPU peak memory vs #cells\")\n",
    "        plt.tight_layout()\n",
    "        _savefig(None if saveprefix is None else f\"{saveprefix}_gpu_mem.png\")\n",
    "        plt.show()\n",
    "\n",
    "    if \"n_train_cells\" in df.columns and \"cpu_rss_mb_delta\" in df.columns:\n",
    "        d = df.sort_values(\"n_train_cells\")\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(d[\"n_train_cells\"], d[\"cpu_rss_mb_delta\"], marker=\"o\")\n",
    "        plt.xlabel(\"# train cells\")\n",
    "        plt.ylabel(\"CPU RSS delta (MB)\")\n",
    "        plt.title(\"Scaling: CPU memory delta vs #cells\")\n",
    "        plt.tight_layout()\n",
    "        _savefig(None if saveprefix is None else f\"{saveprefix}_cpu_mem_delta.png\")\n",
    "        plt.show()\n",
    "\n",
    "# ---- leaderboards ----\n",
    "barplot_best(\n",
    "    df_grid, \"FOSCTTM\", top_n=50,\n",
    "    savepath=os.path.join(OUTDIR, \"figures\", \"grid_top_FOSCTTM.png\"),\n",
    "    title=\"Grid leaderboard: FOSCTTM (lower is better)\"\n",
    ")\n",
    "\n",
    "for m in [\"LT_RNA2ATAC_macroF1\", \"LT_ATAC2RNA_macroF1\", \"mixing_1minus_samefrac_k15\"]:\n",
    "    if m in df_grid.columns:\n",
    "        barplot_best(\n",
    "            df_grid, m, top_n=50, ascending=False,\n",
    "            savepath=os.path.join(OUTDIR, \"figures\", f\"grid_top_{m}.png\")\n",
    "        )\n",
    "\n",
    "# ---- tradeoffs ----\n",
    "if \"FOSCTTM\" in df_grid.columns and \"LT_RNA2ATAC_macroF1\" in df_grid.columns:\n",
    "    scatter_tradeoff(\n",
    "        df_grid, \"FOSCTTM\", \"LT_RNA2ATAC_macroF1\",\n",
    "        annotate_top=8,\n",
    "        savepath=os.path.join(OUTDIR, \"figures\", \"tradeoff_LTmacroF1_vs_FOSCTTM.png\"),\n",
    "        title=\"Tradeoff: label transfer vs FOSCTTM\"\n",
    "    )\n",
    "\n",
    "if \"FOSCTTM\" in df_grid.columns and \"mixing_1minus_samefrac_k15\" in df_grid.columns:\n",
    "    scatter_tradeoff(\n",
    "        df_grid, \"FOSCTTM\", \"mixing_1minus_samefrac_k15\",\n",
    "        annotate_top=8,\n",
    "        savepath=os.path.join(OUTDIR, \"figures\", \"tradeoff_mixing_vs_FOSCTTM.png\"),\n",
    "        title=\"Tradeoff: mixing vs FOSCTTM\"\n",
    "    )\n",
    "\n",
    "# ---- hyperparameter maps ----\n",
    "if \"beta\" in df_grid.columns and \"gamma\" in df_grid.columns:\n",
    "    if \"FOSCTTM\" in df_grid.columns:\n",
    "        heatmap_hparams_vs_metric(\n",
    "            df_grid, \"FOSCTTM\", hp_x=\"beta\", hp_y=\"gamma\", agg=\"median\",\n",
    "            savepath=os.path.join(OUTDIR, \"figures\", \"heatmap_FOSCTTM_beta_gamma.png\"),\n",
    "            title=\"FOSCTTM vs (beta, gamma)\"\n",
    "        )\n",
    "    if \"LT_RNA2ATAC_macroF1\" in df_grid.columns:\n",
    "        heatmap_hparams_vs_metric(\n",
    "            df_grid, \"LT_RNA2ATAC_macroF1\", hp_x=\"beta\", hp_y=\"gamma\", agg=\"median\",\n",
    "            savepath=os.path.join(OUTDIR, \"figures\", \"heatmap_LT_RNA2ATAC_macroF1_beta_gamma.png\"),\n",
    "            title=\"LT_RNA2ATAC_macroF1 vs (beta, gamma)\"\n",
    "        )\n",
    "\n",
    "# ---- scaling plots ----\n",
    "plot_scaling_multi(df_scale, saveprefix=os.path.join(OUTDIR, \"scaling\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ae05e-7bda-456a-8bed-e853b551b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- Tradeoff visualization suite (clean, scalable, paper-friendly) ----\n",
    "# Produces 4 plots per (x, y):\n",
    "#   A) density (hexbin) + optional highlight\n",
    "#   B) scatter + Pareto front + few labels\n",
    "#   C) scatter colored by beta\n",
    "#   D) scatter colored by gamma\n",
    "#\n",
    "# Key ideas:\n",
    "#   - Use hexbin for the \"many points\" overview (no clutter).\n",
    "#   - Use Pareto front to identify true tradeoffs (not just top-by-y).\n",
    "#   - Label only a few points (non-overlapping, near points) for readability.\n",
    "#   - Only one continuous colormap per panel (beta OR gamma), never both.\n",
    "# =============================================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 300\n",
    "mpl.rcParams[\"savefig.dpi\"] = 300\n",
    "mpl.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _ensure_dir(p):\n",
    "    if p:\n",
    "        os.makedirs(os.path.dirname(p), exist_ok=True)\n",
    "\n",
    "def _tight_limits(ax, x, y, pad_frac=0.03, top_pad_frac=0.05):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    xr = float(np.nanmax(x) - np.nanmin(x)) if len(x) else 1.0\n",
    "    yr = float(np.nanmax(y) - np.nanmin(y)) if len(y) else 1.0\n",
    "    xr = xr if xr > 0 else 1.0\n",
    "    yr = yr if yr > 0 else 1.0\n",
    "    ax.set_xlim(float(np.nanmin(x) - pad_frac * xr), float(np.nanmax(x) + pad_frac * xr))\n",
    "    ax.set_ylim(float(np.nanmin(y) - pad_frac * yr), float(np.nanmax(y) + top_pad_frac * yr))\n",
    "\n",
    "def _objective_direction(metric_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Return 'min' if lower is better, else 'max'. You can extend this list.\n",
    "    \"\"\"\n",
    "    m = metric_name.lower()\n",
    "    if any(s in m for s in [\"loss\", \"error\", \"dist\", \"foscttm\", \"rmse\", \"mae\", \"rankfrac\"]):\n",
    "        return \"min\"\n",
    "    return \"max\"\n",
    "\n",
    "def _pareto_front(df, x, y, x_dir=\"min\", y_dir=\"max\"):\n",
    "    \"\"\"\n",
    "    Compute Pareto-efficient points for two objectives.\n",
    "      - x_dir: 'min' or 'max'\n",
    "      - y_dir: 'min' or 'max'\n",
    "    Returns df subset (Pareto front), sorted for nicer plotting.\n",
    "    \"\"\"\n",
    "    d = df[[ \"sweep\", x, y ]].copy()\n",
    "\n",
    "    # Convert to a \"minimize both\" problem:\n",
    "    xx = d[x].to_numpy(dtype=float)\n",
    "    yy = d[y].to_numpy(dtype=float)\n",
    "    if x_dir == \"max\":\n",
    "        xx = -xx\n",
    "    if y_dir == \"max\":\n",
    "        yy = -yy\n",
    "\n",
    "    # Sort by xx then keep those with best (lowest) yy so far\n",
    "    order = np.argsort(xx)\n",
    "    xx_s = xx[order]\n",
    "    yy_s = yy[order]\n",
    "    keep = np.zeros(len(d), dtype=bool)\n",
    "\n",
    "    best_y = np.inf\n",
    "    for k, (xs, ys) in enumerate(zip(xx_s, yy_s)):\n",
    "        if ys < best_y:\n",
    "            best_y = ys\n",
    "            keep[order[k]] = True\n",
    "\n",
    "    front = d.loc[keep].copy()\n",
    "\n",
    "    # Sort front for line plotting (by x in original direction)\n",
    "    front = front.sort_values(x, ascending=(x_dir == \"min\"))\n",
    "    return front\n",
    "\n",
    "def _pick_nonoverlapping_points(ax, xs, ys, k, min_dist_px=28):\n",
    "    \"\"\"\n",
    "    Greedy select up to k points separated by at least min_dist_px in DISPLAY coords.\n",
    "    Preserves order of xs/ys (so provide \"best-first\" ordering).\n",
    "    \"\"\"\n",
    "    pts = ax.transData.transform(np.c_[xs, ys])  # pixels\n",
    "    chosen = []\n",
    "    for i, p in enumerate(pts):\n",
    "        if len(chosen) >= k:\n",
    "            break\n",
    "        ok = True\n",
    "        for j in chosen:\n",
    "            if np.linalg.norm(p - pts[j]) < float(min_dist_px):\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            chosen.append(i)\n",
    "    return chosen\n",
    "\n",
    "def _prep_xy(df, x, y, extra_cols=()):\n",
    "    cols = [\"sweep\", x, y] + list(extra_cols)\n",
    "    for c in [\"sweep\", x, y]:\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"missing column: {c}\")\n",
    "\n",
    "    d = df[cols].copy()\n",
    "    for c in [x, y] + list(extra_cols):\n",
    "        if c in d.columns:\n",
    "            d[c] = pd.to_numeric(d[c], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[x, y])\n",
    "    return d\n",
    "\n",
    "# ---------- plotters ----------\n",
    "def plot_tradeoff_density(\n",
    "    df, x, y, *,\n",
    "    savepath=None, title=None,\n",
    "    gridsize=45,\n",
    "    mincnt=1,\n",
    "    figsize=(6.8, 5.0),\n",
    "):\n",
    "    \"\"\"\n",
    "    Big-picture plot: density via hexbin. Great when there are many points.\n",
    "    \"\"\"\n",
    "    d = _prep_xy(df, x, y)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    hb = ax.hexbin(\n",
    "        d[x].to_numpy(dtype=float),\n",
    "        d[y].to_numpy(dtype=float),\n",
    "        gridsize=int(gridsize),\n",
    "        mincnt=int(mincnt),\n",
    "        linewidths=0.0,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(y)\n",
    "    ax.set_title(title if title is not None else f\"{y} vs {x} (density)\", pad=10)\n",
    "    _tight_limits(ax, d[x].to_numpy(), d[y].to_numpy())\n",
    "\n",
    "    cbar = fig.colorbar(hb, ax=ax, pad=0.02)\n",
    "    cbar.set_label(\"count\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if savepath:\n",
    "        _ensure_dir(savepath)\n",
    "        plt.savefig(savepath, dpi=300, bbox_inches=\"tight\")\n",
    "        print(\"[wrote]\", savepath)\n",
    "    plt.show()\n",
    "\n",
    "def plot_tradeoff_pareto(\n",
    "    df, x, y, *,\n",
    "    savepath=None, title=None,\n",
    "    figsize=(6.8, 5.0),\n",
    "    s=26, alpha=0.45,\n",
    "    edge_alpha=0.12, edge_lw=0.25,\n",
    "    label_k=10,\n",
    "    label_candidates=40,\n",
    "    label_min_dist_px=30,\n",
    "):\n",
    "    \"\"\"\n",
    "    Scatter + Pareto front + a few labels from the Pareto front.\n",
    "    This is the most decision-useful view.\n",
    "    \"\"\"\n",
    "    d = _prep_xy(df, x, y)\n",
    "\n",
    "    x_dir = _objective_direction(x)   # usually x=FOSCTTM => 'min'\n",
    "    y_dir = _objective_direction(y)   # usually y=macroF1 => 'max'\n",
    "    front = _pareto_front(d, x, y, x_dir=x_dir, y_dir=y_dir)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Background cloud\n",
    "    ax.scatter(\n",
    "        d[x].to_numpy(dtype=float),\n",
    "        d[y].to_numpy(dtype=float),\n",
    "        s=s, alpha=alpha,\n",
    "        edgecolors=(0,0,0,edge_alpha),\n",
    "        linewidths=edge_lw,\n",
    "        rasterized=True,  # makes saved PDFs smaller if you export to pdf later\n",
    "    )\n",
    "\n",
    "    # Pareto front overlay (line + points)\n",
    "    ax.plot(front[x].to_numpy(dtype=float), front[y].to_numpy(dtype=float), linewidth=1.2)\n",
    "    ax.scatter(front[x].to_numpy(dtype=float), front[y].to_numpy(dtype=float), s=max(38, s+8), alpha=0.95)\n",
    "\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(y)\n",
    "    ax.set_title(title if title is not None else f\"{y} vs {x} (Pareto front)\", pad=10)\n",
    "    _tight_limits(ax, d[x].to_numpy(), d[y].to_numpy())\n",
    "\n",
    "    # Label a subset of Pareto points (best distributed)\n",
    "    if int(label_k) > 0 and len(front) > 0:\n",
    "        # choose candidate Pareto points (e.g., first N along front)\n",
    "        cand = front.copy()\n",
    "        if len(cand) > int(label_candidates):\n",
    "            cand = cand.head(int(label_candidates))\n",
    "\n",
    "        fig.canvas.draw()  # needed for coordinate transforms\n",
    "        xs = cand[x].to_numpy(dtype=float)\n",
    "        ys = cand[y].to_numpy(dtype=float)\n",
    "\n",
    "        keep = _pick_nonoverlapping_points(ax, xs, ys, k=int(label_k), min_dist_px=float(label_min_dist_px))\n",
    "        cand = cand.iloc[keep].copy()\n",
    "\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        y_thr = ymax - 0.10 * (ymax - ymin)  # flip label below point if near top\n",
    "\n",
    "        for _, r in cand.iterrows():\n",
    "            px, py = float(r[x]), float(r[y])\n",
    "            dx, dy, va = 6, 6, \"bottom\"\n",
    "            if py >= y_thr:\n",
    "                dx, dy, va = 6, -10, \"top\"\n",
    "            ax.annotate(\n",
    "                str(r[\"sweep\"]),\n",
    "                xy=(px, py),\n",
    "                xytext=(dx, dy),\n",
    "                textcoords=\"offset points\",\n",
    "                fontsize=8,\n",
    "                ha=\"left\", va=va,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.15\", fc=\"white\", ec=\"none\", alpha=0.75),\n",
    "                clip_on=True,\n",
    "            )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if savepath:\n",
    "        _ensure_dir(savepath)\n",
    "        plt.savefig(savepath, dpi=300, bbox_inches=\"tight\")\n",
    "        print(\"[wrote]\", savepath)\n",
    "    plt.show()\n",
    "\n",
    "def plot_tradeoff_colored(\n",
    "    df, x, y, *, color_by,\n",
    "    savepath=None, title=None,\n",
    "    figsize=(6.8, 5.0),\n",
    "    s=26, alpha=0.65,\n",
    "    edge_alpha=0.15, edge_lw=0.25,\n",
    "    cmap=\"viridis\",\n",
    "    vmin=None, vmax=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    One continuous variable per panel (beta OR gamma OR gpu mem). Clean + readable.\n",
    "    \"\"\"\n",
    "    d = _prep_xy(df, x, y, extra_cols=(color_by,))\n",
    "    if color_by not in d.columns:\n",
    "        print(f\"[skip] missing: {color_by}\")\n",
    "        return\n",
    "    d = d.dropna(subset=[color_by])\n",
    "    if len(d) == 0:\n",
    "        print(\"[skip] no finite rows after cleaning.\")\n",
    "        return\n",
    "\n",
    "    cvals = d[color_by].to_numpy(dtype=float)\n",
    "    if vmin is None: vmin = float(np.nanmin(cvals))\n",
    "    if vmax is None: vmax = float(np.nanmax(cvals))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sc = ax.scatter(\n",
    "        d[x].to_numpy(dtype=float),\n",
    "        d[y].to_numpy(dtype=float),\n",
    "        c=cvals,\n",
    "        s=s, alpha=alpha,\n",
    "        cmap=cmap,\n",
    "        vmin=vmin, vmax=vmax,\n",
    "        edgecolors=(0,0,0,edge_alpha),\n",
    "        linewidths=edge_lw,\n",
    "        rasterized=True,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(y)\n",
    "    ax.set_title(title if title is not None else f\"{y} vs {x} (colored by {color_by})\", pad=10)\n",
    "    _tight_limits(ax, d[x].to_numpy(), d[y].to_numpy())\n",
    "\n",
    "    cbar = fig.colorbar(sc, ax=ax, pad=0.02)\n",
    "    cbar.set_label(color_by)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if savepath:\n",
    "        _ensure_dir(savepath)\n",
    "        plt.savefig(savepath, dpi=300, bbox_inches=\"tight\")\n",
    "        print(\"[wrote]\", savepath)\n",
    "    plt.show()\n",
    "\n",
    "# ---------- one-call suite ----------\n",
    "def tradeoff_viz_suite(\n",
    "    df, x, y, *,\n",
    "    outdir,\n",
    "    stem,\n",
    "    figsize=(6.8, 5.0),\n",
    "    do_density=True,\n",
    "    do_pareto=True,\n",
    "    do_beta=True,\n",
    "    do_gamma=True,\n",
    "):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    if do_density:\n",
    "        plot_tradeoff_density(\n",
    "            df, x, y,\n",
    "            figsize=figsize,\n",
    "            savepath=os.path.join(outdir, f\"{stem}__density.png\"),\n",
    "            title=f\"{y} vs {x} (density)\",\n",
    "        )\n",
    "\n",
    "    if do_pareto:\n",
    "        plot_tradeoff_pareto(\n",
    "            df, x, y,\n",
    "            figsize=figsize,\n",
    "            savepath=os.path.join(outdir, f\"{stem}__pareto.png\"),\n",
    "            title=f\"{y} vs {x} (Pareto front)\",\n",
    "            label_k=10,\n",
    "            label_candidates=60,\n",
    "            label_min_dist_px=32,\n",
    "        )\n",
    "\n",
    "    # Fixed scales for comparability across multiple plots with same df\n",
    "    if do_beta and (\"beta\" in df.columns):\n",
    "        bmin, bmax = float(pd.to_numeric(df[\"beta\"], errors=\"coerce\").min()), float(pd.to_numeric(df[\"beta\"], errors=\"coerce\").max())\n",
    "        plot_tradeoff_colored(\n",
    "            df, x, y, color_by=\"beta\",\n",
    "            figsize=figsize,\n",
    "            vmin=bmin, vmax=bmax,\n",
    "            savepath=os.path.join(outdir, f\"{stem}__beta.png\"),\n",
    "            title=f\"{y} vs {x} (colored by beta)\",\n",
    "        )\n",
    "\n",
    "    if do_gamma and (\"gamma\" in df.columns):\n",
    "        gmin, gmax = float(pd.to_numeric(df[\"gamma\"], errors=\"coerce\").min()), float(pd.to_numeric(df[\"gamma\"], errors=\"coerce\").max())\n",
    "        plot_tradeoff_colored(\n",
    "            df, x, y, color_by=\"gamma\",\n",
    "            figsize=figsize,\n",
    "            vmin=gmin, vmax=gmax,\n",
    "            savepath=os.path.join(outdir, f\"{stem}__gamma.png\"),\n",
    "            title=f\"{y} vs {x} (colored by gamma)\",\n",
    "        )\n",
    "\n",
    "# =============================================================================\n",
    "# ---- Example usage (your main tradeoff) ----\n",
    "# =============================================================================\n",
    "tradeoff_viz_suite(\n",
    "    df_grid,\n",
    "    x=\"FOSCTTM\",\n",
    "    y=\"LT_RNA2ATAC_macroF1\",\n",
    "    outdir=os.path.join(OUTDIR, \"figures\"),\n",
    "    stem=\"tradeoff_LTmacroF1_vs_FOSCTTM\",\n",
    "    figsize=(14, 12),\n",
    "    do_density=True,\n",
    "    do_pareto=True,\n",
    "    do_beta=True,\n",
    "    do_gamma=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe99ea-0562-4b34-bbff-4412bbce4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ---- 15) Plotting (paired-only) ----\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ---- metric metadata ----\n",
    "# Higher-is-better by default unless listed.\n",
    "LOWER_BETTER_SUBSTR = [\"loss\", \"error\", \"dist\", \"foscttm\", \"rmse\", \"mae\", \"db_\"]\n",
    "DEFAULT_KS = (1, 10, 25, 50, 100)\n",
    "\n",
    "def _is_lower_better(metric: str) -> bool:\n",
    "    m = metric.lower()\n",
    "    return any(s in m for s in LOWER_BETTER_SUBSTR)\n",
    "\n",
    "def _coerce_numeric(df, cols):\n",
    "    d = df.copy()\n",
    "    for c in cols:\n",
    "        if c in d.columns:\n",
    "            d[c] = pd.to_numeric(d[c], errors=\"coerce\")\n",
    "    return d\n",
    "\n",
    "def _savefig(savepath):\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=300)\n",
    "        print(\"[wrote]\", savepath)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Leaderboard barh\n",
    "# -----------------------------------------------------------------------------\n",
    "def barplot_best(df, metric, *, top_n=30, ascending=None, savepath=None, title=None):\n",
    "    if metric not in df.columns:\n",
    "        print(f\"[skip] missing metric: {metric}\")\n",
    "        return\n",
    "    d = _coerce_numeric(df, [metric]).dropna(subset=[metric]).copy()\n",
    "\n",
    "    if ascending is None:\n",
    "        ascending = _is_lower_better(metric)\n",
    "\n",
    "    d = d.sort_values(metric, ascending=bool(ascending)).head(int(top_n))\n",
    "\n",
    "    plt.figure(figsize=(10, 0.32 * len(d) + 2))\n",
    "    plt.barh(d[\"sweep\"].astype(str), d[metric].astype(float))\n",
    "    plt.xlabel(metric)\n",
    "    plt.ylabel(\"sweep\")\n",
    "    plt.title(title if title is not None else f\"Top {top_n}: {metric} ({'lower' if ascending else 'higher'} is better)\")\n",
    "    plt.tight_layout()\n",
    "    _savefig(savepath)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Tradeoff scatter + optional Pareto highlight\n",
    "# -----------------------------------------------------------------------------\n",
    "def pareto_mask(x, y, *, x_lower_better=False, y_lower_better=False):\n",
    "    \"\"\"\n",
    "    Returns boolean mask of Pareto-optimal points for 2D.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float)\n",
    "    y = np.asarray(y, float)\n",
    "\n",
    "    # Convert to \"higher is better\" by flipping if needed\n",
    "    xx = -x if x_lower_better else x\n",
    "    yy = -y if y_lower_better else y\n",
    "\n",
    "    n = len(xx)\n",
    "    keep = np.ones(n, dtype=bool)\n",
    "    for i in range(n):\n",
    "        if not keep[i]:\n",
    "            continue\n",
    "        dominated = (xx >= xx[i]) & (yy >= yy[i]) & ((xx > xx[i]) | (yy > yy[i]))\n",
    "        dominated[i] = False\n",
    "        keep[dominated] = False\n",
    "    return keep\n",
    "\n",
    "def scatter_tradeoff(df, x, y, *, annotate_top=0, savepath=None, title=None,\n",
    "                     max_labels=12, label_fontsize=8):\n",
    "    if x not in df.columns or y not in df.columns:\n",
    "        print(f\"[skip] missing: {x} or {y}\")\n",
    "        return\n",
    "\n",
    "    d = df[[\"sweep\", x, y]].copy()\n",
    "    d[x] = pd.to_numeric(d[x], errors=\"coerce\")\n",
    "    d[y] = pd.to_numeric(d[y], errors=\"coerce\")\n",
    "    d = d.dropna()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6.5, 5))\n",
    "\n",
    "    # points: smaller + slightly transparent helps a lot\n",
    "    ax.scatter(d[x].astype(float), d[y].astype(float), s=30, alpha=0.85)\n",
    "\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(y)\n",
    "    ax.set_title(title if title is not None else f\"{y} vs {x}\")\n",
    "\n",
    "    # ---- tighten margins (like the barplots) ----\n",
    "    ax.margins(x=0.02, y=0.02)  # small breathing room but not the big default padding\n",
    "\n",
    "    # If you want hard clamps based on data (optional but nice):\n",
    "    xvals = d[x].astype(float).to_numpy()\n",
    "    yvals = d[y].astype(float).to_numpy()\n",
    "    xr = float(xvals.max() - xvals.min()) if len(xvals) else 1.0\n",
    "    yr = float(yvals.max() - yvals.min()) if len(yvals) else 1.0\n",
    "    ax.set_xlim(float(xvals.min() - 0.03 * xr), float(xvals.max() + 0.03 * xr))\n",
    "    ax.set_ylim(float(yvals.min() - 0.03 * yr), float(yvals.max() + 0.03 * yr))\n",
    "\n",
    "    # ---- annotations: pick points, then repel text a bit ----\n",
    "    if int(annotate_top) > 0:\n",
    "        # if \"lower is better\" for y, sort ascending; else descending\n",
    "        y_lower_better = any(s in y.lower() for s in [\"loss\", \"error\", \"dist\", \"foscttm\", \"rmse\", \"mae\", \"rankfrac\"])\n",
    "        dd = d.sort_values(y, ascending=bool(y_lower_better)).head(int(annotate_top))\n",
    "        if len(dd) > int(max_labels):\n",
    "            dd = dd.head(int(max_labels))\n",
    "\n",
    "        # initial annotation placement\n",
    "        texts = []\n",
    "        for _, r in dd.iterrows():\n",
    "            txt = ax.text(float(r[x]), float(r[y]), str(r[\"sweep\"]),\n",
    "                          fontsize=label_fontsize, ha=\"left\", va=\"bottom\")\n",
    "            texts.append(txt)\n",
    "\n",
    "        # simple label repulsion: iteratively nudge labels apart in display coords\n",
    "        fig.canvas.draw()  # need renderer for accurate text extents\n",
    "        renderer = fig.canvas.get_renderer()\n",
    "\n",
    "        def _overlap(b1, b2, pad=2.0):\n",
    "            return not (b1.x1 + pad < b2.x0 or b1.x0 - pad > b2.x1 or\n",
    "                        b1.y1 + pad < b2.y0 or b1.y0 - pad > b2.y1)\n",
    "\n",
    "        # nudge loop\n",
    "        for _ in range(80):\n",
    "            moved = False\n",
    "            bbs = [t.get_window_extent(renderer=renderer) for t in texts]\n",
    "            for i in range(len(texts)):\n",
    "                for j in range(i + 1, len(texts)):\n",
    "                    if _overlap(bbs[i], bbs[j], pad=2.0):\n",
    "                        # move j a bit up/right in data units proportional to axis ranges\n",
    "                        xi, yi = texts[j].get_position()\n",
    "                        texts[j].set_position((xi + 0.008 * xr, yi + 0.012 * yr))\n",
    "                        moved = True\n",
    "            if not moved:\n",
    "                break\n",
    "            fig.canvas.draw()\n",
    "            renderer = fig.canvas.get_renderer()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    _savefig(savepath)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Heatmap of hp grid vs metric\n",
    "# -----------------------------------------------------------------------------\n",
    "def heatmap_hparams_vs_metric(df, metric, hp_x=\"beta\", hp_y=\"gamma\", *, agg=\"median\", savepath=None, title=None):\n",
    "    needed = [metric, hp_x, hp_y]\n",
    "    for c in needed:\n",
    "        if c not in df.columns:\n",
    "            print(f\"[skip] missing col: {c}\")\n",
    "            return\n",
    "\n",
    "    d = _coerce_numeric(df[[hp_x, hp_y, metric]], [hp_x, hp_y, metric]).dropna().copy()\n",
    "\n",
    "    if agg == \"mean\":\n",
    "        pv = d.groupby([hp_y, hp_x])[metric].mean().unstack(hp_x)\n",
    "    elif agg == \"min\":\n",
    "        pv = d.groupby([hp_y, hp_x])[metric].min().unstack(hp_x)\n",
    "    elif agg == \"max\":\n",
    "        pv = d.groupby([hp_y, hp_x])[metric].max().unstack(hp_x)\n",
    "    else:\n",
    "        pv = d.groupby([hp_y, hp_x])[metric].median().unstack(hp_x)\n",
    "\n",
    "    # sort axes numerically when possible\n",
    "    try:\n",
    "        pv = pv.sort_index(axis=0).sort_index(axis=1)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    plt.figure(figsize=(1.1 * max(6, pv.shape[1]), 1.0 * max(4, pv.shape[0])))\n",
    "    plt.imshow(pv.values, aspect=\"auto\")\n",
    "    plt.xticks(range(pv.shape[1]), [str(x) for x in pv.columns], rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(pv.shape[0]), [str(y) for y in pv.index])\n",
    "    plt.xlabel(hp_x)\n",
    "    plt.ylabel(hp_y)\n",
    "    plt.title(title if title is not None else f\"{metric} heatmap ({agg})\")\n",
    "    plt.colorbar(label=metric)\n",
    "    plt.tight_layout()\n",
    "    _savefig(savepath)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Retrieval curve: recall_sym@k (or FOSCTTM@k) across k\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_retrieval_curve(df, *, which=\"recall_sym\", ks=DEFAULT_KS, top_n=10, by=\"best\", savepath=None, title=None):\n",
    "    \"\"\"\n",
    "    Plots recall_sym@k (higher better) OR FOSCTTM@k (lower better) across k.\n",
    "    Picks top_n runs by recall_sym@1 or by FOSCTTM_rankfrac depending on 'which'.\n",
    "    \"\"\"\n",
    "    ks = [int(k) for k in ks]\n",
    "    cols = [f\"{which}@{k}\" for k in ks]\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            print(f\"[skip] missing col: {c}\")\n",
    "            return\n",
    "\n",
    "    d = _coerce_numeric(df[[\"sweep\"] + cols + ([\"FOSCTTM_rankfrac\"] if \"FOSCTTM_rankfrac\" in df.columns else [])], cols).dropna().copy()\n",
    "\n",
    "    # choose ranking metric\n",
    "    if which.lower().startswith(\"recall\"):\n",
    "        rank_metric = f\"{which}@{ks[0]}\"\n",
    "        ascending = False\n",
    "    else:\n",
    "        # FOSCTTM@k lower better\n",
    "        rank_metric = f\"{which}@{ks[0]}\"\n",
    "        ascending = True\n",
    "\n",
    "    d = d.sort_values(rank_metric, ascending=bool(ascending)).head(int(top_n))\n",
    "\n",
    "    plt.figure(figsize=(7.2, 4.8))\n",
    "    for _, r in d.iterrows():\n",
    "        y = [float(r[f\"{which}@{k}\"]) for k in ks]\n",
    "        plt.plot(ks, y, marker=\"o\", alpha=0.85, label=str(r[\"sweep\"]))\n",
    "\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(which)\n",
    "    plt.title(title if title is not None else f\"Retrieval curve: {which}@k (top {top_n} by {rank_metric})\")\n",
    "    plt.xticks(ks)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Legend can get huge; only show if small\n",
    "    if len(d) <= 12:\n",
    "        plt.legend(fontsize=8, loc=\"best\")\n",
    "\n",
    "    _savefig(savepath)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Correlation heatmap (redundancy check)\n",
    "# -----------------------------------------------------------------------------\n",
    "def corr_heatmap(df, metrics, *, savepath=None, title=\"Metric correlation (Spearman)\"):\n",
    "    keep = [m for m in metrics if m in df.columns]\n",
    "    if len(keep) < 2:\n",
    "        print(\"[skip] need >=2 metrics present\")\n",
    "        return\n",
    "\n",
    "    d = _coerce_numeric(df[keep], keep).dropna()\n",
    "    if len(d) < 3:\n",
    "        print(\"[skip] too few rows after dropna\")\n",
    "        return\n",
    "\n",
    "    C = d.corr(method=\"spearman\").values\n",
    "\n",
    "    plt.figure(figsize=(0.55 * len(keep) + 3, 0.55 * len(keep) + 3))\n",
    "    plt.imshow(C, aspect=\"auto\", vmin=-1, vmax=1)\n",
    "    plt.xticks(range(len(keep)), keep, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(len(keep)), keep)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(label=\"Spearman rho\")\n",
    "    plt.tight_layout()\n",
    "    _savefig(savepath)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Scaling plots (kept, minor robustness)\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_scaling_multi(df, *, x=\"n_train_cells\", saveprefix=None):\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"[skip] empty df_scale\")\n",
    "        return\n",
    "\n",
    "    if x not in df.columns:\n",
    "        print(f\"[skip] missing x: {x}\")\n",
    "        return\n",
    "\n",
    "    d = df.copy()\n",
    "    d = _coerce_numeric(d, [x, \"wall_seconds\", \"gpu_peak_mem_mb\", \"cpu_rss_mb_delta\"])\n",
    "    d = d.sort_values(x)\n",
    "\n",
    "    if \"wall_seconds\" in d.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(d[x], d[\"wall_seconds\"], marker=\"o\")\n",
    "        plt.xlabel(x)\n",
    "        plt.ylabel(\"wall seconds (train)\")\n",
    "        plt.title(\"Scaling: runtime vs size\")\n",
    "        plt.tight_layout()\n",
    "        _savefig(None if saveprefix is None else f\"{saveprefix}_runtime.png\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(6,4))\n",
    "        thr = d[x].astype(float) / np.maximum(d[\"wall_seconds\"].astype(float), 1e-9)\n",
    "        plt.plot(d[x], thr, marker=\"o\")\n",
    "        plt.xlabel(x)\n",
    "        plt.ylabel(\"train throughput (items/sec)\")\n",
    "        plt.title(\"Scaling: throughput vs size\")\n",
    "        plt.tight_layout()\n",
    "        _savefig(None if saveprefix is None else f\"{saveprefix}_throughput.png\")\n",
    "        plt.show()\n",
    "\n",
    "    if \"gpu_peak_mem_mb\" in d.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(d[x], d[\"gpu_peak_mem_mb\"], marker=\"o\")\n",
    "        plt.xlabel(x)\n",
    "        plt.ylabel(\"GPU peak mem (MB)\")\n",
    "        plt.title(\"Scaling: GPU peak memory vs size\")\n",
    "        plt.tight_layout()\n",
    "        _savefig(None if saveprefix is None else f\"{saveprefix}_gpu_mem.png\")\n",
    "        plt.show()\n",
    "\n",
    "    if \"cpu_rss_mb_delta\" in d.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(d[x], d[\"cpu_rss_mb_delta\"], marker=\"o\")\n",
    "        plt.xlabel(x)\n",
    "        plt.ylabel(\"CPU RSS delta (MB)\")\n",
    "        plt.title(\"Scaling: CPU memory delta vs size\")\n",
    "        plt.tight_layout()\n",
    "        _savefig(None if saveprefix is None else f\"{saveprefix}_cpu_mem_delta.png\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc836c2-bf00-4eeb-a023-ca9b28376da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_best(df_grid, \"recall_sym@1\", top_n=50, ascending=False,\n",
    "            savepath=os.path.join(OUTDIR, \"figures\", \"grid_top_recall_sym_at1.png\"),\n",
    "            title=\"Grid leaderboard: recall_sym@1 (higher is better)\")\n",
    "\n",
    "barplot_best(df_grid, \"FOSCTTM_rankfrac\", top_n=50,\n",
    "            savepath=os.path.join(OUTDIR, \"figures\", \"grid_top_FOSCTTM_rankfrac.png\"),\n",
    "            title=\"Grid leaderboard: FOSCTTM_rankfrac (lower is better)\")\n",
    "\n",
    "for m in [\"ARI\", \"NMI\", \"kNN_LOO_acc_fused\", \"kNN_LOO_macroF1_fused\", \"mixing_1minus_samefrac_k15\"]:\n",
    "    if m in df_grid.columns:\n",
    "        barplot_best(df_grid, m, top_n=50, ascending=False,\n",
    "                    savepath=os.path.join(OUTDIR, \"figures\", f\"grid_top_{m}.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f672323-0ec2-417a-8080-cc9a788c26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_tradeoff(df_grid, \"recall_sym@1\", \"ARI\", annotate_top=25,\n",
    "                 savepath=os.path.join(OUTDIR, \"figures\", \"tradeoff_ARI_vs_recall1.png\"),\n",
    "                 title=\"Tradeoff: fused biology vs pairing quality\")\n",
    "\n",
    "scatter_tradeoff(df_grid, \"recall_sym@1\", \"mixing_1minus_samefrac_k15\", annotate_top=25,\n",
    "                 savepath=os.path.join(OUTDIR, \"figures\", \"tradeoff_mixing_vs_recall1.png\"),\n",
    "                 title=\"Tradeoff: mixing vs pairing quality\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a952b2-e7c8-4c47-a022-3060fefdc64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_retrieval_curve(df_grid, which=\"recall_sym\", ks=(1,10,25,50,100), top_n=25,\n",
    "                     savepath=os.path.join(OUTDIR, \"figures\", \"retrieval_curve_recall_sym.png\"),\n",
    "                     title=\"Paired retrieval: recall_sym@k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8441099b-b13c-4d31-a5c3-8cb60c20e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_retrieval_curve(df_grid, which=\"FOSCTTM\", ks=(1,10,25,50,100), top_n=25,\n",
    "                     savepath=os.path.join(OUTDIR, \"figures\", \"retrieval_curve_FOSCTTM_at_k.png\"),\n",
    "                     title=\"Paired retrieval: FOSCTTM@k (lower is better)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af7374-9a87-4999-9df8-f34464433eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_hparams_vs_metric(df_grid, \"recall_sym@1\", hp_x=\"beta\", hp_y=\"gamma\", agg=\"median\",\n",
    "                          savepath=os.path.join(OUTDIR, \"figures\", \"heatmap_recall1_beta_gamma.png\"),\n",
    "                          title=\"recall_sym@1 vs (beta, gamma)\")\n",
    "\n",
    "heatmap_hparams_vs_metric(df_grid, \"ARI\", hp_x=\"beta\", hp_y=\"gamma\", agg=\"median\",\n",
    "                          savepath=os.path.join(OUTDIR, \"figures\", \"heatmap_ARI_beta_gamma.png\"),\n",
    "                          title=\"ARI vs (beta, gamma)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e0c06-391c-439e-8027-d39d6defd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_heatmap(\n",
    "    df_grid,\n",
    "    metrics=[\n",
    "        \"recall_sym@1\", \"recall_sym@10\", \"FOSCTTM_rankfrac\",\n",
    "        \"ARI\", \"NMI\", \"SIL_true\",\n",
    "        \"kNN_LOO_acc_fused\", \"kNN_LOO_macroF1_fused\",\n",
    "        \"mixing_1minus_samefrac_k15\"\n",
    "    ],\n",
    "    savepath=os.path.join(OUTDIR, \"figures\", \"corr_metrics.png\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b6c522-c087-4160-9583-ad990a0bb246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5a0b42-cbd2-41ee-887b-ccac34d7d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dbe172-a9b4-4ef9-ad7c-d8c27efa7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ee193-6d1d-4efd-a550-095e9655f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a038e92-9133-4ccc-b90e-4f2bc26365b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776301d-1131-4d98-aa21-d829a19a29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350bd348-e3d8-492d-8525-0beb3cb01ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4bee15-a6ad-4185-8dc4-ec0134a0727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f843a7a-0f42-4853-a4dd-b6af3eba74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467cfa2-c1ea-4198-a77f-2ed0dea70f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dcffad-e5e5-4f5c-b87b-0c8ab4725911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b343a-50b8-471b-b7d8-778a74ceeafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c2bbc-fe8a-4e0d-9c5a-344dd0735c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6867dc28-9bd8-4344-9db3-51f01cbac280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a5051-3a4e-4951-b1b7-5f3e48f49e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0db289-2e68-4d7d-92fd-fcc42d7b55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd96b35-3a46-4c41-82a9-dfa627a37ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5b976-8f21-40e6-97a6-bcd8cfe96aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804ebae-4a67-4b7c-b6f2-86615bccab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da3cbcd-21a4-4c57-bb93-7c40b19bf3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ec564-f0fd-48e9-9819-596816ad6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb43669d-8eb1-494d-9038-9d3bc9718a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951fee6b-6d38-426a-a7f5-b0a8daa3ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04d970-ee33-4b69-95b0-bb3535b43663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f893579-2e4f-465a-ba9e-eeb724fa39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726f5503-8675-47cc-86fc-dbeac370b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3099ec2-330c-4c61-b819-125342c93561",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91318549-0ea2-40c7-9039-6e61418b2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38452b-085e-410b-ab3e-01fb097e8aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e452f42c-7c36-4533-8372-e3eee5bec7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e1eff2-d8d8-4370-aa3c-3d7fa3b30a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e609a0-1f85-4f11-b05e-7f8b6399148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521cec3-a613-48f3-ac66-a5f3bc70a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddecda91-baea-4fe8-9fdf-e9b110268508",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e0748-7a95-480c-8814-1c114ee54d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e127985-1994-405a-8bb9-e5fb35592ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23bedfc-8519-4378-9fa3-c861379ffdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e022a73-a959-47ab-b021-2917c0ca9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a45fdb-17b0-4c1a-a743-33b9dc01c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a73560-7f3c-4c0a-8830-5f8c14de9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943389e4-aa24-49c3-88ed-4c266cc824c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877d2e2-41c0-48eb-9ae0-991479ebc0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6a158-6eab-4fa4-ba2c-78e7cc1a51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa73ac-0e37-4d3f-8889-cff15188c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b1f11-eeba-431d-8966-4990cc283dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d2ff6-ef39-40d6-99f7-d7f1b040f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3967824-7c01-4af9-8639-451b5af64118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad4d28e-4173-4e28-8701-fce015858b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8429f575-1090-490d-8e18-361e0083878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c934d6-f004-48e4-afc8-243649813268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561cf350-04dd-4e3f-8013-ce526b7d3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4fc565-3804-4edb-90e9-522bfc1cd090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddcea14-519b-4f92-8fa6-7f466bc48b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1200856-f6a4-458c-81bb-e6c5c96e065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece8864-4ccd-4e80-9ac6-cfeb525b9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25f8ae-6bba-49cc-9239-061c89df54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49900991-73ba-4a34-840c-9291f47e320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f513cf8-87f6-4c9d-9f20-dabac390c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af4715a-165b-4f67-8fd6-fc2af551694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73db22f-0a17-489f-9abf-fcea586beca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd25588-f5b2-4325-8ced-7a9519a1554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a8ca5-46de-4256-b144-bc7ea3fa8364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715791f-de46-4d34-b467-584b6f35ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe8c6b-6a51-4a11-8655-1cccbe55f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11971a0-a33b-40a5-ac6e-cc87ea30dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6325de-42df-4e60-ac22-880305901b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de461da-1260-4f09-869a-52907e8fb00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e7b4b-ddb6-40bd-aee3-2eaa82109567",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238dd57a-420e-42f4-9cbe-5e885b908c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20820a08-2e75-4381-89ce-5047050ca286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f9df3-c3ad-4a95-8a39-8647d06786ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f7499-967c-458e-b588-402fb375c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017063f-3be9-4a87-8076-827fb9516dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac45f3-0dd7-48d3-87d2-f2dd78cdfaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (UniVI v0.3.9)",
   "language": "python",
   "name": "univi_v0.3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
