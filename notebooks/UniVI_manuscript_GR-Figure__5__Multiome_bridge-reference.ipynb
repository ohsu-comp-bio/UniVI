{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83ac317",
   "metadata": {},
   "source": [
    "# UniVI manuscript - Figure 5 generation reproducible workflow\n",
    "### Multiome RNA + ATAC as a bridge to integrate separate unimodal datasets; use Multiome data to train a model and then use the trained model on outside unimodal scRNA and scATAC data\n",
    "\n",
    "Andrew Ashford, Pathways + Omics Group, Oregon Health & Science University, Portland, OR - 12/10/2025\n",
    "\n",
    "This Jupyter Notebook will house the end-to-end workflow to generate the panels in Figure 5 of our manuscript, \"Unifying multimodal single-cell data with a mixture-of-experts β-variational autoencoder framework\" which is currently being revised for Genome Research and is available currently on bioRxiv at the following link: https://www.biorxiv.org/content/10.1101/2025.02.28.640429v1.full\n",
    "\n",
    "GitHub for the project - including a Quickstart guide - can be found at: https://github.com/Ashford-A/UniVI\n",
    "\n",
    "Package is pip installable via the command: \n",
    "```bash\n",
    "pip install univi\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad73266",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import non-UniVI modules\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d2f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ee212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required UniVI modules\n",
    "from univi import (\n",
    "    ModalityConfig,\n",
    "    UniVIConfig,\n",
    "    TrainingConfig,\n",
    "    UniVIMultiModalVAE,\n",
    "    matching,\n",
    "    UniVITrainer,\n",
    "    write_univi_latent,\n",
    "    MultiModalDataset,\n",
    ")\n",
    "\n",
    "import univi as uv\n",
    "import univi.evaluation as ue\n",
    "import univi.plotting as up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485fc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check UniVI module version\n",
    "print(\"Installed version is univi v\" + str(uv.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c551d6",
   "metadata": {},
   "source": [
    "### Specify device to use for model\n",
    "\n",
    "Set \"device\" - preferably device should be \"cuda\" for speedier model implementation/training. Requires GPU and the correct packages/versions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c37f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f017fa37",
   "metadata": {},
   "source": [
    "### Specify file paths\n",
    "\n",
    "Where data lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1593188",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/home/groups/precepts/ashforda/UniVI_v2/UniVI_older-non_git/data/PBMC_10x_Multiome_data/MultiVI_combined_data\")\n",
    "\n",
    "MULTI_PATH = DATA_ROOT / \"10x_Genomics_Multiome_split.h5ad\"\n",
    "UNI_RNA_PATH = DATA_ROOT / \"Ding_scRNA_data_split.h5ad\"\n",
    "UNI_ATAC_PATH = DATA_ROOT / \"Satpathy_scATAC_data_split.h5ad\"\n",
    "\n",
    "print(\"Combined Multiome file: \", MULTI_PATH)\n",
    "print(\"Unimodal RNA file:\", UNI_RNA_PATH)\n",
    "print(\"Unimodal ATAC file:\", UNI_ATAC_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f717b4",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "Read data into AnnData objects using the paths in the code chunk above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36dbdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = sc.read_h5ad(MULTI_PATH)\n",
    "\n",
    "print(multi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into rna and atac adata objects for downstream use using the .var['modality'] variable\n",
    "print(multi.var['modality'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_mask = multi.var['modality'] == 'Gene Expression'\n",
    "atac_mask = multi.var['modality'] == 'Peaks'\n",
    "\n",
    "print(rna_mask.value_counts())   # sanity check\n",
    "print(atac_mask.value_counts())  # sanity check\n",
    "\n",
    "rna = multi[:, rna_mask].copy()\n",
    "atac = multi[:, atac_mask].copy()\n",
    "\n",
    "print(rna)\n",
    "print(atac)\n",
    "\n",
    "print(\"RNA obs names head:\", rna.obs_names[:5].tolist())\n",
    "print(\"ATAC obs names head:\", atac.obs_names[:5].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in unimodal data objects\n",
    "uni_rna = sc.read_h5ad(UNI_RNA_PATH)\n",
    "uni_atac = sc.read_h5ad(UNI_ATAC_PATH)\n",
    "\n",
    "print(uni_rna)\n",
    "print(uni_atac)\n",
    "\n",
    "print(\"RNA obs names head:\", uni_rna.obs_names[:5].tolist())\n",
    "print(\"ATAC obs names head:\", uni_atac.obs_names[:5].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e02781",
   "metadata": {},
   "source": [
    "### Align cells between RNA and ATAC\n",
    "\n",
    "Make sure the cell indices are aligned so UniVI knows which samples are paired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e65aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersect barcodes\n",
    "common_cells = rna.obs_names.intersection(atac.obs_names)\n",
    "print(\"Common cells:\", len(common_cells))\n",
    "\n",
    "rna = rna[common_cells].copy()\n",
    "atac = atac[common_cells].copy()\n",
    "\n",
    "# Make sure order matches\n",
    "atac = atac[rna.obs_names].copy()\n",
    "\n",
    "assert np.array_equal(rna.obs_names.values, atac.obs_names.values)\n",
    "print(\"obs_names aligned between RNA and ATAC.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919617a",
   "metadata": {},
   "source": [
    "### Set up Multiome RNA + ATAC bridge data train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b7bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n = rna.n_obs\n",
    "idx = np.arange(n)\n",
    "rng.shuffle(idx)\n",
    "\n",
    "n_train = int(0.90 * n)\n",
    "n_val   = int(0.10 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "\n",
    "idx_train = idx[:n_train]\n",
    "idx_val   = idx[n_train:n_train+n_val]\n",
    "idx_test  = idx[n_train+n_val:]\n",
    "\n",
    "rna_train  = rna[idx_train].copy()\n",
    "rna_val    = rna[idx_val].copy()\n",
    "rna_test   = rna[idx_test].copy()\n",
    "\n",
    "atac_train = atac[idx_train].copy()\n",
    "atac_val   = atac[idx_val].copy()\n",
    "atac_test  = atac[idx_test].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75458aab",
   "metadata": {},
   "source": [
    "### Subset each dataset by shared features and preprocess individually\n",
    "\n",
    "Also specifying all the data preprocessing functions below, will be used in their own respective sections.\n",
    "\n",
    "* RNA preprocessing (log1p + HVG + scale → Gaussian decoder)\n",
    "\n",
    "* ATAC preprocessing (TF-IDF + LSI + scale → Gaussian decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf813c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1) Multiome preprocessing (train/val/test) with shared statistics\n",
    "# =============================================================================\n",
    "\n",
    "def preprocess_multiome_splits(\n",
    "    rna_train, atac_train,\n",
    "    rna_val,   atac_val,\n",
    "    rna_test,  atac_test,\n",
    "    *,\n",
    "    rna_counts_layer=\"counts\",\n",
    "    atac_counts_layer=\"counts\",\n",
    "    n_hvg=2000,\n",
    "    hvg_list=None,          # <--- NEW\n",
    "    target_sum=1e4,\n",
    "    n_lsi=50,\n",
    "    seed=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess paired RNA/ATAC Multiome splits.\n",
    "\n",
    "    RNA:\n",
    "      - define HVGs on TRAIN only\n",
    "      - normalize_total + log1p on train/val/test\n",
    "      - StandardScaler fit on TRAIN, applied to val/test\n",
    "\n",
    "    ATAC:\n",
    "      - TF-IDF + SVD (LSI) fit on TRAIN only\n",
    "      - StandardScaler in LSI space fit on TRAIN, applied to val/test\n",
    "\n",
    "    Returns:\n",
    "      rna_train_pp, atac_train_lsi,\n",
    "      rna_val_pp,   atac_val_lsi,\n",
    "      rna_test_pp,  atac_test_lsi,\n",
    "      hvg,\n",
    "      tfidf, svd, atac_scaler,\n",
    "      rna_scaler\n",
    "    \"\"\"\n",
    "\n",
    "    # --- ensure counts layers exist ---\n",
    "    for a in (rna_train, rna_val, rna_test):\n",
    "        if rna_counts_layer not in a.layers:\n",
    "            a.layers[rna_counts_layer] = a.X.copy()\n",
    "    for a in (atac_train, atac_val, atac_test):\n",
    "        if atac_counts_layer not in a.layers:\n",
    "            a.layers[atac_counts_layer] = a.X.copy()\n",
    "\n",
    "    # =========================\n",
    "    # RNA: choose HVGs\n",
    "    # =========================\n",
    "    if hvg_list is None:\n",
    "        # define HVGs *from the bridge / train split* (current behavior)\n",
    "        rna_train_tmp = rna_train.copy()\n",
    "        rna_train_tmp.X = rna_train_tmp.layers[rna_counts_layer]\n",
    "\n",
    "        try:\n",
    "            sc.pp.highly_variable_genes(\n",
    "                rna_train_tmp,\n",
    "                n_top_genes=int(n_hvg),\n",
    "                flavor=\"seurat_v3\",\n",
    "            )\n",
    "        except Exception:\n",
    "            sc.pp.highly_variable_genes(\n",
    "                rna_train_tmp,\n",
    "                n_top_genes=int(n_hvg),\n",
    "                flavor=\"seurat\",\n",
    "            )\n",
    "\n",
    "        hvg = rna_train_tmp.var_names[\n",
    "            rna_train_tmp.var[\"highly_variable\"].to_numpy()\n",
    "        ].tolist()\n",
    "    else:\n",
    "        # use user-supplied HVG list (e.g. from Ding / joint)\n",
    "        # enforce intersection + order w.r.t. rna_train\n",
    "        hvg = [g for g in hvg_list if g in rna_train.var_names]\n",
    "        if len(hvg) == 0:\n",
    "            raise ValueError(\n",
    "                \"Provided hvg_list has no overlap with rna_train.var_names.\"\n",
    "            )\n",
    "        # reindex to training order\n",
    "        hvg = list(rna_train.var_names.intersection(hvg))\n",
    "        if len(hvg) == 0:\n",
    "            raise ValueError(\"After intersection, no HVGs remain in rna_train.\")\n",
    "\n",
    "    def _rna_lognorm_to_X(a):\n",
    "        \"\"\"Subset to HVGs, normalize_total + log1p into X (no scaling yet).\"\"\"\n",
    "        adata = a[:, hvg].copy()\n",
    "\n",
    "        if rna_counts_layer not in adata.layers:\n",
    "            adata.layers[rna_counts_layer] = adata.X.copy()\n",
    "\n",
    "        # if no cells, just propagate counts\n",
    "        if adata.n_obs == 0:\n",
    "            X = adata.layers[rna_counts_layer]\n",
    "            if sp.issparse(X):\n",
    "                adata.X = X.copy()\n",
    "            else:\n",
    "                adata.X = np.asarray(X, dtype=np.float32)\n",
    "            return adata\n",
    "\n",
    "        adata.layers[\"log1p\"] = adata.layers[rna_counts_layer].copy()\n",
    "        sc.pp.normalize_total(adata, target_sum=float(target_sum), layer=\"log1p\")\n",
    "        sc.pp.log1p(adata, layer=\"log1p\")\n",
    "\n",
    "        X = adata.layers[\"log1p\"]\n",
    "        if sp.issparse(X):\n",
    "            X = X.toarray()\n",
    "        adata.X = np.asarray(X, dtype=np.float32)\n",
    "        return adata\n",
    "\n",
    "    rna_train_pp = _rna_lognorm_to_X(rna_train)\n",
    "    rna_val_pp   = _rna_lognorm_to_X(rna_val)\n",
    "    rna_test_pp  = _rna_lognorm_to_X(rna_test)\n",
    "\n",
    "    # ---- RNA scaling (feature-wise z-score across cells; fit on TRAIN only) ----\n",
    "    rna_scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "\n",
    "    def _scale_rna_inplace(adata, scaler, fit: bool):\n",
    "        if adata.n_obs == 0:\n",
    "            return\n",
    "        X = adata.X\n",
    "        if sp.issparse(X):\n",
    "            X = X.toarray()\n",
    "        if fit:\n",
    "            Xs = scaler.fit_transform(X)\n",
    "        else:\n",
    "            # sanity check: same #features\n",
    "            if scaler.n_features_in_ != X.shape[1]:\n",
    "                raise ValueError(\n",
    "                    f\"[RNA] StandardScaler expects {scaler.n_features_in_} features, \"\n",
    "                    f\"but got {X.shape[1]}. Check that HVG list matches training.\"\n",
    "                )\n",
    "            Xs = scaler.transform(X)\n",
    "        adata.X = Xs.astype(np.float32, copy=False)\n",
    "\n",
    "    _scale_rna_inplace(rna_train_pp, rna_scaler, fit=True)\n",
    "    _scale_rna_inplace(rna_val_pp,   rna_scaler, fit=False)\n",
    "    _scale_rna_inplace(rna_test_pp,  rna_scaler, fit=False)\n",
    "\n",
    "    # =========================\n",
    "    # ATAC: TFIDF + SVD (LSI) fit on TRAIN only\n",
    "    # =========================\n",
    "    Xtr = atac_train.layers[atac_counts_layer]\n",
    "    Xva = atac_val.layers[atac_counts_layer]\n",
    "    Xte = atac_test.layers[atac_counts_layer]\n",
    "\n",
    "    if not sp.issparse(Xtr):\n",
    "        Xtr = sp.csr_matrix(Xtr)\n",
    "    if not sp.issparse(Xva):\n",
    "        Xva = sp.csr_matrix(Xva)\n",
    "    if not sp.issparse(Xte):\n",
    "        Xte = sp.csr_matrix(Xte)\n",
    "\n",
    "    tfidf = TfidfTransformer(norm=\"l2\", use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "    Xtr_t = tfidf.fit_transform(Xtr)\n",
    "    Xva_t = tfidf.transform(Xva)\n",
    "    Xte_t = tfidf.transform(Xte)\n",
    "\n",
    "    svd = TruncatedSVD(n_components=int(n_lsi), random_state=int(seed))\n",
    "    Ztr = svd.fit_transform(Xtr_t)\n",
    "    Zva = svd.transform(Xva_t)\n",
    "    Zte = svd.transform(Xte_t)\n",
    "\n",
    "    atac_scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    Ztr = atac_scaler.fit_transform(Ztr).astype(np.float32, copy=False)\n",
    "    # sanity: LSI dim is fixed by svd, so this should always match\n",
    "    Zva = atac_scaler.transform(Zva).astype(np.float32, copy=False)\n",
    "    Zte = atac_scaler.transform(Zte).astype(np.float32, copy=False)\n",
    "\n",
    "    atac_train_lsi = ad.AnnData(\n",
    "        X=Ztr,\n",
    "        obs=atac_train.obs.copy(),\n",
    "        var=pd.DataFrame(index=[f\"LSI_{i}\" for i in range(Ztr.shape[1])]),\n",
    "    )\n",
    "    atac_val_lsi = ad.AnnData(\n",
    "        X=Zva,\n",
    "        obs=atac_val.obs.copy(),\n",
    "        var=pd.DataFrame(index=[f\"LSI_{i}\" for i in range(Zva.shape[1])]),\n",
    "    )\n",
    "    atac_test_lsi = ad.AnnData(\n",
    "        X=Zte,\n",
    "        obs=atac_test.obs.copy(),\n",
    "        var=pd.DataFrame(index=[f\"LSI_{i}\" for i in range(Zte.shape[1])]),\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        rna_train_pp,\n",
    "        atac_train_lsi,\n",
    "        rna_val_pp,\n",
    "        atac_val_lsi,\n",
    "        rna_test_pp,\n",
    "        atac_test_lsi,\n",
    "        hvg,\n",
    "        tfidf,\n",
    "        svd,\n",
    "        atac_scaler,  # ATAC LSI scaler\n",
    "        rna_scaler,   # RNA scaler\n",
    "    )\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2) Transform NEW / UNIMODAL data with the SAME pipeline\n",
    "# =============================================================================\n",
    "\n",
    "def transform_rna_with_hvg(\n",
    "    rna,\n",
    "    *,\n",
    "    hvg,\n",
    "    counts_layer=\"counts\",\n",
    "    target_sum=1e4,\n",
    "    rna_scaler: StandardScaler | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply the same RNA preprocessing to a new AnnData:\n",
    "      - subset to given HVGs (MUST match training HVGs/order)\n",
    "      - normalize_total + log1p\n",
    "      - optional z-score with `rna_scaler` fit on the train split\n",
    "    \"\"\"\n",
    "    # sanity: make sure all HVGs are present\n",
    "    missing = [g for g in hvg if g not in rna.var_names]\n",
    "    if len(missing) > 0:\n",
    "        raise ValueError(\n",
    "            f\"transform_rna_with_hvg: {len(missing)} HVGs are missing from the input \"\n",
    "            f\"AnnData (e.g. {missing[:5]} ...). You must use the same gene set as training.\"\n",
    "        )\n",
    "\n",
    "    a = rna[:, hvg].copy()\n",
    "\n",
    "    if counts_layer not in a.layers:\n",
    "        a.layers[counts_layer] = a.X.copy()\n",
    "\n",
    "    a.layers[\"log1p\"] = a.layers[counts_layer].copy()\n",
    "    sc.pp.normalize_total(a, target_sum=float(target_sum), layer=\"log1p\")\n",
    "    sc.pp.log1p(a, layer=\"log1p\")\n",
    "\n",
    "    X = a.layers[\"log1p\"]\n",
    "    if sp.issparse(X):\n",
    "        X = X.toarray()\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "\n",
    "    if rna_scaler is not None:\n",
    "        if rna_scaler.n_features_in_ != X.shape[1]:\n",
    "            raise ValueError(\n",
    "                f\"[RNA external] StandardScaler expects {rna_scaler.n_features_in_} features, \"\n",
    "                f\"but got {X.shape[1]}. Make sure HVG list and order match training.\"\n",
    "            )\n",
    "        X = rna_scaler.transform(X)\n",
    "\n",
    "    a.X = X.astype(np.float32, copy=False)\n",
    "    return a\n",
    "\n",
    "\n",
    "def transform_atac_with_lsi(\n",
    "    atac,\n",
    "    *,\n",
    "    counts_layer=\"counts\",\n",
    "    tfidf=None,\n",
    "    svd=None,\n",
    "    atac_scaler=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply the same ATAC preprocessing to new AnnData:\n",
    "      - ensure counts layer\n",
    "      - TF-IDF using the fitted `tfidf`\n",
    "      - project to LSI using the fitted `svd`\n",
    "      - z-score in LSI space with `atac_scaler`\n",
    "    \"\"\"\n",
    "    if tfidf is None or svd is None or atac_scaler is None:\n",
    "        raise ValueError(\n",
    "            \"Need tfidf, svd, atac_scaler objects from preprocess_multiome_splits().\"\n",
    "        )\n",
    "\n",
    "    a = atac.copy()\n",
    "    if counts_layer not in a.layers:\n",
    "        a.layers[counts_layer] = a.X.copy()\n",
    "\n",
    "    X = a.layers[counts_layer]\n",
    "    if not sp.issparse(X):\n",
    "        X = sp.csr_matrix(X)\n",
    "\n",
    "    Xt = tfidf.transform(X)\n",
    "    Z  = svd.transform(Xt)\n",
    "    Z  = atac_scaler.transform(Z).astype(np.float32, copy=False)\n",
    "\n",
    "    atac_lsi = ad.AnnData(\n",
    "        X=Z,\n",
    "        obs=a.obs.copy(),\n",
    "        var=pd.DataFrame(index=[f\"LSI_{i}\" for i in range(Z.shape[1])]),\n",
    "    )\n",
    "    return atac_lsi\n",
    "\n",
    "\n",
    "def compute_hvgs_from_reference(\n",
    "    ref_rna,\n",
    "    bridge_rna=None,\n",
    "    *,\n",
    "    counts_layer=\"counts\",\n",
    "    n_hvg=5000,\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Compute HVGs from a reference RNA dataset (e.g. Ding),\n",
    "    optionally restricted to genes shared with the bridge RNA.\n",
    "    \"\"\"\n",
    "    ref = ref_rna.copy()\n",
    "\n",
    "    if counts_layer not in ref.layers:\n",
    "        ref.layers[counts_layer] = ref.X.copy()\n",
    "\n",
    "    # restrict to shared genes if a bridge AnnData is provided\n",
    "    if bridge_rna is not None:\n",
    "        shared = ref.var_names.intersection(bridge_rna.var_names)\n",
    "        ref = ref[:, shared].copy()\n",
    "\n",
    "    ref.X = ref.layers[counts_layer]\n",
    "\n",
    "    try:\n",
    "        sc.pp.highly_variable_genes(\n",
    "            ref,\n",
    "            n_top_genes=int(n_hvg),\n",
    "            flavor=\"seurat_v3\",\n",
    "        )\n",
    "    except Exception:\n",
    "        sc.pp.highly_variable_genes(\n",
    "            ref,\n",
    "            n_top_genes=int(n_hvg),\n",
    "            flavor=\"seurat\",\n",
    "        )\n",
    "\n",
    "    hvgs = ref.var_names[ref.var[\"highly_variable\"].to_numpy()].tolist()\n",
    "    return hvgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode idea\n",
    "combined = ad.concat([uni_rna, rna], join=\"inner\", label=\"dataset\")\n",
    "\n",
    "sc.pp.highly_variable_genes(\n",
    "    combined,\n",
    "    n_top_genes=2000,\n",
    "    flavor=\"seurat_v3\",\n",
    "    batch_key=\"dataset\",  # important: HVGs robust across datasets\n",
    ")\n",
    "\n",
    "hvg = combined.var_names[combined.var[\"highly_variable\"]].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# say you have ding_rna and multiome_rna\n",
    "#hvg_ding = compute_hvgs_from_reference(\n",
    "#    ref_rna=uni_rna,\n",
    "#    bridge_rna=rna_train,      # multiome RNA train split\n",
    "#    counts_layer=\"counts\",\n",
    "#    n_hvg=5000,\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57cd4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Fit on multiome train/val/test\n",
    "(\n",
    "    rna_train_pp,\n",
    "    atac_train_lsi,\n",
    "    rna_val_pp,\n",
    "    atac_val_lsi,\n",
    "    rna_test_pp,\n",
    "    atac_test_lsi,\n",
    "    hvg_used,\n",
    "    tfidf,\n",
    "    svd,\n",
    "    atac_scaler,\n",
    "    rna_scaler,\n",
    ") = preprocess_multiome_splits(\n",
    "    rna_train, atac_train,\n",
    "    rna_val,   atac_val,\n",
    "    rna_test,  atac_test,\n",
    "    rna_counts_layer=\"counts\",\n",
    "    atac_counts_layer=\"counts\",\n",
    "    n_hvg=2000,          # ignored when hvg_list is provided\n",
    "    #hvg_list=hvg_ding,\n",
    "    hvg_list=hvg,\n",
    "    target_sum=1e4,\n",
    "    n_lsi=100,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"Multiome is using HVGs:\", len(hvg_used))\n",
    "print(\"RNA train mean/std:\", float(rna_train_pp.X.mean()), float(rna_train_pp.X.std()))\n",
    "print(\"ATAC train mean/std:\", float(atac_train_lsi.X.mean()), float(atac_train_lsi.X.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2392774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Transform unimodal RNA & ATAC using the SAME HVGs / LSI\n",
    "#    (this is the “bridge” part)\n",
    "# RNA: keep only bridge HVGs that exist in the unimodal dataset\n",
    "\n",
    "uni_rna_pp = transform_rna_with_hvg(\n",
    "    uni_rna,\n",
    "    hvg=hvg,\n",
    "    counts_layer=\"counts\",\n",
    "    target_sum=1e4,\n",
    "    rna_scaler=rna_scaler,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATAC: need overlapping peaks; align first\n",
    "common_peaks = atac.var_names.intersection(uni_atac.var_names)\n",
    "print(\"Shared ATAC peaks (bridge vs unimodal):\", len(common_peaks))\n",
    "\n",
    "atac_bridge_aligned = atac[:, common_peaks].copy()\n",
    "uni_atac_aligned    = uni_atac[:, common_peaks].copy()\n",
    "\n",
    "uni_atac_lsi = transform_atac_with_lsi(\n",
    "    uni_atac_aligned,\n",
    "    counts_layer=\"counts\",\n",
    "    tfidf=tfidf,\n",
    "    svd=svd,\n",
    "    atac_scaler=atac_scaler,\n",
    ")\n",
    "\n",
    "# Now you have:\n",
    "# - rna_train_pp / rna_val_pp / rna_test_pp \n",
    "# - atac_train_lsi / atac_val_lsi / atac_test_lsi   \n",
    "#   (for UniVI training + eval)\n",
    "# - uni_rna_pp \n",
    "# - uni_atac_lsi   \n",
    "#   (unimodal datasets mapped into the same feature spaces) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rna_train_pp)\n",
    "print(rna_val_pp)\n",
    "print(rna_test_pp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c61c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rna_train_pp.X.min())\n",
    "print(rna_train_pp.X.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bd1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(atac_train_lsi)\n",
    "print(atac_val_lsi)\n",
    "print(atac_test_lsi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(atac_train_lsi.X.min())\n",
    "print(atac_train_lsi.X.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uni_rna_pp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b44955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uni_atac_lsi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464bf1d9",
   "metadata": {},
   "source": [
    "### Wrap into MultiModalDataset & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d509d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from univi.data import align_paired_obs_names\n",
    "\n",
    "pin_memory = (device == \"cuda\")\n",
    "\n",
    "# Make sure each split is paired and ordered the same across modalities\n",
    "# This was erroring out due to a function bug, fixed it and should be fixed by manuscript publication\n",
    "#train_dict = align_paired_obs_names({\"rna\": rna_train_pp, \"adt\": atac_train_lsi})\n",
    "#val_dict   = align_paired_obs_names({\"rna\": rna_val_pp,   \"adt\": atac_val_lsi})\n",
    "#test_dict  = align_paired_obs_names({\"rna\": rna_test_pp,  \"adt\": atac_test_lsi})\n",
    "\n",
    "# Using this instead for now since we know the data are already paired from above code\n",
    "assert (rna_train_pp.obs_names == atac_train_lsi.obs_names).all()\n",
    "assert (rna_val_pp.obs_names   == atac_val_lsi.obs_names).all()\n",
    "assert (rna_test_pp.obs_names  == atac_test_lsi.obs_names).all()\n",
    "\n",
    "train_dict = {\"rna\": rna_train_pp, \"atac\": atac_train_lsi}\n",
    "val_dict   = {\"rna\": rna_val_pp,   \"atac\": atac_val_lsi}\n",
    "test_dict  = {\"rna\": rna_test_pp,  \"atac\": atac_test_lsi}\n",
    "\n",
    "# Build datasets (CPU tensors; trainer/model moves to GPU)\n",
    "train_ds = MultiModalDataset(adata_dict=train_dict, X_key=\"X\", device=None)\n",
    "val_ds   = MultiModalDataset(adata_dict=val_dict,   X_key=\"X\", device=None)\n",
    "test_ds  = MultiModalDataset(adata_dict=test_dict,  X_key=\"X\", device=None)\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 0\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "'''\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# labels for the TRAIN split (same order as train_ds cells)\n",
    "y = rna_train_pp.obs[\"cell_type\"].astype(str).to_numpy()\n",
    "\n",
    "# inverse frequency weights\n",
    "vals, counts = np.unique(y, return_counts=True)\n",
    "freq = dict(zip(vals, counts))\n",
    "w = np.array([1.0 / freq[c] for c in y], dtype=np.float64)\n",
    "w = w / w.sum()\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=torch.as_tensor(w, dtype=torch.double),\n",
    "    num_samples=len(w),   # one \"epoch\" worth of draws\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler,      # <-- instead of shuffle=True\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    ")\n",
    "'''\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "print(\"n_train / n_val / n_test:\", train_ds.n_cells, val_ds.n_cells, test_ds.n_cells)\n",
    "print(\"batches:\", len(train_loader), len(val_loader), len(test_loader))\n",
    "\n",
    "# sanity check one batch\n",
    "x = next(iter(train_loader))\n",
    "print({k: v.shape for k, v in x.items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440bef8a",
   "metadata": {},
   "source": [
    "### UniVI configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9849b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_codes = rna.obs[\"cell_type\"].astype(\"category\").cat.codes.to_numpy()\n",
    "#n_classes = int(y_codes.max() + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8436ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "univi_cfg = UniVIConfig(\n",
    "    latent_dim=30,\n",
    "    beta=1.0,\n",
    "    gamma=5.0,\n",
    "    encoder_dropout=0.25,\n",
    "    decoder_dropout=0.05,\n",
    "    encoder_batchnorm=True,\n",
    "    decoder_batchnorm=False,\n",
    "    kl_anneal_start=0,\n",
    "    kl_anneal_end=25,\n",
    "    align_anneal_start=15,\n",
    "    align_anneal_end=40,\n",
    "    modalities=[\n",
    "        ModalityConfig(\n",
    "            name=\"rna\",\n",
    "            input_dim=rna_train_pp.n_vars,\n",
    "            encoder_hidden=[512, 256, 128],\n",
    "            decoder_hidden=[128, 256, 512],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "        ModalityConfig(\n",
    "            name=\"atac\",\n",
    "            input_dim=atac_train_lsi.n_vars,\n",
    "            encoder_hidden=[128, 64],\n",
    "            decoder_hidden=[64, 128],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f3b73",
   "metadata": {},
   "source": [
    "If you want raw-count NB/ZINB instead, you’d:\n",
    "* Put raw counts in .layers[\"counts\"]\n",
    "* Set X_key=\"counts\" in the dataset\n",
    "* Use likelihood=\"nb\" or \"zinb\" above\n",
    "\n",
    "But for this \"Figure 5\" notebook, the scaled Gaussian setup is nicely stable and good for the best-integrated latent space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467656e6",
   "metadata": {},
   "source": [
    "### Instantiate model and model objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdceded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = UniVIMultiModalVAE(\n",
    "    univi_cfg,\n",
    "    loss_mode=\"v1\",      # cross-recon + cross-posterior alignment\n",
    "    #loss_mode=\"lite\"\n",
    "    #v1_recon=\"cross\",   # full k→j cross-recon\n",
    "    v1_recon=\"avg\",\n",
    "    #v1_recon_mix=0.5,\n",
    "    normalize_v1_terms=True,\n",
    ").to(device)\n",
    "\n",
    "'''\n",
    "model = UniVIMultiModalVAE(\n",
    "    univi_cfg,\n",
    "    loss_mode=\"v1\",      # cross-recon + cross-posterior alignment\n",
    "    #loss_mode=\"lite\"\n",
    "    #v1_recon=\"cross\",   # full k→j cross-recon\n",
    "    v1_recon=\"avg\",\n",
    "    #v1_recon_mix=0.5,\n",
    "    normalize_v1_terms=True,\n",
    "    n_label_classes=n_classes,\n",
    "    label_loss_weight=5.0,\n",
    "    label_ignore_index=-1,\n",
    "    classify_from_mu=True,\n",
    ").to(device)\n",
    "'''\n",
    "'''\n",
    "model = UniVIMultiModalVAE(\n",
    "    univi_cfg,\n",
    "    loss_mode=\"lite\",\n",
    "\n",
    "    # Optional: keep the decoder-side classification head too\n",
    "    n_label_classes=n_classes,\n",
    "    label_loss_weight=2.0,\n",
    "\n",
    "    # Encoder-side label expert injected into fusion\n",
    "    use_label_encoder=True,\n",
    "    label_moe_weight=3.5,      # >1 => labels influence fusion more\n",
    "    unlabeled_logvar=20.0,     # very high => tiny precision => ignored in fusion\n",
    "    label_encoder_warmup=5,    # wait N epochs before injecting labels into fusion\n",
    "    label_ignore_index=-1,\n",
    ").to(\"cuda\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7700f937",
   "metadata": {},
   "source": [
    "### Instantiate TrainingConfig & trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2debd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg = TrainingConfig(\n",
    "    n_epochs=5000,\n",
    "    batch_size=batch_size,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    device=device,\n",
    "    log_every=100,\n",
    "    grad_clip=5.0,\n",
    "    num_workers=0,\n",
    "    seed=42,\n",
    "    early_stopping=True,\n",
    "    patience=150,         # Setting kind of high patience since training takes ~1s/iteration because of small-ish dataset\n",
    "    min_delta=0.0,\n",
    ")\n",
    "\n",
    "print(train_cfg)\n",
    "print(univi_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80cf3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = UniVITrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    train_cfg=train_cfg,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(trainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c7e3b",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f710c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.fit()\n",
    "\n",
    "# history is a dict with keys like \"train_loss\", \"val_loss\", \"beta\", \"gamma\"\n",
    "print(\"Training finished.\")\n",
    "print(\"Best val loss:\", np.min(history[\"val_loss\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"train_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_loss\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"UniVI training (Multiome)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9965c64",
   "metadata": {},
   "source": [
    "### Write latent z back to AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# If I want to later use existing model weights to instantiate a model and change objectives.\n",
    "# For example\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import univi as uv\n",
    "\n",
    "# -----------------------\n",
    "# 1) Load checkpoint\n",
    "# -----------------------\n",
    "ckpt_path = Path(\"checkpoints/pbmc_bridge_stage1_best.pt\")\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "model_config_stage1 = ckpt.get(\"model_config\")\n",
    "train_config_stage1 = ckpt.get(\"train_config\")\n",
    "\n",
    "# -----------------------\n",
    "# 2) Rebuild the model\n",
    "# -----------------------\n",
    "# However you normally do this:\n",
    "model = uv.models.UniVI(**model_config_stage1[\"model_kwargs\"])\n",
    "model.to(device)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "print(\"Loaded stage-1 weights from\", ckpt_path)\n",
    "\n",
    "# -----------------------\n",
    "# 3) New training config (change objective)\n",
    "# -----------------------\n",
    "# You can start from the old config dict and tweak:\n",
    "train_config_stage2 = train_config_stage1.copy()\n",
    "train_config_stage2.update(\n",
    "    {\n",
    "        \"mode\": \"lite\",        # or \"v1\" -> \"lite\", or whatever flag you’re using\n",
    "        \"max_epochs\": 30,      # shorter fine-tuning\n",
    "        \"lr\": 1e-4,            # usually smaller LR for fine-tuning\n",
    "        # optionally change loss weights here:\n",
    "        # \"lambda_align\": 0.5,\n",
    "        # \"lambda_recon\": 1.0,\n",
    "        # \"lambda_cls\": 1.0,\n",
    "    }\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=train_config_stage2[\"lr\"])\n",
    "\n",
    "# -----------------------\n",
    "# 4) New trainer for stage 2\n",
    "# -----------------------\n",
    "trainer2 = uv.UniVITrainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader_stage2,\n",
    "    val_loader=val_loader_stage2,\n",
    "    config=train_config_stage2,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "trainer2.train()\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e944299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from univi.evaluation import encode_adata\n",
    "\n",
    "# Unimodal RNA → UniVI latent\n",
    "Z_uni_rna = encode_adata(\n",
    "    model,\n",
    "    uni_rna_pp,\n",
    "    modality=\"rna\",\n",
    "    latent=\"modality_mean\",   # or \"moe_mean\" if you want fused-ish\n",
    "    device=device,\n",
    "    batch_size=1024,\n",
    ")\n",
    "uni_rna_pp.obsm[\"X_univi_rna\"] = Z_uni_rna\n",
    "\n",
    "# Unimodal ATAC → UniVI latent\n",
    "Z_uni_atac = encode_adata(\n",
    "    model,\n",
    "    uni_atac_lsi,\n",
    "    modality=\"atac\",\n",
    "    latent=\"modality_mean\",\n",
    "    device=device,\n",
    "    batch_size=1024,\n",
    ")\n",
    "uni_atac_lsi.obsm[\"X_univi_atac\"] = Z_uni_atac\n",
    "\n",
    "print(Z_uni_rna.shape, Z_uni_atac.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b0b35",
   "metadata": {},
   "source": [
    "Now both rna and atac have a shared latent:\n",
    "\n",
    "* rna_test_pp.obsm[\"X_univi\"]\n",
    "\n",
    "* atac_test_pp.obsm[\"X_univi\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e56248",
   "metadata": {},
   "source": [
    "### Code to save/load modal if so inclined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A) You already have rna_train_pp / rna_val_pp / rna_test_pp (no resplitting)\n",
    "from univi.utils.io import save_anndata_splits\n",
    "\n",
    "save_anndata_splits(\n",
    "    outdir=output_dir,\n",
    "    prefix=\"rna\",\n",
    "    splits={\"train\": rna_train_pp, \"val\": rna_val_pp, \"test\": rna_test_pp},\n",
    "    copy=False,\n",
    ")\n",
    "\n",
    "B) You want to split from the original using obs_names / indices / masks\n",
    "save_anndata_splits(\n",
    "    adata=rna,\n",
    "    outdir=output_dir,\n",
    "    prefix=\"rna\",\n",
    "    split_map={\n",
    "        \"train\": rna_train_pp.obs_names.tolist(),\n",
    "        \"val\":   rna_val_pp.obs_names.tolist(),\n",
    "        \"test\":  rna_test_pp.obs_names.tolist(),\n",
    "    },\n",
    "    copy=False,\n",
    ")\n",
    "\n",
    "C) Only save the JSON split map (no huge .h5ad writes)\n",
    "save_anndata_splits(\n",
    "    adata=rna,\n",
    "    outdir=output_dir,\n",
    "    prefix=\"rna\",\n",
    "    split_map={\n",
    "        \"train\": rna_train_pp.obs_names.tolist(),\n",
    "        \"val\":   rna_val_pp.obs_names.tolist(),\n",
    "        \"test\":  rna_test_pp.obs_names.tolist(),\n",
    "    },\n",
    "    save_h5ad=False,\n",
    "    save_split_map=True,\n",
    ")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc058dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_used = \"1.0\"\n",
    "gamma_used = \"5.0\"\n",
    "latent_dims_used = \"30\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c597f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'./results/univi_bridging_unimodal_data_pbmc_beta-{beta_used}_gamma-{gamma_used}_latent_dims-{latent_dims_used}_gaussian_both_reproducibility/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7655f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = f\"trained_multiome_model_beta-{beta_used}_gamma-{gamma_used}_latent_dims-{latent_dims_used}_gaussian_both_reproducibility.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# after training\n",
    "#history = trainer.fit()\n",
    "\n",
    "# trainer.model already has the best weights (because we restored best_state_dict)\n",
    "ckpt_path = output_dir + out_file\n",
    "torch.save(\n",
    "    {\n",
    "        \"state_dict\": trainer.model.state_dict(),\n",
    "        \"univi_cfg\": asdict(univi_cfg),\n",
    "        \"best_epoch\": trainer.best_epoch,\n",
    "        \"best_val_loss\": trainer.best_val_loss,\n",
    "    },\n",
    "    ckpt_path,\n",
    ")\n",
    "print(\"Saved best model to:\", ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later to reload model\n",
    "import torch\n",
    "from univi.config import UniVIConfig, ModalityConfig\n",
    "from univi.models.univi import UniVIMultiModalVAE\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "#device = \"cuda\"  # or \"cuda\" if available\n",
    "\n",
    "ckpt = torch.load(\n",
    "    output_dir + out_file,\n",
    "    map_location=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fce7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Rebuild UniVIConfig, making sure modalities are ModalityConfig objects ----\n",
    "cfg_dict = ckpt[\"univi_cfg\"]\n",
    "\n",
    "# If this is an OmegaConf object or similar, make sure it's a plain dict\n",
    "try:\n",
    "    from omegaconf import DictConfig, OmegaConf\n",
    "    if isinstance(cfg_dict, DictConfig):\n",
    "        cfg_dict = OmegaConf.to_container(cfg_dict, resolve=True)\n",
    "except ImportError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66951dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now rehydrate each modality\n",
    "modalities = [ModalityConfig(**m) for m in cfg_dict[\"modalities\"]]\n",
    "cfg_dict = {**cfg_dict, \"modalities\": modalities}\n",
    "\n",
    "univi_cfg_loaded = UniVIConfig(**cfg_dict)\n",
    "\n",
    "# ---- Rebuild model + load weights ----\n",
    "model_loaded = UniVIMultiModalVAE(univi_cfg_loaded).to(device)\n",
    "model_loaded.load_state_dict(ckpt[\"state_dict\"])\n",
    "\n",
    "print(\"Best epoch was:\", ckpt.get(\"best_epoch\"), \"val loss =\", ckpt.get(\"best_val_loss\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad0f25",
   "metadata": {},
   "source": [
    "### Figure 5 stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57703d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# ----------------------------\n",
    "# Metrics helpers\n",
    "# ----------------------------\n",
    "def foscttm_chunked(Z1, Z2, block=512):\n",
    "    \"\"\"\n",
    "    Exact FOSCTTM computed in blocks to avoid NxN memory blowups.\n",
    "    Assumes 1:1 pairing between rows i in Z1 and Z2.\n",
    "    \"\"\"\n",
    "    Z1 = np.asarray(Z1, dtype=np.float32)\n",
    "    Z2 = np.asarray(Z2, dtype=np.float32)\n",
    "    assert Z1.shape == Z2.shape\n",
    "    n = Z1.shape[0]\n",
    "\n",
    "    Z2_T = Z2.T\n",
    "    n2 = np.sum(Z2 * Z2, axis=1)  # (n,)\n",
    "\n",
    "    fos = np.empty(n, dtype=np.float32)\n",
    "\n",
    "    for i0 in range(0, n, block):\n",
    "        i1 = min(i0 + block, n)\n",
    "        A = Z1[i0:i1]  # (b, d)\n",
    "        n1 = np.sum(A * A, axis=1)[:, None]  # (b,1)\n",
    "\n",
    "        d2 = n1 + n2[None, :] - 2.0 * (A @ Z2_T)  # (b,n)\n",
    "\n",
    "        true = d2[np.arange(i1 - i0), np.arange(i0, i1)]\n",
    "        fos[i0:i1] = (d2 < true[:, None]).sum(axis=1) / (n - 1)\n",
    "\n",
    "    return float(fos.mean()), float(fos.std(ddof=1) / np.sqrt(n))\n",
    "\n",
    "\n",
    "def modality_mixing_score(Z, modality_labels, k=20, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Vanilla modality mixing:\n",
    "    Mean fraction of kNN neighbors that differ in modality.\n",
    "    Use this for *non-duplicated* sets (e.g., concatenated modality-specific embeddings).\n",
    "    \"\"\"\n",
    "    Z = np.asarray(Z, dtype=np.float32)\n",
    "    modality_labels = np.asarray(modality_labels)\n",
    "\n",
    "    n = Z.shape[0]\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    k_eff = int(min(max(int(k), 1), n - 1))\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff + 1, metric=metric)\n",
    "    nn.fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]  # drop self\n",
    "\n",
    "    same = (modality_labels[nbrs] == modality_labels[:, None])\n",
    "    return float((~same).mean())\n",
    "\n",
    "\n",
    "def modality_mixing_score_excluding_pairs(Z, modality_labels, cell_ids, k=20, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Pair-aware modality mixing for 'combo' style stacked data (same cell appears twice: RNA + ADT),\n",
    "    where the fused embedding may be identical (or extremely close) for the paired duplicates.\n",
    "\n",
    "    Computes: for each row, the fraction of neighbors from the other modality,\n",
    "    AFTER removing the paired duplicate (same cell_id) from its neighbor list.\n",
    "\n",
    "    cell_ids must map each row to a shared cell identifier (same for RNA+ADT copy).\n",
    "    \"\"\"\n",
    "    Z = np.asarray(Z, dtype=np.float32)\n",
    "    modality_labels = np.asarray(modality_labels)\n",
    "    cell_ids = np.asarray(cell_ids).astype(str)\n",
    "\n",
    "    n = Z.shape[0]\n",
    "    if n <= 2:\n",
    "        return 0.0\n",
    "\n",
    "    # Need enough neighbors so we can drop self + paired duplicate and still have k\n",
    "    k_eff = int(min(max(int(k), 1), n - 2))\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff + 2, metric=metric)\n",
    "    nn.fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]  # drop self\n",
    "\n",
    "    # Build \"pair index\": for each row i, pair[i] is the index of the other modality copy\n",
    "    first = {}\n",
    "    pair = np.full(n, -1, dtype=np.int64)\n",
    "    for i, cid in enumerate(cell_ids):\n",
    "        if cid in first:\n",
    "            j = first[cid]\n",
    "            pair[i] = j\n",
    "            pair[j] = i\n",
    "        else:\n",
    "            first[cid] = i\n",
    "\n",
    "    frac_other = np.empty(n, dtype=np.float32)\n",
    "    for i in range(n):\n",
    "        neigh = nbrs[i]\n",
    "\n",
    "        # remove paired duplicate if present\n",
    "        pj = pair[i]\n",
    "        if pj != -1:\n",
    "            neigh = neigh[neigh != pj]\n",
    "\n",
    "        neigh = neigh[:k_eff]\n",
    "        frac_other[i] = (modality_labels[neigh] != modality_labels[i]).mean()\n",
    "\n",
    "    return float(frac_other.mean())\n",
    "\n",
    "\n",
    "def knn_label_transfer(Z_source, y_source, Z_target, y_target, k=15, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    kNN label transfer: predict y_target from neighbors in Z_source.\n",
    "    Returns predictions, accuracy, macro-F1, confusion matrix.\n",
    "    \"\"\"\n",
    "    Z_source = np.asarray(Z_source, dtype=np.float32)\n",
    "    Z_target = np.asarray(Z_target, dtype=np.float32)\n",
    "    y_source = np.asarray(y_source, dtype=str)\n",
    "    y_target = np.asarray(y_target, dtype=str)\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=k, metric=metric)\n",
    "    nn.fit(Z_source)\n",
    "    nbrs = nn.kneighbors(Z_target, return_distance=False)\n",
    "\n",
    "    preds = []\n",
    "    for inds in nbrs:\n",
    "        votes = y_source[inds]\n",
    "        vals, cnts = np.unique(votes, return_counts=True)\n",
    "        preds.append(vals[np.argmax(cnts)])\n",
    "    preds = np.asarray(preds, dtype=str)\n",
    "\n",
    "    acc = float(accuracy_score(y_target, preds))\n",
    "    macro_f1 = float(f1_score(y_target, preds, average=\"macro\"))\n",
    "    classes = np.unique(np.concatenate([y_source, y_target]))\n",
    "    cm = confusion_matrix(y_target, preds, labels=classes)\n",
    "    return preds, acc, macro_f1, cm, classes\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# If plots ever don't show in classic notebook, run once:\n",
    "# %matplotlib inline\n",
    "\n",
    "# -------------------------\n",
    "# show-or-save helper\n",
    "# -------------------------\n",
    "def _finish(fig=None, outpath=None, dpi=300, show=True, close=True):\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath, dpi=dpi, bbox_inches=\"tight\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if close:\n",
    "        plt.close(fig if fig is not None else plt.gcf())\n",
    "\n",
    "# -------------------------\n",
    "# plots\n",
    "# -------------------------\n",
    "def plot_metrics_bar(\n",
    "    metrics,\n",
    "    keys,\n",
    "    title=\"Figure 2 summary metrics\",\n",
    "    outpath=None,\n",
    "    err_keys=None,          # dict: metric_key -> error_metric_key\n",
    "    default_err=np.nan,     # np.nan = no error bar drawn; 0.0 = zero-length\n",
    "    capsize=4,\n",
    "):\n",
    "    vals = np.array([float(metrics[k]) for k in keys], dtype=float)\n",
    "\n",
    "    if err_keys is None:\n",
    "        yerr = np.full_like(vals, default_err, dtype=float)\n",
    "    else:\n",
    "        yerr = np.array(\n",
    "            [float(metrics[err_keys[k]]) if k in err_keys and err_keys[k] in metrics else default_err\n",
    "             for k in keys],\n",
    "            dtype=float\n",
    "        )\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.bar(keys, vals, yerr=yerr, capsize=capsize)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # inline “finish” behavior\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_confusion(cm, classes, title, normalize=\"true\", outpath=None, cmap=\"viridis\"):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    cm = np.asarray(cm, dtype=float)\n",
    "    if normalize == \"true\":\n",
    "        cm = cm / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
    "        subtitle = \"Row-normalized\"\n",
    "    elif normalize == \"pred\":\n",
    "        cm = cm / (cm.sum(axis=0, keepdims=True) + 1e-12)\n",
    "        subtitle = \"Col-normalized\"\n",
    "    elif normalize == \"all\":\n",
    "        cm = cm / (cm.sum() + 1e-12)\n",
    "        subtitle = \"Global-normalized\"\n",
    "    else:\n",
    "        subtitle = \"Counts\"\n",
    "\n",
    "    classes = np.asarray(classes, dtype=str)\n",
    "    n = len(classes)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 13))\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\", cmap=cmap, aspect=\"auto\")\n",
    "\n",
    "    # kill any gridlines (including ones from styles)\n",
    "    ax.grid(False)\n",
    "    ax.minorticks_off()\n",
    "\n",
    "    ax.set_title(f\"{title}\\n({subtitle})\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "\n",
    "    ax.set_xticks(np.arange(n))\n",
    "    ax.set_yticks(np.arange(n))\n",
    "    ax.set_xticklabels(classes, rotation=90)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label(\"value\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if outpath is not None:\n",
    "        fig.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_per_class_f1(y_true, y_pred, title=\"Per-class F1\", outpath=None, top_n=None):\n",
    "    y_true = np.asarray(y_true).astype(str)\n",
    "    y_pred = np.asarray(y_pred).astype(str)\n",
    "    classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "\n",
    "    _, _, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=classes, zero_division=0\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame({\"class\": classes, \"f1\": f1, \"support\": support})\n",
    "    df = df.sort_values([\"f1\", \"support\"], ascending=[True, False])\n",
    "\n",
    "    if top_n is not None:\n",
    "        df = df.head(int(top_n))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 0.35 * len(df) + 2.0))\n",
    "    plt.barh(df[\"class\"], df[\"f1\"])\n",
    "    plt.xlabel(\"F1\")\n",
    "    plt.title(title)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n",
    "    return df\n",
    "\n",
    "def plot_modality_mixing_hist(Z, mods, k=20, metric=\"euclidean\", title=\"Modality mixing\", outpath=None):\n",
    "    Z = np.asarray(Z, dtype=np.float32)\n",
    "    mods = np.asarray(mods)\n",
    "\n",
    "    n = Z.shape[0]\n",
    "    k_eff = int(min(max(int(k), 1), n - 1))\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff + 1, metric=metric)\n",
    "    nn.fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]\n",
    "    frac_other = (mods[nbrs] != mods[:, None]).mean(axis=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(7, 4.5))\n",
    "    plt.hist(frac_other, bins=60)\n",
    "    plt.xlabel(\"Fraction of kNN from other modality\")\n",
    "    plt.ylabel(\"# cells\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n",
    "    return frac_other\n",
    "\n",
    "def plot_foscttm_sanity(Z1, Z2, idx, title=\"FOSCTTM sanity\", outpath=None):\n",
    "    Z1s = np.asarray(Z1[idx], dtype=np.float32)\n",
    "    Z2s = np.asarray(Z2[idx], dtype=np.float32)\n",
    "\n",
    "    d_true = np.sum((Z1s - Z2s) ** 2, axis=1)\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=51, metric=\"euclidean\")\n",
    "    nn.fit(np.asarray(Z2, dtype=np.float32))\n",
    "    dist, _ = nn.kneighbors(Z1s)\n",
    "    d_min = dist[:, 0] ** 2\n",
    "\n",
    "    fig = plt.figure(figsize=(5.5, 5.5))\n",
    "    plt.scatter(d_true, d_min, s=8, alpha=0.4)\n",
    "    mx = np.percentile(np.concatenate([d_true, d_min]), 99)\n",
    "    plt.plot([0, mx], [0, mx], linewidth=1)\n",
    "    plt.xlim(0, mx); plt.ylim(0, mx)\n",
    "    plt.xlabel(\"d(true match)^2\")\n",
    "    plt.ylabel(\"d(nearest neighbor)^2\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n",
    "\n",
    "def plot_paired_distance_hist(Z_rna, Z_adt, idx, title=\"Paired latent distance (subset)\", outpath=None):\n",
    "    d_pair = np.sqrt(np.sum((Z_rna[idx] - Z_adt[idx]) ** 2, axis=1))\n",
    "    fig = plt.figure(figsize=(7, 4.5))\n",
    "    plt.hist(d_pair, bins=80)\n",
    "    plt.xlabel(\"||z_rna - z_adt||\")\n",
    "    plt.ylabel(\"# cells\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e3b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_key = \"celltype\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eabab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uni_rna_pp)\n",
    "print(uni_atac_lsi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f529b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper: find a reasonable raw celltype column\n",
    "# ------------------------------------------------\n",
    "def _get_celltype_series(\n",
    "    adata,\n",
    "    candidates=(\"celltype\", \"cell_type\", \"celltype.l2\", \"cell_type_l2\", \"annot\", \"leiden\")\n",
    "):\n",
    "    \"\"\"Return a string Series of celltype labels if any candidate is present, else None.\"\"\"\n",
    "    for key in candidates:\n",
    "        if key in adata.obs:\n",
    "            return adata.obs[key].astype(str), key\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8be6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(uni_rna_pp.obs['celltype']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(uni_atac_lsi.obs['celltype']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cd0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canonical, \"figure-style\" labels\n",
    "CANON = {\n",
    "    \"B\":                           \"B\",\n",
    "    \"Memory B\":                    \"Memory B\",\n",
    "    \"CD14+ monocyte\":              \"CD14+ monocyte\",\n",
    "    \"CD16+ monocyte\":              \"CD16+ monocyte\",\n",
    "    \"Monocyte\":                    \"Monocyte\",\n",
    "    \"NK\":                          \"NK\",\n",
    "    \"CD4 T\":                       \"CD4 T\",\n",
    "    \"CD4 T Helper\":                \"CD4 T helper\",\n",
    "    \"Memory CD4 T\":                \"Memory CD4 T\",\n",
    "    \"Naive CD4 T\":                 \"Naive CD4 T\",\n",
    "    \"Memory CD8 T\":                \"Memory CD8 T\",\n",
    "    \"Naive CD8 T\":                 \"Naive CD8 T\",\n",
    "    \"Cytotoxic T\":                 \"Cytotoxic T\",\n",
    "    \"Regulatory T\":                \"Regulatory T\",\n",
    "    \"Dendritic Cell\":              \"Dendritic cell\",\n",
    "    \"Plasmacytoid dendritic cell\": \"Plasmacytoid dendritic cell\",\n",
    "    \"Conventional dendritic cell\": \"Conventional dendritic cell\",\n",
    "    \"Megakaryocyte\":               \"Megakaryocyte\",\n",
    "    \"General PBMC\":                \"General PBMC\",\n",
    "    \"Unassigned\":                  \"Unassigned\",\n",
    "    \"Unknown\":                     \"Unknown\",\n",
    "}\n",
    "\n",
    "HARMONIZATION_MAP = {\n",
    "    # 'Plasmacytoid dendritic cell', 'Natural killer cell', 'CD4+ T cell', \n",
    "    # 'Megakaryocyte', 'Cytotoxic T cell', 'CD16+ monocyte', 'B cell', \n",
    "    # 'Unassigned', 'CD14+ monocyte', 'Dendritic cell'\n",
    "    \"ding_rna\": {\n",
    "        # ---- T cells ----\n",
    "        \"Naive CD4 T\":          \"Naive CD4 T\",\n",
    "        \"CD4 Naive\":            \"Naive CD4 T\",\n",
    "\n",
    "        \"CD4 TCM\":              \"Memory CD4 T\",\n",
    "        \"CD4 TEM\":              \"Memory CD4 T\",\n",
    "        \"CD4 Memory\":           \"Memory CD4 T\",\n",
    "\n",
    "        \"Naive CD8 T\":          \"Naive CD8 T\",\n",
    "        \"CD8 Naive\":            \"Naive CD8 T\",\n",
    "\n",
    "        \"CD8 TCM\":              \"Memory CD8 T\",\n",
    "        \"CD8 TEM\":              \"Memory CD8 T\",\n",
    "        \"CD8 TEMRA\":            \"Cytotoxic T\",\n",
    "        \"CD8 Effector\":         \"Cytotoxic T\",\n",
    "        \"CD8 Cytotoxic\":        \"Cytotoxic T\",\n",
    "        \"Cytotoxic T cell\":     \"Cytotoxic T\",\n",
    "\n",
    "        \"CD4 T cell\":           \"CD4 T\",\n",
    "        \"CD4+ T cell\":          \"CD4 T\",\n",
    "        \"CD4 Helper T cell\":    \"CD4 T helper\",\n",
    "        \"Treg\":                 \"Regulatory T\",\n",
    "        \"Regulatory T\":         \"Regulatory T\",\n",
    "\n",
    "        # ---- NK / NKT ----\n",
    "        \"NK\":                   \"NK\",\n",
    "        \"NK cell\":              \"NK\",\n",
    "        \"Natural killer cell\":  \"NK\",\n",
    "\n",
    "        # ---- B cells ----\n",
    "        \"B\":                    \"B\",\n",
    "        \"B cell\":               \"B\",\n",
    "        \"B cells\":              \"B\",\n",
    "        \"Memory B\":             \"Memory B\",\n",
    "        \"Memory B cell\":        \"Memory B\",\n",
    "        \"Memory B cells\":       \"Memory B\",\n",
    "\n",
    "        # ---- Monocytes ----\n",
    "        \"CD14+ Monocyte\":       \"CD14+ monocyte\",\n",
    "        \"CD14+ monocyte\":       \"CD14+ monocyte\",\n",
    "        \"CD14 Monocyte\":        \"CD14+ monocyte\",\n",
    "        \"Mono CD14\":            \"CD14+ monocyte\",\n",
    "\n",
    "        \"CD16+ Monocyte\":       \"CD16+ monocyte\",\n",
    "        \"CD16+ monocyte\":       \"CD16+ monocyte\",\n",
    "        \"CD16 Monocyte\":        \"CD16+ monocyte\",\n",
    "        \"Mono CD16\":            \"CD16+ monocyte\",\n",
    "\n",
    "        \"Monocyte\":             \"Monocyte\",\n",
    "        \"Monocytes\":            \"Monocyte\",\n",
    "\n",
    "        # ---- DC / pDC ----\n",
    "        \"Dendritic cell\":       \"Dendritic cell\",\n",
    "        \"Dendritic cells\":      \"Dendritic cell\",\n",
    "        \"DC\":                   \"Dendritic cell\",\n",
    "        \"cDC\":                  \"Dendritic cell\",\n",
    "\n",
    "        \"pDC\":                  \"Plasmacytoid dendritic cell\",\n",
    "        \"BM pDC\":               \"Plasmacytoid dendritic cell\",  # Maybe leave as BM?\n",
    "\n",
    "        # ---- Progenitors / others ----\n",
    "        \"HSPC\":                 \"HSPC\",\n",
    "        \"Progenitor\":           \"HSPC\",\n",
    "        \"Megakaryocyte\":        \"Megakaryocyte\",\n",
    "        \"PBMC\":                 \"General PBMC\",\n",
    "\n",
    "        # ---- catch-alls ----\n",
    "        \"Unassigned\":           \"Unassigned\",\n",
    "        \"Unknown\":              \"Unknown\",\n",
    "    },\n",
    "\n",
    "    # 'Dendritic_Cells', 'Naive_CD4_T_Cells', 'Monocytes', 'Memory_CD4_T_Cells', \n",
    "    # 'Memory_CD8_T_Cells', 'Regulatory_T_Cells', 'B_Cells', 'PBMC', 'NK_Cells', \n",
    "    # 'Naive_CD8_T_Cells', 'Bone_Marrow', 'BM_pDC', 'CD4_HelperT'\n",
    "    \"satpathy_atac\": {\n",
    "        # ---- T cells ----\n",
    "        \"Naive_CD4_T_Cells\":    \"Naive CD4 T\",\n",
    "        \"CD4 T naive\":          \"Naive CD4 T\",\n",
    "\n",
    "        \"Memory_CD4_T_Cells\":   \"Memory CD4 T\",\n",
    "        \"CD4 T memory\":         \"Memory CD4 T\",\n",
    "        \n",
    "        \"CD4_HelperT\":          \"CD4 T helper\",\n",
    "\n",
    "        \"Naive_CD8_T_Cells\":    \"Naive CD8 T\",\n",
    "        \"CD8 Naive\":            \"Naive CD8 T\",\n",
    "        \"CD8 T naive\":          \"Naive CD8 T\",\n",
    "\n",
    "        \"CD8 Effector\":         \"Memory CD8 T\",\n",
    "        \"Memory_CD8_T_Cells\":   \"Memory CD8 T\",\n",
    "        \"CD8 Cytotoxic\":        \"Cytotoxic T\",\n",
    "\n",
    "        \"Regulatory_T_Cells\":   \"Regulatory T\",\n",
    "        \"Regulatory T\":         \"Regulatory T\",\n",
    "        \"TREG\":                 \"Regulatory T\",\n",
    "\n",
    "        # ---- NK ----\n",
    "        \"NK\":                   \"NK\",\n",
    "        \"NK cell\":              \"NK\",\n",
    "        \"NK_Cells\":             \"NK\",\n",
    "        \"Natural killer cell\":  \"NK\",\n",
    "\n",
    "        # ---- B cells ----\n",
    "        \"B\":                    \"B\",\n",
    "        \"B cell\":               \"B\",\n",
    "        \"B cells\":              \"B\",\n",
    "        \"B_Cells\":              \"B\",\n",
    "        \"Memory B\":             \"Memory B\",\n",
    "        \"Memory B cell\":        \"Memory B\",\n",
    "        \"Memory B cells\":       \"Memory B\",\n",
    "\n",
    "        # ---- Monocytes ----\n",
    "        \"CD14 Monocyte\":        \"CD14+ monocyte\",\n",
    "        \"Mono CD14\":            \"CD14+ monocyte\",\n",
    "\n",
    "        \"CD16 Monocyte\":        \"CD16+ monocyte\",\n",
    "        \"Mono CD16\":            \"CD16+ monocyte\",\n",
    "\n",
    "        \"Monocyte\":             \"Monocyte\",\n",
    "        \"Monocytes\":            \"Monocyte\",\n",
    "\n",
    "        # ---- DC / pDC ----\n",
    "        \"Dendritic cell\":       \"Dendritic cell\",\n",
    "        \"Dendritic_Cells\":      \"Dendritic cell\",\n",
    "        \"Conventional DC\":      \"Dendritic cell\",\n",
    "        \"cDC\":                  \"Conventional dendritic cell\",\n",
    "\n",
    "        \"BM_pDC\":               \"Plasmacytoid dendritic cell\",\n",
    "        \"pDC\":                  \"Plasmacytoid dendritic cell\",\n",
    "\n",
    "        # ---- Progenitors / others ----\n",
    "        \"HSPC\":                 \"HSPC\",\n",
    "        \"Progenitor\":           \"HSPC\",\n",
    "        \"PBMC\":                 \"General PBMC\",\n",
    "        \"Bone_Marrow\":          \"General PBMC\",\n",
    "        \"Megakaryocyte\":        \"Megakaryocyte\",\n",
    "\n",
    "        # ---- catch-alls ----\n",
    "        \"Unassigned\":           \"Unassigned\",\n",
    "        \"Unknown\":              \"Unknown\",\n",
    "    },\n",
    "\n",
    "    # Multiome still unlabeled for now\n",
    "    \"multiome_rna\":  {},\n",
    "    \"multiome_atac\": {},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_harmonized_labels(adata, dataset_name):\n",
    "    raw, key = _get_celltype_series(adata)\n",
    "    if raw is None:\n",
    "        adata.obs[\"celltype_raw\"] = pd.Series(\n",
    "            [f\"unlabeled_{dataset_name}\"] * adata.n_obs,\n",
    "            index=adata.obs_names,\n",
    "            dtype=\"object\",\n",
    "        )\n",
    "        adata.obs[\"celltype_harmonized\"] = adata.obs[\"celltype_raw\"].copy()\n",
    "        return adata\n",
    "\n",
    "    adata.obs[\"celltype_raw\"] = raw.astype(str)\n",
    "    mapping = HARMONIZATION_MAP.get(dataset_name, {})\n",
    "\n",
    "    # first-pass: dataset-specific mapping\n",
    "    harm = adata.obs[\"celltype_raw\"].map(mapping)\n",
    "\n",
    "    # fall back to raw where unmapped\n",
    "    mask_missing = harm.isna()\n",
    "    harm[mask_missing] = adata.obs.loc[mask_missing, \"celltype_raw\"]\n",
    "\n",
    "    # snap to canonical spelling if possible\n",
    "    harm = harm.map(lambda x: CANON.get(x, x))\n",
    "\n",
    "    adata.obs[\"celltype_harmonized\"] = harm.astype(\"category\")\n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc03eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from univi.evaluation import encode_adata\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2.1 Build a \"bridge\" reference from all Multiome splits\n",
    "# ------------------------------------------------\n",
    "bridge_rna = ad.concat(\n",
    "    {\"rna_train\": rna_train_pp, \"rna_val\": rna_val_pp, \"rna_test\": rna_test_pp},\n",
    "    axis=0,\n",
    "    join=\"outer\",\n",
    "    label=\"split\",\n",
    "    index_unique=None,\n",
    ")\n",
    "bridge_atac = ad.concat(\n",
    "    {\"atac_train\": atac_train_lsi, \"atac_val\": atac_val_lsi, \"atac_test\": atac_test_lsi},\n",
    "    axis=0,\n",
    "    join=\"outer\",\n",
    "    label=\"split\",\n",
    "    index_unique=None,\n",
    ")\n",
    "\n",
    "print(\"Bridge RNA:\", bridge_rna.shape)\n",
    "print(\"Bridge ATAC:\", bridge_atac.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 2.2 Encode bridge and unimodal into UniVI latent\n",
    "# ------------------------------------------------\n",
    "# Bridge RNA\n",
    "Z_bridge_rna = encode_adata(\n",
    "    model,\n",
    "    bridge_rna,\n",
    "    modality=\"rna\",\n",
    "    latent=\"modality_mean\",\n",
    "    device=device,\n",
    "    batch_size=1024,\n",
    ")\n",
    "bridge_rna.obsm[\"X_univi\"] = Z_bridge_rna\n",
    "\n",
    "# Bridge ATAC\n",
    "Z_bridge_atac = encode_adata(\n",
    "    model,\n",
    "    bridge_atac,\n",
    "    modality=\"atac\",\n",
    "    latent=\"modality_mean\",\n",
    "    device=device,\n",
    "    batch_size=1024,\n",
    ")\n",
    "bridge_atac.obsm[\"X_univi\"] = Z_bridge_atac\n",
    "\n",
    "# Unimodal (already encoded earlier)\n",
    "uni_rna_pp.obsm[\"X_univi\"] = uni_rna_pp.obsm[\"X_univi_rna\"]\n",
    "uni_atac_lsi.obsm[\"X_univi\"] = uni_atac_lsi.obsm[\"X_univi_atac\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d242eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 2.3 Annotate dataset + modality + reference flags\n",
    "# ------------------------------------------------\n",
    "bridge_rna.obs[\"dataset\"] = \"multiome_rna\"\n",
    "bridge_rna.obs[\"modality\"] = \"rna\"\n",
    "bridge_rna.obs[\"is_reference\"] = True\n",
    "\n",
    "bridge_atac.obs[\"dataset\"] = \"multiome_atac\"\n",
    "bridge_atac.obs[\"modality\"] = \"atac\"\n",
    "bridge_atac.obs[\"is_reference\"] = True\n",
    "\n",
    "uni_rna_pp.obs[\"dataset\"] = \"ding_rna\"\n",
    "uni_rna_pp.obs[\"modality\"] = \"rna\"\n",
    "uni_rna_pp.obs[\"is_reference\"] = False\n",
    "\n",
    "uni_atac_lsi.obs[\"dataset\"] = \"satpathy_atac\"\n",
    "uni_atac_lsi.obs[\"modality\"] = \"atac\"\n",
    "uni_atac_lsi.obs[\"is_reference\"] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 2.4 Add harmonized labels where possible\n",
    "#     (bridge gets 'unlabeled_multiome_*' if no celltypes)\n",
    "# ------------------------------------------------\n",
    "bridge_rna = add_harmonized_labels(bridge_rna, \"multiome\")\n",
    "bridge_atac = add_harmonized_labels(bridge_atac, \"multiome\")\n",
    "uni_rna_pp  = add_harmonized_labels(uni_rna_pp,  \"ding_rna\")\n",
    "uni_atac_lsi = add_harmonized_labels(uni_atac_lsi, \"satpathy_atac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "COARSE_MAP = {\n",
    "    # B lineage\n",
    "    \"B\": \"B\",\n",
    "    \"B cell\": \"B\",\n",
    "    \"Memory B\": \"B\",\n",
    "    \"Naive B\": \"B\",\n",
    "\n",
    "    # Monocytes\n",
    "    \"CD14+ monocyte\": \"Monocyte\",\n",
    "    \"CD16+ monocyte\": \"Monocyte\",\n",
    "    \"Monocyte\": \"Monocyte\",\n",
    "\n",
    "    # CD4 T lineage\n",
    "    \"CD4 T\": \"CD4 T\",\n",
    "    \"CD4 T helper\": \"CD4 T\",\n",
    "    \"Naive CD4 T\": \"CD4 T\",\n",
    "    \"Memory CD4 T\": \"CD4 T\",\n",
    "    \"Regulatory T\": \"CD4 T\",\n",
    "    \"Treg\": \"CD4 T\",\n",
    "\n",
    "    # CD8 / cytotoxic T lineage\n",
    "    \"CD8 T\": \"CD8 / cytotoxic T\",\n",
    "    \"Cytotoxic T\": \"CD8 / cytotoxic T\",\n",
    "    \"Naive CD8 T\": \"CD8 / cytotoxic T\",\n",
    "    \"Memory CD8 T\": \"CD8 / cytotoxic T\",\n",
    "\n",
    "    # NK\n",
    "    \"NK\": \"NK\",\n",
    "    \"NK cell\": \"NK\",\n",
    "\n",
    "    # DCs\n",
    "    \"Dendritic cell\": \"Dendritic cell\",\n",
    "    \"Plasmacytoid dendritic cell\": \"Dendritic cell\",\n",
    "    \"pDC\": \"Dendritic cell\",\n",
    "\n",
    "    # Others\n",
    "    \"Megakaryocyte\": \"Megakaryocyte\",\n",
    "    \"HSPC\": \"HSPC / progenitor\",\n",
    "    \"General PBMC\": \"Other\",\n",
    "    \"Unknown\": \"Other\",\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, adata in {\n",
    "    \"ding_rna\": uni_rna_pp,\n",
    "    \"satpathy_atac\": uni_atac_lsi,\n",
    "    \"multiome_rna\": bridge_rna,\n",
    "    \"multiome_atac\": bridge_atac,\n",
    "}.items():\n",
    "    fine = adata.obs[\"celltype_harmonized\"]  # whatever column you’re using now\n",
    "    adata.obs[\"celltype_harmonized_coarse\"] = fine.map(COARSE_MAP).fillna(\"Other\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101bdb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = ad.concat(\n",
    "    {\n",
    "        \"ding_rna\":      uni_rna_pp,\n",
    "        \"satpathy_atac\": uni_atac_lsi,\n",
    "        \"multiome_rna\":  bridge_rna,\n",
    "        \"multiome_atac\": bridge_atac,\n",
    "    },\n",
    "    axis=0,\n",
    "    join=\"outer\",\n",
    "    label=\"dataset\",\n",
    "    index_unique=None,\n",
    ")\n",
    "\n",
    "# sanity check: unique labels per dataset\n",
    "for ds in [\"ding_rna\", \"satpathy_atac\"]:\n",
    "    print(\"\\nDataset:\", ds)\n",
    "    mask = combo.obs[\"dataset\"] == ds\n",
    "    print(\"raw:\", combo.obs.loc[mask, \"celltype_raw\"].unique())\n",
    "    print(\"harm:\", combo.obs.loc[mask, \"celltype_harmonized\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which raw labels got mapped to what, per dataset\n",
    "for ds in [\"ding_rna\", \"satpathy_atac\"]:\n",
    "    print(\"\\n=== Dataset:\", ds, \"===\")\n",
    "    mask = combo.obs[\"dataset\"] == ds\n",
    "    tab = pd.crosstab(\n",
    "        combo.obs.loc[mask, \"celltype_raw\"],\n",
    "        combo.obs.loc[mask, \"celltype_harmonized\"]\n",
    "    )\n",
    "    print(tab)\n",
    "\n",
    "# Dataset composition per harmonized label\n",
    "print(\n",
    "    pd.crosstab(\n",
    "        combo.obs[\"celltype_harmonized\"],\n",
    "        combo.obs[\"dataset\"],\n",
    "        normalize=\"index\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9418a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which raw labels got mapped to what, per dataset\n",
    "for ds in [\"ding_rna\", \"satpathy_atac\"]:\n",
    "    print(\"\\n=== Dataset:\", ds, \"===\")\n",
    "    mask = combo.obs[\"dataset\"] == ds\n",
    "    tab = pd.crosstab(\n",
    "        combo.obs.loc[mask, \"celltype_raw\"],\n",
    "        combo.obs.loc[mask, \"celltype_harmonized_coarse\"]\n",
    "    )\n",
    "    print(tab)\n",
    "\n",
    "# Dataset composition per harmonized label\n",
    "print(\n",
    "    pd.crosstab(\n",
    "        combo.obs[\"celltype_harmonized_coarse\"],\n",
    "        combo.obs[\"dataset\"],\n",
    "        normalize=\"index\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9757ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 2.5 Concatenate all cells into one AnnData with shared latent\n",
    "# ------------------------------------------------\n",
    "'''\n",
    "combo = ad.concat(\n",
    "    {\n",
    "        \"multiome_rna\": bridge_rna,\n",
    "        \"multiome_atac\": bridge_atac,\n",
    "        \"ding_rna\": uni_rna_pp,\n",
    "        \"satpathy_atac\": uni_atac_lsi,\n",
    "    },\n",
    "    join=\"outer\",\n",
    "    index_unique=None,\n",
    "    label=\"source\",\n",
    ")\n",
    "\n",
    "print(\"Combined latent AnnData:\", combo.shape)\n",
    "assert \"X_univi\" in combo.obsm, \"Missing X_univi latent in combined AnnData\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e756d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combo)\n",
    "print(combo.obs['modality'])\n",
    "print(combo.obs['celltype_harmonized'])\n",
    "print(combo.obs['celltype_harmonized_coarse'])\n",
    "print(combo.obs['dataset'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 3.1 Set plotting defaults\n",
    "# ------------------------------------------------\n",
    "\n",
    "sc.set_figure_params(\n",
    "    figsize=(10, 8),\n",
    "    dpi=100,\n",
    "    dpi_save=300,\n",
    "    fontsize=10,\n",
    "    frameon=False,\n",
    ")\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (10, 8),\n",
    "    \"figure.dpi\": 100,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"savefig.pad_inches\": 0.1,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c50942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 3.2 Compute neighbors/UMAP on UniVI latent\n",
    "# ------------------------------------------------\n",
    "sc.pp.neighbors(combo, n_neighbors=20, use_rep=\"X_univi\", metric=\"euclidean\")\n",
    "#sc.pp.neighbors(combo, n_neighbors=30, use_rep=\"X_univi\", metric=\"cosine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(combo, min_dist=0.3, spread=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a846e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 3.3 UMAP views\n",
    "# ------------------------------------------------\n",
    "sc.pl.umap(\n",
    "    combo,\n",
    "    color=[\"dataset\"],\n",
    "    wspace=0.3,\n",
    "    frameon=False,\n",
    "    size=20,\n",
    "    alpha=0.65,\n",
    "    title=[\"Dataset\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dbf386",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    combo,\n",
    "    color=[\"modality\"],\n",
    "    wspace=0.3,\n",
    "    frameon=False,\n",
    "    size=20,\n",
    "    alpha=0.65,\n",
    "    title=[\"Modality\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73886c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    combo,\n",
    "    color=[\"tech\"],\n",
    "    wspace=0.3,\n",
    "    frameon=False,\n",
    "    size=20,\n",
    "    alpha=0.65,\n",
    "    title=[\"Sequencing technology\"],\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to only show labels where they exist, subset:\n",
    "has_labels = ~combo.obs[\"celltype_harmonized\"].str.startswith(\"unlabeled_\")\n",
    "if has_labels.sum() > 0:\n",
    "    sc.pl.umap(\n",
    "        combo[has_labels],\n",
    "        color=[\"celltype_harmonized\"],\n",
    "        wspace=0.3,\n",
    "        frameon=False,\n",
    "        size=20,\n",
    "        alpha=0.65,\n",
    "        title=[\"Harmonized cell types (unimodal)\"],\n",
    "    )\n",
    "    \n",
    "    sc.pl.umap(\n",
    "        combo[has_labels],\n",
    "        color=[\"celltype_harmonized_coarse\"],\n",
    "        wspace=0.3,\n",
    "        frameon=False,\n",
    "        size=20,\n",
    "        alpha=0.65,\n",
    "        title=[\"Harmonized coarse cell types (unimodal)\"],\n",
    "    )\n",
    "    \n",
    "    sc.pl.umap(\n",
    "        combo[has_labels],\n",
    "        color=[\"dataset\"],\n",
    "        wspace=0.3,\n",
    "        frameon=False,\n",
    "        size=20,\n",
    "        alpha=0.65,\n",
    "        title=[\"Dataset\"],\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffaf756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show where the reference lives versus unimodal projections\n",
    "sc.pl.umap(\n",
    "    combo,\n",
    "    color=[\"is_reference\"],\n",
    "    wspace=0.3,\n",
    "    frameon=False,\n",
    "    size=20,\n",
    "    alpha=0.65,\n",
    "    title=[\"Reference vs unimodal\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e95444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reference_neighbor_fraction(\n",
    "    adata,\n",
    "    use_rep=\"X_univi\",\n",
    "    ref_key=\"is_reference\",\n",
    "    k=30,\n",
    "    suffix=\"k30\",\n",
    "):\n",
    "    \"\"\"\n",
    "    For each cell, compute the fraction of its k nearest neighbors that are from the reference.\n",
    "    Adds:\n",
    "      .obs[f'ref_neighbor_frac_{suffix}']\n",
    "    \"\"\"\n",
    "    Z = np.asarray(adata.obsm[use_rep], dtype=np.float32)\n",
    "    ref = adata.obs[ref_key].values.astype(bool)\n",
    "\n",
    "    k_eff = int(min(max(int(k), 1), Z.shape[0] - 1))\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff + 1, metric=\"euclidean\")\n",
    "    nn.fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]  # drop self\n",
    "\n",
    "    frac = ref[nbrs].mean(axis=1)\n",
    "    col = f\"ref_neighbor_frac_{suffix}\"\n",
    "    adata.obs[col] = frac\n",
    "    return col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad4aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and store\n",
    "ref_frac_col = add_reference_neighbor_fraction(combo, use_rep=\"X_univi\", k=30, suffix=\"k30\")\n",
    "\n",
    "# Look at unimodal only\n",
    "unimodal_mask = ~combo.obs[\"is_reference\"].values\n",
    "print(\"Unimodal cells:\", unimodal_mask.sum())\n",
    "print(\"Reference-neighbor fraction (unimodal):\")\n",
    "print(combo.obs.loc[unimodal_mask, ref_frac_col].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ref_neighbor_fraction_by_label(\n",
    "    combo,\n",
    "    frac_col,\n",
    "    label_col=\"celltype_harmonized_coarse\",\n",
    "    outpath=None,\n",
    "):\n",
    "    df = combo.obs.loc[~combo.obs[\"is_reference\"], [frac_col, label_col, \"dataset\"]].copy()\n",
    "    df = df[df[label_col].notna()]\n",
    "\n",
    "    # order labels by median ref-neighbor fraction\n",
    "    med = df.groupby(label_col)[frac_col].median().sort_values(ascending=False)\n",
    "    order = med.index.tolist()\n",
    "    plt.figure(figsize=(0.35 * len(order) + 4, 4.5))\n",
    "    plt.boxplot(\n",
    "        [df.loc[df[label_col] == lab, frac_col].values for lab in order],\n",
    "        labels=order,\n",
    "        showfliers=False,\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"Reference-neighbor fraction\")\n",
    "    plt.title(\"Multiome reference support per harmonized coarse label\")\n",
    "    plt.tight_layout()\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "plot_ref_neighbor_fraction_by_label(combo, ref_frac_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fbeda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "def knn_label_transfer_unpaired(Z_source, y_source, Z_target, y_target, k=15, metric=\"euclidean\"):\n",
    "    nn = NearestNeighbors(n_neighbors=k, metric=metric)\n",
    "    nn.fit(Z_source)\n",
    "    nbrs = nn.kneighbors(Z_target, return_distance=False)\n",
    "\n",
    "    preds = []\n",
    "    for inds in nbrs:\n",
    "        votes = y_source[inds]\n",
    "        vals, cnts = np.unique(votes, return_counts=True)\n",
    "        preds.append(vals[np.argmax(cnts)])\n",
    "    preds = np.asarray(preds, dtype=str)\n",
    "\n",
    "    acc = float(accuracy_score(y_target, preds))\n",
    "    macro_f1 = float(f1_score(y_target, preds, average=\"macro\"))\n",
    "    classes = np.unique(np.concatenate([y_source, y_target]))\n",
    "    cm = confusion_matrix(y_target, preds, labels=classes)\n",
    "    return preds, acc, macro_f1, cm, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee8a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unimodal latents + labels\n",
    "Z_uni_rna = uni_rna_pp.obsm[\"X_univi\"]\n",
    "y_uni_rna = uni_rna_pp.obs[\"celltype_harmonized_coarse\"].astype(str).to_numpy()\n",
    "\n",
    "Z_uni_atac = uni_atac_lsi.obsm[\"X_univi\"]\n",
    "y_uni_atac = uni_atac_lsi.obs[\"celltype_harmonized_coarse\"].astype(str).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNA -> ATAC label transfer\n",
    "pred_atac_from_rna, acc_r2a, f1_r2a, cm_r2a, classes_r2a = knn_label_transfer_unpaired(\n",
    "    Z_source=Z_uni_rna,\n",
    "    y_source=y_uni_rna,\n",
    "    Z_target=Z_uni_atac,\n",
    "    y_target=y_uni_atac,\n",
    "    k=10,\n",
    ")\n",
    "print(\"Unimodal RNA -> ATAC label transfer acc / macroF1:\", acc_r2a, f1_r2a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79870b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATAC -> RNA label transfer\n",
    "pred_rna_from_atac, acc_a2r, f1_a2r, cm_a2r, classes_a2r = knn_label_transfer_unpaired(\n",
    "    Z_source=Z_uni_atac,\n",
    "    y_source=y_uni_atac,\n",
    "    Z_target=Z_uni_rna,\n",
    "    y_target=y_uni_rna,\n",
    "    k=10,\n",
    ")\n",
    "print(\"Unimodal ATAC -> RNA label transfer acc / macroF1:\", acc_a2r, f1_a2r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_ref_neighbor_fraction(\n",
    "    adata,\n",
    "    latent_key=\"X_univi\",\n",
    "    dataset_key=\"dataset\",\n",
    "    label_key=\"harmonized_label\",\n",
    "    ref_datasets=(\"multiome_rna\", \"multiome_atac\"),\n",
    "    uni_datasets=(\"ding_rna\", \"satpathy_atac\"),\n",
    "    k=30,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each unimodal cell, compute the fraction of its k nearest neighbors\n",
    "    (in latent space) that come from the reference (Multiome) datasets.\n",
    "    \"\"\"\n",
    "    Z = np.asarray(adata.obsm[latent_key], dtype=np.float32)\n",
    "\n",
    "    ds = adata.obs[dataset_key].astype(str)\n",
    "    is_ref = ds.isin(ref_datasets).to_numpy()\n",
    "    is_uni = ds.isin(uni_datasets).to_numpy()\n",
    "\n",
    "    if is_ref.sum() == 0:\n",
    "        raise ValueError(\"No reference cells found – check `ref_datasets`/`dataset_key`.\")\n",
    "    if is_uni.sum() == 0:\n",
    "        raise ValueError(\"No unimodal cells found – check `uni_datasets`/`dataset_key`.\")\n",
    "\n",
    "    # fit neighbors on *all* cells\n",
    "    nn = NearestNeighbors(n_neighbors=k + 1).fit(Z)\n",
    "    dists, idx = nn.kneighbors(Z[is_uni])\n",
    "\n",
    "    # drop self (first neighbor)\n",
    "    idx_neighbors = idx[:, 1:]\n",
    "    neigh_is_ref = is_ref[idx_neighbors]   # shape (n_uni, k)\n",
    "\n",
    "    frac_ref = neigh_is_ref.mean(axis=1)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"ref_neighbor_frac_k{}\".format(k): frac_ref,\n",
    "            dataset_key: ds.to_numpy()[is_uni],\n",
    "            label_key: adata.obs[label_key].astype(str).to_numpy()[is_uni],\n",
    "            \"is_reference\": False,\n",
    "        },\n",
    "        index=adata.obs_names[is_uni],\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# ---- run it ----\n",
    "df_uni = compute_ref_neighbor_fraction(\n",
    "    combo,\n",
    "    latent_key=\"X_univi\",\n",
    "    dataset_key=\"dataset\",\n",
    "    label_key=\"celltype_harmonized_coarse\",  # change if your column name differs\n",
    "    ref_datasets=(\"multiome_rna\", \"multiome_atac\"),\n",
    "    uni_datasets=(\"ding_rna\", \"satpathy_atac\"),\n",
    "    k=30,\n",
    ")\n",
    "\n",
    "print(\"Unimodal cells:\", df_uni.shape[0])\n",
    "print(df_uni[\"ref_neighbor_frac_k30\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order labels by median reference support\n",
    "med = df_uni.groupby(\"celltype_harmonized_coarse\")[\"ref_neighbor_frac_k30\"].median().sort_values(ascending=False)\n",
    "order = med.index.tolist()\n",
    "\n",
    "plt.figure(figsize=(12, 3.5))\n",
    "df_uni.boxplot(\n",
    "    column=\"ref_neighbor_frac_k30\",\n",
    "    by=\"celltype_harmonized_coarse\",\n",
    "    positions=range(len(order)),\n",
    "    grid=False,\n",
    ")\n",
    "# the default pandas boxplot ignores `order`, so do it manually:\n",
    "plt.clf()\n",
    "plt.figure(figsize=(12, 3.5))\n",
    "data = [df_uni.loc[df_uni[\"celltype_harmonized_coarse\"] == lab, \"ref_neighbor_frac_k30\"] for lab in order]\n",
    "plt.boxplot(data, showfliers=False)\n",
    "plt.xticks(range(1, len(order) + 1), order, rotation=90)\n",
    "plt.ylabel(\"Reference-neighbor fraction (k=30)\")\n",
    "plt.title(\"Multiome reference support per harmonized label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d96424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset_composition_by_label(\n",
    "    adata,\n",
    "    label_key=\"harmonized_label\",\n",
    "    dataset_key=\"dataset\",\n",
    "    min_cells=50,\n",
    "):\n",
    "    obs = adata.obs[[label_key, dataset_key]].copy()\n",
    "    obs[label_key] = obs[label_key].astype(str)\n",
    "    obs[dataset_key] = obs[dataset_key].astype(str)\n",
    "\n",
    "    counts = (\n",
    "        obs.groupby([label_key, dataset_key])\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "    )\n",
    "\n",
    "    # optionally drop very tiny labels\n",
    "    counts = counts[counts.sum(axis=1) >= min_cells]\n",
    "\n",
    "    frac = counts.div(counts.sum(axis=1), axis=0)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    bottom = np.zeros(frac.shape[0])\n",
    "    x = np.arange(frac.shape[0])\n",
    "\n",
    "    for ds in frac.columns:\n",
    "        plt.bar(x, frac[ds].values, bottom=bottom, label=ds)\n",
    "        bottom += frac[ds].values\n",
    "\n",
    "    plt.xticks(x, frac.index, rotation=90)\n",
    "    plt.ylabel(\"Fraction of cells\")\n",
    "    plt.title(\"Dataset composition per harmonized label\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ---- run it ----\n",
    "plot_dataset_composition_by_label(\n",
    "    combo,\n",
    "    label_key=\"celltype_harmonized_coarse\",\n",
    "    dataset_key=\"dataset\",\n",
    "    min_cells=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f330c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ref_vs_nn_ratio(\n",
    "    adata,\n",
    "    latent_key=\"X_univi\",\n",
    "    dataset_key=\"dataset\",\n",
    "    ref_datasets=(\"multiome_rna\", \"multiome_atac\"),\n",
    "    uni_datasets=(\"ding_rna\", \"satpathy_atac\"),\n",
    "):\n",
    "    Z = np.asarray(adata.obsm[latent_key], dtype=np.float32)\n",
    "\n",
    "    ds = adata.obs[dataset_key].astype(str)\n",
    "    is_ref = ds.isin(ref_datasets).to_numpy()\n",
    "    is_uni = ds.isin(uni_datasets).to_numpy()\n",
    "\n",
    "    Z_ref = Z[is_ref]\n",
    "    Z_uni = Z[is_uni]\n",
    "\n",
    "    if Z_ref.shape[0] == 0 or Z_uni.shape[0] == 0:\n",
    "        raise ValueError(\"Need both reference and unimodal cells.\")\n",
    "\n",
    "    # nearest reference for each unimodal cell\n",
    "    nn_ref = NearestNeighbors(n_neighbors=1).fit(Z_ref)\n",
    "    d_ref, _ = nn_ref.kneighbors(Z_uni)\n",
    "    d_ref = d_ref[:, 0]\n",
    "\n",
    "    # nearest overall neighbor (excluding self within unimodal pool)\n",
    "    nn_uni = NearestNeighbors(n_neighbors=2).fit(Z_uni)\n",
    "    d_all, idx_all = nn_uni.kneighbors(Z_uni)\n",
    "    d_nn = d_all[:, 1]  # skip self\n",
    "\n",
    "    ratio = d_ref / d_nn\n",
    "    s = pd.Series(ratio, index=adata.obs_names[is_uni], name=\"ref_vs_nn_ratio\")\n",
    "    return s\n",
    "\n",
    "# ---- run it ----\n",
    "ratio = compute_ref_vs_nn_ratio(\n",
    "    combo,\n",
    "    latent_key=\"X_univi\",\n",
    "    dataset_key=\"dataset\",\n",
    "    ref_datasets=(\"multiome_rna\", \"multiome_atac\"),\n",
    "    uni_datasets=(\"ding_rna\", \"satpathy_atac\"),\n",
    ")\n",
    "\n",
    "print(ratio.describe())\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(ratio, bins=50)\n",
    "plt.xlabel(\"dist(unimodal → nearest ref) / dist(unimodal → nearest unimodal)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Ref vs nearest-unimodal distance ratio\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc52bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def ref_fraction_null(Z, is_ref, k=30, n_perm=50, random_state=0):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    Z = np.asarray(Z, dtype=np.float32)\n",
    "    is_ref = np.asarray(is_ref).astype(bool)\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=k+1).fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]\n",
    "\n",
    "    frac_perm = []\n",
    "    for _ in range(n_perm):\n",
    "        perm = rng.permutation(len(is_ref))\n",
    "        is_ref_perm = is_ref[perm]\n",
    "        frac = (is_ref_perm[nbrs] & ~is_ref_perm[:, None]).mean(axis=1)\n",
    "        frac_perm.append(frac[~is_ref_perm].mean())  # mean for unimodal cells\n",
    "    return np.mean(frac_perm), np.std(frac_perm)\n",
    "\n",
    "# Example usage (you’d fill these in):\n",
    "# Z_all      = combo.obsm[\"X_univi\"]\n",
    "# is_ref_all = (combo.obs[\"dataset\"] == \"multiome\").to_numpy()\n",
    "# obs_mean   = combo.obs.loc[combo.obs[\"dataset\"]!=\"multiome\", \"ref_neighbor_frac_k30\"].mean()\n",
    "# null_mean, null_std = ref_fraction_null(Z_all, is_ref_all, k=30, n_perm=100)\n",
    "# print(obs_mean, null_mean, null_std)\n",
    "\n",
    "uni_mask = combo.obs[\"dataset\"] != \"multiome\"\n",
    "df_uni = combo.obs.loc[uni_mask, [\"dataset\", \"ref_neighbor_frac_k30\"]]\n",
    "\n",
    "print(df_uni.groupby(\"dataset\")[\"ref_neighbor_frac_k30\"].describe())\n",
    "\n",
    "contact_rate = (df_uni[\"ref_neighbor_frac_k30\"] > 0).mean()\n",
    "print(\"Fraction of unimodal cells with ≥1 reference neighbor:\", contact_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf33655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "Z = combo.obsm[\"X_univi\"].astype(np.float32)\n",
    "\n",
    "# Multiome bridge = reference\n",
    "is_ref = combo.obs[\"dataset\"].isin([\"multiome_rna\", \"multiome_atac\"]).to_numpy()\n",
    "\n",
    "# Everything else = unimodal\n",
    "is_uni = ~is_ref\n",
    "\n",
    "Z_ref = Z[is_ref]\n",
    "Z_uni = Z[is_uni]\n",
    "\n",
    "print(\"Z_ref:\", Z_ref.shape, \"Z_uni:\", Z_uni.shape)\n",
    "print(combo.obs[\"dataset\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Z_ref shape:\", Z_ref.shape)\n",
    "print(\"Z_uni shape:\", Z_uni.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if Z_ref.shape[0] == 0:\n",
    "    # no reference cells here – define a convention and skip\n",
    "    ratio = np.full(Z_uni.shape[0], np.nan)  # or np.inf\n",
    "else:\n",
    "    # nearest ref\n",
    "    nn_ref = NearestNeighbors(n_neighbors=1).fit(Z_ref)\n",
    "    d_ref, _ = nn_ref.kneighbors(Z_uni)\n",
    "    d_ref = d_ref[:, 0]\n",
    "\n",
    "    # nearest neighbor overall (excluding self, within unimodal set)\n",
    "    nn_all = NearestNeighbors(n_neighbors=2).fit(Z_uni)\n",
    "    d_all, idx_all = nn_all.kneighbors(Z_uni)\n",
    "    d_nn = d_all[:, 1]\n",
    "\n",
    "    ratio = d_ref / d_nn\n",
    "\n",
    "print(pd.Series(ratio).describe())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearest ref\n",
    "nn_ref = NearestNeighbors(n_neighbors=1).fit(Z_ref)\n",
    "d_ref, _ = nn_ref.kneighbors(Z_uni)\n",
    "d_ref = d_ref[:, 0]\n",
    "\n",
    "# nearest neighbor overall (excluding self)\n",
    "nn_all = NearestNeighbors(n_neighbors=2).fit(Z_uni)\n",
    "d_all, idx_all = nn_all.kneighbors(Z_uni)\n",
    "# first neighbor is self, second is true nearest other\n",
    "d_nn = d_all[:, 1]\n",
    "\n",
    "ratio = d_ref / d_nn\n",
    "print(pd.Series(ratio).describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearest neighbor overall (excluding self)\n",
    "nn_all = NearestNeighbors(n_neighbors=2).fit(Z_uni)\n",
    "d_all, idx_all = nn_all.kneighbors(Z_uni)\n",
    "# first neighbor is self, second is true nearest other\n",
    "d_nn = d_all[:, 1]\n",
    "\n",
    "ratio = d_ref / d_nn\n",
    "print(pd.Series(ratio).describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45461b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_key = \"celltype_harmonized\"\n",
    "\n",
    "# Quick composition table\n",
    "pd.crosstab(combo.obs[ct_key], combo.obs[\"dataset\"])\n",
    "\n",
    "ref_datasets = [\"multiome_rna\", \"multiome_atac\"]\n",
    "ref_labels = set(combo.obs.loc[combo.obs[\"dataset\"].isin(ref_datasets), ct_key])\n",
    "ding_labels = set(combo.obs.loc[combo.obs[\"dataset\"] == \"ding_rna\", ct_key])\n",
    "\n",
    "only_in_ding = sorted(ding_labels - ref_labels)\n",
    "only_in_ref  = sorted(ref_labels - ding_labels)\n",
    "shared       = sorted(ding_labels & ref_labels)\n",
    "\n",
    "print(\"Labels only in Ding:\", only_in_ding)\n",
    "print(\"Labels only in Multiome:\", only_in_ref)\n",
    "print(\"Shared labels:\", shared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5acdfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def knn_label_transfer_confusion_two_adata(\n",
    "    adata_ref,\n",
    "    adata_tgt,\n",
    "    *,\n",
    "    emb_key: str = \"X_univi\",\n",
    "    ct_key: str = \"celltype_harmonized\",\n",
    "    k: int = 15,\n",
    "    drop_unknown: bool = True,\n",
    "    unknown_labels=(\"Unknown\", \"Unassigned\"),\n",
    "    exclude_labels=None,  # e.g. (\"Other\",)\n",
    "):\n",
    "    \"\"\"\n",
    "    kNN label transfer from adata_ref -> adata_tgt in a shared embedding.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata_ref : AnnData\n",
    "        Reference cells (e.g. multiome_rna + multiome_atac).\n",
    "    adata_tgt : AnnData\n",
    "        Target cells (e.g. ding_rna + satpathy_atac).\n",
    "    emb_key : str\n",
    "        .obsm key for the shared embedding.\n",
    "    ct_key : str\n",
    "        .obs key with harmonized labels (fine or coarse).\n",
    "    k : int\n",
    "        Number of neighbors for kNN.\n",
    "    drop_unknown : bool\n",
    "        If True, drop `unknown_labels` from the *target* side.\n",
    "    unknown_labels : tuple of str\n",
    "        Labels in `ct_key` to consider as unknown/unassigned.\n",
    "    exclude_labels : sequence of str or None\n",
    "        Additional labels in `ct_key` to exclude from BOTH\n",
    "        reference and target (e.g. [\"Other\"] for coarse types).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys:\n",
    "        acc, macro_f1, classes, cm, cm_df, y_true, y_pred\n",
    "    \"\"\"\n",
    "    # ------------- extract embedding + labels -------------\n",
    "    Z_ref = np.asarray(adata_ref.obsm[emb_key], dtype=np.float32)\n",
    "    Z_tgt = np.asarray(adata_tgt.obsm[emb_key], dtype=np.float32)\n",
    "\n",
    "    y_ref = adata_ref.obs[ct_key].astype(str).to_numpy()\n",
    "    y_tgt = adata_tgt.obs[ct_key].astype(str).to_numpy()\n",
    "\n",
    "    print(f\"Reference cells: {Z_ref.shape[0]} | Target cells: {Z_tgt.shape[0]}\")\n",
    "\n",
    "    if Z_ref.shape[0] == 0:\n",
    "        raise ValueError(\"No reference cells found – check your subsetting / dataset names.\")\n",
    "\n",
    "    # ------------- optionally drop Unknown/Unassigned from TARGET -------------\n",
    "    if drop_unknown and unknown_labels:\n",
    "        mask_tgt = ~np.isin(y_tgt, unknown_labels)\n",
    "        Z_tgt = Z_tgt[mask_tgt]\n",
    "        y_tgt = y_tgt[mask_tgt]\n",
    "        print(f\"After dropping unknowns: target cells = {Z_tgt.shape[0]}\")\n",
    "\n",
    "    # ------------- optionally drop additional labels from BOTH sides -------------\n",
    "    if exclude_labels is not None:\n",
    "        exclude_labels = np.asarray(list(exclude_labels), dtype=str)\n",
    "\n",
    "        mask_ref = ~np.isin(y_ref, exclude_labels)\n",
    "        mask_tgt = ~np.isin(y_tgt, exclude_labels)\n",
    "\n",
    "        Z_ref = Z_ref[mask_ref]\n",
    "        y_ref = y_ref[mask_ref]\n",
    "\n",
    "        Z_tgt = Z_tgt[mask_tgt]\n",
    "        y_tgt = y_tgt[mask_tgt]\n",
    "\n",
    "        print(\n",
    "            f\"After excluding labels {list(exclude_labels)}: \"\n",
    "            f\"ref cells = {Z_ref.shape[0]}, tgt cells = {Z_tgt.shape[0]}\"\n",
    "        )\n",
    "\n",
    "    if Z_ref.shape[0] == 0 or Z_tgt.shape[0] == 0:\n",
    "        raise ValueError(\"No cells left after filtering – relax your filters or check labels.\")\n",
    "\n",
    "    # ------------- fit kNN on reference, predict on target -------------\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights=\"distance\")\n",
    "    knn.fit(Z_ref, y_ref)\n",
    "    y_pred = knn.predict(Z_tgt)\n",
    "\n",
    "    # ------------- metrics -------------\n",
    "    classes = np.unique(np.concatenate([y_ref, y_tgt]))\n",
    "    cm = confusion_matrix(y_tgt, y_pred, labels=classes)\n",
    "    acc = accuracy_score(y_tgt, y_pred)\n",
    "    macro_f1 = f1_score(y_tgt, y_pred, average=\"macro\")\n",
    "\n",
    "    cm_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"classes\": classes,\n",
    "        \"cm\": cm,\n",
    "        \"cm_df\": cm_df,\n",
    "        \"y_true\": y_tgt,\n",
    "        \"y_pred\": y_pred,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ccb2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build separate ref / target AnnData from the *full* combo\n",
    "#ref_mask = combo.obs[\"dataset\"].isin([\"multiome_rna\", \"multiome_atac\"])\n",
    "#tgt_mask = combo.obs[\"dataset\"].isin([\"ding_rna\", \"satpathy_atac\"])\n",
    "ref_mask = combo.obs[\"dataset\"].isin([\"ding_rna\"])\n",
    "tgt_mask = combo.obs[\"dataset\"].isin([\"satpathy_atac\"])\n",
    "\n",
    "adata_ref = combo[ref_mask].copy()\n",
    "adata_tgt = combo[tgt_mask].copy()\n",
    "\n",
    "'''\n",
    "res = knn_label_transfer_confusion_two_adata(\n",
    "    adata_ref,\n",
    "    adata_tgt,\n",
    "    emb_key=\"X_univi\",\n",
    "    ct_key=\"celltype_harmonized_coarse\",\n",
    "    k=15,\n",
    "    drop_unknown=True,\n",
    "    unknown_labels=(\"Unknown\", \"Unassigned\"),\n",
    ")\n",
    "'''\n",
    "res = knn_label_transfer_confusion_two_adata(\n",
    "    adata_ref=adata_ref,\n",
    "    adata_tgt=adata_tgt,\n",
    "    emb_key=\"X_univi\",\n",
    "    ct_key=\"celltype_harmonized_coarse\",\n",
    "    k=15,\n",
    "    exclude_labels=(\"Other\", \"Unknown\", \"Unassigned\", \"Megakaryocyte\"),  # drop those coarse “other” cells\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Acc:\", res[\"acc\"])\n",
    "print(\"Macro F1:\", res[\"macro_f1\"])\n",
    "display(res[\"cm_df\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07201de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_knn_confusion_heatmap(\n",
    "    res,\n",
    "    *,\n",
    "    normalize: str | None = \"row\",\n",
    "    title: str | None = None,\n",
    "    figsize=(6, 5),\n",
    "    show_values: bool = True,\n",
    "    value_fmt: str | None = None,\n",
    "    rotation_x: int = 45,\n",
    "    rotation_y: int = 0,\n",
    "    text_color: str = \"white\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a confusion-matrix heatmap from the output of\n",
    "    `knn_label_transfer_confusion_two_adata`.\n",
    "    \"\"\"\n",
    "    cm = np.asarray(res[\"cm\"], dtype=float)\n",
    "    classes = np.asarray(res[\"classes\"], dtype=str)\n",
    "\n",
    "    # ------------- normalization -------------\n",
    "    if normalize is not None:\n",
    "        if normalize == \"row\":\n",
    "            row_sums = cm.sum(axis=1, keepdims=True)\n",
    "            row_sums[row_sums == 0] = 1.0\n",
    "            cm_plot = cm / row_sums\n",
    "        elif normalize == \"col\":\n",
    "            col_sums = cm.sum(axis=0, keepdims=True)\n",
    "            col_sums[col_sums == 0] = 1.0\n",
    "            cm_plot = cm / col_sums\n",
    "        else:\n",
    "            raise ValueError(\"normalize must be one of {'row', 'col', None}\")\n",
    "    else:\n",
    "        cm_plot = cm\n",
    "\n",
    "    # default annotation format\n",
    "    if value_fmt is None:\n",
    "        value_fmt = \".2f\" if normalize is not None else \"d\"\n",
    "\n",
    "    nrows, ncols = cm_plot.shape\n",
    "\n",
    "    # ------------- plotting (pcolormesh to avoid grid lines) -------------\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    mesh = ax.pcolormesh(\n",
    "        cm_plot,\n",
    "        edgecolors=\"face\",   # no visible edges between cells\n",
    "        linewidth=0.0,\n",
    "        shading=\"auto\",\n",
    "    )\n",
    "    mesh.set_rasterized(True)  # avoids hairlines in vector backends\n",
    "\n",
    "    # ticks / labels (note: pcolormesh cell centers at i+0.5)\n",
    "    ax.set_xticks(np.arange(ncols) + 0.5)\n",
    "    ax.set_yticks(np.arange(nrows) + 0.5)\n",
    "    ax.set_xticklabels(classes, rotation=rotation_x, ha=\"right\")\n",
    "    ax.set_yticklabels(classes, rotation=rotation_y)\n",
    "\n",
    "    # keep [0, ncols] x [0, nrows] and put row 0 at top\n",
    "    ax.set_xlim(0, ncols)\n",
    "    ax.set_ylim(nrows, 0)\n",
    "\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "    ax.set_ylabel(\"True label\")\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    # remove any axis grid\n",
    "    ax.grid(False)\n",
    "\n",
    "    # colorbar\n",
    "    cbar = fig.colorbar(mesh, ax=ax)\n",
    "    cbar.set_label(\"Fraction\" if normalize is not None else \"Count\")\n",
    "\n",
    "    # ------------- annotations -------------\n",
    "    if show_values:\n",
    "        annot_mat = cm_plot if normalize is not None else cm\n",
    "\n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                val = annot_mat[i, j]\n",
    "                ax.text(\n",
    "                    j + 0.5,\n",
    "                    i + 0.5,\n",
    "                    format(val, value_fmt),\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    color=text_color,\n",
    "                    fontsize=8,\n",
    "                )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig, ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_knn_confusion_heatmap(\n",
    "    res,\n",
    "    normalize=\"row\",  # show per-true-class fractions\n",
    "    title=\"Ding → Satpathy label transfer (coarse, k=15)\",\n",
    ")\n",
    "# fig.savefig(\"ding_to_satpathy_confusion_coarse.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981dca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build separate ref / target AnnData from the *full* combo\n",
    "#ref_mask = combo.obs[\"dataset\"].isin([\"multiome_rna\", \"multiome_atac\"])\n",
    "#tgt_mask = combo.obs[\"dataset\"].isin([\"ding_rna\", \"satpathy_atac\"])\n",
    "ref_mask = combo.obs[\"dataset\"].isin([\"satpathy_atac\"])\n",
    "tgt_mask = combo.obs[\"dataset\"].isin([\"ding_rna\"])\n",
    "\n",
    "adata_ref = combo[ref_mask].copy()\n",
    "adata_tgt = combo[tgt_mask].copy()\n",
    "\n",
    "'''\n",
    "res = knn_label_transfer_confusion_two_adata(\n",
    "    adata_ref,\n",
    "    adata_tgt,\n",
    "    emb_key=\"X_univi\",\n",
    "    ct_key=\"celltype_harmonized_coarse\",\n",
    "    k=15,\n",
    "    drop_unknown=True,\n",
    "    unknown_labels=(\"Unknown\", \"Unassigned\"),\n",
    ")\n",
    "'''\n",
    "res_atac = knn_label_transfer_confusion_two_adata(\n",
    "    adata_ref=adata_ref,\n",
    "    adata_tgt=adata_tgt,\n",
    "    emb_key=\"X_univi\",\n",
    "    ct_key=\"celltype_harmonized_coarse\",\n",
    "    k=15,\n",
    "    exclude_labels=(\"Other\", \"Unknown\", \"Unassigned\", \"Megakaryocyte\"),  # drop those coarse “other” cells\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Acc:\", res_atac[\"acc\"])\n",
    "print(\"Macro F1:\", res_atac[\"macro_f1\"])\n",
    "display(res_atac[\"cm_df\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_knn_confusion_heatmap(\n",
    "    res_atac,\n",
    "    normalize=\"row\",  # show per-true-class fractions\n",
    "    title=\"Satpathy → Ding label transfer (coarse, k=15)\",\n",
    ")\n",
    "# fig.savefig(\"ding_to_satpathy_confusion_coarse.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build separate ref / target AnnData from the *full* combo\n",
    "#ref_mask = combo.obs[\"dataset\"].isin([\"multiome_rna\", \"multiome_atac\"])\n",
    "#tgt_mask = combo.obs[\"dataset\"].isin([\"ding_rna\", \"satpathy_atac\"])\n",
    "ref_mask = combo.obs[\"dataset\"].isin([\"satpathy_atac\"])\n",
    "tgt_mask = combo.obs[\"dataset\"].isin([\"ding_rna\"])\n",
    "\n",
    "adata_ref = combo[ref_mask].copy()\n",
    "adata_tgt = combo[tgt_mask].copy()\n",
    "\n",
    "res_fine_celltype_atac = knn_label_transfer_confusion_two_adata(\n",
    "    adata_ref=adata_ref,\n",
    "    adata_tgt=adata_tgt,\n",
    "    emb_key=\"X_univi\",\n",
    "    ct_key=\"celltype_harmonized\",\n",
    "    k=15,\n",
    "    #exclude_labels=(\"Other\", \"Unknown\", \"Unassigned\", \"Megakaryocyte\"),  # drop those coarse “other” cells\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb95ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acc:\", res_fine_celltype_atac[\"acc\"])\n",
    "print(\"Macro F1:\", res_fine_celltype_atac[\"macro_f1\"])\n",
    "display(res_fine_celltype_atac[\"cm_df\"])\n",
    "fig, ax = plot_knn_confusion_heatmap(\n",
    "    res_fine_celltype_atac,\n",
    "    normalize=\"row\",  # show per-true-class fractions\n",
    "    title=\"Satpathy → Ding label transfer (fine, k=15)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build separate ref / target AnnData from the *full* combo\n",
    "#ref_mask = combo.obs[\"dataset\"].isin([\"multiome_rna\", \"multiome_atac\"])\n",
    "#tgt_mask = combo.obs[\"dataset\"].isin([\"ding_rna\", \"satpathy_atac\"])\n",
    "ref_mask = combo.obs[\"dataset\"].isin([\"ding_rna\"])\n",
    "tgt_mask = combo.obs[\"dataset\"].isin([\"satpathy_atac\"])\n",
    "\n",
    "adata_ref = combo[ref_mask].copy()\n",
    "adata_tgt = combo[tgt_mask].copy()\n",
    "\n",
    "res_fine_celltype_rna = knn_label_transfer_confusion_two_adata(\n",
    "    adata_ref=adata_ref,\n",
    "    adata_tgt=adata_tgt,\n",
    "    emb_key=\"X_univi\",\n",
    "    ct_key=\"celltype_harmonized\",\n",
    "    k=15,\n",
    "    #exclude_labels=(\"Other\", \"Unknown\", \"Unassigned\", \"Megakaryocyte\"),  # drop those coarse “other” cells\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f2d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acc:\", res_fine_celltype_rna[\"acc\"])\n",
    "print(\"Macro F1:\", res_fine_celltype_rna[\"macro_f1\"])\n",
    "display(res_fine_celltype_rna[\"cm_df\"])\n",
    "fig, ax = plot_knn_confusion_heatmap(\n",
    "    res_fine_celltype_rna,\n",
    "    normalize=\"row\",  # show per-true-class fractions\n",
    "    title=\"Ding → Satpathy label transfer (fine, k=15)\",\n",
    ")\n",
    "# fig.savefig(\"ding_to_satpathy_confusion_coarse.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "Z = combo.obsm[\"X_univi\"].astype(np.float32)\n",
    "\n",
    "# Multiome bridge = reference\n",
    "ref_datasets = [\"multiome_rna\", \"multiome_atac\"]\n",
    "is_ref = combo.obs[\"dataset\"].isin(ref_datasets).to_numpy(bool)\n",
    "is_uni = ~is_ref\n",
    "\n",
    "combo.obs[\"is_reference\"] = is_ref\n",
    "combo.obs[\"is_unimodal\"] = is_uni\n",
    "\n",
    "k = 30\n",
    "\n",
    "# kNN on ALL cells in latent\n",
    "nn = NearestNeighbors(n_neighbors=k + 1).fit(Z)\n",
    "# drop the self-neighbor in column 0\n",
    "nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]\n",
    "\n",
    "# for each cell: which neighbors are reference, while the focal cell is unimodal?\n",
    "nbr_is_ref = is_ref[nbrs] & is_uni[:, None]\n",
    "ref_neighbor_frac = nbr_is_ref.mean(axis=1)\n",
    "\n",
    "combo.obs[\"ref_neighbor_frac_k30\"] = ref_neighbor_frac\n",
    "\n",
    "def ref_fraction_null(Z, is_ref, k=30, n_perm=50, random_state=0):\n",
    "    \"\"\"\n",
    "    Shuffle the is_ref labels and recompute the mean ref-neighbor fraction\n",
    "    for unimodal cells, to get a null mean/std.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    Z = np.asarray(Z, dtype=np.float32)\n",
    "    is_ref = np.asarray(is_ref).astype(bool)\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=k + 1).fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]\n",
    "\n",
    "    frac_perm = []\n",
    "    for _ in range(n_perm):\n",
    "        perm = rng.permutation(len(is_ref))\n",
    "        is_ref_perm = is_ref[perm]\n",
    "\n",
    "        # neighbors that are reference while focal cell is unimodal\n",
    "        nbr_is_ref_perm = is_ref_perm[nbrs] & ~is_ref_perm[:, None]\n",
    "        frac = nbr_is_ref_perm.mean(axis=1)\n",
    "\n",
    "        # mean only over unimodal (non-reference) cells\n",
    "        frac_perm.append(frac[~is_ref_perm].mean())\n",
    "\n",
    "    return float(np.mean(frac_perm)), float(np.std(frac_perm))\n",
    "\n",
    "obs_mean = combo.obs.loc[combo.obs[\"is_unimodal\"], \"ref_neighbor_frac_k30\"].mean()\n",
    "null_mean, null_std = ref_fraction_null(Z, is_ref, k=30, n_perm=100)\n",
    "print(\"Observed unimodal mean:\", obs_mean)\n",
    "print(\"Null mean ± sd:\", null_mean, null_std)\n",
    "\n",
    "uni_mask = combo.obs[\"is_unimodal\"]\n",
    "\n",
    "df_uni = combo.obs.loc[\n",
    "    uni_mask,\n",
    "    [\"dataset\", \"celltype_harmonized\", \"ref_neighbor_frac_k30\", \"is_reference\"],\n",
    "]\n",
    "\n",
    "print(df_uni.groupby(\"dataset\")[\"ref_neighbor_frac_k30\"].describe())\n",
    "print()\n",
    "print(df_uni.groupby(\"celltype_harmonized\")[\"ref_neighbor_frac_k30\"].describe())\n",
    "\n",
    "# global reference fraction (over ALL cells, not only unimodal)\n",
    "frac_ref_global = combo.obs[\"is_reference\"].mean()\n",
    "print(\"Global reference fraction (all cells):\", frac_ref_global)\n",
    "\n",
    "# fraction of unimodal cells that have at least 1 reference neighbor\n",
    "contact_rate = (df_uni[\"ref_neighbor_frac_k30\"] > 0).mean()\n",
    "print(\"Fraction of unimodal cells with ≥1 reference neighbor:\", contact_rate)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "Z_ref = Z[is_ref]\n",
    "Z_uni = Z[is_uni]\n",
    "\n",
    "print(\"Z_ref:\", Z_ref.shape, \"Z_uni:\", Z_uni.shape)\n",
    "print(combo.obs[\"dataset\"].value_counts())\n",
    "\n",
    "# nearest ref to each unimodal cell\n",
    "nn_ref = NearestNeighbors(n_neighbors=1).fit(Z_ref)\n",
    "d_ref, _ = nn_ref.kneighbors(Z_uni)\n",
    "d_ref = d_ref[:, 0]\n",
    "\n",
    "# nearest unimodal neighbor (excluding self)\n",
    "nn_all = NearestNeighbors(n_neighbors=2).fit(Z_uni)\n",
    "d_all, idx_all = nn_all.kneighbors(Z_uni)\n",
    "d_nn = d_all[:, 1]\n",
    "\n",
    "ratio = d_ref / d_nn\n",
    "print(pd.Series(ratio).describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00352ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uni_rna_pp)\n",
    "print(set(uni_rna_pp.obs['tech']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset combo to Ding cells\n",
    "ding = combo[combo.obs[\"dataset\"] == \"ding_rna\"].copy()\n",
    "\n",
    "sc.pl.umap(\n",
    "    ding,\n",
    "    color=\"tech\",\n",
    "    size=20,\n",
    "    alpha=0.65,\n",
    "    legend_loc=\"right margin\",  # or \"on data\"\n",
    "    title=\"Ding RNA cells colored by sequencing technology\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    ding,\n",
    "    color=\"celltype_harmonized_coarse\",\n",
    "    size=20,\n",
    "    alpha=0.65,\n",
    "    legend_loc=\"right margin\",  # or \"on data\"\n",
    "    title=\"Ding RNA cells colored by sequencing technology\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b770118",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    ding,\n",
    "    color=\"celltype_harmonized\",\n",
    "    size=20,\n",
    "    alpha=0.65,\n",
    "    legend_loc=\"right margin\",  # or \"on data\"\n",
    "    title=\"Ding RNA cells colored by sequencing technology\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82793b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset combo to Satpathy cells\n",
    "satpathy = combo[combo.obs[\"dataset\"] == \"satpathy_atac\"].copy()\n",
    "\n",
    "sc.pl.umap(\n",
    "    satpathy,\n",
    "    color=\"celltype_harmonized_coarse\",\n",
    "    size=20,\n",
    "    alpha=0.65,\n",
    "    legend_loc=\"right margin\",  # or \"on data\"\n",
    "    title=\"Ding RNA cells colored by sequencing technology\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    satpathy,\n",
    "    color=\"celltype_harmonized\",\n",
    "    size=20,\n",
    "    alpha=0.65,\n",
    "    legend_loc=\"right margin\",  # or \"on data\"\n",
    "    title=\"Ding RNA cells colored by sequencing technology\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_uni already has ref_neighbor_frac_k30 for unimodal cells\n",
    "df_uni = combo.obs.loc[combo.obs[\"dataset\"].isin([\"ding_rna\", \"satpathy_atac\"])].copy()\n",
    "\n",
    "print(\n",
    "    df_uni.groupby([\"dataset\", \"tech\"])[\"ref_neighbor_frac_k30\"].describe()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ebc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ding = combo[combo.obs[\"dataset\"] == \"ding_rna\"].copy()\n",
    "Z = ding.obsm[\"X_univi\"]\n",
    "tech = ding.obs[\"tech\"].astype(str).to_numpy()\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=15).fit(Z)\n",
    "idx = nn.kneighbors(return_distance=False)\n",
    "\n",
    "# fraction of neighbors with same tech\n",
    "same = (tech[idx] == tech[:, None]).mean(axis=1)\n",
    "print(\"Median same-tech neighbor fraction:\", np.median(same))\n",
    "\n",
    "print(\n",
    "    pd.Series(same, index=ding.obs_names)\n",
    "      .groupby(ding.obs[\"tech\"])\n",
    "      .median()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d21dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf479a30",
   "metadata": {},
   "source": [
    "### Use celltype classification head to fine-tune the bridge-trained model using the unimodal RNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5079ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "satpathy_atac_pp = uni_atac_lsi.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(satpathy_atac_pp.obs['celltype_harmonized']))\n",
    "print(set(uni_rna_pp.obs['celltype_harmonized']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c337c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# UniVI: fine-tune bridge checkpoint with a shared celltype head\n",
    "#   Supervision sources:\n",
    "#     - labeled Ding RNA      (uni_rna_pp)\n",
    "#     - labeled Satpathy ATAC (satpathy_atac_pp)\n",
    "#\n",
    "# Also includes:\n",
    "#   - head predictions + confusion matrices (RNA+ATAC)\n",
    "#   - encode new latent + concat + UMAP\n",
    "#   - kNN label transfer eval in new latent\n",
    "#   - per-dataset head eval (feature-aligned)\n",
    "#   - paired multiome annotation (fused head probs)\n",
    "# ============================================================\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "from univi.config import UniVIConfig, ModalityConfig, ClassHeadConfig\n",
    "from univi.models import UniVIMultiModalVAE\n",
    "from univi.data import MultiModalDataset\n",
    "from univi.evaluation import encode_adata\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# USER CHOICES\n",
    "# -----------------------------\n",
    "#label_col = \"celltype_harmonized_coarse\"\n",
    "label_col = \"celltype_harmonized\"\n",
    "head_name = \"celltype_higher_res\"\n",
    "exclude_labels_train = {\"Unknown\", \"Unassigned\", \"General PBMC\", \"Megakaryocyte\"}   # training-time exclusions\n",
    "\n",
    "# supervised loss weights (balance RNA vs ATAC)\n",
    "lambda_cls_rna  = 1.00\n",
    "lambda_cls_atac = 1.00\n",
    "\n",
    "'''\n",
    "# Try:\n",
    "lambda_gen = 2.0–10.0\n",
    "lambda_cls_rna = lambda_cls_atac = 0.1–0.5\n",
    "'''\n",
    "\n",
    "# protect bridge generative objective\n",
    "lambda_gen     = 2.00\n",
    "lambda_uni_gen = 0.00    # optional: unimodal RNA gen term on RNA supervised steps (0..0.25-ish)\n",
    "lambda_anchor  = 0.00    # optional: L2 anchor to ckpt (excluding head), ~1e-6..1e-4\n",
    "\n",
    "# training regime\n",
    "METHOD = \"head_then_joint\"   # \"head_only\" | \"joint_mixed\" | \"head_then_joint\"\n",
    "n_epochs      = 1000\n",
    "warmup_epochs = 300\n",
    "\n",
    "# batch sizes\n",
    "batch_size_bridge = 256\n",
    "batch_size_lab_tr = 256\n",
    "batch_size_lab_va = 512\n",
    "\n",
    "# learning rates (param groups)\n",
    "lr_backbone = 1e-5\n",
    "lr_head     = 3e-4\n",
    "weight_decay_backbone = 0.0\n",
    "weight_decay_head     = 1e-4\n",
    "\n",
    "# encoding / plotting\n",
    "latent_choice = \"moe_mean\"   # \"modality_mean\" or \"moe_mean\"\n",
    "out_key       = \"X_univi_ft\"\n",
    "umap_n_neighbors = 30\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# REQUIRED INPUTS\n",
    "# -----------------------------\n",
    "assert \"uni_rna_pp\" in globals(), \"Need uni_rna_pp (Ding RNA preprocessed to model RNA input space).\"\n",
    "assert \"satpathy_atac_pp\" in globals(), \"Need satpathy_atac_pp (Satpathy ATAC preprocessed to model ATAC input space).\"\n",
    "assert \"rna_train_pp\" in globals() and \"atac_train_lsi\" in globals(), \"Need rna_train_pp + atac_train_lsi (bridge paired train).\"\n",
    "assert \"output_dir\" in globals() and \"out_file\" in globals(), \"Need output_dir + out_file (bridge checkpoint path pieces).\"\n",
    "assert \"device\" in globals(), \"Need device (e.g. 'cuda' or torch.device).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Load bridge checkpoint + rebuild config\n",
    "# ============================================================\n",
    "ckpt = torch.load(output_dir + out_file, map_location=device)\n",
    "\n",
    "cfg_dict = ckpt[\"univi_cfg\"]\n",
    "try:\n",
    "    from omegaconf import DictConfig, OmegaConf\n",
    "    if isinstance(cfg_dict, DictConfig):\n",
    "        cfg_dict = OmegaConf.to_container(cfg_dict, resolve=True)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "modalities = [ModalityConfig(**m) for m in cfg_dict[\"modalities\"]]\n",
    "cfg_dict = {**cfg_dict, \"modalities\": modalities}\n",
    "univi_cfg = UniVIConfig(**cfg_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2) Build shared label vocab from UNION of labeled RNA + labeled ATAC\n",
    "# ============================================================\n",
    "def _labeled_mask_and_series(adata, label_col, exclude_labels):\n",
    "    if label_col not in adata.obs:\n",
    "        raise KeyError(f\"adata.obs[{label_col!r}] not found\")\n",
    "    y = adata.obs[label_col].astype(str)\n",
    "    m = (~y.str.startswith(\"unlabeled_\")) & (~y.isin(list(exclude_labels)))\n",
    "    return m.to_numpy(), y\n",
    "\n",
    "mask_rna,  y_rna  = _labeled_mask_and_series(uni_rna_pp,       label_col, exclude_labels_train)\n",
    "mask_atac, y_atac = _labeled_mask_and_series(satpathy_atac_pp, label_col, exclude_labels_train)\n",
    "\n",
    "y_rna_lab  = y_rna[mask_rna]\n",
    "y_atac_lab = y_atac[mask_atac]\n",
    "\n",
    "classes = sorted(pd.unique(pd.concat([y_rna_lab, y_atac_lab], axis=0)))\n",
    "label_to_id = {c: i for i, c in enumerate(classes)}\n",
    "id_to_label = {i: c for c, i in label_to_id.items()}\n",
    "n_classes = len(classes)\n",
    "print(f\"Supervised head classes (n={n_classes}):\", classes)\n",
    "\n",
    "def _make_codes(adata, y_raw, mask, label_to_id, head_name, ignore_index=-1):\n",
    "    \"\"\"Store integer codes in adata.obs[f'{head_name}_code'].\"\"\"\n",
    "    codes = np.full(adata.n_obs, ignore_index, dtype=np.int64)\n",
    "    mask = np.asarray(mask, dtype=bool)\n",
    "    if mask.sum() == 0:\n",
    "        adata.obs[f\"{head_name}_code\"] = codes\n",
    "        return codes\n",
    "\n",
    "    idx = np.where(mask)[0]\n",
    "    y = y_raw.iloc[idx].astype(str)\n",
    "    mapped = y.map(label_to_id)          # float with NaN for unknown\n",
    "    keep = mapped.notna().to_numpy()\n",
    "    codes[idx[keep]] = mapped.to_numpy(np.int64)[keep]\n",
    "    adata.obs[f\"{head_name}_code\"] = codes\n",
    "    return codes\n",
    "\n",
    "codes_rna  = _make_codes(uni_rna_pp,       y_rna,  mask_rna,  label_to_id, head_name)\n",
    "codes_atac = _make_codes(satpathy_atac_pp, y_atac, mask_atac, label_to_id, head_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b2b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3) Attach NON-adversarial head + build model + load weights\n",
    "# ============================================================\n",
    "univi_cfg.class_heads = [\n",
    "    ClassHeadConfig(\n",
    "        name=head_name,\n",
    "        n_classes=int(n_classes),\n",
    "        loss_weight=1.0,\n",
    "        ignore_index=-1,\n",
    "        from_mu=True,\n",
    "        warmup=0,\n",
    "        adversarial=False,\n",
    "    )\n",
    "]\n",
    "univi_cfg.validate()\n",
    "\n",
    "model = UniVIMultiModalVAE(\n",
    "    univi_cfg,\n",
    "    loss_mode=\"v1\", # or lite - but original model was trained with v1 so we'll stick with that\n",
    "    v1_recon=\"avg\",\n",
    "    normalize_v1_terms=True,\n",
    ").to(device)\n",
    "\n",
    "missing, unexpected = model.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
    "print(\"Missing keys (expected new head params):\", missing[:8], \"...\")\n",
    "print(\"Unexpected keys:\", unexpected[:8], \"...\")\n",
    "\n",
    "# anchor target = post-load state dict (includes loaded backbone + fresh head)\n",
    "base_state_dict = copy.deepcopy(model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62007296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4) Build loaders (RNA supervised, ATAC supervised, bridge paired)\n",
    "# ============================================================\n",
    "def _split_stratified(idx_all, y_codes, test_size=0.10, seed=42):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "    tr_rel, va_rel = next(sss.split(idx_all, y_codes))\n",
    "    return idx_all[tr_rel], idx_all[va_rel]\n",
    "\n",
    "def _make_supervised_loaders(adata, codes, modality, batch_tr, batch_va):\n",
    "    idx_lab = np.where(codes >= 0)[0]\n",
    "    if len(idx_lab) == 0:\n",
    "        raise ValueError(f\"No labeled cells found for modality={modality!r}.\")\n",
    "    y_codes = codes[idx_lab]\n",
    "    idx_tr, idx_va = _split_stratified(idx_lab, y_codes)\n",
    "\n",
    "    ad_tr = adata[idx_tr].copy()\n",
    "    ad_va = adata[idx_va].copy()\n",
    "    y_tr = torch.from_numpy(codes[idx_tr].astype(np.int64))\n",
    "    y_va = torch.from_numpy(codes[idx_va].astype(np.int64))\n",
    "\n",
    "    ds_tr = MultiModalDataset(\n",
    "        adata_dict={modality: ad_tr},\n",
    "        X_key=\"X\",\n",
    "        labels={head_name: y_tr},\n",
    "        paired=False,\n",
    "        device=None,\n",
    "    )\n",
    "    ds_va = MultiModalDataset(\n",
    "        adata_dict={modality: ad_va},\n",
    "        X_key=\"X\",\n",
    "        labels={head_name: y_va},\n",
    "        paired=False,\n",
    "        device=None,\n",
    "    )\n",
    "\n",
    "    ld_tr = DataLoader(ds_tr, batch_size=batch_tr, shuffle=True,  num_workers=0)\n",
    "    ld_va = DataLoader(ds_va, batch_size=batch_va, shuffle=False, num_workers=0)\n",
    "    return ds_tr, ds_va, ld_tr, ld_va\n",
    "\n",
    "train_ds_rna, val_ds_rna, cls_train_loader_rna, cls_val_loader_rna = _make_supervised_loaders(\n",
    "    uni_rna_pp, codes_rna, \"rna\", batch_size_lab_tr, batch_size_lab_va\n",
    ")\n",
    "train_ds_atac, val_ds_atac, cls_train_loader_atac, cls_val_loader_atac = _make_supervised_loaders(\n",
    "    satpathy_atac_pp, codes_atac, \"atac\", batch_size_lab_tr, batch_size_lab_va\n",
    ")\n",
    "print(\"Labeled RNA train/val:\", len(train_ds_rna), len(val_ds_rna))\n",
    "print(\"Labeled ATAC train/val:\", len(train_ds_atac), len(val_ds_atac))\n",
    "\n",
    "bridge_ds = MultiModalDataset(\n",
    "    adata_dict={\"rna\": rna_train_pp, \"atac\": atac_train_lsi},\n",
    "    X_key=\"X\",\n",
    "    paired=True,\n",
    "    device=None,\n",
    ")\n",
    "bridge_loader = DataLoader(bridge_ds, batch_size=batch_size_bridge, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c4e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5) Training helpers (no missing functions / no global iterators)\n",
    "# ============================================================\n",
    "def _unwrap_x(batch):\n",
    "    \"\"\"MultiModalDataset may yield x or (x,y). Return x dict.\"\"\"\n",
    "    if isinstance(batch, (tuple, list)) and len(batch) == 2:\n",
    "        return batch[0]\n",
    "    return batch\n",
    "\n",
    "def _cycle(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch\n",
    "\n",
    "def set_trainable(model, mode: str):\n",
    "    if mode == \"all\":\n",
    "        for _, p in model.named_parameters():\n",
    "            p.requires_grad = True\n",
    "    elif mode == \"head_only\":\n",
    "        for n, p in model.named_parameters():\n",
    "            p.requires_grad = n.startswith(f\"class_heads.{head_name}.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "def anchor_l2_penalty(model, base_state_dict, exclude_prefix=(\"class_heads.\",)):\n",
    "    loss = 0.0\n",
    "    for k, v in model.state_dict().items():\n",
    "        if any(k.startswith(pref) for pref in exclude_prefix):\n",
    "            continue\n",
    "        v0 = base_state_dict.get(k, None)\n",
    "        if v0 is None:\n",
    "            continue\n",
    "        if not torch.is_floating_point(v) or not torch.is_floating_point(v0):\n",
    "            continue\n",
    "        loss = loss + torch.sum((v - v0.to(device)) ** 2)\n",
    "    return loss\n",
    "\n",
    "def build_optimizers(model):\n",
    "    head_params, backbone_params = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "        if n.startswith(f\"class_heads.{head_name}.\"):\n",
    "            head_params.append(p)\n",
    "        else:\n",
    "            backbone_params.append(p)\n",
    "\n",
    "    opt_backbone = (\n",
    "        torch.optim.AdamW(backbone_params, lr=lr_backbone, weight_decay=weight_decay_backbone)\n",
    "        if backbone_params else None\n",
    "    )\n",
    "    opt_head = (\n",
    "        torch.optim.AdamW(head_params, lr=lr_head, weight_decay=weight_decay_head)\n",
    "        if head_params else None\n",
    "    )\n",
    "    return opt_backbone, opt_head\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_head_on_loader(model, loader):\n",
    "    model.eval()\n",
    "    y_true_all, y_pred_all = [], []\n",
    "    for x_batch, y_batch in loader:\n",
    "        x_batch = {k: v.to(device) for k, v in x_batch.items()}\n",
    "        y_true = y_batch[head_name].to(device).view(-1)\n",
    "\n",
    "        logits = model.predict_heads(\n",
    "            x_batch,\n",
    "            return_probs=False,\n",
    "            use_mean=True,\n",
    "            inject_label_expert=False,\n",
    "        )[head_name]\n",
    "        y_pred = logits.argmax(dim=-1)\n",
    "\n",
    "        y_true_all.append(y_true.cpu().numpy())\n",
    "        y_pred_all.append(y_pred.cpu().numpy())\n",
    "\n",
    "    y_true_all = np.concatenate(y_true_all)\n",
    "    y_pred_all = np.concatenate(y_pred_all)\n",
    "    return float(accuracy_score(y_true_all, y_pred_all)), float(f1_score(y_true_all, y_pred_all, average=\"macro\"))\n",
    "\n",
    "def eval_both(model):\n",
    "    rna_acc, rna_f1   = eval_head_on_loader(model, cls_val_loader_rna)\n",
    "    atac_acc, atac_f1 = eval_head_on_loader(model, cls_val_loader_atac)\n",
    "    mean_f1 = 0.5 * (rna_f1 + atac_f1)\n",
    "    return rna_acc, rna_f1, atac_acc, atac_f1, mean_f1\n",
    "\n",
    "def supervised_step_one_batch(model, opt_backbone, opt_head, epoch, which, it_rna, it_atac):\n",
    "    \"\"\"One supervised optimizer step on exactly ONE batch (rna or atac).\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    if which == \"rna\":\n",
    "        batch = next(it_rna)\n",
    "        w = lambda_cls_rna\n",
    "    elif which == \"atac\":\n",
    "        batch = next(it_atac)\n",
    "        w = lambda_cls_atac\n",
    "    else:\n",
    "        raise ValueError(which)\n",
    "\n",
    "    x_batch, y_batch = batch\n",
    "    x_batch = {k: v.to(device) for k, v in x_batch.items()}\n",
    "    y_batch = {k: v.to(device) for k, v in y_batch.items()}\n",
    "\n",
    "    out = model(x_batch, y=y_batch, epoch=epoch)\n",
    "    loss = w * out[\"head_losses\"][head_name]\n",
    "\n",
    "    # optional: unimodal RNA gen term\n",
    "    if lambda_uni_gen > 0 and which == \"rna\":\n",
    "        out_gen = model(x_batch, epoch=epoch)\n",
    "        loss = loss + (lambda_uni_gen * out_gen[\"loss\"])\n",
    "\n",
    "    if lambda_anchor > 0:\n",
    "        loss = loss + (lambda_anchor * anchor_l2_penalty(model, base_state_dict))\n",
    "\n",
    "    if opt_backbone is not None: opt_backbone.zero_grad(set_to_none=True)\n",
    "    if opt_head is not None:     opt_head.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    if opt_backbone is not None: opt_backbone.step()\n",
    "    if opt_head is not None:     opt_head.step()\n",
    "\n",
    "    return float(loss.detach().cpu())\n",
    "\n",
    "def supervised_epoch_alternating(model, opt_backbone, opt_head, epoch):\n",
    "    \"\"\"Run a supervised epoch by alternating rna/atac for 2*max(len(loader)).\"\"\"\n",
    "    it_rna  = _cycle(cls_train_loader_rna)\n",
    "    it_atac = _cycle(cls_train_loader_atac)\n",
    "\n",
    "    steps = max(len(cls_train_loader_rna), len(cls_train_loader_atac))\n",
    "    losses = []\n",
    "    for s in range(steps * 2):\n",
    "        which = \"rna\" if (s % 2 == 0) else \"atac\"\n",
    "        losses.append(supervised_step_one_batch(model, opt_backbone, opt_head, epoch, which, it_rna, it_atac))\n",
    "    return float(np.mean(losses))\n",
    "\n",
    "def train_head_only(model):\n",
    "    set_trainable(model, \"head_only\")\n",
    "    _, opt_head = build_optimizers(model)\n",
    "    assert opt_head is not None, \"No head params?\"\n",
    "\n",
    "    best = (-np.inf, None)\n",
    "    for epoch in range(n_epochs):\n",
    "        loss = supervised_epoch_alternating(model, opt_backbone=None, opt_head=opt_head, epoch=epoch)\n",
    "        rna_acc, rna_f1, atac_acc, atac_f1, mean_f1 = eval_both(model)\n",
    "\n",
    "        if mean_f1 > best[0]:\n",
    "            best = (mean_f1, {k: v.detach().cpu().clone() for k, v in model.state_dict().items()})\n",
    "\n",
    "        print(\n",
    "            f\"[epoch {epoch:03d}] head_only_loss={loss:.4f} | \"\n",
    "            f\"RNA acc/F1={rna_acc:.3f}/{rna_f1:.3f} | \"\n",
    "            f\"ATAC acc/F1={atac_acc:.3f}/{atac_f1:.3f} | meanF1={mean_f1:.3f}\"\n",
    "        )\n",
    "\n",
    "    if best[1] is not None:\n",
    "        model.load_state_dict(best[1])\n",
    "        print(\"Restored best head-only with meanF1 =\", best[0])\n",
    "\n",
    "def train_joint_mixed(model):\n",
    "    set_trainable(model, \"all\")\n",
    "    opt_backbone, opt_head = build_optimizers(model)\n",
    "    if opt_backbone is None and opt_head is None:\n",
    "        raise RuntimeError(\"No trainable parameters found.\")\n",
    "\n",
    "    best = (-np.inf, None)\n",
    "\n",
    "    it_bridge = _cycle(bridge_loader)\n",
    "    it_rna    = _cycle(cls_train_loader_rna)\n",
    "    it_atac   = _cycle(cls_train_loader_atac)\n",
    "\n",
    "    steps = max(len(bridge_loader), len(cls_train_loader_rna), len(cls_train_loader_atac))\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        gen_losses, sup_losses = [], []\n",
    "\n",
    "        for step in range(steps):\n",
    "            # --- bridge gen: ONE batch ---\n",
    "            batch = next(it_bridge)\n",
    "            x_batch = _unwrap_x(batch)\n",
    "            x_batch = {k: v.to(device) for k, v in x_batch.items()}\n",
    "\n",
    "            out = model(x_batch, epoch=epoch)\n",
    "            loss = lambda_gen * out[\"loss\"]\n",
    "            if lambda_anchor > 0:\n",
    "                loss = loss + (lambda_anchor * anchor_l2_penalty(model, base_state_dict))\n",
    "\n",
    "            if opt_backbone is not None: opt_backbone.zero_grad(set_to_none=True)\n",
    "            if opt_head is not None:     opt_head.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            if opt_backbone is not None: opt_backbone.step()\n",
    "            if opt_head is not None:     opt_head.step()\n",
    "\n",
    "            gen_losses.append(float(loss.detach().cpu()))\n",
    "\n",
    "            # --- supervised: ONE batch (alternate rna/atac) ---\n",
    "            which = \"rna\" if (step % 2 == 0) else \"atac\"\n",
    "            sup_losses.append(supervised_step_one_batch(model, opt_backbone, opt_head, epoch, which, it_rna, it_atac))\n",
    "\n",
    "        rna_acc, rna_f1, atac_acc, atac_f1, mean_f1 = eval_both(model)\n",
    "        if mean_f1 > best[0]:\n",
    "            best = (mean_f1, {k: v.detach().cpu().clone() for k, v in model.state_dict().items()})\n",
    "\n",
    "        print(\n",
    "            f\"[epoch {epoch:03d}] gen_loss={np.mean(gen_losses):.4f} | sup_loss={np.mean(sup_losses):.4f} | \"\n",
    "            f\"RNA acc/F1={rna_acc:.3f}/{rna_f1:.3f} | ATAC acc/F1={atac_acc:.3f}/{atac_f1:.3f} | meanF1={mean_f1:.3f}\"\n",
    "        )\n",
    "\n",
    "    if best[1] is not None:\n",
    "        model.load_state_dict(best[1])\n",
    "        print(\"Restored best joint-mixed with meanF1 =\", best[0])\n",
    "\n",
    "def train_head_then_joint(model):\n",
    "    print(\"Warmup (head_only) ...\")\n",
    "    set_trainable(model, \"head_only\")\n",
    "    _, opt_head = build_optimizers(model)\n",
    "    assert opt_head is not None\n",
    "\n",
    "    best = (-np.inf, None)\n",
    "    for epoch in range(warmup_epochs):\n",
    "        loss = supervised_epoch_alternating(model, opt_backbone=None, opt_head=opt_head, epoch=epoch)\n",
    "        rna_acc, rna_f1, atac_acc, atac_f1, mean_f1 = eval_both(model)\n",
    "\n",
    "        if mean_f1 > best[0]:\n",
    "            best = (mean_f1, {k: v.detach().cpu().clone() for k, v in model.state_dict().items()})\n",
    "\n",
    "        print(\n",
    "            f\"[warmup {epoch:03d}] head_loss={loss:.4f} | \"\n",
    "            f\"RNA acc/F1={rna_acc:.3f}/{rna_f1:.3f} | ATAC acc/F1={atac_acc:.3f}/{atac_f1:.3f} | meanF1={mean_f1:.3f}\"\n",
    "        )\n",
    "\n",
    "    if best[1] is not None:\n",
    "        model.load_state_dict(best[1])\n",
    "        print(\"Warmup restored best with meanF1 =\", best[0])\n",
    "\n",
    "    print(\"\\nSwitching to joint_mixed (backbone unfrozen) ...\\n\")\n",
    "    train_joint_mixed(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d21dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6) RUN TRAINING\n",
    "# ============================================================\n",
    "print(\"METHOD =\", METHOD)\n",
    "if METHOD == \"head_only\":\n",
    "    train_head_only(model)\n",
    "elif METHOD == \"joint_mixed\":\n",
    "    train_joint_mixed(model)\n",
    "elif METHOD == \"head_then_joint\":\n",
    "    train_head_then_joint(model)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown METHOD: {METHOD}\")\n",
    "\n",
    "# keep a consistent name if you used model_cls elsewhere\n",
    "model_cls = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa17336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7) Predict head labels (RNA + ATAC) + confusion matrices\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def predict_head_codes_single_modality(model, adata, modality, *, head_name, device, batch_size=1024):\n",
    "    model.eval()\n",
    "    ds = MultiModalDataset(\n",
    "        adata_dict={modality: adata},\n",
    "        X_key=\"X\",\n",
    "        paired=False,\n",
    "        device=None,\n",
    "    )\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    pred_codes = []\n",
    "    for batch in loader:\n",
    "        x_batch = _unwrap_x(batch)\n",
    "        x_batch = {k: v.to(device) for k, v in x_batch.items()}\n",
    "        logits = model.predict_heads(\n",
    "            x_batch,\n",
    "            return_probs=False,\n",
    "            use_mean=True,\n",
    "            inject_label_expert=False,\n",
    "        )[head_name]\n",
    "        pred_codes.append(logits.argmax(dim=-1).cpu().numpy())\n",
    "\n",
    "    return np.concatenate(pred_codes).astype(np.int64)\n",
    "\n",
    "# Ding RNA predictions\n",
    "uni_rna_pp.obs[f\"{head_name}_pred_code\"] = predict_head_codes_single_modality(\n",
    "    model_cls, uni_rna_pp, \"rna\", head_name=head_name, device=device, batch_size=1024\n",
    ")\n",
    "uni_rna_pp.obs[f\"{head_name}_pred\"] = pd.Categorical(\n",
    "    [id_to_label[int(i)] for i in uni_rna_pp.obs[f\"{head_name}_pred_code\"].to_numpy()],\n",
    "    categories=classes,\n",
    ")\n",
    "\n",
    "# Satpathy ATAC predictions\n",
    "satpathy_atac_pp.obs[f\"{head_name}_pred_code\"] = predict_head_codes_single_modality(\n",
    "    model_cls, satpathy_atac_pp, \"atac\", head_name=head_name, device=device, batch_size=1024\n",
    ")\n",
    "satpathy_atac_pp.obs[f\"{head_name}_pred\"] = pd.Categorical(\n",
    "    [id_to_label[int(i)] for i in satpathy_atac_pp.obs[f\"{head_name}_pred_code\"].to_numpy()],\n",
    "    categories=classes,\n",
    ")\n",
    "\n",
    "# Confusion on labeled cells only (RNA)\n",
    "mask_lab_rna = (uni_rna_pp.obs[f\"{head_name}_code\"].to_numpy() >= 0)\n",
    "y_true = uni_rna_pp.obs.loc[mask_lab_rna, f\"{head_name}_code\"].to_numpy().astype(int)\n",
    "y_pred = uni_rna_pp.obs.loc[mask_lab_rna, f\"{head_name}_pred_code\"].to_numpy().astype(int)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1  = f1_score(y_true, y_pred, average=\"macro\")\n",
    "cm  = confusion_matrix(y_true, y_pred, labels=np.arange(n_classes))\n",
    "print(\"RNA head acc:\", acc, \"macroF1:\", f1)\n",
    "cm_df_rna = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "display(cm_df_rna)\n",
    "\n",
    "# Confusion on labeled cells only (ATAC)\n",
    "mask_lab_atac = (satpathy_atac_pp.obs[f\"{head_name}_code\"].to_numpy() >= 0)\n",
    "y_true = satpathy_atac_pp.obs.loc[mask_lab_atac, f\"{head_name}_code\"].to_numpy().astype(int)\n",
    "y_pred = satpathy_atac_pp.obs.loc[mask_lab_atac, f\"{head_name}_pred_code\"].to_numpy().astype(int)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1  = f1_score(y_true, y_pred, average=\"macro\")\n",
    "cm  = confusion_matrix(y_true, y_pred, labels=np.arange(n_classes))\n",
    "print(\"ATAC head acc:\", acc, \"macroF1:\", f1)\n",
    "cm_df_atac = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "display(cm_df_atac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd7dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latent_choice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c651a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8) Encode new latent for (bridge + unimodal) and UMAP\n",
    "#    (Uses encode_adata; stores in .obsm[out_key])\n",
    "# ============================================================\n",
    "def _ensure_obs_cols(a, dataset, modality, is_reference):\n",
    "    a = a.copy()\n",
    "    a.obs[\"dataset\"] = str(dataset)\n",
    "    a.obs[\"modality\"] = str(modality)\n",
    "    a.obs[\"is_reference\"] = bool(is_reference)\n",
    "    return a\n",
    "\n",
    "# pick bridge datasets for visualization\n",
    "bridge_rna  = globals().get(\"bridge_rna\",  rna_train_pp)\n",
    "bridge_atac = globals().get(\"bridge_atac\", atac_train_lsi)\n",
    "\n",
    "bridge_rna   = _ensure_obs_cols(bridge_rna,   dataset=\"multiome_rna\",  modality=\"rna\",  is_reference=True)\n",
    "bridge_atac  = _ensure_obs_cols(bridge_atac,  dataset=\"multiome_atac\", modality=\"atac\", is_reference=True)\n",
    "ding_rna     = _ensure_obs_cols(uni_rna_pp,   dataset=\"ding_rna\",      modality=\"rna\",  is_reference=False)\n",
    "satpathy_atac= _ensure_obs_cols(satpathy_atac_pp, dataset=\"satpathy_atac\", modality=\"atac\", is_reference=False)\n",
    "\n",
    "def _encode_into(adata, modality):\n",
    "    Z = encode_adata(\n",
    "        model_cls,\n",
    "        adata,\n",
    "        modality=modality,\n",
    "        latent=latent_choice,\n",
    "        device=device,\n",
    "        batch_size=1024,\n",
    "    )\n",
    "    adata = adata.copy()\n",
    "    adata.obsm[out_key] = np.asarray(Z, dtype=np.float32)\n",
    "    return adata\n",
    "\n",
    "bridge_rna    = _encode_into(bridge_rna, \"rna\")\n",
    "bridge_atac   = _encode_into(bridge_atac, \"atac\")\n",
    "ding_rna      = _encode_into(ding_rna, \"rna\")\n",
    "satpathy_atac = _encode_into(satpathy_atac, \"atac\")\n",
    "\n",
    "combo_ft = ad.concat(\n",
    "    {\"multiome_rna\": bridge_rna, \"multiome_atac\": bridge_atac, \"ding_rna\": ding_rna, \"satpathy_atac\": satpathy_atac},\n",
    "    axis=0,\n",
    "    join=\"outer\",\n",
    "    label=\"dataset\",\n",
    "    index_unique=None,\n",
    ")\n",
    "assert out_key in combo_ft.obsm, f\"Missing {out_key} in combo_ft.obsm\"\n",
    "\n",
    "sc.pp.neighbors(combo_ft, n_neighbors=umap_n_neighbors, use_rep=out_key, metric=\"euclidean\")\n",
    "sc.tl.umap(combo_ft, min_dist=0.3, spread=1.0)\n",
    "\n",
    "sc.pl.umap(combo_ft, color=[\"dataset\"],      title=[f\"Dataset ({out_key})\"], frameon=False, size=10, alpha=0.5)\n",
    "sc.pl.umap(combo_ft, color=[\"modality\"],     title=[f\"Modality ({out_key})\"], frameon=False, size=10, alpha=0.5)\n",
    "sc.pl.umap(combo_ft, color=[\"is_reference\"], title=[f\"Reference vs unimodal ({out_key})\"], frameon=False, size=10, alpha=0.5)\n",
    "\n",
    "# labeled celltypes where they exist\n",
    "has_labels = combo_ft.obs[label_col].notna() & ~combo_ft.obs[label_col].astype(str).str.startswith(\"unlabeled_\")\n",
    "if has_labels.sum() > 0:\n",
    "    sc.pl.umap(combo_ft[has_labels], color=[label_col], title=[f\"{label_col} ({out_key})\"], frameon=False, size=10, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ea1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(combo_ft, color=[\"tech\"], title=[f\"Tech ({out_key})\"], frameon=False, size=10, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c846773",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combo_ft.uns['dataset_colors'])\n",
    "print(combo_ft.uns['modality_colors'])\n",
    "print(combo_ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee06c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combo_ft.obs[\"dataset\"].value_counts(dropna=False))\n",
    "print(sorted(combo_ft.obs[\"dataset\"].astype(str).unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 0) clean labels (prevents invisible whitespace bugs)\n",
    "combo_ft.obs[\"dataset\"] = combo_ft.obs[\"dataset\"].astype(str).str.strip()\n",
    "\n",
    "# 1) the order you want in the legend (match your 2nd image)\n",
    "dataset_order = [\"multiome_rna\", \"multiome_atac\", \"ding_rna\", \"satpathy_atac\"]\n",
    "\n",
    "# 2) exact colors (match your 1st image)\n",
    "palette = {\n",
    "    #\"multiome_rna\":   \"#1f77b4\",  # blue\n",
    "    \"multiome_rna\":   \"#2ca02c\",  # green\n",
    "    #\"multiome_atac\":  \"#ff7f0e\",  # orange\n",
    "    \"multiome_atac\":  \"#d62728\",  # red\n",
    "    #\"ding_rna\":       \"#2ca02c\",  # green\n",
    "    \"ding_rna\":       \"#1f77b4\",  # blue\n",
    "    #\"satpathy_atac\":  \"#d62728\",  # red\n",
    "    \"satpathy_atac\":  \"#ff7f0e\",  # orange\n",
    "}\n",
    "\n",
    "# enforce categorical order\n",
    "combo_ft.obs[\"dataset\"] = pd.Categorical(\n",
    "    combo_ft.obs[\"dataset\"],\n",
    "    categories=dataset_order,\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "# force Scanpy's internal color list to match that order\n",
    "combo_ft.uns[\"dataset_colors\"] = [palette[k] for k in dataset_order]\n",
    "\n",
    "sc.pl.umap(\n",
    "    combo_ft,\n",
    "    color=\"dataset\",\n",
    "    title=f\"Dataset ({out_key})\",\n",
    "    frameon=False,\n",
    "    size=10,\n",
    "    alpha=0.5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f409d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 9) kNN label transfer in NEW latent (optional, requires your functions)\n",
    "# ============================================================\n",
    "# Requires: knn_label_transfer_confusion_two_adata, plot_knn_confusion_heatmap\n",
    "if \"knn_label_transfer_confusion_two_adata\" in globals():\n",
    "    exclude_labels_knn = (\"Other\", \"Unknown\", \"Unassigned\", \"General PBMC\", \"Megakaryocyte\")\n",
    "    k = 15\n",
    "\n",
    "    ding_mask = combo_ft.obs[\"dataset\"].astype(str).eq(\"ding_rna\").to_numpy()\n",
    "    sat_mask  = combo_ft.obs[\"dataset\"].astype(str).eq(\"satpathy_atac\").to_numpy()\n",
    "    adata_ding = combo_ft[ding_mask].copy()\n",
    "    adata_sat  = combo_ft[sat_mask].copy()\n",
    "\n",
    "    res_r2a = knn_label_transfer_confusion_two_adata(\n",
    "        adata_ref=adata_ding,\n",
    "        adata_tgt=adata_sat,\n",
    "        emb_key=out_key,\n",
    "        ct_key=label_col,\n",
    "        k=k,\n",
    "        exclude_labels=exclude_labels_knn,\n",
    "    )\n",
    "    print(\"Ding RNA → Satpathy ATAC\", \"Acc:\", res_r2a[\"acc\"], \"MacroF1:\", res_r2a[\"macro_f1\"])\n",
    "    display(res_r2a[\"cm_df\"])\n",
    "    if \"plot_knn_confusion_heatmap\" in globals():\n",
    "        plot_knn_confusion_heatmap(res_r2a, normalize=\"row\", title=f\"Ding RNA → Satpathy ATAC (k={k}, {out_key})\")\n",
    "\n",
    "    res_a2r = knn_label_transfer_confusion_two_adata(\n",
    "        adata_ref=adata_sat,\n",
    "        adata_tgt=adata_ding,\n",
    "        emb_key=out_key,\n",
    "        ct_key=label_col,\n",
    "        k=k,\n",
    "        exclude_labels=exclude_labels_knn,\n",
    "    )\n",
    "    print(\"Satpathy ATAC → Ding RNA\", \"Acc:\", res_a2r[\"acc\"], \"MacroF1:\", res_a2r[\"macro_f1\"])\n",
    "    display(res_a2r[\"cm_df\"])\n",
    "    if \"plot_knn_confusion_heatmap\" in globals():\n",
    "        plot_knn_confusion_heatmap(res_a2r, normalize=\"row\", title=f\"Satpathy ATAC → Ding RNA (k={k}, {out_key})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 10) Per-dataset head eval with feature alignment (robust)\n",
    "# ============================================================\n",
    "def _infer_modality_from_dataset_name(ds: str) -> str:\n",
    "    s = str(ds).lower()\n",
    "    if \"atac\" in s: return \"atac\"\n",
    "    if \"rna\"  in s: return \"rna\"\n",
    "    raise ValueError(f\"Can't infer modality from dataset={ds!r}.\")\n",
    "\n",
    "def _align_to_expected_vars(adata, expected_vars, *, name=\"\"):\n",
    "    expected_vars = pd.Index(expected_vars)\n",
    "    have = adata.var_names\n",
    "    missing = expected_vars.difference(have)\n",
    "    if len(missing) > 0:\n",
    "        raise ValueError(\n",
    "            f\"{name}: missing {len(missing)} expected features. Example missing: {missing[:10].tolist()}\"\n",
    "        )\n",
    "    return adata[:, expected_vars].copy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_head_on_subset(\n",
    "    model,\n",
    "    adata_sub,\n",
    "    *,\n",
    "    modality: str,\n",
    "    head_name: str,\n",
    "    label_col: str,\n",
    "    label_to_id: dict,\n",
    "    expected_vars_by_modality: dict,\n",
    "    exclude_labels=(),\n",
    "    batch_size: int = 1024,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    y_raw = adata_sub.obs[label_col].astype(str)\n",
    "    mask = (\n",
    "        (~y_raw.str.startswith(\"unlabeled_\"))\n",
    "        & (~y_raw.isin(list(exclude_labels)))\n",
    "        & (y_raw.isin(label_to_id.keys()))\n",
    "    )\n",
    "    if mask.sum() == 0:\n",
    "        return None\n",
    "\n",
    "    ad0 = adata_sub[mask.to_numpy()].copy()\n",
    "    ad0 = _align_to_expected_vars(ad0, expected_vars_by_modality[modality], name=f\"{modality}/{head_name}\")\n",
    "\n",
    "    y = torch.from_numpy(y_raw[mask].map(label_to_id).to_numpy(np.int64))\n",
    "\n",
    "    ds = MultiModalDataset(\n",
    "        adata_dict={modality: ad0},\n",
    "        X_key=\"X\",\n",
    "        labels={head_name: y},\n",
    "        paired=False,\n",
    "        device=None,\n",
    "    )\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    model.eval()\n",
    "    y_true_all, y_pred_all = [], []\n",
    "    for x_batch, y_batch in loader:\n",
    "        x_batch = {k: v.to(device) for k, v in x_batch.items()}\n",
    "        y_true = y_batch[head_name].to(device).view(-1)\n",
    "        logits = model.predict_heads(x_batch, return_probs=False, use_mean=True, inject_label_expert=False)[head_name]\n",
    "        y_pred = logits.argmax(dim=-1)\n",
    "        y_true_all.append(y_true.cpu().numpy())\n",
    "        y_pred_all.append(y_pred.cpu().numpy())\n",
    "\n",
    "    y_true_all = np.concatenate(y_true_all)\n",
    "    y_pred_all = np.concatenate(y_pred_all)\n",
    "    acc = float(accuracy_score(y_true_all, y_pred_all))\n",
    "    f1  = float(f1_score(y_true_all, y_pred_all, average=\"macro\"))\n",
    "    cm  = confusion_matrix(y_true_all, y_pred_all)\n",
    "    return {\"n\": int(len(y_true_all)), \"acc\": acc, \"macroF1\": f1, \"cm\": cm}\n",
    "\n",
    "expected_vars_by_modality = {\n",
    "    \"rna\":  list(rna_train_pp.var_names),\n",
    "    \"atac\": list(atac_train_lsi.var_names),\n",
    "}\n",
    "\n",
    "dataset_key = \"dataset\"\n",
    "results = []\n",
    "cms = {}\n",
    "\n",
    "for ds_name in pd.unique(combo_ft.obs[dataset_key].astype(str)):\n",
    "    ad_ds = combo_ft[combo_ft.obs[dataset_key].astype(str).eq(ds_name).to_numpy()].copy()\n",
    "    modality = _infer_modality_from_dataset_name(ds_name)\n",
    "\n",
    "    out = eval_head_on_subset(\n",
    "        model_cls,\n",
    "        ad_ds,\n",
    "        modality=modality,\n",
    "        head_name=head_name,\n",
    "        label_col=label_col,\n",
    "        label_to_id=label_to_id,\n",
    "        expected_vars_by_modality=expected_vars_by_modality,\n",
    "        exclude_labels=exclude_labels_train,\n",
    "        batch_size=1024,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    if out is None:\n",
    "        results.append({\"dataset\": ds_name, \"modality\": modality, \"n\": 0, \"acc\": np.nan, \"macroF1\": np.nan})\n",
    "    else:\n",
    "        results.append({\"dataset\": ds_name, \"modality\": modality, \"n\": out[\"n\"], \"acc\": out[\"acc\"], \"macroF1\": out[\"macroF1\"]})\n",
    "        cms[ds_name] = out[\"cm\"]\n",
    "\n",
    "df_head_by_dataset = pd.DataFrame(results).sort_values([\"modality\", \"acc\"], ascending=[True, False])\n",
    "display(df_head_by_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3521aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bridge_rna)\n",
    "print(bridge_atac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d71742",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_multiome_pp = bridge_rna.copy()\n",
    "atac_multiome_lsi = bridge_atac.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _labeled_mask(adata, label_col, exclude_labels):\n",
    "    if label_col not in adata.obs:\n",
    "        raise KeyError(f\"adata.obs[{label_col!r}] not found\")\n",
    "    y = adata.obs[label_col].astype(str)\n",
    "    m = (~y.str.startswith(\"unlabeled_\")) & (~y.isin(list(exclude_labels)))\n",
    "    return m.to_numpy(), y\n",
    "\n",
    "def _make_codes(adata, y_raw, mask, label_to_id, head_name, ignore_index=-1):\n",
    "    codes = np.full(adata.n_obs, ignore_index, dtype=np.int64)\n",
    "    mask = np.asarray(mask, dtype=bool)\n",
    "    if mask.sum() == 0:\n",
    "        adata.obs[f\"{head_name}_code\"] = codes\n",
    "        return codes\n",
    "\n",
    "    idx = np.where(mask)[0]\n",
    "    y = y_raw.iloc[idx].astype(str)\n",
    "\n",
    "    mapped = y.map(label_to_id)          # NaN for OOV\n",
    "    keep = mapped.notna().to_numpy()\n",
    "\n",
    "    codes[idx[keep]] = mapped.to_numpy(dtype=np.int64)[keep]\n",
    "    adata.obs[f\"{head_name}_code\"] = codes\n",
    "    return codes\n",
    "\n",
    "def _split_stratified(idx_all, y_codes, test_size=0.10, seed=42):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "    tr_rel, va_rel = next(sss.split(idx_all, y_codes))\n",
    "    return idx_all[tr_rel], idx_all[va_rel]\n",
    "\n",
    "def _make_supervised_loaders(adata, codes, modality, batch_tr, batch_va):\n",
    "    idx_lab = np.where(codes >= 0)[0]\n",
    "    if len(idx_lab) == 0:\n",
    "        raise ValueError(f\"No labeled cells for modality={modality!r}\")\n",
    "    y_codes = codes[idx_lab]\n",
    "    idx_tr, idx_va = _split_stratified(idx_lab, y_codes)\n",
    "\n",
    "    ad_tr = adata[idx_tr].copy()\n",
    "    ad_va = adata[idx_va].copy()\n",
    "\n",
    "    y_tr = torch.from_numpy(codes[idx_tr].astype(np.int64))\n",
    "    y_va = torch.from_numpy(codes[idx_va].astype(np.int64))\n",
    "\n",
    "    ds_tr = MultiModalDataset(\n",
    "        adata_dict={modality: ad_tr},\n",
    "        X_key=\"X\",\n",
    "        labels={head_name: y_tr},\n",
    "        paired=False,\n",
    "        device=None,\n",
    "    )\n",
    "    ds_va = MultiModalDataset(\n",
    "        adata_dict={modality: ad_va},\n",
    "        X_key=\"X\",\n",
    "        labels={head_name: y_va},\n",
    "        paired=False,\n",
    "        device=None,\n",
    "    )\n",
    "\n",
    "    ld_tr = DataLoader(ds_tr, batch_size=batch_tr, shuffle=True,  num_workers=0)\n",
    "    ld_va = DataLoader(ds_va, batch_size=batch_va, shuffle=False, num_workers=0)\n",
    "    return ds_tr, ds_va, ld_tr, ld_va\n",
    "\n",
    "def _cycle(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch\n",
    "\n",
    "def _align_features_strict(adata, ref, modality_name):\n",
    "    if ref is None:\n",
    "        return adata\n",
    "    if not np.array_equal(adata.var_names, ref.var_names):\n",
    "        missing = ref.var_names.difference(adata.var_names)\n",
    "        extra   = adata.var_names.difference(ref.var_names)\n",
    "        if len(missing) or len(extra):\n",
    "            raise ValueError(\n",
    "                f\"[{modality_name}] Feature mismatch vs reference.\\n\"\n",
    "                f\"  missing (need in adata): {len(missing)}\\n\"\n",
    "                f\"  extra   (in adata only): {len(extra)}\\n\"\n",
    "                f\"Fix preprocessing/projecting so var_names match.\"\n",
    "            )\n",
    "        adata = adata[:, ref.var_names].copy()\n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"rna_multiome_pp\" in globals() and \"atac_multiome_lsi\" in globals(), \"Provide multiome RNA+ATAC to annotate.\"\n",
    "\n",
    "# Align cells\n",
    "if not np.array_equal(rna_multiome_pp.obs_names, atac_multiome_lsi.obs_names):\n",
    "    common = rna_multiome_pp.obs_names.intersection(atac_multiome_lsi.obs_names)\n",
    "    rna_multiome_pp = rna_multiome_pp[common].copy()\n",
    "    atac_multiome_lsi = atac_multiome_lsi[common].copy()\n",
    "    atac_multiome_lsi = atac_multiome_lsi[rna_multiome_pp.obs_names].copy()\n",
    "\n",
    "# Align features\n",
    "rna_multiome_pp  = _align_features_strict(rna_multiome_pp,  rna_train_pp,  \"rna\")\n",
    "atac_multiome_lsi = _align_features_strict(atac_multiome_lsi, atac_train_lsi, \"atac\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_fused_to_obs(model, rna_ad, atac_ad, *, head_name, id_to_label, batch_size=1024):\n",
    "    ds = MultiModalDataset(\n",
    "        adata_dict={\"rna\": rna_ad, \"atac\": atac_ad},\n",
    "        X_key=\"X\",\n",
    "        paired=True,\n",
    "        device=None,\n",
    "    )\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    model.eval()\n",
    "    probs_all = []\n",
    "    for batch in loader:\n",
    "        x_batch = batch[0] if isinstance(batch, (tuple, list)) else batch\n",
    "        x_batch = {k: v.to(device) for k, v in x_batch.items()}\n",
    "\n",
    "        probs = model.predict_heads(\n",
    "            x_batch,\n",
    "            return_probs=True,\n",
    "            use_mean=True,\n",
    "            inject_label_expert=False,\n",
    "        )[head_name]\n",
    "        probs_all.append(probs.detach().cpu())\n",
    "\n",
    "    probs_all = torch.cat(probs_all, dim=0).numpy()\n",
    "    pred_id = probs_all.argmax(axis=1).astype(np.int64)\n",
    "    conf = probs_all.max(axis=1).astype(np.float32)\n",
    "    pred_label = np.array([id_to_label[int(i)] for i in pred_id], dtype=object)\n",
    "\n",
    "    for ad_ in (rna_ad, atac_ad):\n",
    "        ad_.obs[f\"{head_name}_pred_code\"] = pred_id\n",
    "        ad_.obs[f\"{head_name}_pred\"] = pd.Categorical(pred_label, categories=list(id_to_label.values()))\n",
    "        ad_.obs[f\"{head_name}_conf\"] = conf\n",
    "\n",
    "    return pred_id, conf\n",
    "\n",
    "pred_id_fused, conf_fused = predict_fused_to_obs(\n",
    "    model, rna_multiome_pp, atac_multiome_lsi, head_name=head_name, id_to_label=id_to_label, batch_size=1024\n",
    ")\n",
    "\n",
    "# Optional confidence thresholding\n",
    "CONF_THRESH = 0.25\n",
    "low = conf_fused < CONF_THRESH\n",
    "for ad_ in (rna_multiome_pp, atac_multiome_lsi):\n",
    "    col = f\"{head_name}_pred_thresh{CONF_THRESH:g}\"\n",
    "    tmp = ad_.obs[f\"{head_name}_pred\"].astype(str).to_numpy()\n",
    "    tmp[low] = \"Unassigned\"\n",
    "    ad_.obs[col] = pd.Categorical(tmp)\n",
    "\n",
    "print(\"Annotated multiome cells:\", rna_multiome_pp.n_obs, \"| low-conf frac:\", float(low.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode latents\n",
    "#latent_choice = \"modality_mean\"\n",
    "latent_choice = \"moe_mean\"\n",
    "out_key = \"X_univi_ft\"\n",
    "\n",
    "def _encode_into(adata, modality):\n",
    "    Z = encode_adata(\n",
    "        model,\n",
    "        adata,\n",
    "        modality=modality,\n",
    "        latent=latent_choice,\n",
    "        device=device,\n",
    "        batch_size=1024,\n",
    "    )\n",
    "    adata.obsm[out_key] = np.asarray(Z, dtype=np.float32)\n",
    "    return adata\n",
    "\n",
    "# Make small wrappers for consistent metadata\n",
    "def _ensure_obs_cols(a, dataset, modality, is_reference):\n",
    "    a = a.copy()\n",
    "    a.obs[\"dataset\"] = str(dataset)\n",
    "    a.obs[\"modality\"] = str(modality)\n",
    "    a.obs[\"is_reference\"] = bool(is_reference)\n",
    "    return a\n",
    "\n",
    "bridge_rna   = _ensure_obs_cols(rna_train_pp,      \"multiome_rna\",  \"rna\",  True)\n",
    "bridge_atac  = _ensure_obs_cols(atac_train_lsi,    \"multiome_atac\", \"atac\", True)\n",
    "ding_rna     = _ensure_obs_cols(uni_rna_pp,        \"ding_rna\",      \"rna\",  False)\n",
    "sat_atac     = _ensure_obs_cols(satpathy_atac_pp,  \"satpathy_atac\", \"atac\", False)\n",
    "\n",
    "bridge_rna  = _encode_into(bridge_rna,  \"rna\")\n",
    "bridge_atac = _encode_into(bridge_atac, \"atac\")\n",
    "ding_rna    = _encode_into(ding_rna,    \"rna\")\n",
    "sat_atac    = _encode_into(sat_atac,    \"atac\")\n",
    "\n",
    "# Concatenate fresh (avoids accidentally reusing old neighbor/umap)\n",
    "combo_ft = ad.concat(\n",
    "    {\"multiome_rna\": bridge_rna, \"multiome_atac\": bridge_atac, \"ding_rna\": ding_rna, \"satpathy_atac\": sat_atac},\n",
    "    axis=0,\n",
    "    join=\"outer\",\n",
    "    label=\"dataset\",\n",
    "    index_unique=None,\n",
    ")\n",
    "\n",
    "assert out_key in combo_ft.obsm, f\"Missing {out_key} in combo_ft.obsm\"\n",
    "\n",
    "# NEW UMAP stored under a new basis name\n",
    "suffix = \"univi_ft\"\n",
    "neighbors_key = f\"neighbors_{suffix}\"\n",
    "\n",
    "sc.pp.neighbors(combo_ft, n_neighbors=30, use_rep=out_key, metric=\"euclidean\", key_added=neighbors_key)\n",
    "sc.tl.umap(combo_ft, neighbors_key=neighbors_key, min_dist=0.3, spread=1.0)\n",
    "\n",
    "# stash it so you can plot without overwriting later\n",
    "combo_ft.obsm[f\"X_umap_{suffix}\"] = combo_ft.obsm[\"X_umap\"].copy()\n",
    "\n",
    "# Plot the NEW one explicitly\n",
    "sc.pl.embedding(combo_ft, basis=f\"umap_{suffix}\", color=[\"dataset\"], frameon=False, size=2,\n",
    "                title=[f\"Dataset ({out_key}) [{suffix}]\"])\n",
    "sc.pl.embedding(combo_ft, basis=f\"umap_{suffix}\", color=[\"modality\"], frameon=False, size=2,\n",
    "                title=[f\"Modality ({out_key}) [{suffix}]\"])\n",
    "sc.pl.embedding(combo_ft, basis=f\"umap_{suffix}\", color=[\"is_reference\"], frameon=False, size=2,\n",
    "                title=[f\"Reference vs unimodal ({out_key}) [{suffix}]\"])\n",
    "\n",
    "if \"tech\" in combo_ft.obs.columns:\n",
    "    sc.pl.embedding(combo_ft, basis=f\"umap_{suffix}\", color=[\"tech\"], frameon=False, size=2,\n",
    "                    title=[f\"Tech ({out_key}) [{suffix}]\"])\n",
    "\n",
    "has_labels = combo_ft.obs[label_col].notna() & ~combo_ft.obs[label_col].astype(str).str.startswith(\"unlabeled_\")\n",
    "if has_labels.sum() > 0:\n",
    "    sc.pl.embedding(combo_ft[has_labels], basis=f\"umap_{suffix}\", color=[label_col], frameon=False, size=2,\n",
    "                    title=[f\"{label_col} ({out_key}) [{suffix}]\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes you already have knn_label_transfer_confusion_two_adata and plot_knn_confusion_heatmap\n",
    "label_col_lt = \"celltype_harmonized_coarse\"\n",
    "exclude_lt = (\"Other\", \"Unknown\", \"Unassigned\", \"Megakaryocyte\")\n",
    "k = 15\n",
    "\n",
    "ding_mask = combo_ft.obs[\"dataset\"].astype(str).eq(\"ding_rna\").to_numpy()\n",
    "sat_mask  = combo_ft.obs[\"dataset\"].astype(str).eq(\"satpathy_atac\").to_numpy()\n",
    "\n",
    "adata_ding = combo_ft[ding_mask].copy()\n",
    "adata_sat  = combo_ft[sat_mask].copy()\n",
    "\n",
    "res_r2a = knn_label_transfer_confusion_two_adata(\n",
    "    adata_ref=adata_ding,\n",
    "    adata_tgt=adata_sat,\n",
    "    emb_key=out_key,\n",
    "    ct_key=label_col_lt,\n",
    "    k=k,\n",
    "    exclude_labels=exclude_lt,\n",
    ")\n",
    "print(\"Ding RNA → Satpathy ATAC\")\n",
    "print(\"  Acc:\", res_r2a[\"acc\"])\n",
    "print(\"  MacroF1:\", res_r2a[\"macro_f1\"])\n",
    "display(res_r2a[\"cm_df\"])\n",
    "plot_knn_confusion_heatmap(res_r2a, normalize=\"row\",\n",
    "                           title=f\"Ding RNA → Satpathy ATAC (k={k}, {out_key})\")\n",
    "\n",
    "res_a2r = knn_label_transfer_confusion_two_adata(\n",
    "    adata_ref=adata_sat,\n",
    "    adata_tgt=adata_ding,\n",
    "    emb_key=out_key,\n",
    "    ct_key=label_col_lt,\n",
    "    k=k,\n",
    "    exclude_labels=exclude_lt,\n",
    ")\n",
    "print(\"Satpathy ATAC → Ding RNA\")\n",
    "print(\"  Acc:\", res_a2r[\"acc\"])\n",
    "print(\"  MacroF1:\", res_a2r[\"macro_f1\"])\n",
    "display(res_a2r[\"cm_df\"])\n",
    "plot_knn_confusion_heatmap(res_a2r, normalize=\"row\",\n",
    "                           title=f\"Satpathy ATAC → Ding RNA (k={k}, {out_key})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combo_ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad598d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(combo_ft, basis=f\"X_umap_univi_ft\", color=[\"celltype_harmonized\"], frameon=False, size=3, alpha=0.65,\n",
    "                title=[f\"Reference vs unimodal by harmonized celltype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fa9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(combo_ft, basis=f\"X_umap_univi_ft\", color=[\"celltype_harmonized_coarse\"], frameon=False, size=3, alpha=0.65,\n",
    "                title=[f\"Reference vs unimodal by harmonized coarse celltype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dceb266-3adc-4eed-9782-0afbab019376",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_rna = combo_ft[combo_ft.obs['modality'] == 'rna']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5044b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6a) UMAP overlays for a *small* set of markers (pick ~6–12 so it’s readable)\n",
    "umap_genes = [g for g in [\"MS4A1\",\"CD79A\",\"IL7R\",\"CCR7\",\"NKG7\",\"GNLY\",\"LST1\",\"S100A8\",\"LYZ\",\"TRAC\",\"FCER1A\",\"CLEC10A\"] if g in combo_rna.var_names]\n",
    "#sc.pl.umap(combo_ft, color=umap_genes, frameon=False, size=20, alpha=0.65, ncols=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pl.umap(combo_ft, color=umap_genes, frameon=False, size=20, alpha=0.65, ncols=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pl.embedding(combo_ft, basis=f\"X_umap_univi_ft\", color=[\"celltype_pred\"], frameon=False, size=2,\n",
    "#                title=[f\"Reference vs unimodal by harmonized coarse celltype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccc269",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(combo_ft, basis=f\"X_umap_univi_ft\", color=[\"modality\"], frameon=False, size=3, alpha=0.65,\n",
    "                title=[f\"Reference vs unimodal by harmonized coarse celltype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d5ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(combo_ft, basis=f\"X_umap_univi_ft\", color=[\"celltype_higher_res_pred\"], frameon=False, size=3, alpha=0.65,\n",
    "                title=[f\"Reference vs unimodal by harmonized celltype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61370b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(combo_ft, basis=f\"X_umap_univi_ft\", color=[\"dataset\"], frameon=False, size=3, alpha=0.65,\n",
    "                title=[f\"Reference vs unimodal by harmonized celltype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(combo_ft, basis=f\"X_umap_univi_ft\", color=[\"tech\"], frameon=False, size=3, alpha=0.3,\n",
    "                title=[f\"Reference vs unimodal by harmonized celltype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08745bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rna_multiome_pp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223643ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(rna_multiome_pp, basis=f\"X_umap\", color=[\"celltype_higher_res_conf\"], frameon=False, size=3, alpha=0.65,\n",
    "                title=[f\"Reference bridge data annotated by classification decoder head\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(rna_multiome_pp, basis=f\"X_umap\", color=[\"celltype_higher_res_pred\"], frameon=False, size=3, alpha=0.65,\n",
    "                title=[f\"Reference bridge data annotated by classification decoder head\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(atac_multiome_lsi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e66fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(atac_multiome_lsi, basis=f\"X_univi_ft\", color=[\"celltype_higher_res_pred\"], frameon=False, size=3, alpha=0.65,\n",
    "                title=[f\"Reference bridge data annotated by classification decoder head\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a2be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "from univi.evaluation import encode_adata\n",
    "\n",
    "# -----------------------------\n",
    "# Inputs you already have\n",
    "# -----------------------------\n",
    "# rna_multiome_pp : AnnData (RNA; preprocessed to match model input space)\n",
    "# atac_multiome_lsi : AnnData (ATAC; preprocessed LSI to match model input space)\n",
    "# model_cls : fine-tuned UniVI model (with head)\n",
    "# device : \"cuda\" / \"cpu\"\n",
    "#\n",
    "# And you said both already have head outputs in .obs, e.g.:\n",
    "#   obs[f\"{head_name}_pred\"], obs[f\"{head_name}_conf\"] etc.\n",
    "\n",
    "# -----------------------------\n",
    "# Settings\n",
    "# -----------------------------\n",
    "out_key = \"X_univi_ft_multiome\"   # where to store latent in .obsm\n",
    "latent_choice = \"moe_mean\"        # \"moe_mean\" (shared) or \"modality_mean\"\n",
    "head_name = \"celltype_higher_res\" # change if you used a different head name\n",
    "anno_key = f\"{head_name}_pred\"    # your predicted annotation column in .obs\n",
    "\n",
    "# -----------------------------\n",
    "# (1) Align cells if needed (paired multiome)\n",
    "# -----------------------------\n",
    "if not np.array_equal(rna_multiome_pp.obs_names, atac_multiome_lsi.obs_names):\n",
    "    common = rna_multiome_pp.obs_names.intersection(atac_multiome_lsi.obs_names)\n",
    "    rna_multiome_pp = rna_multiome_pp[common].copy()\n",
    "    atac_multiome_lsi = atac_multiome_lsi[common].copy()\n",
    "    atac_multiome_lsi = atac_multiome_lsi[rna_multiome_pp.obs_names].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# (2) Encode into latent with the fine-tuned model\n",
    "# -----------------------------\n",
    "model_cls.eval()\n",
    "\n",
    "Z_rna = encode_adata(\n",
    "    model_cls,\n",
    "    rna_multiome_pp,\n",
    "    modality=\"rna\",\n",
    "    latent=latent_choice,\n",
    "    device=device,\n",
    "    batch_size=1024,\n",
    ")\n",
    "rna_multiome_pp.obsm[out_key] = np.asarray(Z_rna, dtype=np.float32)\n",
    "\n",
    "Z_atac = encode_adata(\n",
    "    model_cls,\n",
    "    atac_multiome_lsi,\n",
    "    modality=\"atac\",\n",
    "    latent=latent_choice,\n",
    "    device=device,\n",
    "    batch_size=1024,\n",
    ")\n",
    "atac_multiome_lsi.obsm[out_key] = np.asarray(Z_atac, dtype=np.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# (3) Make a combined AnnData for UMAP\n",
    "# -----------------------------\n",
    "rna_plot = rna_multiome_pp.copy()\n",
    "atac_plot = atac_multiome_lsi.copy()\n",
    "\n",
    "rna_plot.obs[\"modality\"] = \"rna\"\n",
    "atac_plot.obs[\"modality\"] = \"atac\"\n",
    "\n",
    "# ensure the annotation column exists (optional safeguard)\n",
    "if anno_key not in rna_plot.obs.columns:\n",
    "    raise KeyError(f\"{anno_key!r} not found in rna_multiome_pp.obs\")\n",
    "if anno_key not in atac_plot.obs.columns:\n",
    "    raise KeyError(f\"{anno_key!r} not found in atac_multiome_lsi.obs\")\n",
    "\n",
    "combo = ad.concat(\n",
    "    {\"multiome_rna\": rna_plot, \"multiome_atac\": atac_plot},\n",
    "    axis=0,\n",
    "    join=\"outer\",\n",
    "    label=\"dataset\",\n",
    "    index_unique=None,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# (4) Neighbors + UMAP on new latent\n",
    "# -----------------------------\n",
    "sc.pp.neighbors(combo, n_neighbors=30, use_rep=out_key, metric=\"euclidean\")\n",
    "sc.tl.umap(combo, min_dist=0.3, spread=1.0)\n",
    "\n",
    "# -----------------------------\n",
    "# (5) Plot UMAP colored by new annotations (+ modality)\n",
    "# -----------------------------\n",
    "sc.pl.umap(combo, color=[\"modality\"], frameon=False, size=30, alpha=0.65, title=f\"Multiome ({latent_choice}) by modality\")\n",
    "sc.pl.umap(combo, color=[anno_key], frameon=False, size=30, alpha=0.65, title=f\"Multiome ({latent_choice}) by {anno_key}\")\n",
    "\n",
    "# optional: show confidence if you have it\n",
    "conf_key = f\"{head_name}_conf\"\n",
    "if conf_key in combo.obs.columns:\n",
    "    sc.pl.umap(combo, color=[conf_key], frameon=False, size=30, alpha=0.65, title=f\"Multiome ({latent_choice}) by {conf_key}\")\n",
    "\n",
    "# If you want the per-modality plots:\n",
    "sc.pl.umap(combo[combo.obs[\"modality\"] == \"rna\"],  color=[anno_key], frameon=False, size=30, alpha=0.65, title=f\"RNA only ({latent_choice})\")\n",
    "sc.pl.umap(combo[combo.obs[\"modality\"] == \"atac\"], color=[anno_key], frameon=False, size=30, alpha=0.65, title=f\"ATAC only ({latent_choice})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf214bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 3.1 Set plotting defaults\n",
    "# ------------------------------------------------\n",
    "\n",
    "sc.set_figure_params(\n",
    "    figsize=(10, 8),\n",
    "    dpi=100,\n",
    "    dpi_save=300,\n",
    "    fontsize=12,\n",
    "    frameon=False,\n",
    ")\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (10, 8),\n",
    "    \"figure.dpi\": 100,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"savefig.pad_inches\": 0.1,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combo_ft.obs['dataset'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977c25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# (6) Quick marker genes (RNA only) for your predicted cell types\n",
    "# -----------------------------\n",
    "'''\n",
    "marker_genes = {\n",
    "    \"B\": [\"MS4A1\", \"CD79A\", \"CD74\"],\n",
    "    \"CD4 T\": [\"IL7R\", \"CCR7\", \"LTB\"],\n",
    "    \"CD8/cytotoxic\": [\"NKG7\", \"GNLY\", \"GZMB\", \"PRF1\"],\n",
    "    \"NK\": [\"NKG7\", \"FCGR3A\", \"TRAC\"],   # TRAC sanity check that these are T/NK-like\n",
    "    \"Monocyte\": [\"LST1\", \"S100A8\", \"S100A9\", \"FCN1\", \"LYZ\"],\n",
    "    \"Dendritic\": [\"CLEC10A\"],  # LILRA4 more pDC-ish (if present)\n",
    "}\n",
    "'''\n",
    "'''\n",
    "marker_genes = {\n",
    "    \"B\": [\"MS4A1\", \"CD79A\", \"CD74\"],\n",
    "    \"CD4 T\": [\"IL7R\", \"CCR7\", \"LTB\", \"TRAC\"],      # T-lineage check\n",
    "    \"CD8/cytotoxic\": [\"NKG7\", \"GNLY\", \"GZMB\", \"PRF1\", \"TRAC\"],  # helps distinguish cytotoxic T vs NK\n",
    "    \"NK\": [\"NKG7\", \"FCGR3A\"],                      # NK markers only\n",
    "    \"TCR/CD3\": [\"TRAC\", \"CD3D\", \"CD3E\"],           # optional: best for “NK should be negative”\n",
    "    \"Monocyte\": [\"LST1\", \"S100A8\", \"S100A9\", \"FCN1\", \"LYZ\"],\n",
    "    \"Dendritic\": [\"CLEC10A\"],\n",
    "}\n",
    "'''\n",
    "'''\n",
    "marker_genes = {\n",
    "    # --- B cells (naive + memory + antigen presentation) ---\n",
    "    \"B\": [\n",
    "        \"MS4A1\", \"CD79A\", \"CD74\",\n",
    "        \"CD79B\", \"HLA-DRA\", \"HLA-DPA1\", \"HLA-DPB1\",\n",
    "        \"CD22\", \"CD19\",\n",
    "        \"BANK1\", \"CD83\"\n",
    "    ],\n",
    "\n",
    "    # --- CD4 T (naive/central memory leaning) ---\n",
    "    \"CD4 T\": [\n",
    "        \"IL7R\", \"CCR7\", \"LTB\", \"TRAC\",\n",
    "        \"MAL\", \"TCF7\", \"LEF1\", \"LST1\",  # (remove LST1 if you want zero myeloid bleed)\n",
    "        \"TRBC1\", \"ICOS\", \"IL32\"\n",
    "    ],\n",
    "\n",
    "    # --- CD8 / cytotoxic program (overlaps NK on purpose) ---\n",
    "    \"CD8/cytotoxic\": [\n",
    "        \"NKG7\", \"GNLY\", \"GZMB\", \"PRF1\", \"TRAC\",\n",
    "        \"GZMK\", \"GZMH\", \"FGFBP2\",\n",
    "        \"CTSW\", \"KLRD1\", \"KLRB1\",\n",
    "        \"TRBC1\", \"CD8A\", \"CD8B\"\n",
    "    ],\n",
    "\n",
    "    # --- NK (TRAC-/CD3-; split CD56bright vs CD16+) ---\n",
    "    \"NK\": [\n",
    "        \"NKG7\", \"FCGR3A\",\n",
    "        \"KLRD1\", \"TRDC\",  # (drop TRDC if you don't want gamma-delta signal here)\n",
    "        \"TYROBP\", \"FCER1G\", \"XCL2\", \"KLRC1\", \"KLRC2\",\n",
    "        \"IL7R\"  # (optional; can highlight CD56bright-like NK if present)\n",
    "    ],\n",
    "\n",
    "    # --- TCR/CD3 lineage check (should be ~0 in true NK/mono) ---\n",
    "    \"TCR/CD3\": [\n",
    "        \"TRAC\", \"TRBC1\", \"TRBC2\",\n",
    "        \"CD247\", \"TRAT1\"\n",
    "    ],\n",
    "\n",
    "    # --- Monocytes (classical + non-classical) ---\n",
    "    \"Monocyte\": [\n",
    "        \"LST1\", \"S100A8\", \"S100A9\", \"FCN1\", \"LYZ\",\n",
    "        \"CTSS\", \"LGALS3\", \"MNDA\", \"TYROBP\",\n",
    "        \"MS4A7\", \"FCGR3A\", \"LILRB1\",\n",
    "        \"VCAN\", \"IFITM3\"\n",
    "    ],\n",
    "\n",
    "    # --- Dendritic (cDC2 + cDC1 + pDC coverage) ---\n",
    "    \"Dendritic\": [\n",
    "        \"CST3\", \"ITGAX\", \"CLEC10A\",\n",
    "        \"IL3RA\", \"GZMB\",                  # pDC-ish\n",
    "        \"IRF7\"                            # optional support depending on dataset\n",
    "    ],\n",
    "}\n",
    "'''\n",
    "\n",
    "marker_genes = {\n",
    "    \"B\": [\"MS4A1\", \"CD79A\", \"CD74\", \"CD37\", \"CD19\"],\n",
    "\n",
    "    \"CD4 T\": [\"IL7R\", \"CCR7\", \"LTB\", \"TCF7\", \"LEF1\"],\n",
    "\n",
    "    \"CD8/cytotoxic\": [\"CD8A\", \"NKG7\", \"GNLY\", \"GZMB\", \"PRF1\", \"FGFBP2\"],\n",
    "\n",
    "    \"NK\": [\"FCGR3A\", \"KLRD1\", \"TYROBP\", \"FCER1G\", \"XCL1\"],\n",
    "\n",
    "    \"TCR/CD3\": [\"TRAC\", \"TRBC1\", \"CD3D\", \"CD3E\", \"CD247\"],\n",
    "\n",
    "    \"Monocyte\": [\"LST1\", \"S100A8\", \"S100A9\", \"FCN1\", \"LYZ\", \"MS4A7\"],\n",
    "\n",
    "    \"Dendritic\": [\"FCER1A\", \"CLEC10A\", \"CST3\", \"ITGAX\", \"CLEC9A\", \"FCER1A\"],\n",
    "\n",
    "    # optional if you actually have pDC as a row:\n",
    "    \"pDC\": [\"IL3RA\", \"LILRA4\", \"GZMB\", \"IRF7\"],\n",
    "}\n",
    "\n",
    "# subset to RNA rows for gene expression plots\n",
    "combo_rna = combo[combo.obs[\"modality\"] == \"rna\"].copy()\n",
    "#combo_rna = combo_ft[combo_ft.obs['dataset'] == 'ding_rna'].copy()\n",
    "\n",
    "# keep only genes that actually exist\n",
    "flat = sorted({g for gs in marker_genes.values() for g in gs})\n",
    "present = [g for g in flat if g in combo_rna.var_names]\n",
    "missing = [g for g in flat if g not in combo_rna.var_names]\n",
    "print(f\"Marker genes present: {len(present)}/{len(flat)}\")\n",
    "if missing:\n",
    "    print(\"Missing markers (ok):\", missing)\n",
    "\n",
    "# (6a) UMAP overlays for a *small* set of markers (pick ~6–12 so it’s readable)\n",
    "#umap_genes = [g for g in [\"MS4A1\",\"CD79A\",\"IL7R\",\"TRAC\",\"CD8A\",\"NKG7\",\"FCGR3A\",\"LST1\",\"S100A8\",\"LYZ\",\"FCER1A\",\"CLEC10A\"]\n",
    "# if g in combo_rna.var_names]\n",
    "#sc.pl.umap(combo_rna, color=umap_genes, frameon=False, size=20, alpha=0.65, ncols=2)\n",
    "\n",
    "# (6b) Dotplot by predicted labels (clean “what’s activating in each class” view)\n",
    "'''\n",
    "sc.pl.dotplot(\n",
    "    combo_rna,\n",
    "    var_names=marker_genes,      # dict -> grouped gene panels\n",
    "    groupby=anno_key,\n",
    "    standard_scale=\"var\",        # z-score genes for comparability\n",
    "    dot_min=0.0,\n",
    "    dot_max=0.7,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6a) UMAP overlays for a *small* set of markers (pick ~6–12 so it’s readable)\n",
    "umap_genes = [g for g in [\"MS4A1\",\"CD79A\",\"IL7R\",\"TRAC\",\"CD8A\",\"NKG7\",\"FCGR3A\",\"LST1\",\"S100A8\",\"LYZ\",\"FCER1A\",\"CLEC10A\"]\n",
    " if g in combo_rna.var_names]\n",
    "sc.pl.umap(combo_rna, color=umap_genes, frameon=False, size=20, alpha=0.65, ncols=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838701fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(combo_rna, color=\"celltype_harmonized\", frameon=False, size=3, alpha=0.65, ncols=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(combo_rna, color=\"tech\", frameon=False, size=3, alpha=0.65, ncols=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# pick an order that matches your marker panels left→right\n",
    "desired_order = [\n",
    "    \"B\",\n",
    "    \"CD4 T\", \"Naive CD4 T\", \"Memory CD4 T\", \"CD4 T helper\", \"Regulatory T\",\n",
    "    \"Cytotoxic T\", \"Memory CD8 T\", \"Naive CD8 T\",   # or your exact CD8 label\n",
    "    \"NK\",\n",
    "    \"CD14+ monocyte\", \"CD16+ monocyte\", \"Monocyte\",\n",
    "    \"Dendritic cell\", \"Plasmacytoid dendritic cell\",\n",
    "]\n",
    "\n",
    "# keep only labels that exist, append leftovers at the end\n",
    "present = combo_rna.obs[anno_key].astype(str).unique().tolist()\n",
    "cats = [c for c in desired_order if c in present] + [c for c in present if c not in desired_order]\n",
    "\n",
    "combo_rna.obs[anno_key] = pd.Categorical(combo_rna.obs[anno_key].astype(str), categories=cats, ordered=True)\n",
    "\n",
    "# (important) filter marker dict so dotplot doesn't choke on missing genes\n",
    "marker_genes_filt = {\n",
    "    ct: [g for g in genes if g in combo_rna.var_names]\n",
    "    for ct, genes in marker_genes.items()\n",
    "}\n",
    "marker_genes_filt = {ct: genes for ct, genes in marker_genes_filt.items() if len(genes) > 0}\n",
    "\n",
    "sc.pl.dotplot(\n",
    "    combo_rna,\n",
    "    var_names=marker_genes_filt,\n",
    "    groupby=anno_key,\n",
    "    categories_order=cats,     # <- forces y-axis order\n",
    "    standard_scale=\"var\",\n",
    "    dot_min=0.0,\n",
    "    dot_max=1.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6c) Optional: gene-set scores per lineage and visualize as violin (less noisy)\n",
    "for ct, genes in marker_genes.items():\n",
    "    g = [x for x in genes if x in combo_rna.var_names]\n",
    "    if len(g) >= 2:\n",
    "        sc.tl.score_genes(combo_rna, g, score_name=f\"score_{ct}\")\n",
    "\n",
    "score_cols = [c for c in combo_rna.obs.columns if c.startswith(\"score_\")]\n",
    "sc.pl.violin(combo_rna, keys=score_cols, groupby=anno_key, stripplot=False, rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e9cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e039e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1af2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba68935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a174bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9138ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ecdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6e5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f93b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (UniVI v0.2.3)",
   "language": "python",
   "name": "univi_v0.2.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
