{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11c6bb1",
   "metadata": {},
   "source": [
    "# Benchmarking UniVI using CITE-seq data\n",
    "\n",
    "Andrew Ashford, Pathways + Omics Group, Oregon Health & Science University - 11/18/2025\n",
    "\n",
    "This Jupyter Notebook will be used to benchmark UniVI models trained using Hao CITE-seq human PBMC data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f6c995",
   "metadata": {},
   "source": [
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215048e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Imports\n",
    "import os, sys, json\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import torch\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from univi import (\n",
    "    UniVIMultiModalVAE,\n",
    "    ModalityConfig,\n",
    "    UniVIConfig,\n",
    "    TrainingConfig,\n",
    "    matching,\n",
    ")\n",
    "from univi.data import MultiModalDataset\n",
    "from univi.trainer import UniVITrainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a044032",
   "metadata": {},
   "source": [
    "#### Read in and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18669fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/precepts/ashforda/anaconda3/envs/UniVI_working_environment_v2/lib/python3.8/site-packages/anndata/compat/__init__.py:229: FutureWarning: Moving element from .uns['neighbors']['distances'] to .obsp['distances'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 1. Load AnnData objects\n",
    "# -------------------------\n",
    "# Load RNA AnnData object\n",
    "rna_adata = sc.read_h5ad(\"../data/Hao_CITE-seq_data/Hao_RNA_data.h5ad\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3970a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the RNA counts to raw counts so they're not log-normalized and use ZINB or NB as the decoder distribution\n",
    "# for model training\n",
    "rna_adata.layers['log1p'] = rna_adata.X\n",
    "rna_adata.X = rna_adata.raw.X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848f1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your counts are in rna_adata.X (raw or log-normalized), this is fine:\n",
    "sc.pp.highly_variable_genes(\n",
    "    rna_adata,\n",
    "    layer='log1p',\n",
    "    n_top_genes=2000,\n",
    "    flavor=\"seurat\",   # or \"cell_ranger\" / \"seurat_v3\"\n",
    "    inplace=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64bb883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2000 highly variable genes.\n",
      "['HES4', 'ISG15', 'TNFRSF18', 'TNFRSF4', 'RBP7', 'EPHA2', 'PADI4', 'CDA', 'EIF4G3', 'AL031005.1', 'C1QA', 'C1QC', 'C1QB', 'TCEA3', 'ID3', 'RCAN3', 'LDLRAP1', 'STMN1', 'ZNF683', 'IFI6']\n"
     ]
    }
   ],
   "source": [
    "# Boolean mask of HVGs\n",
    "hvg_mask = rna_adata.var[\"highly_variable\"].values\n",
    "\n",
    "# Names of the top HVGs\n",
    "hvg_genes = rna_adata.var_names[hvg_mask].tolist()\n",
    "print(f\"Selected {len(hvg_genes)} highly variable genes.\")\n",
    "print(hvg_genes[:20])  # peek at first few\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0209e830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 161764 × 2000\n",
      "    obs: 'nCount_ADT', 'nFeature_ADT', 'nCount_RNA', 'nFeature_RNA', 'orig.ident', 'lane', 'donor', 'time', 'celltype.l1', 'celltype.l2', 'celltype.l3', 'Phase', 'nCount_SCT', 'nFeature_SCT'\n",
      "    var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
      "    uns: 'neighbors', 'hvg'\n",
      "    obsm: 'X_apca', 'X_aumap', 'X_pca', 'X_spca', 'X_umap', 'X_wnn.umap'\n",
      "    varm: 'PCs', 'SPCA'\n",
      "    layers: 'log1p'\n",
      "    obsp: 'distances'\n"
     ]
    }
   ],
   "source": [
    "# Optional: make a HVG-only AnnData for modeling\n",
    "rna_adata_hvg = rna_adata[:, hvg_mask].copy()\n",
    "print(rna_adata_hvg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0102e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ADT AnnData object\n",
    "adt_adata = sc.read_h5ad(\"../data/Hao_CITE-seq_data/Hao_ADT_data.h5ad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f966713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ADT data to raw counts and use a NB or ZINB decoder in model training and save the current .X counts to\n",
    "# .layers['log1p']\n",
    "adt_adata.layers['log1p'] = adt_adata.X\n",
    "adt_adata.X = adt_adata.raw.X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e837d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "\n",
    "def get_X_values(adata, n_cells: int = 5000):\n",
    "    \"\"\"\n",
    "    Return flattened values from adata.X (optionally subsampled over cells).\n",
    "    Uses only non-zero entries if X is sparse.\n",
    "    \"\"\"\n",
    "    X = adata.X\n",
    "\n",
    "    # Optional subsampling over cells (rows)\n",
    "    if n_cells is not None and adata.n_obs > n_cells:\n",
    "        idx = np.random.choice(adata.n_obs, size=n_cells, replace=False)\n",
    "        X = X[idx]\n",
    "\n",
    "    if sparse.issparse(X):\n",
    "        vals = X.data  # nonzero values\n",
    "    else:\n",
    "        vals = np.asarray(X).ravel()\n",
    "\n",
    "    # Remove zeros explicitly (just to focus on count/ADT magnitude)\n",
    "    vals = vals[vals > 0]\n",
    "    return vals\n",
    "\n",
    "def plot_X_distribution(rna_adata, adt_adata, n_cells: int = 5000):\n",
    "    rna_vals = get_X_values(rna_adata, n_cells=n_cells)\n",
    "    adt_vals = get_X_values(adt_adata, n_cells=n_cells)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # --- RNA raw ---\n",
    "    axes[0, 0].hist(rna_vals, bins=100, alpha=0.8)\n",
    "    axes[0, 0].set_title(\"RNA .X nonzero values (raw)\")\n",
    "    axes[0, 0].set_xlabel(\"Value\")\n",
    "    axes[0, 0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    # --- RNA log10 ---\n",
    "    axes[0, 1].hist(np.log10(rna_vals + 1e-8), bins=100, alpha=0.8)\n",
    "    axes[0, 1].set_title(\"RNA .X nonzero values (log10)\")\n",
    "    axes[0, 1].set_xlabel(\"log10(value)\")\n",
    "    axes[0, 1].set_ylabel(\"Frequency\")\n",
    "\n",
    "    # --- ADT raw ---\n",
    "    axes[1, 0].hist(adt_vals, bins=100, alpha=0.8)\n",
    "    axes[1, 0].set_title(\"ADT .X nonzero values (raw)\")\n",
    "    axes[1, 0].set_xlabel(\"Value\")\n",
    "    axes[1, 0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    # --- ADT log10 ---\n",
    "    axes[1, 1].hist(np.log10(adt_vals + 1e-8), bins=100, alpha=0.8)\n",
    "    axes[1, 1].set_title(\"ADT .X nonzero values (log10)\")\n",
    "    axes[1, 1].set_xlabel(\"log10(value)\")\n",
    "    axes[1, 1].set_ylabel(\"Frequency\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call it:\n",
    "plot_X_distribution(rna_adata_hvg, adt_adata, n_cells=50000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "415c14cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 161764 × 2000\n",
      "    obs: 'nCount_ADT', 'nFeature_ADT', 'nCount_RNA', 'nFeature_RNA', 'orig.ident', 'lane', 'donor', 'time', 'celltype.l1', 'celltype.l2', 'celltype.l3', 'Phase', 'nCount_SCT', 'nFeature_SCT'\n",
      "    var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
      "    uns: 'neighbors', 'hvg'\n",
      "    obsm: 'X_apca', 'X_aumap', 'X_pca', 'X_spca', 'X_umap', 'X_wnn.umap'\n",
      "    varm: 'PCs', 'SPCA'\n",
      "    layers: 'log1p'\n",
      "    obsp: 'distances'\n",
      "{'DC', 'other T', 'CD8 T', 'Mono', 'CD4 T', 'B', 'other', 'NK'}\n",
      "Mono       49010\n",
      "CD4 T      41001\n",
      "CD8 T      25469\n",
      "NK         18664\n",
      "B          13800\n",
      "other T     6789\n",
      "DC          3589\n",
      "other       3442\n",
      "Name: celltype.l1, dtype: int64\n",
      "{'NK_CD56bright', 'Plasmablast', 'Platelet', 'gdT', 'B memory', 'CD4 CTL', 'B intermediate', 'Treg', 'Eryth', 'CD4 TCM', 'ASDC', 'CD8 TEM', 'HSPC', 'CD8 Proliferating', 'CD8 TCM', 'pDC', 'CD4 Naive', 'CD4 Proliferating', 'CD8 Naive', 'CD16 Mono', 'NK Proliferating', 'cDC1', 'cDC2', 'CD4 TEM', 'B naive', 'NK', 'dnT', 'ILC', 'CD14 Mono', 'MAIT', 'Doublet'}\n",
      "CD14 Mono            42690\n",
      "CD4 Naive            17479\n",
      "NK                   17173\n",
      "CD4 TCM              14889\n",
      "CD8 TEM              11727\n",
      "CD8 Naive            10768\n",
      "B naive               7718\n",
      "CD16 Mono             6320\n",
      "CD4 TEM               4282\n",
      "gdT                   3649\n",
      "B memory              3285\n",
      "CD8 TCM               2883\n",
      "MAIT                  2784\n",
      "Treg                  2507\n",
      "cDC2                  2501\n",
      "B intermediate        2431\n",
      "Platelet              2293\n",
      "CD4 CTL               1736\n",
      "NK_CD56bright          943\n",
      "pDC                    861\n",
      "Doublet                605\n",
      "NK Proliferating       548\n",
      "Plasmablast            366\n",
      "dnT                    356\n",
      "HSPC                   329\n",
      "cDC1                   151\n",
      "ILC                    132\n",
      "CD4 Proliferating      108\n",
      "CD8 Proliferating       91\n",
      "Eryth                   83\n",
      "ASDC                    76\n",
      "Name: celltype.l2, dtype: int64\n",
      "{'gdT_4', 'Treg Memory', 'CD8 Naive_2', 'NK_CD56bright', 'NK_4', 'dnT_1', 'Plasmablast', 'NK_3', 'ASDC_mDC', 'Platelet', 'CD8 TEM_6', 'B naive kappa', 'CD4 TCM_1', 'CD8 TEM_5', 'cDC2_2', 'CD4 CTL', 'Eryth', 'CD4 TEM_3', 'B memory lambda', 'cDC2_1', 'gdT_2', 'CD8 TEM_4', 'HSPC', 'CD8 Proliferating', 'CD4 TCM_2', 'CD4 Naive', 'pDC', 'CD4 Proliferating', 'dnT_2', 'CD4 TEM_1', 'CD4 TEM_2', 'gdT_3', 'CD8 Naive', 'CD16 Mono', 'B memory kappa', 'NK_2', 'NK Proliferating', 'cDC1', 'B intermediate kappa', 'B intermediate lambda', 'B naive lambda', 'CD8 TCM_1', 'CD8 TCM_2', 'gdT_1', 'CD4 TEM_4', 'CD8 TEM_3', 'CD14 Mono', 'CD8 TEM_1', 'NK_1', 'ILC', 'Treg Naive', 'Plasma', 'MAIT', 'Doublet', 'CD4 TCM_3', 'CD8 TCM_3', 'ASDC_pDC', 'CD8 TEM_2'}\n",
      "CD14 Mono                42690\n",
      "CD4 Naive                17479\n",
      "CD8 Naive                10478\n",
      "NK_2                      9418\n",
      "CD4 TCM_1                 8141\n",
      "CD16 Mono                 6320\n",
      "CD4 TCM_3                 6155\n",
      "B naive kappa             4852\n",
      "NK_1                      4126\n",
      "CD8 TEM_4                 3504\n",
      "B naive lambda            2866\n",
      "CD8 TEM_1                 2786\n",
      "MAIT                      2784\n",
      "CD8 TEM_2                 2435\n",
      "Platelet                  2293\n",
      "NK_3                      2152\n",
      "CD4 TEM_3                 2044\n",
      "B memory kappa            2037\n",
      "CD8 TEM_5                 1973\n",
      "CD4 CTL                   1736\n",
      "cDC2_2                    1729\n",
      "CD4 TEM_1                 1706\n",
      "gdT_1                     1633\n",
      "NK_4                      1477\n",
      "B intermediate lambda     1331\n",
      "CD8 TCM_2                 1322\n",
      "Treg Naive                1295\n",
      "B memory lambda           1248\n",
      "Treg Memory               1212\n",
      "B intermediate kappa      1100\n",
      "NK_CD56bright              943\n",
      "CD8 TCM_1                  929\n",
      "pDC                        861\n",
      "cDC2_1                     772\n",
      "gdT_2                      769\n",
      "gdT_3                      724\n",
      "CD8 TEM_6                  636\n",
      "CD8 TCM_3                  632\n",
      "Doublet                    605\n",
      "CD4 TCM_2                  593\n",
      "NK Proliferating           548\n",
      "gdT_4                      523\n",
      "CD4 TEM_2                  452\n",
      "CD8 TEM_3                  393\n",
      "HSPC                       329\n",
      "Plasma                     318\n",
      "CD8 Naive_2                290\n",
      "dnT_1                      189\n",
      "dnT_2                      167\n",
      "cDC1                       151\n",
      "ILC                        132\n",
      "CD4 Proliferating          108\n",
      "CD8 Proliferating           91\n",
      "Eryth                       83\n",
      "CD4 TEM_4                   80\n",
      "Plasmablast                 48\n",
      "ASDC_mDC                    40\n",
      "ASDC_pDC                    36\n",
      "Name: celltype.l3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rna_adata_hvg)\n",
    "print(set(rna_adata_hvg.obs['celltype.l1']))\n",
    "print(rna_adata_hvg.obs['celltype.l1'].value_counts())\n",
    "print(set(rna_adata_hvg.obs['celltype.l2']))\n",
    "print(rna_adata_hvg.obs['celltype.l2'].value_counts())\n",
    "print(set(rna_adata_hvg.obs['celltype.l3']))\n",
    "print(rna_adata_hvg.obs['celltype.l3'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1e3e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc7d0b",
   "metadata": {},
   "source": [
    "#### Specify any additional helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a79bd959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_univi_model(\n",
    "    rna_adata_hvg,\n",
    "    adt_adata,\n",
    "    train_cfg,\n",
    "    likelihood_rna=\"nb\",\n",
    "    likelihood_adt=\"zinb\",\n",
    "    seed=0,\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    modality_cfgs = [\n",
    "        ModalityConfig(\n",
    "            name=\"rna\",\n",
    "            input_dim=rna_adata_hvg.n_vars,\n",
    "            encoder_hidden=[512, 256],\n",
    "            decoder_hidden=[256, 512],\n",
    "            likelihood=likelihood_rna,\n",
    "        ),\n",
    "        ModalityConfig(\n",
    "            name=\"adt\",\n",
    "            input_dim=adt_adata.n_vars,\n",
    "            encoder_hidden=[128, 64],\n",
    "            decoder_hidden=[64, 128],\n",
    "            likelihood=likelihood_adt,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    univi_cfg = UniVIConfig(\n",
    "        latent_dim=40,\n",
    "        modalities=modality_cfgs,\n",
    "        beta=80.0,\n",
    "        gamma=120.0,\n",
    "        encoder_dropout=0.0,\n",
    "        encoder_batchnorm=True,\n",
    "        decoder_dropout=0.0,\n",
    "        decoder_batchnorm=False,\n",
    "        kl_anneal_start=0,\n",
    "        kl_anneal_end=0,\n",
    "        align_anneal_start=0,\n",
    "        align_anneal_end=0,\n",
    "    )\n",
    "\n",
    "    model = UniVIMultiModalVAE(univi_cfg).to(train_cfg.device)\n",
    "\n",
    "    trainer = UniVITrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,  # from your earlier split code\n",
    "        val_loader=val_loader,\n",
    "        train_cfg=train_cfg,\n",
    "        device=train_cfg.device,\n",
    "    )\n",
    "\n",
    "    history = trainer.fit()\n",
    "    return model, trainer, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e954770a",
   "metadata": {},
   "source": [
    "#### Load data with data loaders for training/validation/test/unused sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "872945f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9847e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg = TrainingConfig(\n",
    "    n_epochs=200,\n",
    "    batch_size=512,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    device=device,\n",
    "    log_every=10,\n",
    "    grad_clip=5.0,\n",
    "    num_workers=4,\n",
    "    seed=42,\n",
    "    early_stopping=True,\n",
    "    patience=20,\n",
    "    min_delta=0.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e962ab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paired cells BEFORE subsampling: 161764\n",
      "Total paired cells AFTER per-celltype cap: 22649\n",
      "Train: 18119, Val: 2264, Test: 2266\n",
      "RNA split sizes: {'train': 18119, 'val': 2264, 'test': 2266, 'unused': 139115}\n",
      "ADT split sizes: {'train': 18119, 'val': 2264, 'test': 2266, 'unused': 139115}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from univi.data import MultiModalDataset\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 0. Sanity check: RNA / ADT are already aligned\n",
    "# --------------------------------------------------\n",
    "assert rna_adata_hvg.n_obs == adt_adata.n_obs, \"RNA and ADT have different #cells\"\n",
    "assert np.array_equal(rna_adata_hvg.obs_names, adt_adata.obs_names), (\n",
    "    \"RNA and ADT obs_names are not aligned – align them first.\"\n",
    ")\n",
    "\n",
    "print(f\"Total paired cells BEFORE subsampling: {rna_adata_hvg.n_obs}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Per-celltype subsampling for balance\n",
    "# --------------------------------------------------\n",
    "celltype_key = \"celltype.l2\"\n",
    "max_per_type = 1000\n",
    "\n",
    "labels = rna_adata_hvg.obs[celltype_key].astype(str).values\n",
    "unique_ct = np.unique(labels)\n",
    "\n",
    "rng = np.random.default_rng(train_cfg.seed)\n",
    "\n",
    "selected_indices_list = []\n",
    "for ct in unique_ct:\n",
    "    idx_ct = np.where(labels == ct)[0]\n",
    "    if len(idx_ct) == 0:\n",
    "        continue\n",
    "    if len(idx_ct) > max_per_type:\n",
    "        chosen = rng.choice(idx_ct, size=max_per_type, replace=False)\n",
    "    else:\n",
    "        chosen = idx_ct\n",
    "    selected_indices_list.append(chosen)\n",
    "\n",
    "selected_indices = np.concatenate(selected_indices_list)\n",
    "rng.shuffle(selected_indices)\n",
    "\n",
    "n_cells = len(selected_indices)\n",
    "print(f\"Total paired cells AFTER per-celltype cap: {n_cells}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Build MultiModalDataset (full, indices will subset)\n",
    "# --------------------------------------------------\n",
    "adata_by_mod = {\"rna\": rna_adata_hvg, \"adt\": adt_adata}\n",
    "\n",
    "full_dataset = MultiModalDataset(\n",
    "    adata_dict=adata_by_mod,\n",
    "    X_key=\"X\",                # or your desired layer/key\n",
    "    device=train_cfg.device,\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Train / val / test splits on selected_indices\n",
    "# --------------------------------------------------\n",
    "frac_train = 0.8\n",
    "frac_val   = 0.1\n",
    "\n",
    "n_train = int(frac_train * n_cells)\n",
    "n_val   = int(frac_val   * n_cells)\n",
    "\n",
    "train_idx = selected_indices[:n_train]\n",
    "val_idx   = selected_indices[n_train:n_train + n_val]\n",
    "test_idx  = selected_indices[n_train + n_val:]\n",
    "\n",
    "print(f\"Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "val_dataset   = Subset(full_dataset, val_idx)\n",
    "test_dataset  = Subset(full_dataset, test_idx)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=train_cfg.num_workers,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=train_cfg.num_workers,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=train_cfg.num_workers,\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Mark splits + unused cells for later reference\n",
    "# --------------------------------------------------\n",
    "def init_split_column(adata, col=\"univi_split\"):\n",
    "    if col not in adata.obs.columns:\n",
    "        adata.obs[col] = \"unused\"\n",
    "\n",
    "init_split_column(rna_adata, \"univi_split\")\n",
    "init_split_column(adt_adata, \"univi_split\")\n",
    "\n",
    "# start everything as unused\n",
    "rna_adata.obs[\"univi_split\"] = \"unused\"\n",
    "adt_adata.obs[\"univi_split\"] = \"unused\"\n",
    "\n",
    "# mark train / val / test\n",
    "rna_adata.obs.iloc[train_idx, rna_adata.obs.columns.get_loc(\"univi_split\")] = \"train\"\n",
    "rna_adata.obs.iloc[val_idx,   rna_adata.obs.columns.get_loc(\"univi_split\")] = \"val\"\n",
    "rna_adata.obs.iloc[test_idx,  rna_adata.obs.columns.get_loc(\"univi_split\")] = \"test\"\n",
    "\n",
    "adt_adata.obs.iloc[train_idx, adt_adata.obs.columns.get_loc(\"univi_split\")] = \"train\"\n",
    "adt_adata.obs.iloc[val_idx,   adt_adata.obs.columns.get_loc(\"univi_split\")] = \"val\"\n",
    "adt_adata.obs.iloc[test_idx,  adt_adata.obs.columns.get_loc(\"univi_split\")] = \"test\"\n",
    "\n",
    "rna_train_adata = rna_adata[rna_adata.obs[\"univi_split\"] == \"train\"].copy()\n",
    "rna_val_adata   = rna_adata[rna_adata.obs[\"univi_split\"] == \"val\"].copy()\n",
    "rna_test_adata  = rna_adata[rna_adata.obs[\"univi_split\"] == \"test\"].copy()\n",
    "rna_unused      = rna_adata[rna_adata.obs[\"univi_split\"] == \"unused\"].copy()\n",
    "\n",
    "adt_train_adata = adt_adata[adt_adata.obs[\"univi_split\"] == \"train\"].copy()\n",
    "adt_val_adata   = adt_adata[adt_adata.obs[\"univi_split\"] == \"val\"].copy()\n",
    "adt_test_adata  = adt_adata[adt_adata.obs[\"univi_split\"] == \"test\"].copy()\n",
    "adt_unused      = adt_adata[adt_adata.obs[\"univi_split\"] == \"unused\"].copy()\n",
    "\n",
    "print(\n",
    "    \"RNA split sizes:\",\n",
    "    {k: v.n_obs for k, v in dict(\n",
    "        train=rna_train_adata,\n",
    "        val=rna_val_adata,\n",
    "        test=rna_test_adata,\n",
    "        unused=rna_unused,\n",
    "    ).items()},\n",
    ")\n",
    "print(\n",
    "    \"ADT split sizes:\",\n",
    "    {k: v.n_obs for k, v in dict(\n",
    "        train=adt_train_adata,\n",
    "        val=adt_val_adata,\n",
    "        test=adt_test_adata,\n",
    "        unused=adt_unused,\n",
    "    ).items()},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a0b161",
   "metadata": {},
   "source": [
    "#### Set up model configs/loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c77ea2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training UniVI (gaussian) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-18 17:46:22,241] [UniVITrainer] [INFO] TrainingConfig:\n",
      "[2025-11-18 17:46:22,257] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "[2025-11-18 17:46:22,257] [UniVITrainer] [INFO]   batch_size: 512\n",
      "[2025-11-18 17:46:22,258] [UniVITrainer] [INFO]   lr: 0.001\n",
      "[2025-11-18 17:46:22,258] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "[2025-11-18 17:46:22,259] [UniVITrainer] [INFO]   device: cpu\n",
      "[2025-11-18 17:46:22,260] [UniVITrainer] [INFO]   log_every: 10\n",
      "[2025-11-18 17:46:22,260] [UniVITrainer] [INFO]   grad_clip: 5.0\n",
      "[2025-11-18 17:46:22,261] [UniVITrainer] [INFO]   num_workers: 4\n",
      "[2025-11-18 17:46:22,261] [UniVITrainer] [INFO]   seed: 42\n",
      "[2025-11-18 17:46:22,262] [UniVITrainer] [INFO]   early_stopping: True\n",
      "[2025-11-18 17:46:22,263] [UniVITrainer] [INFO]   patience: 20\n",
      "[2025-11-18 17:46:22,263] [UniVITrainer] [INFO]   min_delta: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9c2545230741acaea29e10e18d1bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-18 17:53:31,661] [UniVITrainer] [INFO] [Epoch 001] Train loss: 4533699.8611 (beta=80.000, gamma=120.000)\n",
      "[2025-11-18 17:54:02,777] [UniVITrainer] [INFO] [Epoch 001] Val loss: 3999420.2500 (beta=80.000, gamma=120.000)\n",
      "[2025-11-18 17:54:02,840] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 3999420.2500\n",
      "[2025-11-18 18:03:31,221] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 3026773.4000\n",
      "[2025-11-18 18:11:22,318] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 2451629.8500\n",
      "[2025-11-18 18:19:56,827] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 2345326.5500\n",
      "[2025-11-18 18:28:02,917] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 2255746.3250\n",
      "[2025-11-18 18:37:23,969] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 1919575.1500\n",
      "[2025-11-18 18:46:32,464] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 1565593.9250\n",
      "[2025-11-18 18:54:56,966] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 1420966.7750\n",
      "[2025-11-18 19:03:08,443] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 1362760.2500\n",
      "[2025-11-18 19:05:02,698] [UniVITrainer] [INFO] [Epoch 010] Train loss: 1826898.0556 (beta=80.000, gamma=120.000)\n",
      "[2025-11-18 19:05:35,406] [UniVITrainer] [INFO] [Epoch 010] Val loss: 1298843.2000 (beta=80.000, gamma=120.000)\n",
      "[2025-11-18 19:05:35,602] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 1298843.2000\n",
      "[2025-11-18 19:14:28,495] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 1216914.1875\n",
      "[2025-11-18 19:22:24,106] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 1146625.4875\n",
      "[2025-11-18 19:29:15,566] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 1100668.9750\n",
      "[2025-11-18 19:37:51,826] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 1051082.6000\n",
      "[2025-11-18 19:46:42,935] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 1003972.1000\n",
      "[2025-11-18 19:55:33,665] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 927935.9250\n",
      "[2025-11-18 20:03:52,198] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 816180.7000\n",
      "[2025-11-18 20:12:08,530] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 729867.6562\n",
      "[2025-11-18 20:21:36,865] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 678265.0875\n",
      "[2025-11-18 20:29:35,763] [UniVITrainer] [INFO] [Epoch 020] Train loss: 1161871.3863 (beta=80.000, gamma=120.000)\n",
      "[2025-11-18 20:30:04,010] [UniVITrainer] [INFO] [Epoch 020] Val loss: 651095.4750 (beta=80.000, gamma=120.000)\n",
      "[2025-11-18 20:30:04,130] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 651095.4750\n",
      "[2025-11-18 20:39:41,678] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 625943.2438\n",
      "[2025-11-18 20:47:47,162] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 607085.8812\n",
      "[2025-11-18 20:51:44,943] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 589664.2812\n",
      "[2025-11-18 21:01:03,566] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 587150.1937\n",
      "[2025-11-18 21:09:40,134] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 574503.1813\n",
      "[2025-11-18 21:18:26,100] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 561428.6188\n",
      "[2025-11-18 21:27:05,623] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 547460.1375\n",
      "[2025-11-18 21:35:53,028] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 532383.7812\n",
      "[2025-11-18 21:45:59,176] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 481166.8000\n",
      "[2025-11-18 21:54:52,944] [UniVITrainer] [INFO] [Epoch 030] Train loss: 765842.1458 (beta=80.000, gamma=120.000)\n",
      "[2025-11-18 21:55:25,115] [UniVITrainer] [INFO] [Epoch 030] Val loss: 439447.3187 (beta=80.000, gamma=120.000)\n",
      "[2025-11-18 21:55:25,254] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 439447.3187\n",
      "[2025-11-18 22:04:56,675] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 405100.0125\n",
      "[2025-11-18 22:10:31,214] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 398927.7375\n",
      "[2025-11-18 22:14:19,630] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 358574.0938\n",
      "[2025-11-18 22:17:54,427] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 340597.9000\n",
      "[2025-11-18 22:22:14,970] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 339513.8000\n",
      "[2025-11-18 22:28:43,883] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 331724.0438\n",
      "[2025-11-18 22:38:41,898] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 324907.3875\n",
      "[2025-11-18 22:47:05,364] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 319000.4250\n",
      "[2025-11-18 23:04:24,960] [UniVITrainer] [INFO] [Epoch 040] Train loss: 447228.8624 (beta=80.000, gamma=120.000)\n",
      "[2025-11-18 23:04:54,275] [UniVITrainer] [INFO] [Epoch 040] Val loss: 309529.4125 (beta=80.000, gamma=120.000)\n",
      "[2025-11-18 23:04:54,361] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 309529.4125\n",
      "[2025-11-18 23:14:00,793] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 303373.5812\n",
      "[2025-11-18 23:31:23,351] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 298730.9344\n",
      "[2025-11-18 23:40:26,740] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 293920.7125\n",
      "[2025-11-18 23:57:36,870] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 292094.7969\n",
      "[2025-11-19 00:06:55,558] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 286438.2812\n",
      "[2025-11-19 00:24:15,520] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 284124.7250\n",
      "[2025-11-19 00:33:04,325] [UniVITrainer] [INFO] [Epoch 050] Train loss: 417107.5169 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 00:33:32,831] [UniVITrainer] [INFO] [Epoch 050] Val loss: 274071.6656 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 00:33:32,937] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 274071.6656\n",
      "[2025-11-19 00:41:30,439] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 270992.5375\n",
      "[2025-11-19 00:47:57,273] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 270843.9875\n",
      "[2025-11-19 00:52:17,004] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 259343.5938\n",
      "[2025-11-19 01:04:50,053] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 252445.9406\n",
      "[2025-11-19 01:07:02,206] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 251756.2875\n",
      "[2025-11-19 01:10:36,327] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 246846.6094\n",
      "[2025-11-19 01:15:24,615] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 240270.1000\n",
      "[2025-11-19 01:20:09,192] [UniVITrainer] [INFO] [Epoch 060] Train loss: 366669.3433 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 01:20:18,857] [UniVITrainer] [INFO] [Epoch 060] Val loss: 240957.8563 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 01:22:05,784] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 233347.0375\n",
      "[2025-11-19 01:27:02,520] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 226942.3844\n",
      "[2025-11-19 01:33:26,252] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 219348.5406\n",
      "[2025-11-19 01:37:38,208] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 216882.1437\n",
      "[2025-11-19 01:46:24,449] [UniVITrainer] [INFO] [Epoch 070] Train loss: 331282.5859 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 01:46:44,062] [UniVITrainer] [INFO] [Epoch 070] Val loss: 215938.0344 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 01:46:44,069] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 215938.0344\n",
      "[2025-11-19 01:50:44,496] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 201016.2469\n",
      "[2025-11-19 01:58:10,469] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 196797.7469\n",
      "[2025-11-19 02:01:48,975] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 195312.1969\n",
      "[2025-11-19 02:14:09,630] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 191760.2938\n",
      "[2025-11-19 02:17:44,558] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 191655.9438\n",
      "[2025-11-19 02:21:34,240] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 189603.7000\n",
      "[2025-11-19 02:25:04,860] [UniVITrainer] [INFO] [Epoch 080] Train loss: 314538.7144 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 02:25:10,557] [UniVITrainer] [INFO] [Epoch 080] Val loss: 190540.6531 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 02:31:27,002] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 188495.4625\n",
      "[2025-11-19 02:35:40,069] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 183567.1844\n",
      "[2025-11-19 02:48:25,152] [UniVITrainer] [INFO] [Epoch 086] New best val loss: 182447.7313\n",
      "[2025-11-19 02:51:52,132] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 181526.9969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 03:03:35,839] [UniVITrainer] [INFO] [Epoch 090] Train loss: 300385.8151 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 03:03:52,835] [UniVITrainer] [INFO] [Epoch 090] Val loss: 181361.7437 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 03:03:52,950] [UniVITrainer] [INFO] [Epoch 090] New best val loss: 181361.7437\n",
      "[2025-11-19 03:13:35,622] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 176863.6375\n",
      "[2025-11-19 03:25:26,194] [UniVITrainer] [INFO] [Epoch 095] New best val loss: 176575.5812\n",
      "[2025-11-19 03:29:11,450] [UniVITrainer] [INFO] [Epoch 096] New best val loss: 176306.2781\n",
      "[2025-11-19 03:42:09,742] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 173405.0719\n",
      "[2025-11-19 03:46:50,673] [UniVITrainer] [INFO] [Epoch 100] Train loss: 296530.9631 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 03:47:07,552] [UniVITrainer] [INFO] [Epoch 100] Val loss: 179567.0250 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 03:50:40,676] [UniVITrainer] [INFO] [Epoch 101] New best val loss: 172859.3438\n",
      "[2025-11-19 03:58:12,087] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 172334.5375\n",
      "[2025-11-19 04:06:35,485] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 168827.4031\n",
      "[2025-11-19 04:27:43,508] [UniVITrainer] [INFO] [Epoch 110] Train loss: 285045.6148 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 04:28:00,375] [UniVITrainer] [INFO] [Epoch 110] Val loss: 166101.0625 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 04:28:00,440] [UniVITrainer] [INFO] [Epoch 110] New best val loss: 166101.0625\n",
      "[2025-11-19 04:53:11,760] [UniVITrainer] [INFO] [Epoch 116] New best val loss: 162846.0594\n",
      "[2025-11-19 04:58:03,466] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 161881.9594\n",
      "[2025-11-19 05:10:21,428] [UniVITrainer] [INFO] [Epoch 120] Train loss: 274575.6068 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 05:10:43,184] [UniVITrainer] [INFO] [Epoch 120] Val loss: 169262.6000 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 05:30:54,352] [UniVITrainer] [INFO] [Epoch 125] New best val loss: 160589.5141\n",
      "[2025-11-19 05:34:22,079] [UniVITrainer] [INFO] [Epoch 126] New best val loss: 160471.9312\n",
      "[2025-11-19 05:39:05,661] [UniVITrainer] [INFO] [Epoch 127] New best val loss: 158298.5391\n",
      "[2025-11-19 05:44:13,214] [UniVITrainer] [INFO] [Epoch 130] Train loss: 267911.4382 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 05:44:26,687] [UniVITrainer] [INFO] [Epoch 130] Val loss: 160393.8719 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 05:50:55,223] [UniVITrainer] [INFO] [Epoch 134] New best val loss: 157468.1953\n",
      "[2025-11-19 05:53:03,612] [UniVITrainer] [INFO] [Epoch 135] New best val loss: 157395.5812\n",
      "[2025-11-19 05:55:49,107] [UniVITrainer] [INFO] [Epoch 137] New best val loss: 153932.9125\n",
      "[2025-11-19 05:59:25,314] [UniVITrainer] [INFO] [Epoch 140] Train loss: 261761.2784 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 05:59:28,341] [UniVITrainer] [INFO] [Epoch 140] Val loss: 154983.5156 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:01:18,031] [UniVITrainer] [INFO] [Epoch 144] New best val loss: 153532.0703\n",
      "[2025-11-19 06:02:12,955] [UniVITrainer] [INFO] [Epoch 146] New best val loss: 150944.2656\n",
      "[2025-11-19 06:02:40,377] [UniVITrainer] [INFO] [Epoch 147] New best val loss: 150772.8906\n",
      "[2025-11-19 06:03:35,711] [UniVITrainer] [INFO] [Epoch 149] New best val loss: 149018.9797\n",
      "[2025-11-19 06:04:00,314] [UniVITrainer] [INFO] [Epoch 150] Train loss: 253121.8954 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:04:03,382] [UniVITrainer] [INFO] [Epoch 150] Val loss: 150377.5719 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:06:49,537] [UniVITrainer] [INFO] [Epoch 156] New best val loss: 148005.9766\n",
      "[2025-11-19 06:07:45,122] [UniVITrainer] [INFO] [Epoch 158] New best val loss: 147356.9469\n",
      "[2025-11-19 06:08:12,967] [UniVITrainer] [INFO] [Epoch 159] New best val loss: 145767.8578\n",
      "[2025-11-19 06:08:37,795] [UniVITrainer] [INFO] [Epoch 160] Train loss: 246064.0328 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:08:40,823] [UniVITrainer] [INFO] [Epoch 160] Val loss: 147346.1875 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:12:24,722] [UniVITrainer] [INFO] [Epoch 168] New best val loss: 144809.2437\n",
      "[2025-11-19 06:13:17,449] [UniVITrainer] [INFO] [Epoch 170] Train loss: 231033.8728 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:13:20,613] [UniVITrainer] [INFO] [Epoch 170] Val loss: 145068.1172 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:14:16,654] [UniVITrainer] [INFO] [Epoch 172] New best val loss: 140979.7109\n",
      "[2025-11-19 06:17:57,955] [UniVITrainer] [INFO] [Epoch 180] Train loss: 222661.3223 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:18:01,033] [UniVITrainer] [INFO] [Epoch 180] Val loss: 141895.9125 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:19:25,963] [UniVITrainer] [INFO] [Epoch 183] New best val loss: 139832.0000\n",
      "[2025-11-19 06:19:54,172] [UniVITrainer] [INFO] [Epoch 184] New best val loss: 138315.8375\n",
      "[2025-11-19 06:22:39,695] [UniVITrainer] [INFO] [Epoch 190] Train loss: 211222.9555 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:22:42,753] [UniVITrainer] [INFO] [Epoch 190] Val loss: 141835.4547 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:24:07,453] [UniVITrainer] [INFO] [Epoch 193] New best val loss: 137753.0047\n",
      "[2025-11-19 06:25:04,199] [UniVITrainer] [INFO] [Epoch 195] New best val loss: 135217.6156\n",
      "[2025-11-19 06:26:29,179] [UniVITrainer] [INFO] [Epoch 198] New best val loss: 134564.0422\n",
      "[2025-11-19 06:27:22,316] [UniVITrainer] [INFO] [Epoch 200] Train loss: 201315.8531 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:27:25,420] [UniVITrainer] [INFO] [Epoch 200] Val loss: 139798.2891 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:27:25,426] [UniVITrainer] [INFO] Restored best model from epoch 198 (val loss = 134564.0422)\n",
      "[2025-11-19 06:27:25,466] [UniVITrainer] [INFO] TrainingConfig:\n",
      "[2025-11-19 06:27:25,467] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "[2025-11-19 06:27:25,468] [UniVITrainer] [INFO]   batch_size: 512\n",
      "[2025-11-19 06:27:25,468] [UniVITrainer] [INFO]   lr: 0.001\n",
      "[2025-11-19 06:27:25,469] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "[2025-11-19 06:27:25,469] [UniVITrainer] [INFO]   device: cpu\n",
      "[2025-11-19 06:27:25,470] [UniVITrainer] [INFO]   log_every: 10\n",
      "[2025-11-19 06:27:25,470] [UniVITrainer] [INFO]   grad_clip: 5.0\n",
      "[2025-11-19 06:27:25,471] [UniVITrainer] [INFO]   num_workers: 4\n",
      "[2025-11-19 06:27:25,471] [UniVITrainer] [INFO]   seed: 42\n",
      "[2025-11-19 06:27:25,472] [UniVITrainer] [INFO]   early_stopping: True\n",
      "[2025-11-19 06:27:25,472] [UniVITrainer] [INFO]   patience: 20\n",
      "[2025-11-19 06:27:25,473] [UniVITrainer] [INFO]   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training UniVI (nb) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec89010ef79142a1a56f503b2a68eef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 06:27:33,773] [UniVITrainer] [INFO] [Epoch 001] Train loss: 4967.9705 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:27:36,761] [UniVITrainer] [INFO] [Epoch 001] Val loss: 2518.9084 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:27:36,766] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 2518.9084\n",
      "[2025-11-19 06:27:48,129] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1794.1826\n",
      "[2025-11-19 06:27:59,372] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1674.7476\n",
      "[2025-11-19 06:28:10,684] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 1626.8135\n",
      "[2025-11-19 06:28:21,886] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 1611.1355\n",
      "[2025-11-19 06:28:33,133] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 1597.1507\n",
      "[2025-11-19 06:28:44,433] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 1586.7056\n",
      "[2025-11-19 06:28:55,658] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 1578.6624\n",
      "[2025-11-19 06:29:06,715] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 1573.1591\n",
      "[2025-11-19 06:29:14,971] [UniVITrainer] [INFO] [Epoch 010] Train loss: 1582.6051 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:29:18,056] [UniVITrainer] [INFO] [Epoch 010] Val loss: 1570.0537 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:29:18,062] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 1570.0537\n",
      "[2025-11-19 06:29:29,385] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 1566.6703\n",
      "[2025-11-19 06:29:40,752] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 1556.4461\n",
      "[2025-11-19 06:29:52,100] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 1548.2094\n",
      "[2025-11-19 06:30:03,256] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 1544.3425\n",
      "[2025-11-19 06:30:14,543] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 1536.3849\n",
      "[2025-11-19 06:30:26,143] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 1532.7042\n",
      "[2025-11-19 06:30:37,450] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 1524.8195\n",
      "[2025-11-19 06:30:48,822] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 1520.7227\n",
      "[2025-11-19 06:31:08,600] [UniVITrainer] [INFO] [Epoch 020] Train loss: 1529.4445 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:31:11,676] [UniVITrainer] [INFO] [Epoch 020] Val loss: 1515.7433 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:31:11,681] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 1515.7433\n",
      "[2025-11-19 06:31:22,934] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 1512.0247\n",
      "[2025-11-19 06:31:34,079] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 1509.3528\n",
      "[2025-11-19 06:31:45,488] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 1508.2792\n",
      "[2025-11-19 06:31:56,726] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 1505.7168\n",
      "[2025-11-19 06:32:08,047] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 1504.0802\n",
      "[2025-11-19 06:32:19,493] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 1504.0457\n",
      "[2025-11-19 06:32:30,756] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 1498.6800\n",
      "[2025-11-19 06:32:53,309] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 1498.0843\n",
      "[2025-11-19 06:33:01,628] [UniVITrainer] [INFO] [Epoch 030] Train loss: 1506.8322 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:33:04,661] [UniVITrainer] [INFO] [Epoch 030] Val loss: 1493.7288 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:33:04,670] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 1493.7288\n",
      "[2025-11-19 06:33:27,229] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 1491.0455\n",
      "[2025-11-19 06:33:38,441] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 1486.7008\n",
      "[2025-11-19 06:34:35,290] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 1482.6725\n",
      "[2025-11-19 06:34:54,869] [UniVITrainer] [INFO] [Epoch 040] Train loss: 1494.1867 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:34:57,890] [UniVITrainer] [INFO] [Epoch 040] Val loss: 1483.3263 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:35:09,369] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 1480.0546\n",
      "[2025-11-19 06:35:32,864] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 1478.5570\n",
      "[2025-11-19 06:36:10,099] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 1476.7452\n",
      "[2025-11-19 06:37:15,768] [UniVITrainer] [INFO] [Epoch 050] Train loss: 1488.5623 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:37:18,850] [UniVITrainer] [INFO] [Epoch 050] Val loss: 1474.8701 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:37:18,855] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 1474.8701\n",
      "[2025-11-19 06:38:01,717] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 1473.9090\n",
      "[2025-11-19 06:38:47,607] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 1473.0251\n",
      "[2025-11-19 06:40:27,059] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 1472.5588\n",
      "[2025-11-19 06:40:52,898] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 1472.0566\n",
      "[2025-11-19 06:41:16,167] [UniVITrainer] [INFO] [Epoch 060] Train loss: 1485.0997 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:41:19,310] [UniVITrainer] [INFO] [Epoch 060] Val loss: 1476.3031 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:41:46,044] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 1470.9654\n",
      "[2025-11-19 06:42:40,193] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 1470.8788\n",
      "[2025-11-19 06:43:34,037] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 1467.8846\n",
      "[2025-11-19 06:45:47,223] [UniVITrainer] [INFO] [Epoch 070] Train loss: 1481.1265 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:45:50,334] [UniVITrainer] [INFO] [Epoch 070] Val loss: 1472.8180 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:46:18,213] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 1466.7548\n",
      "[2025-11-19 06:48:12,321] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 1466.0257\n",
      "[2025-11-19 06:50:35,517] [UniVITrainer] [INFO] [Epoch 080] Train loss: 1478.3545 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:50:38,710] [UniVITrainer] [INFO] [Epoch 080] Val loss: 1464.9598 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:50:38,715] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 1464.9598\n",
      "[2025-11-19 06:51:08,231] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 1463.2604\n",
      "[2025-11-19 06:52:06,595] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 1463.0082\n",
      "[2025-11-19 06:54:32,728] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 1462.2686\n",
      "[2025-11-19 06:55:28,435] [UniVITrainer] [INFO] [Epoch 090] Train loss: 1475.1682 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:55:31,596] [UniVITrainer] [INFO] [Epoch 090] Val loss: 1464.6645 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 06:56:59,952] [UniVITrainer] [INFO] [Epoch 093] New best val loss: 1461.7713\n",
      "[2025-11-19 06:58:57,423] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 1458.7184\n",
      "[2025-11-19 07:00:22,863] [UniVITrainer] [INFO] [Epoch 100] Train loss: 1472.8326 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:00:26,064] [UniVITrainer] [INFO] [Epoch 100] Val loss: 1460.7176 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:05:11,065] [UniVITrainer] [INFO] [Epoch 110] Train loss: 1470.6225 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:05:14,322] [UniVITrainer] [INFO] [Epoch 110] Val loss: 1461.0043 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:06:38,418] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 1458.4704\n",
      "[2025-11-19 07:09:00,561] [UniVITrainer] [INFO] [Epoch 118] New best val loss: 1457.7745\n",
      "[2025-11-19 07:09:55,190] [UniVITrainer] [INFO] [Epoch 120] Train loss: 1470.2424 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:09:58,415] [UniVITrainer] [INFO] [Epoch 120] Val loss: 1460.3202 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:11:53,921] [UniVITrainer] [INFO] [Epoch 124] New best val loss: 1457.7178\n",
      "[2025-11-19 07:12:23,199] [UniVITrainer] [INFO] [Epoch 125] New best val loss: 1457.0640\n",
      "[2025-11-19 07:14:45,498] [UniVITrainer] [INFO] [Epoch 130] Train loss: 1469.1340 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:14:48,634] [UniVITrainer] [INFO] [Epoch 130] Val loss: 1456.9340 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:14:48,643] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 1456.9340\n",
      "[2025-11-19 07:15:17,908] [UniVITrainer] [INFO] [Epoch 131] New best val loss: 1456.4684\n",
      "[2025-11-19 07:18:13,413] [UniVITrainer] [INFO] [Epoch 137] New best val loss: 1455.3748\n",
      "[2025-11-19 07:19:38,095] [UniVITrainer] [INFO] [Epoch 140] Train loss: 1467.9315 (beta=80.000, gamma=120.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 07:19:41,252] [UniVITrainer] [INFO] [Epoch 140] Val loss: 1457.1738 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:22:09,413] [UniVITrainer] [INFO] [Epoch 145] New best val loss: 1454.5656\n",
      "[2025-11-19 07:24:34,688] [UniVITrainer] [INFO] [Epoch 150] Train loss: 1468.6757 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:24:37,806] [UniVITrainer] [INFO] [Epoch 150] Val loss: 1457.9668 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:29:33,134] [UniVITrainer] [INFO] [Epoch 160] Train loss: 1467.8952 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:29:36,409] [UniVITrainer] [INFO] [Epoch 160] Val loss: 1457.9863 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:32:05,823] [UniVITrainer] [INFO] Early stopping at epoch 165 (best val loss = 1454.5656)\n",
      "[2025-11-19 07:32:05,832] [UniVITrainer] [INFO] Restored best model from epoch 145 (val loss = 1454.5656)\n",
      "[2025-11-19 07:32:05,860] [UniVITrainer] [INFO] TrainingConfig:\n",
      "[2025-11-19 07:32:05,860] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "[2025-11-19 07:32:05,861] [UniVITrainer] [INFO]   batch_size: 512\n",
      "[2025-11-19 07:32:05,861] [UniVITrainer] [INFO]   lr: 0.001\n",
      "[2025-11-19 07:32:05,862] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "[2025-11-19 07:32:05,862] [UniVITrainer] [INFO]   device: cpu\n",
      "[2025-11-19 07:32:05,863] [UniVITrainer] [INFO]   log_every: 10\n",
      "[2025-11-19 07:32:05,863] [UniVITrainer] [INFO]   grad_clip: 5.0\n",
      "[2025-11-19 07:32:05,863] [UniVITrainer] [INFO]   num_workers: 4\n",
      "[2025-11-19 07:32:05,864] [UniVITrainer] [INFO]   seed: 42\n",
      "[2025-11-19 07:32:05,864] [UniVITrainer] [INFO]   early_stopping: True\n",
      "[2025-11-19 07:32:05,865] [UniVITrainer] [INFO]   patience: 20\n",
      "[2025-11-19 07:32:05,865] [UniVITrainer] [INFO]   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training UniVI (zinb) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca7c1953fb645be976b55cc3c1e9054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 07:32:14,097] [UniVITrainer] [INFO] [Epoch 001] Train loss: 5099.9798 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:32:17,229] [UniVITrainer] [INFO] [Epoch 001] Val loss: 2641.5582 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:32:17,234] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 2641.5582\n",
      "[2025-11-19 07:32:28,754] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1910.9781\n",
      "[2025-11-19 07:32:40,179] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1786.3101\n",
      "[2025-11-19 07:32:51,474] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 1733.9581\n",
      "[2025-11-19 07:33:02,774] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 1713.4069\n",
      "[2025-11-19 07:33:14,309] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 1695.9573\n",
      "[2025-11-19 07:33:25,713] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 1681.7292\n",
      "[2025-11-19 07:33:37,218] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 1670.8198\n",
      "[2025-11-19 07:33:48,832] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 1662.2043\n",
      "[2025-11-19 07:33:57,081] [UniVITrainer] [INFO] [Epoch 010] Train loss: 1669.4784 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:34:00,174] [UniVITrainer] [INFO] [Epoch 010] Val loss: 1655.7996 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:34:00,179] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 1655.7996\n",
      "[2025-11-19 07:34:11,412] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 1649.7386\n",
      "[2025-11-19 07:34:22,526] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 1637.0738\n",
      "[2025-11-19 07:34:33,925] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 1626.4706\n",
      "[2025-11-19 07:34:45,206] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 1620.4899\n",
      "[2025-11-19 07:34:56,506] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 1609.8228\n",
      "[2025-11-19 07:35:07,793] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 1603.6846\n",
      "[2025-11-19 07:35:19,217] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 1593.7734\n",
      "[2025-11-19 07:35:30,597] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 1587.0851\n",
      "[2025-11-19 07:35:42,082] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 1585.6003\n",
      "[2025-11-19 07:35:50,283] [UniVITrainer] [INFO] [Epoch 020] Train loss: 1592.6324 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:35:53,321] [UniVITrainer] [INFO] [Epoch 020] Val loss: 1577.7118 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:35:53,326] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 1577.7118\n",
      "[2025-11-19 07:36:04,989] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 1572.6861\n",
      "[2025-11-19 07:36:16,426] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 1567.9382\n",
      "[2025-11-19 07:36:27,790] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 1563.9961\n",
      "[2025-11-19 07:36:39,069] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 1559.8143\n",
      "[2025-11-19 07:36:50,438] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 1557.1983\n",
      "[2025-11-19 07:37:01,913] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 1555.6102\n",
      "[2025-11-19 07:37:13,316] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 1549.1584\n",
      "[2025-11-19 07:37:24,720] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 1548.2394\n",
      "[2025-11-19 07:37:36,160] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 1545.3716\n",
      "[2025-11-19 07:37:44,498] [UniVITrainer] [INFO] [Epoch 030] Train loss: 1553.6084 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:37:47,556] [UniVITrainer] [INFO] [Epoch 030] Val loss: 1539.7132 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:37:47,562] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 1539.7132\n",
      "[2025-11-19 07:38:10,352] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 1535.1700\n",
      "[2025-11-19 07:38:21,846] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 1529.0944\n",
      "[2025-11-19 07:38:44,567] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 1526.0894\n",
      "[2025-11-19 07:38:55,999] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 1525.3402\n",
      "[2025-11-19 07:39:18,985] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 1520.2063\n",
      "[2025-11-19 07:39:38,870] [UniVITrainer] [INFO] [Epoch 040] Train loss: 1531.1592 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:39:41,960] [UniVITrainer] [INFO] [Epoch 040] Val loss: 1520.4062 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:39:53,578] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 1516.7261\n",
      "[2025-11-19 07:40:17,482] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 1513.5720\n",
      "[2025-11-19 07:40:54,822] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 1509.3247\n",
      "[2025-11-19 07:41:56,608] [UniVITrainer] [INFO] [Epoch 050] Train loss: 1518.8942 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:41:59,678] [UniVITrainer] [INFO] [Epoch 050] Val loss: 1505.3198 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:41:59,684] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 1505.3198\n",
      "[2025-11-19 07:42:19,181] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 1505.0829\n",
      "[2025-11-19 07:42:39,465] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 1503.3716\n",
      "[2025-11-19 07:43:20,377] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 1501.9239\n",
      "[2025-11-19 07:44:02,558] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 1500.2517\n",
      "[2025-11-19 07:44:46,507] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 1498.8623\n",
      "[2025-11-19 07:45:09,235] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 1497.8500\n",
      "[2025-11-19 07:45:29,145] [UniVITrainer] [INFO] [Epoch 060] Train loss: 1509.3335 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:45:32,259] [UniVITrainer] [INFO] [Epoch 060] Val loss: 1499.9203 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:45:55,921] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 1495.5783\n",
      "[2025-11-19 07:46:44,038] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 1493.5776\n",
      "[2025-11-19 07:47:07,788] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 1492.4742\n",
      "[2025-11-19 07:47:31,761] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 1491.5294\n",
      "[2025-11-19 07:48:46,023] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 1490.3110\n",
      "[2025-11-19 07:49:35,528] [UniVITrainer] [INFO] [Epoch 070] Train loss: 1501.7265 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:49:38,691] [UniVITrainer] [INFO] [Epoch 070] Val loss: 1493.6658 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 07:50:09,844] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 1487.1321\n",
      "[2025-11-19 07:52:44,089] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 1487.0913\n",
      "[2025-11-19 07:59:45,260] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 1483.7466\n",
      "[2025-11-19 08:01:58,957] [UniVITrainer] [INFO] [Epoch 080] Train loss: 1495.0853 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 08:02:02,093] [UniVITrainer] [INFO] [Epoch 080] Val loss: 1481.0110 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 08:02:02,098] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 1481.0110\n",
      "[2025-11-19 08:02:29,666] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 1479.4155\n",
      "[2025-11-19 08:03:24,590] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 1478.3231\n",
      "[2025-11-19 08:04:48,127] [UniVITrainer] [INFO] [Epoch 086] New best val loss: 1477.7301\n",
      "[2025-11-19 08:05:16,610] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 1476.6433\n",
      "[2025-11-19 08:05:45,206] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 1476.1377\n",
      "[2025-11-19 08:06:39,768] [UniVITrainer] [INFO] [Epoch 090] Train loss: 1488.7133 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 08:06:42,956] [UniVITrainer] [INFO] [Epoch 090] Val loss: 1478.8240 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 08:07:11,708] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 1475.3663\n",
      "[2025-11-19 08:08:09,859] [UniVITrainer] [INFO] [Epoch 093] New best val loss: 1474.3615\n",
      "[2025-11-19 08:13:53,911] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 1470.5428\n",
      "[2025-11-19 08:15:19,162] [UniVITrainer] [INFO] [Epoch 100] Train loss: 1484.1623 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 08:15:22,350] [UniVITrainer] [INFO] [Epoch 100] Val loss: 1471.6589 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 08:19:04,473] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 1470.4122\n",
      "[2025-11-19 08:19:34,081] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 1469.6815\n",
      "[2025-11-19 08:21:59,446] [UniVITrainer] [INFO] [Epoch 110] Train loss: 1479.7749 (beta=80.000, gamma=120.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 08:22:02,573] [UniVITrainer] [INFO] [Epoch 110] Val loss: 1469.2903 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 08:22:02,581] [UniVITrainer] [INFO] [Epoch 110] New best val loss: 1469.2903\n",
      "[2025-11-19 08:23:01,876] [UniVITrainer] [INFO] [Epoch 112] New best val loss: 1467.8465\n",
      "[2025-11-19 08:23:31,317] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 1467.0413\n",
      "[2025-11-19 08:25:30,185] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 1466.9196\n",
      "[2025-11-19 08:25:59,924] [UniVITrainer] [INFO] [Epoch 118] New best val loss: 1465.6605\n",
      "[2025-11-19 08:26:56,671] [UniVITrainer] [INFO] [Epoch 120] Train loss: 1477.9663 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 08:26:59,823] [UniVITrainer] [INFO] [Epoch 120] Val loss: 1467.7647 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 08:32:14,099] [UniVITrainer] [INFO] [Epoch 124] New best val loss: 1464.7875\n",
      "[2025-11-19 08:36:46,682] [UniVITrainer] [INFO] [Epoch 125] New best val loss: 1464.1799\n",
      "[2025-11-19 08:49:03,593] [UniVITrainer] [INFO] [Epoch 130] Train loss: 1475.8717 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 08:49:06,816] [UniVITrainer] [INFO] [Epoch 130] Val loss: 1463.1662 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 08:49:06,821] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 1463.1662\n",
      "[2025-11-19 08:49:36,418] [UniVITrainer] [INFO] [Epoch 131] New best val loss: 1462.6864\n",
      "[2025-11-19 08:53:38,966] [UniVITrainer] [INFO] [Epoch 137] New best val loss: 1461.1676\n",
      "[2025-11-19 09:02:33,461] [UniVITrainer] [INFO] [Epoch 140] Train loss: 1473.3992 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 09:02:53,340] [UniVITrainer] [INFO] [Epoch 140] Val loss: 1462.2964 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 09:09:05,831] [UniVITrainer] [INFO] [Epoch 144] New best val loss: 1461.0584\n",
      "[2025-11-19 09:09:35,627] [UniVITrainer] [INFO] [Epoch 145] New best val loss: 1459.0144\n",
      "[2025-11-19 09:12:01,411] [UniVITrainer] [INFO] [Epoch 150] Train loss: 1473.3899 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 09:12:04,658] [UniVITrainer] [INFO] [Epoch 150] Val loss: 1462.2284 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 09:16:04,713] [UniVITrainer] [INFO] [Epoch 158] New best val loss: 1458.4412\n",
      "[2025-11-19 09:17:02,209] [UniVITrainer] [INFO] [Epoch 160] Train loss: 1471.8141 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 09:17:05,755] [UniVITrainer] [INFO] [Epoch 160] Val loss: 1461.0839 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 09:24:25,783] [UniVITrainer] [INFO] [Epoch 168] New best val loss: 1457.7287\n",
      "[2025-11-19 09:36:20,310] [UniVITrainer] [INFO] [Epoch 170] Train loss: 1470.2610 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 09:36:59,885] [UniVITrainer] [INFO] [Epoch 170] Val loss: 1457.9693 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 09:53:11,999] [UniVITrainer] [INFO] [Epoch 172] New best val loss: 1457.3592\n",
      "[2025-11-19 10:04:28,128] [UniVITrainer] [INFO] [Epoch 173] New best val loss: 1457.2794\n",
      "[2025-11-19 10:24:01,746] [UniVITrainer] [INFO] [Epoch 175] New best val loss: 1457.2316\n",
      "[2025-11-19 11:06:27,332] [UniVITrainer] [INFO] [Epoch 180] Train loss: 1468.4933 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 11:07:02,107] [UniVITrainer] [INFO] [Epoch 180] Val loss: 1457.6522 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 11:25:29,165] [UniVITrainer] [INFO] [Epoch 182] New best val loss: 1457.1854\n",
      "[2025-11-19 12:30:30,652] [UniVITrainer] [INFO] [Epoch 187] New best val loss: 1455.6793\n",
      "[2025-11-19 13:09:59,529] [UniVITrainer] [INFO] [Epoch 190] Train loss: 1468.0596 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 13:10:47,472] [UniVITrainer] [INFO] [Epoch 190] Val loss: 1457.3216 (beta=80.000, gamma=120.000)\n",
      "[2025-11-19 13:51:26,628] [UniVITrainer] [INFO] [Epoch 193] New best val loss: 1455.2924\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "histories = {}\n",
    "\n",
    "for tag, (lik_rna, lik_adt) in {\n",
    "    \"gaussian\": (\"gaussian\", \"gaussian\"),\n",
    "    \"nb\":       (\"nb\",       \"nb\"),\n",
    "    \"zinb\":     (\"nb\",       \"zinb\"),  # RNA NB, ADT ZINB\n",
    "}.items():\n",
    "    print(f\"\\n=== Training UniVI ({tag}) ===\")\n",
    "    model, trainer, history = train_univi_model(\n",
    "        rna_adata_hvg,\n",
    "        adt_adata,\n",
    "        train_cfg,\n",
    "        likelihood_rna=lik_rna,\n",
    "        likelihood_adt=lik_adt,\n",
    "        seed=42,\n",
    "    )\n",
    "    models[tag] = (model, trainer)\n",
    "    histories[tag] = history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"univi_{tag}_benchmarking_best.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41043c60",
   "metadata": {},
   "source": [
    "#### Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcbf64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "def encode_full_latents(model, trainer, rna_adata, adt_adata, batch_size=1024):\n",
    "    model.eval()\n",
    "    device = trainer.device\n",
    "\n",
    "    def _encode(adata, modality):\n",
    "        X = adata.X\n",
    "        if sp.issparse(X):\n",
    "            X = X.toarray()\n",
    "        X_t = torch.as_tensor(X, dtype=torch.float32, device=device)\n",
    "\n",
    "        zs = []\n",
    "        for start in range(0, X_t.shape[0], batch_size):\n",
    "            xb = X_t[start:start+batch_size]\n",
    "            mu_dict, logvar_dict = model.encode_modalities({modality: xb})\n",
    "            mu_z, logvar_z = model.mixture_of_experts(\n",
    "                {modality: mu_dict[modality]},\n",
    "                {modality: logvar_dict[modality]},\n",
    "            )\n",
    "            zs.append(mu_z.detach().cpu().numpy())\n",
    "        return np.vstack(zs)\n",
    "\n",
    "    z_rna = _encode(rna_adata, \"rna\")\n",
    "    z_adt = _encode(adt_adata, \"adt\")\n",
    "    return z_rna, z_adt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8734ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from univi import evaluation as univi_eval\n",
    "from univi import plotting as univi_plot\n",
    "\n",
    "results = []\n",
    "\n",
    "for tag, (model, trainer) in models.items():\n",
    "    print(f\"\\n=== Eval: {tag} ===\")\n",
    "\n",
    "    # 1. Latents\n",
    "    z_rna, z_adt = encode_full_latents(model, trainer, rna_test_adata, adt_test_adata)\n",
    "\n",
    "    # 2. FOSCTTM\n",
    "    fos = univi_eval.compute_foscttm(z_rna, z_adt)\n",
    "    print(f\"FOSCTTM: {fos:.4f}\")\n",
    "\n",
    "    # 3. Modality mixing\n",
    "    Z_joint = np.concatenate([z_rna, z_adt], axis=0)\n",
    "    mods = np.array([\"rna\"] * z_rna.shape[0] + [\"adt\"] * z_adt.shape[0])\n",
    "    mix = univi_eval.compute_modality_mixing(Z_joint, mods, k=20)\n",
    "    print(f\"Mixing score (k=20): {mix:.3f}\")\n",
    "\n",
    "    # 4. Label transfer (ADT → RNA on test)\n",
    "    labels_rna = rna_test_adata.obs[\"celltype.l2\"].astype(str).values\n",
    "    labels_adt = adt_test_adata.obs[\"celltype.l2\"].astype(str).values\n",
    "\n",
    "    pred_rna_from_adt, acc_rna, cm_rna = univi_eval.label_transfer_knn(\n",
    "        Z_source=z_adt,\n",
    "        labels_source=labels_adt,\n",
    "        Z_target=z_rna,\n",
    "        labels_target=labels_rna,\n",
    "        k=15,\n",
    "    )\n",
    "    print(f\"Label transfer acc (ADT→RNA, test, k=15): {acc_rna:.3f}\")\n",
    "\n",
    "    # 5. Cross-modal reconstruction: RNA→ADT (test set)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_rna = rna_test_adata.X\n",
    "        if sp.issparse(X_rna):\n",
    "            X_rna = X_rna.toarray()\n",
    "        X_rna_t = torch.as_tensor(X_rna, dtype=torch.float32, device=trainer.device)\n",
    "\n",
    "        xhat_adt_list = []\n",
    "        bs = 512\n",
    "        for start in range(0, X_rna_t.shape[0], bs):\n",
    "            xb = X_rna_t[start:start+bs]\n",
    "            mu_dict, logvar_dict = model.encode_modalities({\"rna\": xb})\n",
    "            mu_z, logvar_z = model.mixture_of_experts(\n",
    "                {\"rna\": mu_dict[\"rna\"]},\n",
    "                {\"rna\": logvar_dict[\"rna\"]},\n",
    "            )\n",
    "            xhat_raw = model.decode_modalities(mu_z)\n",
    "            xhat_adt_list.append(xhat_raw[\"adt\"].cpu().numpy())\n",
    "\n",
    "        xhat_adt = np.vstack(xhat_adt_list)\n",
    "\n",
    "    X_adt = adt_test_adata.X\n",
    "    if sp.issparse(X_adt):\n",
    "        X_adt = X_adt.toarray()\n",
    "\n",
    "    mse_feat = univi_eval.mse_per_feature(X_adt, xhat_adt)\n",
    "    corr_feat = univi_eval.pearson_corr_per_feature(X_adt, xhat_adt)\n",
    "\n",
    "    print(f\"ADT MSE (RNA→ADT, test): {mse_feat.mean():.4f}\")\n",
    "    print(f\"ADT Pearson r (RNA→ADT, test): {corr_feat.mean():.3f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"model\": tag,\n",
    "        \"foscttm\": float(fos),\n",
    "        \"mixing\": float(mix),\n",
    "        \"label_acc\": float(acc_rna),\n",
    "        \"adt_mse\": float(mse_feat.mean()),\n",
    "        \"adt_corr\": float(corr_feat.mean()),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eeacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e431c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniVI_working_environment_v2",
   "language": "python",
   "name": "univi_working_environment_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
