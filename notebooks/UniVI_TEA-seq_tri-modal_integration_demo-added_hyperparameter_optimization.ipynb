{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cc2305c",
   "metadata": {},
   "source": [
    "# UniVI TEA-seq tri-modal data integration demonstration/tutorial - Added hyperparameter optimization code\n",
    "\n",
    "Andrew Ashford, Pathways + Omics Group, Oregon Health & Science University - 11/18/2025\n",
    "\n",
    "This Jupyter Notebook will be used to outline the training steps for a UniVI model using human PBMC TEA-seq tri-modal data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3861d19",
   "metadata": {},
   "source": [
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf6fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import snapatac2 as snap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b78984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 0. Wire up package import\n",
    "# -------------------------\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from univi import (\n",
    "    UniVIMultiModalVAE,\n",
    "    ModalityConfig,\n",
    "    UniVIConfig,\n",
    "    TrainingConfig,\n",
    "    matching,\n",
    ")\n",
    "from univi.data import MultiModalDataset\n",
    "from univi.trainer import UniVITrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9573a941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.1+cu128\n",
      "torch.version.cuda: 12.8\n",
      "CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb267f1",
   "metadata": {},
   "source": [
    "#### Read in and preprocess data as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d959e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/TEA-seq_data\")\n",
    "prefix   = \"GSM5123953_X066-MP0C1W5_leukopak_perm-cells_tea\"\n",
    "\n",
    "rna_h5         = data_dir / f\"{prefix}_200M_cellranger-arc_filtered_feature_bc_matrix.h5\"\n",
    "adt_counts_csv = data_dir / f\"{prefix}_48M_adt_counts.csv.gz\"\n",
    "frag_tsv       = data_dir / f\"{prefix}_200M_atac_filtered_fragments.tsv.gz\"\n",
    "atac_meta_csv  = data_dir / f\"{prefix}_200M_atac_filtered_metadata.csv.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d53b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading RNA (ARC filtered_feature_bc_matrix.h5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/precepts/ashforda/anaconda3/envs/UniVI_TEA-seq_working_environment/lib/python3.10/site-packages/anndata/_core/anndata.py:1756: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 8496 × 36601\n",
      "    var: 'gene_ids', 'feature_types', 'genome', 'interval'\n",
      "Feature types: ['Gene Expression']\n",
      "Initial RNA shape: (8496, 36601)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/precepts/ashforda/anaconda3/envs/UniVI_TEA-seq_working_environment/lib/python3.10/site-packages/anndata/_core/anndata.py:1756: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/groups/precepts/ashforda/anaconda3/envs/UniVI_TEA-seq_working_environment/lib/python3.10/site-packages/anndata/_core/anndata.py:1756: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# 1) RNA\n",
    "# ----------------------\n",
    "print(\"Reading RNA (ARC filtered_feature_bc_matrix.h5)...\")\n",
    "m = sc.read_10x_h5(rna_h5)\n",
    "print(m)\n",
    "\n",
    "print(\"Feature types:\", m.var[\"feature_types\"].unique())\n",
    "\n",
    "rna_adata = m.copy()\n",
    "rna_adata.var_names_make_unique()\n",
    "print(\"Initial RNA shape:\", rna_adata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5efddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ADT counts...\n",
      "ADT counts shape: (719170, 47)\n",
      "ADT AnnData: (719170, 47)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# 2) ADT\n",
    "# ----------------------\n",
    "print(\"Reading ADT counts...\")\n",
    "adt_df = pd.read_csv(adt_counts_csv, index_col=0)  # rows = barcodes, cols = ADT names\n",
    "print(\"ADT counts shape:\", adt_df.shape)\n",
    "\n",
    "adt_adata = ad.AnnData(\n",
    "    X=sp.csr_matrix(adt_df.values),\n",
    "    obs=pd.DataFrame(index=adt_df.index.astype(str)),\n",
    "    var=pd.DataFrame(index=adt_df.columns.astype(str)),\n",
    ")\n",
    "adt_adata.var_names_make_unique()\n",
    "print(\"ADT AnnData:\", adt_adata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18165b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing ATAC fragments with snapatac2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_513649/1577877949.py:5: DeprecationWarning: import_data is deprecated and will be removed in v2.9.0. Use import_fragments instead.\n",
      "  atac_raw = snap.pp.import_data(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATAC raw object: AnnData object with n_obs × n_vars = 7540 × 0\n",
      "    obs: 'n_fragment', 'frac_dup', 'frac_mito'\n",
      "    uns: 'reference_sequences'\n",
      "    obsm: 'fragment_paired'\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# 3) ATAC: fragments + metadata -> LSI\n",
    "# ----------------------\n",
    "print(\"Importing ATAC fragments with snapatac2...\")\n",
    "atac_raw = snap.pp.import_data(\n",
    "    fragment_file=str(frag_tsv),\n",
    "    chrom_sizes=snap.genome.hg38,   # use chrom_sizes\n",
    "    sorted_by_barcode=False,        # TEA-seq fragments usually unsorted\n",
    ")\n",
    "\n",
    "print(\"ATAC raw object:\", atac_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449388e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATAC meta columns: ['original_barcodes', 'n_fragments', 'n_duplicate', 'n_mito', 'n_unique', 'altius_count', 'altius_frac', 'gene_bodies_count', 'gene_bodies_frac', 'peaks_count', 'peaks_frac', 'tss_count', 'tss_frac', 'barcodes', 'cell_name', 'well_id', 'chip_id', 'batch_id', 'pbmc_sample_id', 'DoubletScore', 'DoubletEnrichment', 'TSSEnrichment']\n",
      "ATAC cells with metadata: 7540 of 7540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/precepts/ashforda/anaconda3/envs/UniVI_TEA-seq_working_environment/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "# ---- 3a. Attach external metadata and map barcodes ----\n",
    "meta = pd.read_csv(atac_meta_csv)\n",
    "print(\"ATAC meta columns:\", meta.columns.tolist())\n",
    "\n",
    "# Index metadata by hex barcodes; they match atac_raw.obs_names\n",
    "meta = meta.set_index(\"barcodes\")\n",
    "\n",
    "# Align cells common between fragments + metadata\n",
    "common_ids = atac_raw.obs_names.intersection(meta.index)\n",
    "print(\"ATAC cells with metadata:\", len(common_ids), \"of\", atac_raw.n_obs)\n",
    "\n",
    "atac_raw = atac_raw[common_ids].copy()\n",
    "atac_raw.obs = atac_raw.obs.join(meta, how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac738e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 7540 of 7540 ATAC cells with n_fragments >= 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/precepts/ashforda/anaconda3/envs/UniVI_TEA-seq_working_environment/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# 4) Simple ATAC QC (using n_fragments from metadata)\n",
    "# ----------------------\n",
    "if \"n_fragments\" in atac_raw.obs.columns:\n",
    "    mask = atac_raw.obs[\"n_fragments\"] >= 1500\n",
    "    print(\"Keeping\", mask.sum(), \"of\", atac_raw.n_obs, \"ATAC cells with n_fragments >= 1000\")\n",
    "    atac_raw = atac_raw[mask].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeac55d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding ATAC tile matrix...\n",
      "Tile matrix shape: (7540, 6062095) (cells x genomic tiles)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# 5) Tile matrix + TF–IDF + LSI\n",
    "# ----------------------\n",
    "print(\"Adding ATAC tile matrix...\")\n",
    "snap.pp.add_tile_matrix(atac_raw)\n",
    "print(\"Tile matrix shape:\", atac_raw.shape, \"(cells x genomic tiles)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b94b2d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TF–IDF and LSI on ATAC tiles...\n",
      "ATAC tile matrix: 7540 cells × 6062095 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing TF–IDF and LSI on ATAC tiles...\")\n",
    "X = atac_raw.X\n",
    "if not sp.issparse(X):\n",
    "    X = sp.csr_matrix(X)\n",
    "\n",
    "n_cells, n_feats = X.shape\n",
    "print(f\"ATAC tile matrix: {n_cells} cells × {n_feats} features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8767f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF: normalize by per-cell counts\n",
    "tf = normalize(X, norm=\"l1\", axis=1)\n",
    "\n",
    "# DF: number of cells with a non-zero in each feature\n",
    "df = np.array((X > 0).sum(axis=0)).ravel()\n",
    "idf = np.log1p(n_cells / (1.0 + df))\n",
    "\n",
    "# TF-IDF\n",
    "X_tfidf = tf.multiply(idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c8470b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\n\\n# X: sparse matrix of shape (n_cells, n_peaks)\\nmin_cells_per_peak = 50  # or 20, depending on sparsity\\n\\n# number of nonzeros per peak (i.e., per column)\\npeak_nnz = X.getnnz(axis=0)          # returns a 1D np.array-like\\npeak_nnz = np.asarray(peak_nnz).ravel()\\n\\nkeep_peaks = peak_nnz >= min_cells_per_peak\\n\\nX_filtered = X[:, keep_peaks]\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "\n",
    "# X: sparse matrix of shape (n_cells, n_peaks)\n",
    "min_cells_per_peak = 50  # or 20, depending on sparsity\n",
    "\n",
    "# number of nonzeros per peak (i.e., per column)\n",
    "peak_nnz = X.getnnz(axis=0)          # returns a 1D np.array-like\n",
    "peak_nnz = np.asarray(peak_nnz).ravel()\n",
    "\n",
    "keep_peaks = peak_nnz >= min_cells_per_peak\n",
    "\n",
    "X_filtered = X[:, keep_peaks]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eadfb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_tfidf.dtype != np.float32:\n",
    "    X_tfidf = X_tfidf.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "839e4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD → LSI\n",
    "n_lsi = 100\n",
    "svd = TruncatedSVD(n_components=n_lsi, random_state=42)\n",
    "lsi = svd.fit_transform(X_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f665a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row L2-normalize\n",
    "lsi = normalize(lsi, norm=\"l2\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63b08081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATAC LSI AnnData: (7540, 100)\n"
     ]
    }
   ],
   "source": [
    "# Wrap as ATAC AnnData for UniVI\n",
    "atac_adata = ad.AnnData(\n",
    "    X=lsi.astype(np.float32),\n",
    "    obs=atac_raw.obs.copy(),   # includes original_barcodes, etc.\n",
    ")\n",
    "print(\"ATAC LSI AnnData:\", atac_adata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8be31c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# 6) Put everything into shared barcode space\n",
    "# ----------------------\n",
    "def strip_suffix(idx):\n",
    "    # drop trailing \"-<number>\" if present\n",
    "    return idx.astype(str).str.replace(r\"-\\d+$\", \"\", regex=True)\n",
    "\n",
    "# RNA & ADT already indexed by 10x barcodes with \"-1\"\n",
    "rna_adata.obs_names = strip_suffix(rna_adata.obs_names.to_series())\n",
    "adt_adata.obs_names = strip_suffix(adt_adata.obs_names.to_series())\n",
    "\n",
    "# For ATAC, map from hex barcodes -> original 10x barcodes, then strip suffix\n",
    "atac_adata.obs[\"barcode_10x\"] = atac_adata.obs[\"original_barcodes\"].astype(str)\n",
    "atac_adata.obs_names = strip_suffix(atac_adata.obs[\"barcode_10x\"])\n",
    "\n",
    "# Also strip suffix from RNA/ADT now for consistency\n",
    "rna_adata.obs_names = strip_suffix(rna_adata.obs_names.to_series())\n",
    "adt_adata.obs_names = strip_suffix(adt_adata.obs_names.to_series())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb6cfc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common tri-modal cells: 7421\n",
      "Aligned shapes:\n",
      "  RNA : (7421, 36601)\n",
      "  ADT : (7421, 47)\n",
      "  ATAC: (7421, 100)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# 7) Tri-modal intersection\n",
    "# ----------------------\n",
    "common_barcodes = (\n",
    "    set(rna_adata.obs_names)\n",
    "    & set(adt_adata.obs_names)\n",
    "    & set(atac_adata.obs_names)\n",
    ")\n",
    "\n",
    "print(\"Common tri-modal cells:\", len(common_barcodes))\n",
    "if len(common_barcodes) == 0:\n",
    "    raise ValueError(\"No overlapping barcodes across RNA/ADT/ATAC after mapping.\")\n",
    "\n",
    "common_barcodes = sorted(common_barcodes)\n",
    "\n",
    "rna_adata  = rna_adata[common_barcodes].copy()\n",
    "adt_adata  = adt_adata[common_barcodes].copy()\n",
    "atac_adata = atac_adata[common_barcodes].copy()\n",
    "\n",
    "print(\"Aligned shapes:\")\n",
    "print(\"  RNA :\", rna_adata.shape)\n",
    "print(\"  ADT :\", adt_adata.shape)\n",
    "print(\"  ATAC:\", atac_adata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c31d647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After optional subsampling: 7421 cells.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# 8) Optional subsampling\n",
    "# ----------------------\n",
    "target_n = 10000\n",
    "n_cells  = rna_adata.n_obs\n",
    "\n",
    "if n_cells > target_n:\n",
    "    rng = np.random.default_rng(42)\n",
    "    keep_idx = rng.choice(n_cells, size=target_n, replace=False)\n",
    "    keep_barcodes = rna_adata.obs_names[keep_idx]\n",
    "\n",
    "    rna_adata  = rna_adata[keep_barcodes].copy()\n",
    "    adt_adata  = adt_adata[keep_barcodes].copy()\n",
    "    atac_adata = atac_adata[keep_barcodes].copy()\n",
    "\n",
    "print(\"After optional subsampling:\", rna_adata.n_obs, \"cells.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e02b2",
   "metadata": {},
   "source": [
    "#### Preprocess data since we will be using Gaussian decoders in this case to prioritize data alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c077cb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# --- RNA: log-normalize + HVGs ---\\nrna = rna_adata.copy()\\nrna.layers[\"counts\"] = rna.X.copy()\\n\\nsc.pp.normalize_total(rna, target_sum=1e4)\\nsc.pp.log1p(rna)\\nsc.pp.highly_variable_genes(rna, n_top_genes=2000, flavor=\"seurat_v3\")\\nrna = rna[:, rna.var[\"highly_variable\"]].copy()\\nprint(\"RNA (HVG log1p) shape:\", rna.shape)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------\n",
    "# 9) Modality-specific preprocessing\n",
    "# ----------------------\n",
    "'''\n",
    "# --- RNA: log-normalize + HVGs ---\n",
    "rna = rna_adata.copy()\n",
    "rna.layers[\"counts\"] = rna.X.copy()\n",
    "\n",
    "sc.pp.normalize_total(rna, target_sum=1e4)\n",
    "sc.pp.log1p(rna)\n",
    "sc.pp.highly_variable_genes(rna, n_top_genes=2000, flavor=\"seurat_v3\")\n",
    "rna = rna[:, rna.var[\"highly_variable\"]].copy()\n",
    "print(\"RNA (HVG log1p) shape:\", rna.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b2f88ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# --- ADT: CLR per cell ---\\nadt = adt_adata.copy()\\nadt.layers[\"counts\"] = adt.X.copy()\\n\\nX = adt.layers[\"counts\"].astype(float)\\nif sp.issparse(X):\\n    X = X.toarray()\\n\\neps = 1e-6\\nX_log = np.log1p(X + eps)\\nX_clr = X_log - X_log.mean(axis=1, keepdims=True)\\nadt.X = X_clr.astype(np.float32)\\nprint(\"ADT CLR shape:\", adt.shape)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# --- ADT: CLR per cell ---\n",
    "adt = adt_adata.copy()\n",
    "adt.layers[\"counts\"] = adt.X.copy()\n",
    "\n",
    "X = adt.layers[\"counts\"].astype(float)\n",
    "if sp.issparse(X):\n",
    "    X = X.toarray()\n",
    "\n",
    "eps = 1e-6\n",
    "X_log = np.log1p(X + eps)\n",
    "X_clr = X_log - X_log.mean(axis=1, keepdims=True)\n",
    "adt.X = X_clr.astype(np.float32)\n",
    "print(\"ADT CLR shape:\", adt.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77d4849f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# --- ATAC: z-score each LSI dimension ---\\natac = atac_adata.copy()\\nX_atac = atac.X.astype(np.float32)\\n\\nmean = X_atac.mean(axis=0, keepdims=True)\\nstd  = X_atac.std(axis=0, keepdims=True) + 1e-6\\nX_z  = (X_atac - mean) / std\\natac.X = X_z.astype(np.float32)\\nprint(\"ATAC LSI-z shape:\", atac.shape)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# --- ATAC: z-score each LSI dimension ---\n",
    "atac = atac_adata.copy()\n",
    "X_atac = atac.X.astype(np.float32)\n",
    "\n",
    "mean = X_atac.mean(axis=0, keepdims=True)\n",
    "std  = X_atac.std(axis=0, keepdims=True) + 1e-6\n",
    "X_z  = (X_atac - mean) / std\n",
    "atac.X = X_z.astype(np.float32)\n",
    "print(\"ATAC LSI-z shape:\", atac.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e240bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/precepts/ashforda/anaconda3/envs/UniVI_TEA-seq_working_environment/lib/python3.10/site-packages/legacy_api_wrap/__init__.py:88: UserWarning: `flavor='seurat_v3'` expects raw count data, but non-integers were found.\n",
      "  return fn(*args_all, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNA (HVG log1p) shape: (7421, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/precepts/ashforda/anaconda3/envs/UniVI_TEA-seq_working_environment/lib/python3.10/functools.py:889: UserWarning: zero-centering a sparse array/matrix densifies it.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNA scaled shape: (7421, 2000)\n",
      "ADT CLR+z shape: (7421, 47)\n",
      "ATAC LSI-z shape: (7421, 100)\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# ---------- RNA ----------\n",
    "rna = rna_adata.copy()\n",
    "rna.layers[\"counts\"] = rna.X.copy()\n",
    "\n",
    "# Normalize + log1p\n",
    "sc.pp.normalize_total(rna, target_sum=1e4)\n",
    "sc.pp.log1p(rna)\n",
    "\n",
    "# HVGs\n",
    "sc.pp.highly_variable_genes(rna, n_top_genes=2000, flavor=\"seurat_v3\")\n",
    "rna = rna[:, rna.var[\"highly_variable\"]].copy()\n",
    "print(\"RNA (HVG log1p) shape:\", rna.shape)\n",
    "\n",
    "# Z-score per gene across cells (for Gaussian decoder)\n",
    "sc.pp.scale(rna, max_value=10)\n",
    "print(\"RNA scaled shape:\", rna.shape)\n",
    "\n",
    "\n",
    "# ---------- ADT ----------\n",
    "adt = adt_adata.copy()\n",
    "adt.layers[\"counts\"] = adt.X.copy()\n",
    "\n",
    "X = adt.layers[\"counts\"].astype(float)\n",
    "if sp.issparse(X):\n",
    "    X = X.toarray()\n",
    "\n",
    "eps = 1e-6\n",
    "# CLR per cell\n",
    "X_log = np.log1p(X + eps)\n",
    "X_clr = X_log - X_log.mean(axis=1, keepdims=True)\n",
    "\n",
    "# Then per-feature z-score across cells\n",
    "mean_adt = X_clr.mean(axis=0, keepdims=True)\n",
    "std_adt  = X_clr.std(axis=0, keepdims=True) + 1e-6\n",
    "X_clr_z  = (X_clr - mean_adt) / std_adt\n",
    "\n",
    "adt.X = X_clr_z.astype(np.float32)\n",
    "print(\"ADT CLR+z shape:\", adt.shape)\n",
    "\n",
    "\n",
    "# ---------- ATAC ----------\n",
    "atac = atac_adata.copy()\n",
    "\n",
    "X_atac = atac.X.astype(np.float32)  # assume this is LSI already\n",
    "mean_atac = X_atac.mean(axis=0, keepdims=True)\n",
    "std_atac  = X_atac.std(axis=0, keepdims=True) + 1e-6\n",
    "X_z = (X_atac - mean_atac) / std_atac\n",
    "\n",
    "atac.X = X_z.astype(np.float32)\n",
    "print(\"ATAC LSI-z shape:\", atac.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e61bf3",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization code for TEA-seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48d47efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Random split over 7421 cells\n",
      "  Train: 5936\n",
      "  Val  : 742\n",
      "  Test : 743\n",
      "TEA-seq tri-modal train/val/test splits prepared.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# UniVI hyperparameter search (TEA-seq: RNA / ADT / ATAC, tri-modal)\n",
    "# ==============================================\n",
    "import itertools\n",
    "import json\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from univi.config import UniVIConfig, ModalityConfig, TrainingConfig\n",
    "from univi.data import MultiModalDataset\n",
    "from univi.models.univi import UniVIMultiModalVAE\n",
    "from univi.trainer import UniVITrainer\n",
    "from univi import evaluation as univi_eval\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 0. Assumes you already have:\n",
    "#    - rna  : AnnData (RNA, HVGs or other preproc features)\n",
    "#    - adt  : AnnData (ADT features)\n",
    "#    - atac : AnnData (ATAC features, e.g. LSI / gene-body)\n",
    "#      * obs_names aligned across all three:\n",
    "#        rna.obs_names == adt.obs_names == atac.obs_names\n",
    "#    - TEA-seq is label-free in this setup (no celltype key used)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1. Random train/val/test split (label-free)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def make_random_split(\n",
    "    n_cells,\n",
    "    frac_train=0.8,\n",
    "    frac_val=0.1,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns train_idx, val_idx, test_idx (indices 0..n_cells-1),\n",
    "    using a random split.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(n_cells)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    n = idx.shape[0]\n",
    "    n_train = int(frac_train * n)\n",
    "    n_val = int(frac_val * n)\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    train_idx = idx[:n_train]\n",
    "    val_idx   = idx[n_train:n_train + n_val]\n",
    "    test_idx  = idx[n_train + n_val:]\n",
    "\n",
    "    print(f\"Random split over {n} cells\")\n",
    "    print(f\"  Train: {len(train_idx)}\")\n",
    "    print(f\"  Val  : {len(val_idx)}\")\n",
    "    print(f\"  Test : {len(test_idx)}\")\n",
    "\n",
    "    return train_idx, val_idx, test_idx\n",
    "\n",
    "\n",
    "# Use the unified names here\n",
    "n_cells_total = rna.n_obs\n",
    "assert n_cells_total == adt.n_obs == atac.n_obs, \"n_obs mismatch across modalities!\"\n",
    "assert np.array_equal(rna.obs_names, adt.obs_names), \"rna.obs_names != adt.obs_names\"\n",
    "assert np.array_equal(rna.obs_names, atac.obs_names), \"rna.obs_names != atac.obs_names\"\n",
    "\n",
    "train_idx, val_idx, test_idx = make_random_split(\n",
    "    n_cells_total,\n",
    "    frac_train=0.8,\n",
    "    frac_val=0.1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Build view-specific AnnDatas for the split (so we can reuse them)\n",
    "rna_train  = rna[train_idx].copy()\n",
    "rna_val    = rna[val_idx].copy()\n",
    "rna_test   = rna[test_idx].copy()\n",
    "\n",
    "adt_train  = adt[train_idx].copy()\n",
    "adt_val    = adt[val_idx].copy()\n",
    "adt_test   = adt[test_idx].copy()\n",
    "\n",
    "atac_train = atac[train_idx].copy()\n",
    "atac_val   = atac[val_idx].copy()\n",
    "atac_test  = atac[test_idx].copy()\n",
    "\n",
    "# Consistency checks\n",
    "assert np.all(rna_train.obs_names  == adt_train.obs_names)\n",
    "assert np.all(rna_val.obs_names    == adt_val.obs_names)\n",
    "assert np.all(rna_test.obs_names   == adt_test.obs_names)\n",
    "assert np.all(rna_train.obs_names  == atac_train.obs_names)\n",
    "assert np.all(rna_val.obs_names    == atac_val.obs_names)\n",
    "assert np.all(rna_test.obs_names   == atac_test.obs_names)\n",
    "\n",
    "print(\"TEA-seq tri-modal train/val/test splits prepared.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee6c77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train+Val cells in dataset: 6678\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# 2. Build a base MultiModalDataset (train+val only)\n",
    "#    – we will reuse this across all hyperparameters.\n",
    "# ------------------------------------------------------\n",
    "\n",
    "adata_trainval = {\n",
    "    \"rna\":  rna[np.concatenate([train_idx, val_idx])].copy(),\n",
    "    \"adt\":  adt[np.concatenate([train_idx, val_idx])].copy(),\n",
    "    \"atac\": atac[np.concatenate([train_idx, val_idx])].copy(),\n",
    "}\n",
    "\n",
    "trainval_obs_names = adata_trainval[\"rna\"].obs_names.to_numpy()\n",
    "assert np.array_equal(trainval_obs_names, adata_trainval[\"adt\"].obs_names)\n",
    "assert np.array_equal(trainval_obs_names, adata_trainval[\"atac\"].obs_names)\n",
    "\n",
    "dataset = MultiModalDataset(\n",
    "    adata_dict=adata_trainval,\n",
    "    X_key=\"X\",          # rna.X, adt.X, atac.X used as UniVI inputs\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "n_cells_tv = dataset.n_cells\n",
    "print(\"Train+Val cells in dataset:\", n_cells_tv)\n",
    "\n",
    "# Remap train/val indices into [0..n_cells_tv)\n",
    "name_to_pos = {name: i for i, name in enumerate(trainval_obs_names)}\n",
    "train_idx_ds = np.array([name_to_pos[n] for n in rna_train.obs_names])\n",
    "val_idx_ds   = np.array([name_to_pos[n] for n in rna_val.obs_names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "308a9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 3. Hyperparameter search space (arch + regularization)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Architecture options; tweak as needed\n",
    "rna_arch_options = [\n",
    "    {\"name\": \"rna_med2\",  \"enc\": [512, 256],         \"dec\": [256, 512]},\n",
    "    {\"name\": \"rna_wide2\", \"enc\": [1024, 512],        \"dec\": [512, 1024]},\n",
    "    {\"name\": \"rna_wide3\", \"enc\": [1024, 512, 256],   \"dec\": [256, 512, 1024]},\n",
    "]\n",
    "\n",
    "adt_arch_options = [\n",
    "    {\"name\": \"adt_small2\", \"enc\": [128, 64],      \"dec\": [64, 128]},\n",
    "    {\"name\": \"adt_med2\",   \"enc\": [256, 128],     \"dec\": [128, 256]},\n",
    "]\n",
    "\n",
    "atac_arch_options = [\n",
    "    {\"name\": \"atac_small2\", \"enc\": [128, 64],      \"dec\": [64, 128]},\n",
    "    {\"name\": \"atac_med2\",   \"enc\": [256, 128],     \"dec\": [128, 256]},\n",
    "    {\"name\": \"atac_wide2\",  \"enc\": [512, 256],     \"dec\": [256, 512]},\n",
    "]\n",
    "\n",
    "search_space = {\n",
    "    \"latent_dim\":        [20, 32, 40, 50, 64, 72, 86, 100, 124, 156, 200],\n",
    "    \"beta\":              [0.0, 1.0, 10.0, 40.0, 60.0, 80.0, 100.0, 140.0, 180.0, 240.0, 300.0, 400.0],\n",
    "    \"gamma\":             [0.0, 40.0, 60.0, 80.0, 100.0, 140.0, 180.0, 240.0, 300.0, 400.0, 500.0, 1000.0],\n",
    "    \"lr\":                [1e-3, 5e-4],\n",
    "    \"weight_decay\":      [1e-4, 1e-5],\n",
    "    \"encoder_dropout\":   [0.0, 0.1],\n",
    "    \"decoder_batchnorm\": [False, True],\n",
    "    \"rna_arch\":          rna_arch_options,\n",
    "    \"adt_arch\":          adt_arch_options,\n",
    "    \"atac_arch\":         atac_arch_options,\n",
    "}\n",
    "\n",
    "MAX_CONFIGS = 120  # how many random configs to try\n",
    "\n",
    "\n",
    "def iter_hparam_configs(space_dict, max_configs=MAX_CONFIGS, seed=0):\n",
    "    \"\"\"\n",
    "    Random sampler over the hyperparameter space.\n",
    "    Each config independently samples a value for each key.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    keys = list(space_dict.keys())\n",
    "    for _ in range(max_configs):\n",
    "        hp = {}\n",
    "        for k in keys:\n",
    "            options = space_dict[k]\n",
    "            idx = rng.integers(len(options))\n",
    "            hp[k] = options[idx]\n",
    "        yield hp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "185ca570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 4. Helper to build UniVI + TrainingConfig from hparams\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def build_univi_and_train_cfg(hp):\n",
    "    latent_dim        = hp[\"latent_dim\"]\n",
    "    beta              = hp[\"beta\"]\n",
    "    gamma             = hp[\"gamma\"]\n",
    "    lr                = hp[\"lr\"]\n",
    "    weight_decay      = hp[\"weight_decay\"]\n",
    "    encoder_dropout   = hp[\"encoder_dropout\"]      # from search space\n",
    "    decoder_batchnorm = hp[\"decoder_batchnorm\"]    # from search space\n",
    "\n",
    "    rna_arch  = hp[\"rna_arch\"]\n",
    "    adt_arch  = hp[\"adt_arch\"]\n",
    "    atac_arch = hp[\"atac_arch\"]\n",
    "\n",
    "    # -------- modality configs (no dropout here) --------\n",
    "    mod_rna = ModalityConfig(\n",
    "        name=\"rna\",\n",
    "        input_dim=rna.n_vars,\n",
    "        encoder_hidden=rna_arch[\"enc\"],\n",
    "        decoder_hidden=rna_arch[\"dec\"],\n",
    "        likelihood=\"gaussian\",       # or \"nb\" if rna.X are counts\n",
    "    )\n",
    "\n",
    "    mod_adt = ModalityConfig(\n",
    "        name=\"adt\",\n",
    "        input_dim=adt.X.shape[1],\n",
    "        encoder_hidden=adt_arch[\"enc\"],\n",
    "        decoder_hidden=adt_arch[\"dec\"],\n",
    "        likelihood=\"gaussian\",       # CLR / standardized ADT\n",
    "    )\n",
    "\n",
    "    mod_atac = ModalityConfig(\n",
    "        name=\"atac\",\n",
    "        input_dim=atac.X.shape[1],\n",
    "        encoder_hidden=atac_arch[\"enc\"],\n",
    "        decoder_hidden=atac_arch[\"dec\"],\n",
    "        likelihood=\"gaussian\",       # LSI / gene-body\n",
    "    )\n",
    "\n",
    "    # -------- global UniVI config (dropout + batchnorm here) --------\n",
    "    univi_cfg = UniVIConfig(\n",
    "        latent_dim=latent_dim,\n",
    "        modalities=[mod_rna, mod_adt, mod_atac],\n",
    "        beta=beta,\n",
    "        gamma=gamma,\n",
    "        encoder_dropout=encoder_dropout,\n",
    "        # you can also search this if you want:\n",
    "        decoder_dropout=0.0,\n",
    "        encoder_batchnorm=True,\n",
    "        decoder_batchnorm=decoder_batchnorm,\n",
    "        # set annealing if you want non-default behavior:\n",
    "        # kl_anneal_start=0,\n",
    "        # kl_anneal_end=0,\n",
    "        # align_anneal_start=0,\n",
    "        # align_anneal_end=0,\n",
    "    )\n",
    "\n",
    "    # -------- training config --------\n",
    "    train_cfg = TrainingConfig(\n",
    "        n_epochs=200,\n",
    "        batch_size=256,\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        device=device,\n",
    "        log_every=10,\n",
    "        num_workers=0,\n",
    "        seed=42,\n",
    "        early_stopping=True,\n",
    "        patience=20,\n",
    "        min_delta=0.0,\n",
    "    )\n",
    "\n",
    "    return univi_cfg, train_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44c800be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 5. Train + evaluate one hyperparameter configuration (TEA-seq tri-modal)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def evaluate_config(hp, config_id):\n",
    "    \"\"\"\n",
    "    Train a UniVI tri-modal model with hyperparameters hp, evaluate on val set.\n",
    "\n",
    "    Returns a dict with:\n",
    "      - best_val_loss\n",
    "      - FOSCTTM for each pair (RNA–ADT, RNA–ATAC, ADT–ATAC) on val\n",
    "      - global modality mixing score on val\n",
    "      - composite score for hyperparam selection (lower = better)\n",
    "      - training history and hp\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"[Config {config_id}] Hyperparameters:\")\n",
    "    pretty_hp = {\n",
    "        **{k: v for k, v in hp.items() if k not in (\"rna_arch\", \"adt_arch\", \"atac_arch\")},\n",
    "        \"rna_arch\": hp[\"rna_arch\"][\"name\"],\n",
    "        \"adt_arch\": hp[\"adt_arch\"][\"name\"],\n",
    "        \"atac_arch\": hp[\"atac_arch\"][\"name\"],\n",
    "    }\n",
    "    print(json.dumps(pretty_hp, indent=2))\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    univi_cfg, train_cfg = build_univi_and_train_cfg(hp)\n",
    "\n",
    "    model = UniVIMultiModalVAE(univi_cfg).to(device)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_ds = Subset(dataset, train_idx_ds)\n",
    "    val_ds   = Subset(dataset, val_idx_ds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=train_cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=train_cfg.num_workers,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=train_cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=train_cfg.num_workers,\n",
    "    )\n",
    "\n",
    "    trainer = UniVITrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        train_cfg=train_cfg,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    history = trainer.fit()\n",
    "    t1 = time.time()\n",
    "\n",
    "    best_val    = float(min(trainer.history[\"val_loss\"]))\n",
    "    final_train = float(trainer.history[\"train_loss\"][-1])\n",
    "    final_beta  = float(trainer.history[\"beta\"][-1])\n",
    "    final_gamma = float(trainer.history[\"gamma\"][-1])\n",
    "    elapsed_min = (t1 - t0) / 60.0\n",
    "\n",
    "    # Latent embeddings for validation cells (from val AnnDatas, not the dataset)\n",
    "    z_rna_val  = trainer.encode_modality(rna_val,  modality=\"rna\")\n",
    "    z_adt_val  = trainer.encode_modality(adt_val,  modality=\"adt\")\n",
    "    z_atac_val = trainer.encode_modality(atac_val, modality=\"atac\")\n",
    "\n",
    "    # Pairwise FOSCTTM\n",
    "    fos_rna_adt  = float(univi_eval.compute_foscttm(z_rna_val,  z_adt_val))\n",
    "    fos_rna_atac = float(univi_eval.compute_foscttm(z_rna_val,  z_atac_val))\n",
    "    fos_adt_atac = float(univi_eval.compute_foscttm(z_adt_val, z_atac_val))\n",
    "\n",
    "    fos_mean = float((fos_rna_adt + fos_rna_atac + fos_adt_atac) / 3.0)\n",
    "\n",
    "    # Global mixing score (lower = better, same convention as your CITE-seq code)\n",
    "    Z_joint_val = np.concatenate([z_rna_val, z_adt_val, z_atac_val], axis=0)\n",
    "    modality_labels_val = np.array(\n",
    "        [\"rna\"]  * z_rna_val.shape[0]\n",
    "        + [\"adt\"]  * z_adt_val.shape[0]\n",
    "        + [\"atac\"] * z_atac_val.shape[0]\n",
    "    )\n",
    "\n",
    "    mixing_score = float(univi_eval.compute_modality_mixing(\n",
    "        Z_joint_val,\n",
    "        modality_labels_val,\n",
    "        k=20,\n",
    "    ))\n",
    "\n",
    "    # Composite score: lower val_loss, FOSCTTM, and mixing are all better\n",
    "    score = best_val * (1.0 + fos_mean) * (1.0 + mixing_score)\n",
    "\n",
    "    result = {\n",
    "        \"config_id\": config_id,\n",
    "        \"best_val_loss\": best_val,\n",
    "        \"final_train_loss\": final_train,\n",
    "        \"final_beta\": final_beta,\n",
    "        \"final_gamma\": final_gamma,\n",
    "        \"fos_rna_adt_val\": fos_rna_adt,\n",
    "        \"fos_rna_atac_val\": fos_rna_atac,\n",
    "        \"fos_adt_atac_val\": fos_adt_atac,\n",
    "        \"fos_mean_val\": fos_mean,\n",
    "        \"mixing_score_val\": mixing_score,\n",
    "        \"score\": float(score),\n",
    "        \"minutes\": elapsed_min,\n",
    "        \"history\": history,\n",
    "        \"hp\": deepcopy(hp),\n",
    "    }\n",
    "\n",
    "    print(f\"[Config {config_id}] Done in {elapsed_min:.1f} min\")\n",
    "    print(f\"  best_val_loss              = {best_val:.3f}\")\n",
    "    print(f\"  FOSCTTM (RNA vs ADT, val)  = {fos_rna_adt:.4f}\")\n",
    "    print(f\"  FOSCTTM (RNA vs ATAC, val) = {fos_rna_atac:.4f}\")\n",
    "    print(f\"[Config {config_id}] FOSCTTM (ADT vs ATAC, val) = {fos_adt_atac:.4f}\")\n",
    "    print(f\"  Mean FOSCTTM (3 pairs)     = {fos_mean:.4f}\")\n",
    "    print(f\"  Modality mixing (k=20)     = {mixing_score:.4f}\")\n",
    "    print(f\"  Composite score            = {score:.2f}\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7dbe4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 23:11:44,140] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-19 23:11:44 - INFO - TrainingConfig:\n",
      "[2025-11-19 23:11:44,142] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-19 23:11:44 - INFO -   n_epochs: 200\n",
      "[2025-11-19 23:11:44,146] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-19 23:11:44 - INFO -   batch_size: 256\n",
      "[2025-11-19 23:11:44,156] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-19 23:11:44 - INFO -   lr: 0.001\n",
      "[2025-11-19 23:11:44,158] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-19 23:11:44 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-19 23:11:44,165] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-19 23:11:44 - INFO -   device: cuda\n",
      "[2025-11-19 23:11:44,167] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-19 23:11:44 - INFO -   log_every: 10\n",
      "[2025-11-19 23:11:44,168] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-19 23:11:44 - INFO -   grad_clip: None\n",
      "[2025-11-19 23:11:44,169] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-19 23:11:44 - INFO -   num_workers: 0\n",
      "[2025-11-19 23:11:44,170] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-19 23:11:44 - INFO -   seed: 42\n",
      "[2025-11-19 23:11:44,171] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-19 23:11:44 - INFO -   early_stopping: True\n",
      "[2025-11-19 23:11:44,172] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-19 23:11:44 - INFO -   patience: 20\n",
      "[2025-11-19 23:11:44,174] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-19 23:11:44 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[Config 1] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 156,\n",
      "  \"beta\": 240.0,\n",
      "  \"gamma\": 180.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.0,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_med2\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_wide2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2351dd16d54dac8f9bc80c63548d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 23:11:51,112] [UniVITrainer] [INFO] [Epoch 001] Train loss: 6900.0410 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:11:51 - INFO - [Epoch 001] Train loss: 6900.0410 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:11:51,953] [UniVITrainer] [INFO] [Epoch 001] Val loss: 2012.9840 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:11:51 - INFO - [Epoch 001] Val loss: 2012.9840 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:11:51,969] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 2012.9840\n",
      "2025-11-19 23:11:51 - INFO - [Epoch 001] New best val loss: 2012.9840\n",
      "[2025-11-19 23:12:00,004] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1203.1804\n",
      "2025-11-19 23:12:00 - INFO - [Epoch 002] New best val loss: 1203.1804\n",
      "[2025-11-19 23:12:08,021] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1005.3835\n",
      "2025-11-19 23:12:08 - INFO - [Epoch 003] New best val loss: 1005.3835\n",
      "[2025-11-19 23:12:15,801] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 944.9690\n",
      "2025-11-19 23:12:15 - INFO - [Epoch 004] New best val loss: 944.9690\n",
      "[2025-11-19 23:12:23,838] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 914.4583\n",
      "2025-11-19 23:12:23 - INFO - [Epoch 005] New best val loss: 914.4583\n",
      "[2025-11-19 23:12:31,614] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 884.3416\n",
      "2025-11-19 23:12:31 - INFO - [Epoch 006] New best val loss: 884.3416\n",
      "[2025-11-19 23:12:39,352] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 870.1510\n",
      "2025-11-19 23:12:39 - INFO - [Epoch 007] New best val loss: 870.1510\n",
      "[2025-11-19 23:12:46,955] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 861.6271\n",
      "2025-11-19 23:12:46 - INFO - [Epoch 008] New best val loss: 861.6271\n",
      "[2025-11-19 23:12:54,395] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 852.5967\n",
      "2025-11-19 23:12:54 - INFO - [Epoch 009] New best val loss: 852.5967\n",
      "[2025-11-19 23:13:01,165] [UniVITrainer] [INFO] [Epoch 010] Train loss: 834.0108 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:13:01 - INFO - [Epoch 010] Train loss: 834.0108 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:13:01,999] [UniVITrainer] [INFO] [Epoch 010] Val loss: 843.5710 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:13:01 - INFO - [Epoch 010] Val loss: 843.5710 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:13:02,013] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 843.5710\n",
      "2025-11-19 23:13:02 - INFO - [Epoch 010] New best val loss: 843.5710\n",
      "[2025-11-19 23:13:09,666] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 836.2458\n",
      "2025-11-19 23:13:09 - INFO - [Epoch 011] New best val loss: 836.2458\n",
      "[2025-11-19 23:13:17,258] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 830.2184\n",
      "2025-11-19 23:13:17 - INFO - [Epoch 012] New best val loss: 830.2184\n",
      "[2025-11-19 23:13:25,479] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 826.0407\n",
      "2025-11-19 23:13:25 - INFO - [Epoch 013] New best val loss: 826.0407\n",
      "[2025-11-19 23:13:35,318] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 823.6093\n",
      "2025-11-19 23:13:35 - INFO - [Epoch 014] New best val loss: 823.6093\n",
      "[2025-11-19 23:13:45,499] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 818.9429\n",
      "2025-11-19 23:13:45 - INFO - [Epoch 015] New best val loss: 818.9429\n",
      "[2025-11-19 23:13:56,057] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 815.5535\n",
      "2025-11-19 23:13:56 - INFO - [Epoch 016] New best val loss: 815.5535\n",
      "[2025-11-19 23:14:06,238] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 814.9374\n",
      "2025-11-19 23:14:06 - INFO - [Epoch 017] New best val loss: 814.9374\n",
      "[2025-11-19 23:14:16,827] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 810.8688\n",
      "2025-11-19 23:14:16 - INFO - [Epoch 018] New best val loss: 810.8688\n",
      "[2025-11-19 23:14:25,607] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 809.3819\n",
      "2025-11-19 23:14:25 - INFO - [Epoch 019] New best val loss: 809.3819\n",
      "[2025-11-19 23:14:34,505] [UniVITrainer] [INFO] [Epoch 020] Train loss: 791.8528 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:14:34 - INFO - [Epoch 020] Train loss: 791.8528 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:14:35,591] [UniVITrainer] [INFO] [Epoch 020] Val loss: 809.1167 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:14:35 - INFO - [Epoch 020] Val loss: 809.1167 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:14:36,011] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 809.1167\n",
      "2025-11-19 23:14:36 - INFO - [Epoch 020] New best val loss: 809.1167\n",
      "[2025-11-19 23:14:46,414] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 807.4694\n",
      "2025-11-19 23:14:46 - INFO - [Epoch 021] New best val loss: 807.4694\n",
      "[2025-11-19 23:14:55,633] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 806.2136\n",
      "2025-11-19 23:14:55 - INFO - [Epoch 022] New best val loss: 806.2136\n",
      "[2025-11-19 23:15:15,914] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 805.0263\n",
      "2025-11-19 23:15:15 - INFO - [Epoch 024] New best val loss: 805.0263\n",
      "[2025-11-19 23:15:26,427] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 803.0833\n",
      "2025-11-19 23:15:26 - INFO - [Epoch 025] New best val loss: 803.0833\n",
      "[2025-11-19 23:15:36,675] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 799.1283\n",
      "2025-11-19 23:15:36 - INFO - [Epoch 026] New best val loss: 799.1283\n",
      "[2025-11-19 23:16:07,202] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 795.8301\n",
      "2025-11-19 23:16:07 - INFO - [Epoch 029] New best val loss: 795.8301\n",
      "[2025-11-19 23:16:15,982] [UniVITrainer] [INFO] [Epoch 030] Train loss: 781.8418 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:16:15 - INFO - [Epoch 030] Train loss: 781.8418 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:16:17,087] [UniVITrainer] [INFO] [Epoch 030] Val loss: 794.9924 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:16:17 - INFO - [Epoch 030] Val loss: 794.9924 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:16:17,171] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 794.9924\n",
      "2025-11-19 23:16:17 - INFO - [Epoch 030] New best val loss: 794.9924\n",
      "[2025-11-19 23:16:36,807] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 793.8697\n",
      "2025-11-19 23:16:36 - INFO - [Epoch 032] New best val loss: 793.8697\n",
      "[2025-11-19 23:16:47,319] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 792.9170\n",
      "2025-11-19 23:16:47 - INFO - [Epoch 033] New best val loss: 792.9170\n",
      "[2025-11-19 23:16:57,856] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 791.1282\n",
      "2025-11-19 23:16:57 - INFO - [Epoch 034] New best val loss: 791.1282\n",
      "[2025-11-19 23:17:27,836] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 790.8169\n",
      "2025-11-19 23:17:27 - INFO - [Epoch 037] New best val loss: 790.8169\n",
      "[2025-11-19 23:17:38,238] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 790.6235\n",
      "2025-11-19 23:17:38 - INFO - [Epoch 038] New best val loss: 790.6235\n",
      "[2025-11-19 23:17:48,750] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 788.5443\n",
      "2025-11-19 23:17:48 - INFO - [Epoch 039] New best val loss: 788.5443\n",
      "[2025-11-19 23:17:57,651] [UniVITrainer] [INFO] [Epoch 040] Train loss: 776.4348 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:17:57 - INFO - [Epoch 040] Train loss: 776.4348 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:17:58,754] [UniVITrainer] [INFO] [Epoch 040] Val loss: 787.6811 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:17:58 - INFO - [Epoch 040] Val loss: 787.6811 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:17:59,184] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 787.6811\n",
      "2025-11-19 23:17:59 - INFO - [Epoch 040] New best val loss: 787.6811\n",
      "[2025-11-19 23:18:09,621] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 787.4060\n",
      "2025-11-19 23:18:09 - INFO - [Epoch 041] New best val loss: 787.4060\n",
      "[2025-11-19 23:18:20,147] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 786.6508\n",
      "2025-11-19 23:18:20 - INFO - [Epoch 042] New best val loss: 786.6508\n",
      "[2025-11-19 23:18:30,444] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 785.8953\n",
      "2025-11-19 23:18:30 - INFO - [Epoch 043] New best val loss: 785.8953\n",
      "[2025-11-19 23:19:00,780] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 784.8532\n",
      "2025-11-19 23:19:00 - INFO - [Epoch 046] New best val loss: 784.8532\n",
      "[2025-11-19 23:19:30,983] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 784.4553\n",
      "2025-11-19 23:19:30 - INFO - [Epoch 049] New best val loss: 784.4553\n",
      "[2025-11-19 23:19:39,980] [UniVITrainer] [INFO] [Epoch 050] Train loss: 782.9580 (beta=240.000, gamma=180.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 23:19:39 - INFO - [Epoch 050] Train loss: 782.9580 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:19:41,077] [UniVITrainer] [INFO] [Epoch 050] Val loss: 784.6361 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:19:41 - INFO - [Epoch 050] Val loss: 784.6361 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:19:51,392] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 783.2460\n",
      "2025-11-19 23:19:51 - INFO - [Epoch 051] New best val loss: 783.2460\n",
      "[2025-11-19 23:20:11,604] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 782.9938\n",
      "2025-11-19 23:20:11 - INFO - [Epoch 053] New best val loss: 782.9938\n",
      "[2025-11-19 23:20:21,924] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 782.2261\n",
      "2025-11-19 23:20:21 - INFO - [Epoch 054] New best val loss: 782.2261\n",
      "[2025-11-19 23:21:12,082] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 780.1767\n",
      "2025-11-19 23:21:12 - INFO - [Epoch 059] New best val loss: 780.1767\n",
      "[2025-11-19 23:21:21,100] [UniVITrainer] [INFO] [Epoch 060] Train loss: 770.6018 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:21:21 - INFO - [Epoch 060] Train loss: 770.6018 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:21:22,149] [UniVITrainer] [INFO] [Epoch 060] Val loss: 780.3487 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:21:22 - INFO - [Epoch 060] Val loss: 780.3487 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:21:52,387] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 779.1448\n",
      "2025-11-19 23:21:52 - INFO - [Epoch 063] New best val loss: 779.1448\n",
      "[2025-11-19 23:22:13,475] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 778.8694\n",
      "2025-11-19 23:22:13 - INFO - [Epoch 065] New best val loss: 778.8694\n",
      "[2025-11-19 23:22:34,148] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 778.0707\n",
      "2025-11-19 23:22:34 - INFO - [Epoch 067] New best val loss: 778.0707\n",
      "[2025-11-19 23:22:54,978] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 777.8770\n",
      "2025-11-19 23:22:54 - INFO - [Epoch 069] New best val loss: 777.8770\n",
      "[2025-11-19 23:23:04,012] [UniVITrainer] [INFO] [Epoch 070] Train loss: 770.0668 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:23:04 - INFO - [Epoch 070] Train loss: 770.0668 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:23:05,108] [UniVITrainer] [INFO] [Epoch 070] Val loss: 777.8285 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:23:05 - INFO - [Epoch 070] Val loss: 777.8285 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:23:05,520] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 777.8285\n",
      "2025-11-19 23:23:05 - INFO - [Epoch 070] New best val loss: 777.8285\n",
      "[2025-11-19 23:23:26,157] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 777.1488\n",
      "2025-11-19 23:23:26 - INFO - [Epoch 072] New best val loss: 777.1488\n",
      "[2025-11-19 23:23:36,798] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 776.8440\n",
      "2025-11-19 23:23:36 - INFO - [Epoch 073] New best val loss: 776.8440\n",
      "[2025-11-19 23:23:57,148] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 776.7266\n",
      "2025-11-19 23:23:57 - INFO - [Epoch 075] New best val loss: 776.7266\n",
      "[2025-11-19 23:24:07,552] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 776.6813\n",
      "2025-11-19 23:24:07 - INFO - [Epoch 076] New best val loss: 776.6813\n",
      "[2025-11-19 23:24:28,175] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 776.0788\n",
      "2025-11-19 23:24:28 - INFO - [Epoch 078] New best val loss: 776.0788\n",
      "[2025-11-19 23:24:38,593] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 776.0189\n",
      "2025-11-19 23:24:38 - INFO - [Epoch 079] New best val loss: 776.0189\n",
      "[2025-11-19 23:24:47,498] [UniVITrainer] [INFO] [Epoch 080] Train loss: 769.7464 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:24:47 - INFO - [Epoch 080] Train loss: 769.7464 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:24:48,594] [UniVITrainer] [INFO] [Epoch 080] Val loss: 775.9191 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:24:48 - INFO - [Epoch 080] Val loss: 775.9191 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:24:49,015] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 775.9191\n",
      "2025-11-19 23:24:49 - INFO - [Epoch 080] New best val loss: 775.9191\n",
      "[2025-11-19 23:24:59,238] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 775.8325\n",
      "2025-11-19 23:24:59 - INFO - [Epoch 081] New best val loss: 775.8325\n",
      "[2025-11-19 23:25:09,674] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 775.1779\n",
      "2025-11-19 23:25:09 - INFO - [Epoch 082] New best val loss: 775.1779\n",
      "[2025-11-19 23:25:40,288] [UniVITrainer] [INFO] [Epoch 085] New best val loss: 774.8567\n",
      "2025-11-19 23:25:40 - INFO - [Epoch 085] New best val loss: 774.8567\n",
      "[2025-11-19 23:26:20,565] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 774.7911\n",
      "2025-11-19 23:26:20 - INFO - [Epoch 089] New best val loss: 774.7911\n",
      "[2025-11-19 23:26:29,462] [UniVITrainer] [INFO] [Epoch 090] Train loss: 768.3599 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:26:29 - INFO - [Epoch 090] Train loss: 768.3599 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:26:30,483] [UniVITrainer] [INFO] [Epoch 090] Val loss: 774.2496 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:26:30 - INFO - [Epoch 090] Val loss: 774.2496 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:26:30,944] [UniVITrainer] [INFO] [Epoch 090] New best val loss: 774.2496\n",
      "2025-11-19 23:26:30 - INFO - [Epoch 090] New best val loss: 774.2496\n",
      "[2025-11-19 23:26:41,714] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 773.8335\n",
      "2025-11-19 23:26:41 - INFO - [Epoch 091] New best val loss: 773.8335\n",
      "[2025-11-19 23:27:12,459] [UniVITrainer] [INFO] [Epoch 094] New best val loss: 773.7600\n",
      "2025-11-19 23:27:12 - INFO - [Epoch 094] New best val loss: 773.7600\n",
      "[2025-11-19 23:27:32,917] [UniVITrainer] [INFO] [Epoch 096] New best val loss: 773.6858\n",
      "2025-11-19 23:27:32 - INFO - [Epoch 096] New best val loss: 773.6858\n",
      "[2025-11-19 23:27:53,550] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 773.3165\n",
      "2025-11-19 23:27:53 - INFO - [Epoch 098] New best val loss: 773.3165\n",
      "[2025-11-19 23:28:12,290] [UniVITrainer] [INFO] [Epoch 100] Train loss: 769.9968 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:28:12 - INFO - [Epoch 100] Train loss: 769.9968 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:28:13,248] [UniVITrainer] [INFO] [Epoch 100] Val loss: 773.1209 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:28:13 - INFO - [Epoch 100] Val loss: 773.1209 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:28:13,697] [UniVITrainer] [INFO] [Epoch 100] New best val loss: 773.1209\n",
      "2025-11-19 23:28:13 - INFO - [Epoch 100] New best val loss: 773.1209\n",
      "[2025-11-19 23:28:34,289] [UniVITrainer] [INFO] [Epoch 102] New best val loss: 773.0852\n",
      "2025-11-19 23:28:34 - INFO - [Epoch 102] New best val loss: 773.0852\n",
      "[2025-11-19 23:28:44,668] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 772.9312\n",
      "2025-11-19 23:28:44 - INFO - [Epoch 103] New best val loss: 772.9312\n",
      "[2025-11-19 23:28:55,038] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 772.9011\n",
      "2025-11-19 23:28:55 - INFO - [Epoch 104] New best val loss: 772.9011\n",
      "[2025-11-19 23:29:05,485] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 772.8118\n",
      "2025-11-19 23:29:05 - INFO - [Epoch 105] New best val loss: 772.8118\n",
      "[2025-11-19 23:29:25,748] [UniVITrainer] [INFO] [Epoch 107] New best val loss: 772.6225\n",
      "2025-11-19 23:29:25 - INFO - [Epoch 107] New best val loss: 772.6225\n",
      "[2025-11-19 23:29:53,555] [UniVITrainer] [INFO] [Epoch 110] Train loss: 765.4900 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:29:53 - INFO - [Epoch 110] Train loss: 765.4900 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:29:54,653] [UniVITrainer] [INFO] [Epoch 110] Val loss: 772.2399 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:29:54 - INFO - [Epoch 110] Val loss: 772.2399 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:29:55,093] [UniVITrainer] [INFO] [Epoch 110] New best val loss: 772.2399\n",
      "2025-11-19 23:29:55 - INFO - [Epoch 110] New best val loss: 772.2399\n",
      "[2025-11-19 23:30:05,536] [UniVITrainer] [INFO] [Epoch 111] New best val loss: 772.1939\n",
      "2025-11-19 23:30:05 - INFO - [Epoch 111] New best val loss: 772.1939\n",
      "[2025-11-19 23:30:25,630] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 772.1493\n",
      "2025-11-19 23:30:25 - INFO - [Epoch 113] New best val loss: 772.1493\n",
      "[2025-11-19 23:30:35,755] [UniVITrainer] [INFO] [Epoch 114] New best val loss: 772.1453\n",
      "2025-11-19 23:30:35 - INFO - [Epoch 114] New best val loss: 772.1453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 23:31:04,579] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 772.1107\n",
      "2025-11-19 23:31:04 - INFO - [Epoch 117] New best val loss: 772.1107\n",
      "[2025-11-19 23:31:14,411] [UniVITrainer] [INFO] [Epoch 118] New best val loss: 771.8345\n",
      "2025-11-19 23:31:14 - INFO - [Epoch 118] New best val loss: 771.8345\n",
      "[2025-11-19 23:31:24,457] [UniVITrainer] [INFO] [Epoch 119] New best val loss: 771.6207\n",
      "2025-11-19 23:31:24 - INFO - [Epoch 119] New best val loss: 771.6207\n",
      "[2025-11-19 23:31:32,881] [UniVITrainer] [INFO] [Epoch 120] Train loss: 765.7484 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:31:32 - INFO - [Epoch 120] Train loss: 765.7484 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:31:33,945] [UniVITrainer] [INFO] [Epoch 120] Val loss: 771.7509 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:31:33 - INFO - [Epoch 120] Val loss: 771.7509 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:31:43,971] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 771.5199\n",
      "2025-11-19 23:31:43 - INFO - [Epoch 121] New best val loss: 771.5199\n",
      "[2025-11-19 23:31:53,774] [UniVITrainer] [INFO] [Epoch 122] New best val loss: 771.3781\n",
      "2025-11-19 23:31:53 - INFO - [Epoch 122] New best val loss: 771.3781\n",
      "[2025-11-19 23:32:31,785] [UniVITrainer] [INFO] [Epoch 126] New best val loss: 771.2949\n",
      "2025-11-19 23:32:31 - INFO - [Epoch 126] New best val loss: 771.2949\n",
      "[2025-11-19 23:33:01,001] [UniVITrainer] [INFO] [Epoch 129] New best val loss: 770.9882\n",
      "2025-11-19 23:33:01 - INFO - [Epoch 129] New best val loss: 770.9882\n",
      "[2025-11-19 23:33:09,302] [UniVITrainer] [INFO] [Epoch 130] Train loss: 768.8305 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:33:09 - INFO - [Epoch 130] Train loss: 768.8305 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:33:10,277] [UniVITrainer] [INFO] [Epoch 130] Val loss: 771.0976 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:33:10 - INFO - [Epoch 130] Val loss: 771.0976 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:33:58,310] [UniVITrainer] [INFO] [Epoch 135] New best val loss: 770.9726\n",
      "2025-11-19 23:33:58 - INFO - [Epoch 135] New best val loss: 770.9726\n",
      "[2025-11-19 23:34:08,328] [UniVITrainer] [INFO] [Epoch 136] New best val loss: 770.7869\n",
      "2025-11-19 23:34:08 - INFO - [Epoch 136] New best val loss: 770.7869\n",
      "[2025-11-19 23:34:27,962] [UniVITrainer] [INFO] [Epoch 138] New best val loss: 770.6953\n",
      "2025-11-19 23:34:27 - INFO - [Epoch 138] New best val loss: 770.6953\n",
      "[2025-11-19 23:34:38,013] [UniVITrainer] [INFO] [Epoch 139] New best val loss: 770.6277\n",
      "2025-11-19 23:34:38 - INFO - [Epoch 139] New best val loss: 770.6277\n",
      "[2025-11-19 23:34:46,384] [UniVITrainer] [INFO] [Epoch 140] Train loss: 766.3990 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:34:46 - INFO - [Epoch 140] Train loss: 766.3990 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:34:47,450] [UniVITrainer] [INFO] [Epoch 140] Val loss: 770.6225 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:34:47 - INFO - [Epoch 140] Val loss: 770.6225 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:34:47,875] [UniVITrainer] [INFO] [Epoch 140] New best val loss: 770.6225\n",
      "2025-11-19 23:34:47 - INFO - [Epoch 140] New best val loss: 770.6225\n",
      "[2025-11-19 23:35:16,943] [UniVITrainer] [INFO] [Epoch 143] New best val loss: 770.4810\n",
      "2025-11-19 23:35:16 - INFO - [Epoch 143] New best val loss: 770.4810\n",
      "[2025-11-19 23:35:46,157] [UniVITrainer] [INFO] [Epoch 146] New best val loss: 770.4508\n",
      "2025-11-19 23:35:46 - INFO - [Epoch 146] New best val loss: 770.4508\n",
      "[2025-11-19 23:35:56,096] [UniVITrainer] [INFO] [Epoch 147] New best val loss: 770.3373\n",
      "2025-11-19 23:35:56 - INFO - [Epoch 147] New best val loss: 770.3373\n",
      "[2025-11-19 23:36:15,918] [UniVITrainer] [INFO] [Epoch 149] New best val loss: 770.2312\n",
      "2025-11-19 23:36:15 - INFO - [Epoch 149] New best val loss: 770.2312\n",
      "[2025-11-19 23:36:24,435] [UniVITrainer] [INFO] [Epoch 150] Train loss: 768.2601 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:36:24 - INFO - [Epoch 150] Train loss: 768.2601 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:36:25,503] [UniVITrainer] [INFO] [Epoch 150] Val loss: 770.2775 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:36:25 - INFO - [Epoch 150] Val loss: 770.2775 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:36:45,148] [UniVITrainer] [INFO] [Epoch 152] New best val loss: 769.9734\n",
      "2025-11-19 23:36:45 - INFO - [Epoch 152] New best val loss: 769.9734\n",
      "[2025-11-19 23:37:43,965] [UniVITrainer] [INFO] [Epoch 158] New best val loss: 769.8225\n",
      "2025-11-19 23:37:43 - INFO - [Epoch 158] New best val loss: 769.8225\n",
      "[2025-11-19 23:38:01,804] [UniVITrainer] [INFO] [Epoch 160] Train loss: 767.4274 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:38:01 - INFO - [Epoch 160] Train loss: 767.4274 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:38:02,847] [UniVITrainer] [INFO] [Epoch 160] Val loss: 769.9879 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:38:02 - INFO - [Epoch 160] Val loss: 769.9879 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:38:12,808] [UniVITrainer] [INFO] [Epoch 161] New best val loss: 769.4811\n",
      "2025-11-19 23:38:12 - INFO - [Epoch 161] New best val loss: 769.4811\n",
      "[2025-11-19 23:39:37,104] [UniVITrainer] [INFO] [Epoch 170] Train loss: 768.5802 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:39:37 - INFO - [Epoch 170] Train loss: 768.5802 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:39:38,162] [UniVITrainer] [INFO] [Epoch 170] Val loss: 769.3438 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:39:38 - INFO - [Epoch 170] Val loss: 769.3438 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:39:38,584] [UniVITrainer] [INFO] [Epoch 170] New best val loss: 769.3438\n",
      "2025-11-19 23:39:38 - INFO - [Epoch 170] New best val loss: 769.3438\n",
      "[2025-11-19 23:40:16,971] [UniVITrainer] [INFO] [Epoch 174] New best val loss: 769.3432\n",
      "2025-11-19 23:40:16 - INFO - [Epoch 174] New best val loss: 769.3432\n",
      "[2025-11-19 23:41:13,278] [UniVITrainer] [INFO] [Epoch 180] Train loss: 766.0470 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:41:13 - INFO - [Epoch 180] Train loss: 766.0470 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:41:14,344] [UniVITrainer] [INFO] [Epoch 180] Val loss: 769.0672 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:41:14 - INFO - [Epoch 180] Val loss: 769.0672 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:41:14,789] [UniVITrainer] [INFO] [Epoch 180] New best val loss: 769.0672\n",
      "2025-11-19 23:41:14 - INFO - [Epoch 180] New best val loss: 769.0672\n",
      "[2025-11-19 23:41:24,687] [UniVITrainer] [INFO] [Epoch 181] New best val loss: 769.0618\n",
      "2025-11-19 23:41:24 - INFO - [Epoch 181] New best val loss: 769.0618\n",
      "[2025-11-19 23:41:44,405] [UniVITrainer] [INFO] [Epoch 183] New best val loss: 768.9769\n",
      "2025-11-19 23:41:44 - INFO - [Epoch 183] New best val loss: 768.9769\n",
      "[2025-11-19 23:41:54,521] [UniVITrainer] [INFO] [Epoch 184] New best val loss: 768.9667\n",
      "2025-11-19 23:41:54 - INFO - [Epoch 184] New best val loss: 768.9667\n",
      "[2025-11-19 23:42:51,037] [UniVITrainer] [INFO] [Epoch 190] Train loss: 767.8020 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:42:51 - INFO - [Epoch 190] Train loss: 767.8020 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:42:52,092] [UniVITrainer] [INFO] [Epoch 190] Val loss: 769.1975 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:42:52 - INFO - [Epoch 190] Val loss: 769.1975 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:43:21,293] [UniVITrainer] [INFO] [Epoch 193] New best val loss: 768.8741\n",
      "2025-11-19 23:43:21 - INFO - [Epoch 193] New best val loss: 768.8741\n",
      "[2025-11-19 23:43:50,400] [UniVITrainer] [INFO] [Epoch 196] New best val loss: 768.8698\n",
      "2025-11-19 23:43:50 - INFO - [Epoch 196] New best val loss: 768.8698\n",
      "[2025-11-19 23:44:27,529] [UniVITrainer] [INFO] [Epoch 200] Train loss: 768.0256 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:44:27 - INFO - [Epoch 200] Train loss: 768.0256 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:44:28,553] [UniVITrainer] [INFO] [Epoch 200] Val loss: 768.6850 (beta=240.000, gamma=180.000)\n",
      "2025-11-19 23:44:28 - INFO - [Epoch 200] Val loss: 768.6850 (beta=240.000, gamma=180.000)\n",
      "[2025-11-19 23:44:28,955] [UniVITrainer] [INFO] [Epoch 200] New best val loss: 768.6850\n",
      "2025-11-19 23:44:28 - INFO - [Epoch 200] New best val loss: 768.6850\n",
      "[2025-11-19 23:44:29,007] [UniVITrainer] [INFO] Restored best model from epoch 200 (val loss = 768.6850)\n",
      "2025-11-19 23:44:29 - INFO - Restored best model from epoch 200 (val loss = 768.6850)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 23:44:33,822] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-19 23:44:33 - INFO - TrainingConfig:\n",
      "[2025-11-19 23:44:33,824] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-19 23:44:33 - INFO -   n_epochs: 200\n",
      "[2025-11-19 23:44:33,825] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-19 23:44:33 - INFO -   batch_size: 256\n",
      "[2025-11-19 23:44:33,826] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-19 23:44:33 - INFO -   lr: 0.0005\n",
      "[2025-11-19 23:44:33,827] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-19 23:44:33 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-19 23:44:33,828] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-19 23:44:33 - INFO -   device: cuda\n",
      "[2025-11-19 23:44:33,829] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-19 23:44:33 - INFO -   log_every: 10\n",
      "[2025-11-19 23:44:33,830] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-19 23:44:33 - INFO -   grad_clip: None\n",
      "[2025-11-19 23:44:33,831] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-19 23:44:33 - INFO -   num_workers: 0\n",
      "[2025-11-19 23:44:33,832] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-19 23:44:33 - INFO -   seed: 42\n",
      "[2025-11-19 23:44:33,833] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-19 23:44:33 - INFO -   early_stopping: True\n",
      "[2025-11-19 23:44:33,834] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-19 23:44:33 - INFO -   patience: 20\n",
      "[2025-11-19 23:44:33,835] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-19 23:44:33 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 1] Done in 32.7 min\n",
      "  best_val_loss              = 768.685\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5396\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.5196\n",
      "[Config 1] FOSCTTM (ADT vs ATAC, val) = 0.4995\n",
      "  Mean FOSCTTM (3 pairs)     = 0.5196\n",
      "  Modality mixing (k=20)     = 0.0095\n",
      "  Composite score            = 1179.14\n",
      "--> New best config (id=1) with score=1179.136\n",
      "\n",
      "================================================================================\n",
      "[Config 2] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 100,\n",
      "  \"beta\": 500.0,\n",
      "  \"gamma\": 180.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_wide2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_wide2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9319a064ff447609b2de82c194e67b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 23:44:42,863] [UniVITrainer] [INFO] [Epoch 001] Train loss: 9315.6695 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:44:42 - INFO - [Epoch 001] Train loss: 9315.6695 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:44:43,935] [UniVITrainer] [INFO] [Epoch 001] Val loss: 3017.1510 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:44:43 - INFO - [Epoch 001] Val loss: 3017.1510 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:44:43,970] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 3017.1510\n",
      "2025-11-19 23:44:43 - INFO - [Epoch 001] New best val loss: 3017.1510\n",
      "[2025-11-19 23:44:53,716] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1470.7642\n",
      "2025-11-19 23:44:53 - INFO - [Epoch 002] New best val loss: 1470.7642\n",
      "[2025-11-19 23:45:03,444] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1200.8636\n",
      "2025-11-19 23:45:03 - INFO - [Epoch 003] New best val loss: 1200.8636\n",
      "[2025-11-19 23:45:13,039] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 1079.7780\n",
      "2025-11-19 23:45:13 - INFO - [Epoch 004] New best val loss: 1079.7780\n",
      "[2025-11-19 23:45:22,907] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 1030.3762\n",
      "2025-11-19 23:45:22 - INFO - [Epoch 005] New best val loss: 1030.3762\n",
      "[2025-11-19 23:45:33,017] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 998.1135\n",
      "2025-11-19 23:45:33 - INFO - [Epoch 006] New best val loss: 998.1135\n",
      "[2025-11-19 23:45:43,069] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 964.5863\n",
      "2025-11-19 23:45:43 - INFO - [Epoch 007] New best val loss: 964.5863\n",
      "[2025-11-19 23:45:53,098] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 940.4473\n",
      "2025-11-19 23:45:53 - INFO - [Epoch 008] New best val loss: 940.4473\n",
      "[2025-11-19 23:46:03,227] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 921.2784\n",
      "2025-11-19 23:46:03 - INFO - [Epoch 009] New best val loss: 921.2784\n",
      "[2025-11-19 23:46:12,043] [UniVITrainer] [INFO] [Epoch 010] Train loss: 1114.9889 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:46:12 - INFO - [Epoch 010] Train loss: 1114.9889 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:46:13,106] [UniVITrainer] [INFO] [Epoch 010] Val loss: 910.2442 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:46:13 - INFO - [Epoch 010] Val loss: 910.2442 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:46:13,381] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 910.2442\n",
      "2025-11-19 23:46:13 - INFO - [Epoch 010] New best val loss: 910.2442\n",
      "[2025-11-19 23:46:23,296] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 899.6992\n",
      "2025-11-19 23:46:23 - INFO - [Epoch 011] New best val loss: 899.6992\n",
      "[2025-11-19 23:46:33,339] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 892.2637\n",
      "2025-11-19 23:46:33 - INFO - [Epoch 012] New best val loss: 892.2637\n",
      "[2025-11-19 23:46:43,899] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 883.2703\n",
      "2025-11-19 23:46:43 - INFO - [Epoch 013] New best val loss: 883.2703\n",
      "[2025-11-19 23:46:54,266] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 875.0517\n",
      "2025-11-19 23:46:54 - INFO - [Epoch 014] New best val loss: 875.0517\n",
      "[2025-11-19 23:47:04,853] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 874.6702\n",
      "2025-11-19 23:47:04 - INFO - [Epoch 015] New best val loss: 874.6702\n",
      "[2025-11-19 23:47:15,309] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 870.1487\n",
      "2025-11-19 23:47:15 - INFO - [Epoch 016] New best val loss: 870.1487\n",
      "[2025-11-19 23:47:25,628] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 869.5278\n",
      "2025-11-19 23:47:25 - INFO - [Epoch 017] New best val loss: 869.5278\n",
      "[2025-11-19 23:47:36,213] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 855.8280\n",
      "2025-11-19 23:47:36 - INFO - [Epoch 018] New best val loss: 855.8280\n",
      "[2025-11-19 23:47:55,318] [UniVITrainer] [INFO] [Epoch 020] Train loss: 928.0141 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:47:55 - INFO - [Epoch 020] Train loss: 928.0141 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:47:56,398] [UniVITrainer] [INFO] [Epoch 020] Val loss: 850.8353 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:47:56 - INFO - [Epoch 020] Val loss: 850.8353 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:47:56,672] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 850.8353\n",
      "2025-11-19 23:47:56 - INFO - [Epoch 020] New best val loss: 850.8353\n",
      "[2025-11-19 23:48:13,984] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 847.4834\n",
      "2025-11-19 23:48:13 - INFO - [Epoch 022] New best val loss: 847.4834\n",
      "[2025-11-19 23:48:26,792] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 845.4775\n",
      "2025-11-19 23:48:26 - INFO - [Epoch 024] New best val loss: 845.4775\n",
      "[2025-11-19 23:48:41,447] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 839.2543\n",
      "2025-11-19 23:48:41 - INFO - [Epoch 026] New best val loss: 839.2543\n",
      "[2025-11-19 23:49:10,593] [UniVITrainer] [INFO] [Epoch 030] Train loss: 865.9983 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:49:10 - INFO - [Epoch 030] Train loss: 865.9983 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:49:11,277] [UniVITrainer] [INFO] [Epoch 030] Val loss: 834.2181 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:49:11 - INFO - [Epoch 030] Val loss: 834.2181 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:49:11,437] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 834.2181\n",
      "2025-11-19 23:49:11 - INFO - [Epoch 030] New best val loss: 834.2181\n",
      "[2025-11-19 23:49:19,308] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 832.5906\n",
      "2025-11-19 23:49:19 - INFO - [Epoch 031] New best val loss: 832.5906\n",
      "[2025-11-19 23:49:41,641] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 832.3536\n",
      "2025-11-19 23:49:41 - INFO - [Epoch 034] New best val loss: 832.3536\n",
      "[2025-11-19 23:49:49,316] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 829.8929\n",
      "2025-11-19 23:49:49 - INFO - [Epoch 035] New best val loss: 829.8929\n",
      "[2025-11-19 23:49:57,372] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 829.8651\n",
      "2025-11-19 23:49:57 - INFO - [Epoch 036] New best val loss: 829.8651\n",
      "[2025-11-19 23:50:12,862] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 829.0581\n",
      "2025-11-19 23:50:12 - INFO - [Epoch 038] New best val loss: 829.0581\n",
      "[2025-11-19 23:50:20,959] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 824.7123\n",
      "2025-11-19 23:50:20 - INFO - [Epoch 039] New best val loss: 824.7123\n",
      "[2025-11-19 23:50:27,522] [UniVITrainer] [INFO] [Epoch 040] Train loss: 832.7263 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:50:27 - INFO - [Epoch 040] Train loss: 832.7263 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:50:28,346] [UniVITrainer] [INFO] [Epoch 040] Val loss: 822.0359 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:50:28 - INFO - [Epoch 040] Val loss: 822.0359 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:50:28,653] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 822.0359\n",
      "2025-11-19 23:50:28 - INFO - [Epoch 040] New best val loss: 822.0359\n",
      "[2025-11-19 23:50:36,435] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 821.4053\n",
      "2025-11-19 23:50:36 - INFO - [Epoch 041] New best val loss: 821.4053\n",
      "[2025-11-19 23:51:36,076] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 818.1849\n",
      "2025-11-19 23:51:36 - INFO - [Epoch 049] New best val loss: 818.1849\n",
      "[2025-11-19 23:51:43,305] [UniVITrainer] [INFO] [Epoch 050] Train loss: 823.0138 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:51:43 - INFO - [Epoch 050] Train loss: 823.0138 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:51:44,139] [UniVITrainer] [INFO] [Epoch 050] Val loss: 817.5064 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:51:44 - INFO - [Epoch 050] Val loss: 817.5064 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:51:44,400] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 817.5064\n",
      "2025-11-19 23:51:44 - INFO - [Epoch 050] New best val loss: 817.5064\n",
      "[2025-11-19 23:52:15,233] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 815.4193\n",
      "2025-11-19 23:52:15 - INFO - [Epoch 054] New best val loss: 815.4193\n",
      "[2025-11-19 23:52:38,693] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 814.9288\n",
      "2025-11-19 23:52:38 - INFO - [Epoch 057] New best val loss: 814.9288\n",
      "[2025-11-19 23:52:46,726] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 814.8861\n",
      "2025-11-19 23:52:46 - INFO - [Epoch 058] New best val loss: 814.8861\n",
      "[2025-11-19 23:53:01,194] [UniVITrainer] [INFO] [Epoch 060] Train loss: 811.2552 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:53:01 - INFO - [Epoch 060] Train loss: 811.2552 (beta=500.000, gamma=180.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 23:53:02,026] [UniVITrainer] [INFO] [Epoch 060] Val loss: 819.0218 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:53:02 - INFO - [Epoch 060] Val loss: 819.0218 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:53:25,488] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 814.0481\n",
      "2025-11-19 23:53:25 - INFO - [Epoch 063] New best val loss: 814.0481\n",
      "[2025-11-19 23:54:14,824] [UniVITrainer] [INFO] [Epoch 070] Train loss: 798.5115 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:54:14 - INFO - [Epoch 070] Train loss: 798.5115 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:54:15,572] [UniVITrainer] [INFO] [Epoch 070] Val loss: 814.5974 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:54:15 - INFO - [Epoch 070] Val loss: 814.5974 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:54:21,730] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 811.8329\n",
      "2025-11-19 23:54:21 - INFO - [Epoch 071] New best val loss: 811.8329\n",
      "[2025-11-19 23:54:29,210] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 811.4152\n",
      "2025-11-19 23:54:29 - INFO - [Epoch 072] New best val loss: 811.4152\n",
      "[2025-11-19 23:55:05,918] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 808.8923\n",
      "2025-11-19 23:55:05 - INFO - [Epoch 077] New best val loss: 808.8923\n",
      "[2025-11-19 23:55:25,388] [UniVITrainer] [INFO] [Epoch 080] Train loss: 793.0411 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:55:25 - INFO - [Epoch 080] Train loss: 793.0411 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:55:26,042] [UniVITrainer] [INFO] [Epoch 080] Val loss: 810.9600 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:55:26 - INFO - [Epoch 080] Val loss: 810.9600 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:56:09,315] [UniVITrainer] [INFO] [Epoch 086] New best val loss: 808.1497\n",
      "2025-11-19 23:56:09 - INFO - [Epoch 086] New best val loss: 808.1497\n",
      "[2025-11-19 23:56:17,169] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 807.9145\n",
      "2025-11-19 23:56:17 - INFO - [Epoch 087] New best val loss: 807.9145\n",
      "[2025-11-19 23:56:24,726] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 806.9862\n",
      "2025-11-19 23:56:24 - INFO - [Epoch 088] New best val loss: 806.9862\n",
      "[2025-11-19 23:56:38,810] [UniVITrainer] [INFO] [Epoch 090] Train loss: 785.9659 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:56:38 - INFO - [Epoch 090] Train loss: 785.9659 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:56:39,631] [UniVITrainer] [INFO] [Epoch 090] Val loss: 810.7058 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:56:39 - INFO - [Epoch 090] Val loss: 810.7058 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:57:08,944] [UniVITrainer] [INFO] [Epoch 094] New best val loss: 805.0552\n",
      "2025-11-19 23:57:08 - INFO - [Epoch 094] New best val loss: 805.0552\n",
      "[2025-11-19 23:57:50,438] [UniVITrainer] [INFO] [Epoch 100] Train loss: 779.8255 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:57:50 - INFO - [Epoch 100] Train loss: 779.8255 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:57:51,251] [UniVITrainer] [INFO] [Epoch 100] Val loss: 807.0023 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:57:51 - INFO - [Epoch 100] Val loss: 807.0023 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:57:59,143] [UniVITrainer] [INFO] [Epoch 101] New best val loss: 803.5504\n",
      "2025-11-19 23:57:59 - INFO - [Epoch 101] New best val loss: 803.5504\n",
      "[2025-11-19 23:58:57,859] [UniVITrainer] [INFO] [Epoch 109] New best val loss: 803.0585\n",
      "2025-11-19 23:58:57 - INFO - [Epoch 109] New best val loss: 803.0585\n",
      "[2025-11-19 23:59:04,656] [UniVITrainer] [INFO] [Epoch 110] Train loss: 782.1602 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:59:04 - INFO - [Epoch 110] Train loss: 782.1602 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:59:05,478] [UniVITrainer] [INFO] [Epoch 110] Val loss: 804.7058 (beta=500.000, gamma=180.000)\n",
      "2025-11-19 23:59:05 - INFO - [Epoch 110] Val loss: 804.7058 (beta=500.000, gamma=180.000)\n",
      "[2025-11-19 23:59:11,830] [UniVITrainer] [INFO] [Epoch 111] New best val loss: 801.3252\n",
      "2025-11-19 23:59:11 - INFO - [Epoch 111] New best val loss: 801.3252\n",
      "[2025-11-19 23:59:27,111] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 799.4480\n",
      "2025-11-19 23:59:27 - INFO - [Epoch 113] New best val loss: 799.4480\n",
      "[2025-11-20 00:00:16,553] [UniVITrainer] [INFO] [Epoch 120] Train loss: 778.9188 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:00:16 - INFO - [Epoch 120] Train loss: 778.9188 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:00:17,362] [UniVITrainer] [INFO] [Epoch 120] Val loss: 795.6024 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:00:17 - INFO - [Epoch 120] Val loss: 795.6024 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:00:17,653] [UniVITrainer] [INFO] [Epoch 120] New best val loss: 795.6024\n",
      "2025-11-20 00:00:17 - INFO - [Epoch 120] New best val loss: 795.6024\n",
      "[2025-11-20 00:00:38,417] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 795.4379\n",
      "2025-11-20 00:00:38 - INFO - [Epoch 123] New best val loss: 795.4379\n",
      "[2025-11-20 00:01:24,318] [UniVITrainer] [INFO] [Epoch 130] Train loss: 777.9774 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:01:24 - INFO - [Epoch 130] Train loss: 777.9774 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:01:25,135] [UniVITrainer] [INFO] [Epoch 130] Val loss: 795.0071 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:01:25 - INFO - [Epoch 130] Val loss: 795.0071 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:01:25,424] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 795.0071\n",
      "2025-11-20 00:01:25 - INFO - [Epoch 130] New best val loss: 795.0071\n",
      "[2025-11-20 00:01:38,186] [UniVITrainer] [INFO] [Epoch 132] New best val loss: 793.1895\n",
      "2025-11-20 00:01:38 - INFO - [Epoch 132] New best val loss: 793.1895\n",
      "[2025-11-20 00:02:08,102] [UniVITrainer] [INFO] [Epoch 136] New best val loss: 792.3281\n",
      "2025-11-20 00:02:08 - INFO - [Epoch 136] New best val loss: 792.3281\n",
      "[2025-11-20 00:02:13,588] [UniVITrainer] [INFO] [Epoch 137] New best val loss: 791.7080\n",
      "2025-11-20 00:02:13 - INFO - [Epoch 137] New best val loss: 791.7080\n",
      "[2025-11-20 00:02:35,119] [UniVITrainer] [INFO] [Epoch 140] Train loss: 776.2680 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:02:35 - INFO - [Epoch 140] Train loss: 776.2680 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:02:35,943] [UniVITrainer] [INFO] [Epoch 140] Val loss: 789.3162 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:02:35 - INFO - [Epoch 140] Val loss: 789.3162 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:02:36,241] [UniVITrainer] [INFO] [Epoch 140] New best val loss: 789.3162\n",
      "2025-11-20 00:02:36 - INFO - [Epoch 140] New best val loss: 789.3162\n",
      "[2025-11-20 00:03:42,654] [UniVITrainer] [INFO] [Epoch 150] Train loss: 773.0804 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:03:42 - INFO - [Epoch 150] Train loss: 773.0804 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:03:43,472] [UniVITrainer] [INFO] [Epoch 150] Val loss: 789.1486 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:03:43 - INFO - [Epoch 150] Val loss: 789.1486 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:03:43,502] [UniVITrainer] [INFO] [Epoch 150] New best val loss: 789.1486\n",
      "2025-11-20 00:03:43 - INFO - [Epoch 150] New best val loss: 789.1486\n",
      "[2025-11-20 00:03:50,164] [UniVITrainer] [INFO] [Epoch 151] New best val loss: 788.2899\n",
      "2025-11-20 00:03:50 - INFO - [Epoch 151] New best val loss: 788.2899\n",
      "[2025-11-20 00:04:33,850] [UniVITrainer] [INFO] [Epoch 157] New best val loss: 788.2536\n",
      "2025-11-20 00:04:33 - INFO - [Epoch 157] New best val loss: 788.2536\n",
      "[2025-11-20 00:04:49,267] [UniVITrainer] [INFO] [Epoch 159] New best val loss: 785.8230\n",
      "2025-11-20 00:04:49 - INFO - [Epoch 159] New best val loss: 785.8230\n",
      "[2025-11-20 00:04:56,151] [UniVITrainer] [INFO] [Epoch 160] Train loss: 767.7359 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:04:56 - INFO - [Epoch 160] Train loss: 767.7359 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:04:56,970] [UniVITrainer] [INFO] [Epoch 160] Val loss: 784.7467 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:04:56 - INFO - [Epoch 160] Val loss: 784.7467 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:04:57,080] [UniVITrainer] [INFO] [Epoch 160] New best val loss: 784.7467\n",
      "2025-11-20 00:04:57 - INFO - [Epoch 160] New best val loss: 784.7467\n",
      "[2025-11-20 00:06:05,940] [UniVITrainer] [INFO] [Epoch 170] Train loss: 769.2865 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:06:05 - INFO - [Epoch 170] Train loss: 769.2865 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:06:06,759] [UniVITrainer] [INFO] [Epoch 170] Val loss: 786.9663 (beta=500.000, gamma=180.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 00:06:06 - INFO - [Epoch 170] Val loss: 786.9663 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:06:29,294] [UniVITrainer] [INFO] [Epoch 173] New best val loss: 784.6318\n",
      "2025-11-20 00:06:29 - INFO - [Epoch 173] New best val loss: 784.6318\n",
      "[2025-11-20 00:06:44,399] [UniVITrainer] [INFO] [Epoch 175] New best val loss: 784.2018\n",
      "2025-11-20 00:06:44 - INFO - [Epoch 175] New best val loss: 784.2018\n",
      "[2025-11-20 00:06:51,751] [UniVITrainer] [INFO] [Epoch 176] New best val loss: 784.1520\n",
      "2025-11-20 00:06:51 - INFO - [Epoch 176] New best val loss: 784.1520\n",
      "[2025-11-20 00:07:20,076] [UniVITrainer] [INFO] [Epoch 180] Train loss: 772.2194 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:07:20 - INFO - [Epoch 180] Train loss: 772.2194 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:07:20,757] [UniVITrainer] [INFO] [Epoch 180] Val loss: 784.8333 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:07:20 - INFO - [Epoch 180] Val loss: 784.8333 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:08:09,124] [UniVITrainer] [INFO] [Epoch 187] New best val loss: 784.0385\n",
      "2025-11-20 00:08:09 - INFO - [Epoch 187] New best val loss: 784.0385\n",
      "[2025-11-20 00:08:23,443] [UniVITrainer] [INFO] [Epoch 189] New best val loss: 783.7228\n",
      "2025-11-20 00:08:23 - INFO - [Epoch 189] New best val loss: 783.7228\n",
      "[2025-11-20 00:08:30,091] [UniVITrainer] [INFO] [Epoch 190] Train loss: 770.8517 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:08:30 - INFO - [Epoch 190] Train loss: 770.8517 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:08:30,908] [UniVITrainer] [INFO] [Epoch 190] Val loss: 783.2741 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:08:30 - INFO - [Epoch 190] Val loss: 783.2741 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:08:30,948] [UniVITrainer] [INFO] [Epoch 190] New best val loss: 783.2741\n",
      "2025-11-20 00:08:30 - INFO - [Epoch 190] New best val loss: 783.2741\n",
      "[2025-11-20 00:08:58,390] [UniVITrainer] [INFO] [Epoch 194] New best val loss: 782.3546\n",
      "2025-11-20 00:08:58 - INFO - [Epoch 194] New best val loss: 782.3546\n",
      "[2025-11-20 00:09:12,060] [UniVITrainer] [INFO] [Epoch 196] New best val loss: 781.1793\n",
      "2025-11-20 00:09:12 - INFO - [Epoch 196] New best val loss: 781.1793\n",
      "[2025-11-20 00:09:40,193] [UniVITrainer] [INFO] [Epoch 200] Train loss: 770.2556 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:09:40 - INFO - [Epoch 200] Train loss: 770.2556 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:09:41,007] [UniVITrainer] [INFO] [Epoch 200] Val loss: 780.6773 (beta=500.000, gamma=180.000)\n",
      "2025-11-20 00:09:41 - INFO - [Epoch 200] Val loss: 780.6773 (beta=500.000, gamma=180.000)\n",
      "[2025-11-20 00:09:41,278] [UniVITrainer] [INFO] [Epoch 200] New best val loss: 780.6773\n",
      "2025-11-20 00:09:41 - INFO - [Epoch 200] New best val loss: 780.6773\n",
      "[2025-11-20 00:09:41,316] [UniVITrainer] [INFO] Restored best model from epoch 200 (val loss = 780.6773)\n",
      "2025-11-20 00:09:41 - INFO - Restored best model from epoch 200 (val loss = 780.6773)\n",
      "[2025-11-20 00:09:43,807] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 00:09:43 - INFO - TrainingConfig:\n",
      "[2025-11-20 00:09:43,811] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 00:09:43 - INFO -   n_epochs: 200\n",
      "[2025-11-20 00:09:43,814] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 00:09:43 - INFO -   batch_size: 256\n",
      "[2025-11-20 00:09:43,817] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 00:09:43 - INFO -   lr: 0.001\n",
      "[2025-11-20 00:09:43,819] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 00:09:43 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 00:09:43,822] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 00:09:43 - INFO -   device: cuda\n",
      "[2025-11-20 00:09:43,825] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 00:09:43 - INFO -   log_every: 10\n",
      "[2025-11-20 00:09:43,828] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 00:09:43 - INFO -   grad_clip: None\n",
      "[2025-11-20 00:09:43,831] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 00:09:43 - INFO -   num_workers: 0\n",
      "[2025-11-20 00:09:43,833] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 00:09:43 - INFO -   seed: 42\n",
      "[2025-11-20 00:09:43,836] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 00:09:43 - INFO -   early_stopping: True\n",
      "[2025-11-20 00:09:43,837] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 00:09:43 - INFO -   patience: 20\n",
      "[2025-11-20 00:09:43,838] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 00:09:43 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 2] Done in 25.1 min\n",
      "  best_val_loss              = 780.677\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.6390\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.5004\n",
      "[Config 2] FOSCTTM (ADT vs ATAC, val) = 0.4969\n",
      "  Mean FOSCTTM (3 pairs)     = 0.5454\n",
      "  Modality mixing (k=20)     = 0.0005\n",
      "  Composite score            = 1207.08\n",
      "\n",
      "================================================================================\n",
      "[Config 3] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 50,\n",
      "  \"beta\": 400.0,\n",
      "  \"gamma\": 300.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_med2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_wide2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e259529f6cc4eacb7d258556a265e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 00:09:49,563] [UniVITrainer] [INFO] [Epoch 001] Train loss: 4315.9104 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:09:49 - INFO - [Epoch 001] Train loss: 4315.9104 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:09:50,378] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1268.7218 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:09:50 - INFO - [Epoch 001] Val loss: 1268.7218 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:09:50,616] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1268.7218\n",
      "2025-11-20 00:09:50 - INFO - [Epoch 001] New best val loss: 1268.7218\n",
      "[2025-11-20 00:09:58,183] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1036.5960\n",
      "2025-11-20 00:09:58 - INFO - [Epoch 002] New best val loss: 1036.5960\n",
      "[2025-11-20 00:10:05,966] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 924.1252\n",
      "2025-11-20 00:10:05 - INFO - [Epoch 003] New best val loss: 924.1252\n",
      "[2025-11-20 00:10:13,469] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 883.4719\n",
      "2025-11-20 00:10:13 - INFO - [Epoch 004] New best val loss: 883.4719\n",
      "[2025-11-20 00:10:21,217] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 861.7426\n",
      "2025-11-20 00:10:21 - INFO - [Epoch 005] New best val loss: 861.7426\n",
      "[2025-11-20 00:10:27,634] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 842.9477\n",
      "2025-11-20 00:10:27 - INFO - [Epoch 006] New best val loss: 842.9477\n",
      "[2025-11-20 00:10:34,312] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 836.3954\n",
      "2025-11-20 00:10:34 - INFO - [Epoch 007] New best val loss: 836.3954\n",
      "[2025-11-20 00:10:42,012] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 829.4882\n",
      "2025-11-20 00:10:42 - INFO - [Epoch 008] New best val loss: 829.4882\n",
      "[2025-11-20 00:10:48,290] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 822.3413\n",
      "2025-11-20 00:10:48 - INFO - [Epoch 009] New best val loss: 822.3413\n",
      "[2025-11-20 00:10:55,067] [UniVITrainer] [INFO] [Epoch 010] Train loss: 891.6731 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:10:55 - INFO - [Epoch 010] Train loss: 891.6731 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:10:55,879] [UniVITrainer] [INFO] [Epoch 010] Val loss: 816.9529 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:10:55 - INFO - [Epoch 010] Val loss: 816.9529 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:10:55,920] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 816.9529\n",
      "2025-11-20 00:10:55 - INFO - [Epoch 010] New best val loss: 816.9529\n",
      "[2025-11-20 00:11:10,076] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 812.6882\n",
      "2025-11-20 00:11:10 - INFO - [Epoch 012] New best val loss: 812.6882\n",
      "[2025-11-20 00:11:17,538] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 809.6984\n",
      "2025-11-20 00:11:17 - INFO - [Epoch 013] New best val loss: 809.6984\n",
      "[2025-11-20 00:11:25,310] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 803.7114\n",
      "2025-11-20 00:11:25 - INFO - [Epoch 014] New best val loss: 803.7114\n",
      "[2025-11-20 00:11:40,556] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 800.2088\n",
      "2025-11-20 00:11:40 - INFO - [Epoch 016] New best val loss: 800.2088\n",
      "[2025-11-20 00:11:48,081] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 799.7202\n",
      "2025-11-20 00:11:48 - INFO - [Epoch 017] New best val loss: 799.7202\n",
      "[2025-11-20 00:11:55,851] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 796.9404\n",
      "2025-11-20 00:11:55 - INFO - [Epoch 018] New best val loss: 796.9404\n",
      "[2025-11-20 00:12:01,778] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 796.0703\n",
      "2025-11-20 00:12:01 - INFO - [Epoch 019] New best val loss: 796.0703\n",
      "[2025-11-20 00:12:08,491] [UniVITrainer] [INFO] [Epoch 020] Train loss: 815.6003 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:12:08 - INFO - [Epoch 020] Train loss: 815.6003 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:12:08,994] [UniVITrainer] [INFO] [Epoch 020] Val loss: 794.9945 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:12:08 - INFO - [Epoch 020] Val loss: 794.9945 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:12:09,278] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 794.9945\n",
      "2025-11-20 00:12:09 - INFO - [Epoch 020] New best val loss: 794.9945\n",
      "[2025-11-20 00:12:15,093] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 793.1028\n",
      "2025-11-20 00:12:15 - INFO - [Epoch 021] New best val loss: 793.1028\n",
      "[2025-11-20 00:12:27,345] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 792.1206\n",
      "2025-11-20 00:12:27 - INFO - [Epoch 023] New best val loss: 792.1206\n",
      "[2025-11-20 00:12:35,031] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 791.9951\n",
      "2025-11-20 00:12:35 - INFO - [Epoch 024] New best val loss: 791.9951\n",
      "[2025-11-20 00:12:42,829] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 790.1594\n",
      "2025-11-20 00:12:42 - INFO - [Epoch 025] New best val loss: 790.1594\n",
      "[2025-11-20 00:12:58,283] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 789.7711\n",
      "2025-11-20 00:12:58 - INFO - [Epoch 027] New best val loss: 789.7711\n",
      "[2025-11-20 00:13:05,877] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 789.5422\n",
      "2025-11-20 00:13:05 - INFO - [Epoch 028] New best val loss: 789.5422\n",
      "[2025-11-20 00:13:19,949] [UniVITrainer] [INFO] [Epoch 030] Train loss: 801.3139 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:13:19 - INFO - [Epoch 030] Train loss: 801.3139 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:13:20,770] [UniVITrainer] [INFO] [Epoch 030] Val loss: 788.7613 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:13:20 - INFO - [Epoch 030] Val loss: 788.7613 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:13:20,946] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 788.7613\n",
      "2025-11-20 00:13:20 - INFO - [Epoch 030] New best val loss: 788.7613\n",
      "[2025-11-20 00:13:26,160] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 786.1426\n",
      "2025-11-20 00:13:26 - INFO - [Epoch 031] New best val loss: 786.1426\n",
      "[2025-11-20 00:13:48,063] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 785.9840\n",
      "2025-11-20 00:13:48 - INFO - [Epoch 034] New best val loss: 785.9840\n",
      "[2025-11-20 00:14:10,994] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 784.9317\n",
      "2025-11-20 00:14:10 - INFO - [Epoch 037] New best val loss: 784.9317\n",
      "[2025-11-20 00:14:18,597] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 784.3004\n",
      "2025-11-20 00:14:18 - INFO - [Epoch 038] New best val loss: 784.3004\n",
      "[2025-11-20 00:14:25,297] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 784.0127\n",
      "2025-11-20 00:14:25 - INFO - [Epoch 039] New best val loss: 784.0127\n",
      "[2025-11-20 00:14:32,316] [UniVITrainer] [INFO] [Epoch 040] Train loss: 786.5153 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:14:32 - INFO - [Epoch 040] Train loss: 786.5153 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:14:33,122] [UniVITrainer] [INFO] [Epoch 040] Val loss: 784.0495 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:14:33 - INFO - [Epoch 040] Val loss: 784.0495 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:14:40,355] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 783.5493\n",
      "2025-11-20 00:14:40 - INFO - [Epoch 041] New best val loss: 783.5493\n",
      "[2025-11-20 00:14:48,408] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 781.2677\n",
      "2025-11-20 00:14:48 - INFO - [Epoch 042] New best val loss: 781.2677\n",
      "[2025-11-20 00:15:34,458] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 781.2098\n",
      "2025-11-20 00:15:34 - INFO - [Epoch 048] New best val loss: 781.2098\n",
      "[2025-11-20 00:15:46,047] [UniVITrainer] [INFO] [Epoch 050] Train loss: 782.8666 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:15:46 - INFO - [Epoch 050] Train loss: 782.8666 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:15:46,637] [UniVITrainer] [INFO] [Epoch 050] Val loss: 780.3764 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:15:46 - INFO - [Epoch 050] Val loss: 780.3764 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:15:46,852] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 780.3764\n",
      "2025-11-20 00:15:46 - INFO - [Epoch 050] New best val loss: 780.3764\n",
      "[2025-11-20 00:16:10,032] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 779.3700\n",
      "2025-11-20 00:16:10 - INFO - [Epoch 053] New best val loss: 779.3700\n",
      "[2025-11-20 00:16:25,804] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 777.8580\n",
      "2025-11-20 00:16:25 - INFO - [Epoch 055] New best val loss: 777.8580\n",
      "[2025-11-20 00:17:00,036] [UniVITrainer] [INFO] [Epoch 060] Train loss: 779.5572 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:17:00 - INFO - [Epoch 060] Train loss: 779.5572 (beta=400.000, gamma=300.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 00:17:00,885] [UniVITrainer] [INFO] [Epoch 060] Val loss: 780.3376 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:17:00 - INFO - [Epoch 060] Val loss: 780.3376 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:17:53,055] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 777.0358\n",
      "2025-11-20 00:17:53 - INFO - [Epoch 067] New best val loss: 777.0358\n",
      "[2025-11-20 00:18:13,042] [UniVITrainer] [INFO] [Epoch 070] Train loss: 775.6922 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:18:13 - INFO - [Epoch 070] Train loss: 775.6922 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:18:13,878] [UniVITrainer] [INFO] [Epoch 070] Val loss: 777.8863 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:18:13 - INFO - [Epoch 070] Val loss: 777.8863 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:18:19,492] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 776.0653\n",
      "2025-11-20 00:18:19 - INFO - [Epoch 071] New best val loss: 776.0653\n",
      "[2025-11-20 00:18:27,546] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 775.6269\n",
      "2025-11-20 00:18:27 - INFO - [Epoch 072] New best val loss: 775.6269\n",
      "[2025-11-20 00:18:56,967] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 775.6183\n",
      "2025-11-20 00:18:56 - INFO - [Epoch 076] New best val loss: 775.6183\n",
      "[2025-11-20 00:19:24,012] [UniVITrainer] [INFO] [Epoch 080] Train loss: 775.3718 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:19:24 - INFO - [Epoch 080] Train loss: 775.3718 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:19:24,822] [UniVITrainer] [INFO] [Epoch 080] Val loss: 777.8164 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:19:24 - INFO - [Epoch 080] Val loss: 777.8164 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:19:46,136] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 774.4053\n",
      "2025-11-20 00:19:46 - INFO - [Epoch 083] New best val loss: 774.4053\n",
      "[2025-11-20 00:20:15,298] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 774.0970\n",
      "2025-11-20 00:20:15 - INFO - [Epoch 087] New best val loss: 774.0970\n",
      "[2025-11-20 00:20:36,687] [UniVITrainer] [INFO] [Epoch 090] Train loss: 773.3373 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:20:36 - INFO - [Epoch 090] Train loss: 773.3373 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:20:37,497] [UniVITrainer] [INFO] [Epoch 090] Val loss: 772.9250 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:20:37 - INFO - [Epoch 090] Val loss: 772.9250 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:20:37,691] [UniVITrainer] [INFO] [Epoch 090] New best val loss: 772.9250\n",
      "2025-11-20 00:20:37 - INFO - [Epoch 090] New best val loss: 772.9250\n",
      "[2025-11-20 00:21:13,520] [UniVITrainer] [INFO] [Epoch 095] New best val loss: 772.6042\n",
      "2025-11-20 00:21:13 - INFO - [Epoch 095] New best val loss: 772.6042\n",
      "[2025-11-20 00:21:21,120] [UniVITrainer] [INFO] [Epoch 096] New best val loss: 772.4989\n",
      "2025-11-20 00:21:21 - INFO - [Epoch 096] New best val loss: 772.4989\n",
      "[2025-11-20 00:21:43,854] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 772.1493\n",
      "2025-11-20 00:21:43 - INFO - [Epoch 099] New best val loss: 772.1493\n",
      "[2025-11-20 00:21:50,590] [UniVITrainer] [INFO] [Epoch 100] Train loss: 773.5442 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:21:50 - INFO - [Epoch 100] Train loss: 773.5442 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:21:51,397] [UniVITrainer] [INFO] [Epoch 100] Val loss: 772.4908 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:21:51 - INFO - [Epoch 100] Val loss: 772.4908 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:21:58,856] [UniVITrainer] [INFO] [Epoch 101] New best val loss: 771.6766\n",
      "2025-11-20 00:21:58 - INFO - [Epoch 101] New best val loss: 771.6766\n",
      "[2025-11-20 00:22:13,281] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 771.6237\n",
      "2025-11-20 00:22:13 - INFO - [Epoch 103] New best val loss: 771.6237\n",
      "[2025-11-20 00:22:27,739] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 771.3960\n",
      "2025-11-20 00:22:27 - INFO - [Epoch 105] New best val loss: 771.3960\n",
      "[2025-11-20 00:22:50,434] [UniVITrainer] [INFO] [Epoch 108] New best val loss: 771.3659\n",
      "2025-11-20 00:22:50 - INFO - [Epoch 108] New best val loss: 771.3659\n",
      "[2025-11-20 00:23:04,449] [UniVITrainer] [INFO] [Epoch 110] Train loss: 772.7875 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:23:04 - INFO - [Epoch 110] Train loss: 772.7875 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:23:05,261] [UniVITrainer] [INFO] [Epoch 110] Val loss: 770.4533 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:23:05 - INFO - [Epoch 110] Val loss: 770.4533 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:23:05,483] [UniVITrainer] [INFO] [Epoch 110] New best val loss: 770.4533\n",
      "2025-11-20 00:23:05 - INFO - [Epoch 110] New best val loss: 770.4533\n",
      "[2025-11-20 00:23:41,100] [UniVITrainer] [INFO] [Epoch 115] New best val loss: 770.3298\n",
      "2025-11-20 00:23:41 - INFO - [Epoch 115] New best val loss: 770.3298\n",
      "[2025-11-20 00:24:02,455] [UniVITrainer] [INFO] [Epoch 118] New best val loss: 769.9858\n",
      "2025-11-20 00:24:02 - INFO - [Epoch 118] New best val loss: 769.9858\n",
      "[2025-11-20 00:24:16,570] [UniVITrainer] [INFO] [Epoch 120] Train loss: 771.8141 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:24:16 - INFO - [Epoch 120] Train loss: 771.8141 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:24:17,367] [UniVITrainer] [INFO] [Epoch 120] Val loss: 769.8917 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:24:17 - INFO - [Epoch 120] Val loss: 769.8917 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:24:17,378] [UniVITrainer] [INFO] [Epoch 120] New best val loss: 769.8917\n",
      "2025-11-20 00:24:17 - INFO - [Epoch 120] New best val loss: 769.8917\n",
      "[2025-11-20 00:24:25,163] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 769.8161\n",
      "2025-11-20 00:24:25 - INFO - [Epoch 121] New best val loss: 769.8161\n",
      "[2025-11-20 00:24:32,750] [UniVITrainer] [INFO] [Epoch 122] New best val loss: 769.7976\n",
      "2025-11-20 00:24:32 - INFO - [Epoch 122] New best val loss: 769.7976\n",
      "[2025-11-20 00:24:40,419] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 769.4126\n",
      "2025-11-20 00:24:40 - INFO - [Epoch 123] New best val loss: 769.4126\n",
      "[2025-11-20 00:25:18,152] [UniVITrainer] [INFO] [Epoch 128] New best val loss: 769.1700\n",
      "2025-11-20 00:25:18 - INFO - [Epoch 128] New best val loss: 769.1700\n",
      "[2025-11-20 00:25:25,379] [UniVITrainer] [INFO] [Epoch 129] New best val loss: 769.1487\n",
      "2025-11-20 00:25:25 - INFO - [Epoch 129] New best val loss: 769.1487\n",
      "[2025-11-20 00:25:31,775] [UniVITrainer] [INFO] [Epoch 130] Train loss: 765.4421 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:25:31 - INFO - [Epoch 130] Train loss: 765.4421 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:25:32,612] [UniVITrainer] [INFO] [Epoch 130] Val loss: 769.0329 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:25:32 - INFO - [Epoch 130] Val loss: 769.0329 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:25:32,627] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 769.0329\n",
      "2025-11-20 00:25:32 - INFO - [Epoch 130] New best val loss: 769.0329\n",
      "[2025-11-20 00:25:46,530] [UniVITrainer] [INFO] [Epoch 132] New best val loss: 768.7054\n",
      "2025-11-20 00:25:46 - INFO - [Epoch 132] New best val loss: 768.7054\n",
      "[2025-11-20 00:25:54,077] [UniVITrainer] [INFO] [Epoch 133] New best val loss: 768.7048\n",
      "2025-11-20 00:25:54 - INFO - [Epoch 133] New best val loss: 768.7048\n",
      "[2025-11-20 00:26:24,287] [UniVITrainer] [INFO] [Epoch 137] New best val loss: 768.4682\n",
      "2025-11-20 00:26:24 - INFO - [Epoch 137] New best val loss: 768.4682\n",
      "[2025-11-20 00:26:45,187] [UniVITrainer] [INFO] [Epoch 140] Train loss: 768.7554 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:26:45 - INFO - [Epoch 140] Train loss: 768.7554 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:26:46,018] [UniVITrainer] [INFO] [Epoch 140] Val loss: 768.3050 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:26:46 - INFO - [Epoch 140] Val loss: 768.3050 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:26:46,209] [UniVITrainer] [INFO] [Epoch 140] New best val loss: 768.3050\n",
      "2025-11-20 00:26:46 - INFO - [Epoch 140] New best val loss: 768.3050\n",
      "[2025-11-20 00:27:21,839] [UniVITrainer] [INFO] [Epoch 145] New best val loss: 768.1994\n",
      "2025-11-20 00:27:21 - INFO - [Epoch 145] New best val loss: 768.1994\n",
      "[2025-11-20 00:27:28,852] [UniVITrainer] [INFO] [Epoch 146] New best val loss: 767.8871\n",
      "2025-11-20 00:27:28 - INFO - [Epoch 146] New best val loss: 767.8871\n",
      "[2025-11-20 00:27:44,407] [UniVITrainer] [INFO] [Epoch 148] New best val loss: 767.8772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 00:27:44 - INFO - [Epoch 148] New best val loss: 767.8772\n",
      "[2025-11-20 00:27:52,376] [UniVITrainer] [INFO] [Epoch 149] New best val loss: 767.8339\n",
      "2025-11-20 00:27:52 - INFO - [Epoch 149] New best val loss: 767.8339\n",
      "[2025-11-20 00:27:59,343] [UniVITrainer] [INFO] [Epoch 150] Train loss: 771.6810 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:27:59 - INFO - [Epoch 150] Train loss: 771.6810 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:28:00,180] [UniVITrainer] [INFO] [Epoch 150] Val loss: 767.8877 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:28:00 - INFO - [Epoch 150] Val loss: 767.8877 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:28:08,210] [UniVITrainer] [INFO] [Epoch 151] New best val loss: 767.7776\n",
      "2025-11-20 00:28:08 - INFO - [Epoch 151] New best val loss: 767.7776\n",
      "[2025-11-20 00:28:59,519] [UniVITrainer] [INFO] [Epoch 158] New best val loss: 767.4820\n",
      "2025-11-20 00:28:59 - INFO - [Epoch 158] New best val loss: 767.4820\n",
      "[2025-11-20 00:29:13,523] [UniVITrainer] [INFO] [Epoch 160] Train loss: 766.9896 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:29:13 - INFO - [Epoch 160] Train loss: 766.9896 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:29:14,360] [UniVITrainer] [INFO] [Epoch 160] Val loss: 767.7762 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:29:14 - INFO - [Epoch 160] Val loss: 767.7762 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:29:29,657] [UniVITrainer] [INFO] [Epoch 162] New best val loss: 767.3030\n",
      "2025-11-20 00:29:29 - INFO - [Epoch 162] New best val loss: 767.3030\n",
      "[2025-11-20 00:29:37,390] [UniVITrainer] [INFO] [Epoch 163] New best val loss: 767.2441\n",
      "2025-11-20 00:29:37 - INFO - [Epoch 163] New best val loss: 767.2441\n",
      "[2025-11-20 00:30:28,258] [UniVITrainer] [INFO] [Epoch 170] Train loss: 769.5985 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:30:28 - INFO - [Epoch 170] Train loss: 769.5985 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:30:29,059] [UniVITrainer] [INFO] [Epoch 170] Val loss: 767.3165 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:30:29 - INFO - [Epoch 170] Val loss: 767.3165 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:30:52,344] [UniVITrainer] [INFO] [Epoch 173] New best val loss: 767.1778\n",
      "2025-11-20 00:30:52 - INFO - [Epoch 173] New best val loss: 767.1778\n",
      "[2025-11-20 00:31:35,817] [UniVITrainer] [INFO] [Epoch 179] New best val loss: 766.9990\n",
      "2025-11-20 00:31:35 - INFO - [Epoch 179] New best val loss: 766.9990\n",
      "[2025-11-20 00:31:42,776] [UniVITrainer] [INFO] [Epoch 180] Train loss: 769.2882 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:31:42 - INFO - [Epoch 180] Train loss: 769.2882 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:31:43,611] [UniVITrainer] [INFO] [Epoch 180] Val loss: 767.0207 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:31:43 - INFO - [Epoch 180] Val loss: 767.0207 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:32:41,522] [UniVITrainer] [INFO] [Epoch 188] New best val loss: 766.9803\n",
      "2025-11-20 00:32:41 - INFO - [Epoch 188] New best val loss: 766.9803\n",
      "[2025-11-20 00:32:47,422] [UniVITrainer] [INFO] [Epoch 189] New best val loss: 766.9636\n",
      "2025-11-20 00:32:47 - INFO - [Epoch 189] New best val loss: 766.9636\n",
      "[2025-11-20 00:32:54,102] [UniVITrainer] [INFO] [Epoch 190] Train loss: 769.6640 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:32:54 - INFO - [Epoch 190] Train loss: 769.6640 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:32:54,921] [UniVITrainer] [INFO] [Epoch 190] Val loss: 766.9724 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:32:54 - INFO - [Epoch 190] Val loss: 766.9724 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:33:35,757] [UniVITrainer] [INFO] [Epoch 196] New best val loss: 766.8918\n",
      "2025-11-20 00:33:35 - INFO - [Epoch 196] New best val loss: 766.8918\n",
      "[2025-11-20 00:33:50,926] [UniVITrainer] [INFO] [Epoch 198] New best val loss: 766.8711\n",
      "2025-11-20 00:33:50 - INFO - [Epoch 198] New best val loss: 766.8711\n",
      "[2025-11-20 00:34:04,996] [UniVITrainer] [INFO] [Epoch 200] Train loss: 769.1867 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:34:04 - INFO - [Epoch 200] Train loss: 769.1867 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:34:05,494] [UniVITrainer] [INFO] [Epoch 200] Val loss: 767.1886 (beta=400.000, gamma=300.000)\n",
      "2025-11-20 00:34:05 - INFO - [Epoch 200] Val loss: 767.1886 (beta=400.000, gamma=300.000)\n",
      "[2025-11-20 00:34:05,533] [UniVITrainer] [INFO] Restored best model from epoch 198 (val loss = 766.8711)\n",
      "2025-11-20 00:34:05 - INFO - Restored best model from epoch 198 (val loss = 766.8711)\n",
      "[2025-11-20 00:34:07,803] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 00:34:07 - INFO - TrainingConfig:\n",
      "[2025-11-20 00:34:07,805] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 00:34:07 - INFO -   n_epochs: 200\n",
      "[2025-11-20 00:34:07,808] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 00:34:07 - INFO -   batch_size: 256\n",
      "[2025-11-20 00:34:07,811] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 00:34:07 - INFO -   lr: 0.0005\n",
      "[2025-11-20 00:34:07,816] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 00:34:07 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 00:34:07,817] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 00:34:07 - INFO -   device: cuda\n",
      "[2025-11-20 00:34:07,819] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 00:34:07 - INFO -   log_every: 10\n",
      "[2025-11-20 00:34:07,821] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 00:34:07 - INFO -   grad_clip: None\n",
      "[2025-11-20 00:34:07,823] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 00:34:07 - INFO -   num_workers: 0\n",
      "[2025-11-20 00:34:07,825] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 00:34:07 - INFO -   seed: 42\n",
      "[2025-11-20 00:34:07,826] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 00:34:07 - INFO -   early_stopping: True\n",
      "[2025-11-20 00:34:07,827] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 00:34:07 - INFO -   patience: 20\n",
      "[2025-11-20 00:34:07,828] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 00:34:07 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 3] Done in 24.4 min\n",
      "  best_val_loss              = 766.871\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5191\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.5203\n",
      "[Config 3] FOSCTTM (ADT vs ATAC, val) = 0.4517\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4970\n",
      "  Modality mixing (k=20)     = 0.0000\n",
      "  Composite score            = 1148.02\n",
      "--> New best config (id=3) with score=1148.017\n",
      "\n",
      "================================================================================\n",
      "[Config 4] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 156,\n",
      "  \"beta\": 60.0,\n",
      "  \"gamma\": 40.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_med2\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed29b423293341afb54440c2479aac4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 00:34:14,607] [UniVITrainer] [INFO] [Epoch 001] Train loss: 3438.2481 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:34:14 - INFO - [Epoch 001] Train loss: 3438.2481 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:34:15,410] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1936.3228 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:34:15 - INFO - [Epoch 001] Val loss: 1936.3228 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:34:15,534] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1936.3228\n",
      "2025-11-20 00:34:15 - INFO - [Epoch 001] New best val loss: 1936.3228\n",
      "[2025-11-20 00:34:23,299] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1143.9238\n",
      "2025-11-20 00:34:23 - INFO - [Epoch 002] New best val loss: 1143.9238\n",
      "[2025-11-20 00:34:30,388] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 943.6554\n",
      "2025-11-20 00:34:30 - INFO - [Epoch 003] New best val loss: 943.6554\n",
      "[2025-11-20 00:34:38,160] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 886.7045\n",
      "2025-11-20 00:34:38 - INFO - [Epoch 004] New best val loss: 886.7045\n",
      "[2025-11-20 00:34:45,935] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 863.8438\n",
      "2025-11-20 00:34:45 - INFO - [Epoch 005] New best val loss: 863.8438\n",
      "[2025-11-20 00:34:53,570] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 844.1472\n",
      "2025-11-20 00:34:53 - INFO - [Epoch 006] New best val loss: 844.1472\n",
      "[2025-11-20 00:35:01,329] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 832.7780\n",
      "2025-11-20 00:35:01 - INFO - [Epoch 007] New best val loss: 832.7780\n",
      "[2025-11-20 00:35:08,081] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 822.9306\n",
      "2025-11-20 00:35:08 - INFO - [Epoch 008] New best val loss: 822.9306\n",
      "[2025-11-20 00:35:15,770] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 813.5657\n",
      "2025-11-20 00:35:15 - INFO - [Epoch 009] New best val loss: 813.5657\n",
      "[2025-11-20 00:35:22,327] [UniVITrainer] [INFO] [Epoch 010] Train loss: 876.6558 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:35:22 - INFO - [Epoch 010] Train loss: 876.6558 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:35:23,146] [UniVITrainer] [INFO] [Epoch 010] Val loss: 806.7854 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:35:23 - INFO - [Epoch 010] Val loss: 806.7854 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:35:23,165] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 806.7854\n",
      "2025-11-20 00:35:23 - INFO - [Epoch 010] New best val loss: 806.7854\n",
      "[2025-11-20 00:35:29,856] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 801.9648\n",
      "2025-11-20 00:35:29 - INFO - [Epoch 011] New best val loss: 801.9648\n",
      "[2025-11-20 00:35:37,171] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 800.5243\n",
      "2025-11-20 00:35:37 - INFO - [Epoch 012] New best val loss: 800.5243\n",
      "[2025-11-20 00:35:44,991] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 794.6547\n",
      "2025-11-20 00:35:44 - INFO - [Epoch 013] New best val loss: 794.6547\n",
      "[2025-11-20 00:35:51,497] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 793.7160\n",
      "2025-11-20 00:35:51 - INFO - [Epoch 014] New best val loss: 793.7160\n",
      "[2025-11-20 00:35:59,214] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 791.7957\n",
      "2025-11-20 00:35:59 - INFO - [Epoch 015] New best val loss: 791.7957\n",
      "[2025-11-20 00:36:14,232] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 789.4639\n",
      "2025-11-20 00:36:14 - INFO - [Epoch 017] New best val loss: 789.4639\n",
      "[2025-11-20 00:36:28,419] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 789.1986\n",
      "2025-11-20 00:36:28 - INFO - [Epoch 019] New best val loss: 789.1986\n",
      "[2025-11-20 00:36:33,956] [UniVITrainer] [INFO] [Epoch 020] Train loss: 816.0414 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:36:33 - INFO - [Epoch 020] Train loss: 816.0414 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:36:34,769] [UniVITrainer] [INFO] [Epoch 020] Val loss: 786.4921 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:36:34 - INFO - [Epoch 020] Val loss: 786.4921 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:36:34,945] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 786.4921\n",
      "2025-11-20 00:36:34 - INFO - [Epoch 020] New best val loss: 786.4921\n",
      "[2025-11-20 00:36:41,376] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 783.0957\n",
      "2025-11-20 00:36:41 - INFO - [Epoch 021] New best val loss: 783.0957\n",
      "[2025-11-20 00:37:18,902] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 781.8939\n",
      "2025-11-20 00:37:18 - INFO - [Epoch 026] New best val loss: 781.8939\n",
      "[2025-11-20 00:37:26,561] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 780.6612\n",
      "2025-11-20 00:37:26 - INFO - [Epoch 027] New best val loss: 780.6612\n",
      "[2025-11-20 00:37:34,407] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 780.3345\n",
      "2025-11-20 00:37:34 - INFO - [Epoch 028] New best val loss: 780.3345\n",
      "[2025-11-20 00:37:48,828] [UniVITrainer] [INFO] [Epoch 030] Train loss: 794.6412 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:37:48 - INFO - [Epoch 030] Train loss: 794.6412 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:37:49,642] [UniVITrainer] [INFO] [Epoch 030] Val loss: 779.3339 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:37:49 - INFO - [Epoch 030] Val loss: 779.3339 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:37:49,816] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 779.3339\n",
      "2025-11-20 00:37:49 - INFO - [Epoch 030] New best val loss: 779.3339\n",
      "[2025-11-20 00:38:04,138] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 778.2081\n",
      "2025-11-20 00:38:04 - INFO - [Epoch 032] New best val loss: 778.2081\n",
      "[2025-11-20 00:38:25,010] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 777.6803\n",
      "2025-11-20 00:38:25 - INFO - [Epoch 035] New best val loss: 777.6803\n",
      "[2025-11-20 00:38:31,261] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 776.8631\n",
      "2025-11-20 00:38:31 - INFO - [Epoch 036] New best val loss: 776.8631\n",
      "[2025-11-20 00:38:59,074] [UniVITrainer] [INFO] [Epoch 040] Train loss: 781.7317 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:38:59 - INFO - [Epoch 040] Train loss: 781.7317 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:38:59,908] [UniVITrainer] [INFO] [Epoch 040] Val loss: 774.9990 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:38:59 - INFO - [Epoch 040] Val loss: 774.9990 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:39:00,092] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 774.9990\n",
      "2025-11-20 00:39:00 - INFO - [Epoch 040] New best val loss: 774.9990\n",
      "[2025-11-20 00:39:28,907] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 774.6260\n",
      "2025-11-20 00:39:28 - INFO - [Epoch 044] New best val loss: 774.6260\n",
      "[2025-11-20 00:39:36,330] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 774.5821\n",
      "2025-11-20 00:39:36 - INFO - [Epoch 045] New best val loss: 774.5821\n",
      "[2025-11-20 00:39:44,272] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 772.8070\n",
      "2025-11-20 00:39:44 - INFO - [Epoch 046] New best val loss: 772.8070\n",
      "[2025-11-20 00:40:05,466] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 772.0316\n",
      "2025-11-20 00:40:05 - INFO - [Epoch 049] New best val loss: 772.0316\n",
      "[2025-11-20 00:40:12,065] [UniVITrainer] [INFO] [Epoch 050] Train loss: 776.3985 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:40:12 - INFO - [Epoch 050] Train loss: 776.3985 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:40:12,896] [UniVITrainer] [INFO] [Epoch 050] Val loss: 771.6847 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:40:12 - INFO - [Epoch 050] Val loss: 771.6847 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:40:13,071] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 771.6847\n",
      "2025-11-20 00:40:13 - INFO - [Epoch 050] New best val loss: 771.6847\n",
      "[2025-11-20 00:40:20,163] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 770.0767\n",
      "2025-11-20 00:40:20 - INFO - [Epoch 051] New best val loss: 770.0767\n",
      "[2025-11-20 00:41:26,321] [UniVITrainer] [INFO] [Epoch 060] Train loss: 774.1462 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:41:26 - INFO - [Epoch 060] Train loss: 774.1462 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:41:27,132] [UniVITrainer] [INFO] [Epoch 060] Val loss: 769.5588 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:41:27 - INFO - [Epoch 060] Val loss: 769.5588 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:41:27,270] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 769.5588\n",
      "2025-11-20 00:41:27 - INFO - [Epoch 060] New best val loss: 769.5588\n",
      "[2025-11-20 00:42:04,424] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 767.9202\n",
      "2025-11-20 00:42:04 - INFO - [Epoch 065] New best val loss: 767.9202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 00:42:19,803] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 766.0083\n",
      "2025-11-20 00:42:19 - INFO - [Epoch 067] New best val loss: 766.0083\n",
      "[2025-11-20 00:42:41,495] [UniVITrainer] [INFO] [Epoch 070] Train loss: 771.1906 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:42:41 - INFO - [Epoch 070] Train loss: 771.1906 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:42:42,328] [UniVITrainer] [INFO] [Epoch 070] Val loss: 769.8859 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:42:42 - INFO - [Epoch 070] Val loss: 769.8859 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:43:54,035] [UniVITrainer] [INFO] [Epoch 080] Train loss: 773.1522 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:43:54 - INFO - [Epoch 080] Train loss: 773.1522 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:43:54,524] [UniVITrainer] [INFO] [Epoch 080] Val loss: 770.8414 (beta=60.000, gamma=40.000)\n",
      "2025-11-20 00:43:54 - INFO - [Epoch 080] Val loss: 770.8414 (beta=60.000, gamma=40.000)\n",
      "[2025-11-20 00:44:46,771] [UniVITrainer] [INFO] Early stopping at epoch 87 (best val loss = 766.0083)\n",
      "2025-11-20 00:44:46 - INFO - Early stopping at epoch 87 (best val loss = 766.0083)\n",
      "[2025-11-20 00:44:46,798] [UniVITrainer] [INFO] Restored best model from epoch 67 (val loss = 766.0083)\n",
      "2025-11-20 00:44:46 - INFO - Restored best model from epoch 67 (val loss = 766.0083)\n",
      "[2025-11-20 00:44:49,239] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 00:44:49 - INFO - TrainingConfig:\n",
      "[2025-11-20 00:44:49,241] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 00:44:49 - INFO -   n_epochs: 200\n",
      "[2025-11-20 00:44:49,248] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 00:44:49 - INFO -   batch_size: 256\n",
      "[2025-11-20 00:44:49,255] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 00:44:49 - INFO -   lr: 0.001\n",
      "[2025-11-20 00:44:49,256] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 00:44:49 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 00:44:49,264] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 00:44:49 - INFO -   device: cuda\n",
      "[2025-11-20 00:44:49,265] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 00:44:49 - INFO -   log_every: 10\n",
      "[2025-11-20 00:44:49,266] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 00:44:49 - INFO -   grad_clip: None\n",
      "[2025-11-20 00:44:49,267] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 00:44:49 - INFO -   num_workers: 0\n",
      "[2025-11-20 00:44:49,268] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 00:44:49 - INFO -   seed: 42\n",
      "[2025-11-20 00:44:49,269] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 00:44:49 - INFO -   early_stopping: True\n",
      "[2025-11-20 00:44:49,270] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 00:44:49 - INFO -   patience: 20\n",
      "[2025-11-20 00:44:49,271] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 00:44:49 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 4] Done in 10.6 min\n",
      "  best_val_loss              = 766.008\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.2176\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.2234\n",
      "[Config 4] FOSCTTM (ADT vs ATAC, val) = 0.2329\n",
      "  Mean FOSCTTM (3 pairs)     = 0.2246\n",
      "  Modality mixing (k=20)     = 0.1448\n",
      "  Composite score            = 1073.90\n",
      "--> New best config (id=4) with score=1073.902\n",
      "\n",
      "================================================================================\n",
      "[Config 5] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 64,\n",
      "  \"beta\": 0.0,\n",
      "  \"gamma\": 0.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_wide2\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38eca0b59204a96814da31b048b04c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 00:44:54,366] [UniVITrainer] [INFO] [Epoch 001] Train loss: 782.8636 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:44:54 - INFO - [Epoch 001] Train loss: 782.8636 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:44:55,186] [UniVITrainer] [INFO] [Epoch 001] Val loss: 731.5600 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:44:55 - INFO - [Epoch 001] Val loss: 731.5600 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:44:55,291] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 731.5600\n",
      "2025-11-20 00:44:55 - INFO - [Epoch 001] New best val loss: 731.5600\n",
      "[2025-11-20 00:45:02,224] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 648.3118\n",
      "2025-11-20 00:45:02 - INFO - [Epoch 002] New best val loss: 648.3118\n",
      "[2025-11-20 00:45:09,186] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 642.5913\n",
      "2025-11-20 00:45:09 - INFO - [Epoch 003] New best val loss: 642.5913\n",
      "[2025-11-20 00:45:16,620] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 640.9319\n",
      "2025-11-20 00:45:16 - INFO - [Epoch 004] New best val loss: 640.9319\n",
      "[2025-11-20 00:45:24,394] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 634.9470\n",
      "2025-11-20 00:45:24 - INFO - [Epoch 005] New best val loss: 634.9470\n",
      "[2025-11-20 00:45:32,051] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 629.6702\n",
      "2025-11-20 00:45:32 - INFO - [Epoch 006] New best val loss: 629.6702\n",
      "[2025-11-20 00:45:39,376] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 625.9605\n",
      "2025-11-20 00:45:39 - INFO - [Epoch 007] New best val loss: 625.9605\n",
      "[2025-11-20 00:45:46,667] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 621.4080\n",
      "2025-11-20 00:45:46 - INFO - [Epoch 008] New best val loss: 621.4080\n",
      "[2025-11-20 00:45:52,962] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 618.9651\n",
      "2025-11-20 00:45:52 - INFO - [Epoch 009] New best val loss: 618.9651\n",
      "[2025-11-20 00:45:59,731] [UniVITrainer] [INFO] [Epoch 010] Train loss: 602.5143 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:45:59 - INFO - [Epoch 010] Train loss: 602.5143 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:46:00,550] [UniVITrainer] [INFO] [Epoch 010] Val loss: 618.5369 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:46:00 - INFO - [Epoch 010] Val loss: 618.5369 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:46:00,591] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 618.5369\n",
      "2025-11-20 00:46:00 - INFO - [Epoch 010] New best val loss: 618.5369\n",
      "[2025-11-20 00:46:08,137] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 609.9894\n",
      "2025-11-20 00:46:08 - INFO - [Epoch 011] New best val loss: 609.9894\n",
      "[2025-11-20 00:46:15,555] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 604.7412\n",
      "2025-11-20 00:46:15 - INFO - [Epoch 012] New best val loss: 604.7412\n",
      "[2025-11-20 00:46:22,990] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 601.1477\n",
      "2025-11-20 00:46:22 - INFO - [Epoch 013] New best val loss: 601.1477\n",
      "[2025-11-20 00:46:30,609] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 597.5001\n",
      "2025-11-20 00:46:30 - INFO - [Epoch 014] New best val loss: 597.5001\n",
      "[2025-11-20 00:46:37,960] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 593.6022\n",
      "2025-11-20 00:46:37 - INFO - [Epoch 015] New best val loss: 593.6022\n",
      "[2025-11-20 00:46:45,592] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 592.7612\n",
      "2025-11-20 00:46:45 - INFO - [Epoch 016] New best val loss: 592.7612\n",
      "[2025-11-20 00:46:52,906] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 587.0265\n",
      "2025-11-20 00:46:52 - INFO - [Epoch 017] New best val loss: 587.0265\n",
      "[2025-11-20 00:47:00,655] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 584.2309\n",
      "2025-11-20 00:47:00 - INFO - [Epoch 018] New best val loss: 584.2309\n",
      "[2025-11-20 00:47:14,703] [UniVITrainer] [INFO] [Epoch 020] Train loss: 523.2729 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:47:14 - INFO - [Epoch 020] Train loss: 523.2729 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:47:15,524] [UniVITrainer] [INFO] [Epoch 020] Val loss: 582.2923 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:47:15 - INFO - [Epoch 020] Val loss: 582.2923 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:47:15,661] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 582.2923\n",
      "2025-11-20 00:47:15 - INFO - [Epoch 020] New best val loss: 582.2923\n",
      "[2025-11-20 00:47:30,676] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 577.6628\n",
      "2025-11-20 00:47:30 - INFO - [Epoch 022] New best val loss: 577.6628\n",
      "[2025-11-20 00:47:37,754] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 577.3656\n",
      "2025-11-20 00:47:37 - INFO - [Epoch 023] New best val loss: 577.3656\n",
      "[2025-11-20 00:47:45,248] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 574.8129\n",
      "2025-11-20 00:47:45 - INFO - [Epoch 024] New best val loss: 574.8129\n",
      "[2025-11-20 00:48:00,463] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 573.6152\n",
      "2025-11-20 00:48:00 - INFO - [Epoch 026] New best val loss: 573.6152\n",
      "[2025-11-20 00:48:08,213] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 572.9894\n",
      "2025-11-20 00:48:08 - INFO - [Epoch 027] New best val loss: 572.9894\n",
      "[2025-11-20 00:48:30,072] [UniVITrainer] [INFO] [Epoch 030] Train loss: 467.4258 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:48:30 - INFO - [Epoch 030] Train loss: 467.4258 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:48:30,890] [UniVITrainer] [INFO] [Epoch 030] Val loss: 572.7286 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:48:30 - INFO - [Epoch 030] Val loss: 572.7286 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:48:31,007] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 572.7286\n",
      "2025-11-20 00:48:31 - INFO - [Epoch 030] New best val loss: 572.7286\n",
      "[2025-11-20 00:48:38,667] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 571.3728\n",
      "2025-11-20 00:48:38 - INFO - [Epoch 031] New best val loss: 571.3728\n",
      "[2025-11-20 00:48:46,452] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 571.0903\n",
      "2025-11-20 00:48:46 - INFO - [Epoch 032] New best val loss: 571.0903\n",
      "[2025-11-20 00:49:45,487] [UniVITrainer] [INFO] [Epoch 040] Train loss: 426.1639 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:49:45 - INFO - [Epoch 040] Train loss: 426.1639 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:49:46,307] [UniVITrainer] [INFO] [Epoch 040] Val loss: 572.4468 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:49:46 - INFO - [Epoch 040] Val loss: 572.4468 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:51:01,431] [UniVITrainer] [INFO] [Epoch 050] Train loss: 395.5559 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:51:01 - INFO - [Epoch 050] Train loss: 395.5559 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:51:02,253] [UniVITrainer] [INFO] [Epoch 050] Val loss: 577.8527 (beta=0.000, gamma=0.000)\n",
      "2025-11-20 00:51:02 - INFO - [Epoch 050] Val loss: 577.8527 (beta=0.000, gamma=0.000)\n",
      "[2025-11-20 00:51:16,935] [UniVITrainer] [INFO] Early stopping at epoch 52 (best val loss = 571.0903)\n",
      "2025-11-20 00:51:16 - INFO - Early stopping at epoch 52 (best val loss = 571.0903)\n",
      "[2025-11-20 00:51:16,989] [UniVITrainer] [INFO] Restored best model from epoch 32 (val loss = 571.0903)\n",
      "2025-11-20 00:51:16 - INFO - Restored best model from epoch 32 (val loss = 571.0903)\n",
      "[2025-11-20 00:51:19,460] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 00:51:19 - INFO - TrainingConfig:\n",
      "[2025-11-20 00:51:19,463] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 00:51:19 - INFO -   n_epochs: 200\n",
      "[2025-11-20 00:51:19,467] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 00:51:19 - INFO -   batch_size: 256\n",
      "[2025-11-20 00:51:19,474] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 00:51:19 - INFO -   lr: 0.0005\n",
      "[2025-11-20 00:51:19,479] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 00:51:19 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 00:51:19,481] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 00:51:19 - INFO -   device: cuda\n",
      "[2025-11-20 00:51:19,487] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 00:51:19 - INFO -   log_every: 10\n",
      "[2025-11-20 00:51:19,488] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 00:51:19 - INFO -   grad_clip: None\n",
      "[2025-11-20 00:51:19,489] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 00:51:19 - INFO -   num_workers: 0\n",
      "[2025-11-20 00:51:19,490] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 00:51:19 - INFO -   seed: 42\n",
      "[2025-11-20 00:51:19,491] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 00:51:19 - INFO -   early_stopping: True\n",
      "[2025-11-20 00:51:19,492] [UniVITrainer] [INFO]   patience: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 00:51:19 - INFO -   patience: 20\n",
      "[2025-11-20 00:51:19,501] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 00:51:19 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 5] Done in 6.5 min\n",
      "  best_val_loss              = 571.090\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.2039\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.3829\n",
      "[Config 5] FOSCTTM (ADT vs ATAC, val) = 0.4202\n",
      "  Mean FOSCTTM (3 pairs)     = 0.3357\n",
      "  Modality mixing (k=20)     = 0.0149\n",
      "  Composite score            = 774.19\n",
      "--> New best config (id=5) with score=774.193\n",
      "\n",
      "================================================================================\n",
      "[Config 6] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 124,\n",
      "  \"beta\": 100.0,\n",
      "  \"gamma\": 140.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cebc5b73694cfe88c8dd96f6d3b694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 00:51:26,316] [UniVITrainer] [INFO] [Epoch 001] Train loss: 5561.9546 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:51:26 - INFO - [Epoch 001] Train loss: 5561.9546 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:51:27,135] [UniVITrainer] [INFO] [Epoch 001] Val loss: 2317.4333 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:51:27 - INFO - [Epoch 001] Val loss: 2317.4333 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:51:27,316] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 2317.4333\n",
      "2025-11-20 00:51:27 - INFO - [Epoch 001] New best val loss: 2317.4333\n",
      "[2025-11-20 00:51:34,660] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1195.9583\n",
      "2025-11-20 00:51:34 - INFO - [Epoch 002] New best val loss: 1195.9583\n",
      "[2025-11-20 00:51:40,907] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 997.3190\n",
      "2025-11-20 00:51:40 - INFO - [Epoch 003] New best val loss: 997.3190\n",
      "[2025-11-20 00:51:48,314] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 947.8478\n",
      "2025-11-20 00:51:48 - INFO - [Epoch 004] New best val loss: 947.8478\n",
      "[2025-11-20 00:51:54,839] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 916.7564\n",
      "2025-11-20 00:51:54 - INFO - [Epoch 005] New best val loss: 916.7564\n",
      "[2025-11-20 00:52:02,049] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 892.6672\n",
      "2025-11-20 00:52:02 - INFO - [Epoch 006] New best val loss: 892.6672\n",
      "[2025-11-20 00:52:09,806] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 875.5347\n",
      "2025-11-20 00:52:09 - INFO - [Epoch 007] New best val loss: 875.5347\n",
      "[2025-11-20 00:52:17,454] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 861.6640\n",
      "2025-11-20 00:52:17 - INFO - [Epoch 008] New best val loss: 861.6640\n",
      "[2025-11-20 00:52:25,065] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 855.2920\n",
      "2025-11-20 00:52:25 - INFO - [Epoch 009] New best val loss: 855.2920\n",
      "[2025-11-20 00:52:31,229] [UniVITrainer] [INFO] [Epoch 010] Train loss: 997.5743 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:52:31 - INFO - [Epoch 010] Train loss: 997.5743 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:52:32,038] [UniVITrainer] [INFO] [Epoch 010] Val loss: 844.9603 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:52:32 - INFO - [Epoch 010] Val loss: 844.9603 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:52:32,215] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 844.9603\n",
      "2025-11-20 00:52:32 - INFO - [Epoch 010] New best val loss: 844.9603\n",
      "[2025-11-20 00:52:45,749] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 834.3492\n",
      "2025-11-20 00:52:45 - INFO - [Epoch 012] New best val loss: 834.3492\n",
      "[2025-11-20 00:52:53,013] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 827.3211\n",
      "2025-11-20 00:52:53 - INFO - [Epoch 013] New best val loss: 827.3211\n",
      "[2025-11-20 00:53:00,762] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 823.4327\n",
      "2025-11-20 00:53:00 - INFO - [Epoch 014] New best val loss: 823.4327\n",
      "[2025-11-20 00:53:08,491] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 818.5592\n",
      "2025-11-20 00:53:08 - INFO - [Epoch 015] New best val loss: 818.5592\n",
      "[2025-11-20 00:53:16,196] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 815.2387\n",
      "2025-11-20 00:53:16 - INFO - [Epoch 016] New best val loss: 815.2387\n",
      "[2025-11-20 00:53:22,264] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 811.6669\n",
      "2025-11-20 00:53:22 - INFO - [Epoch 017] New best val loss: 811.6669\n",
      "[2025-11-20 00:53:28,453] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 806.9305\n",
      "2025-11-20 00:53:28 - INFO - [Epoch 018] New best val loss: 806.9305\n",
      "[2025-11-20 00:53:40,404] [UniVITrainer] [INFO] [Epoch 020] Train loss: 867.2606 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:53:40 - INFO - [Epoch 020] Train loss: 867.2606 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:53:41,204] [UniVITrainer] [INFO] [Epoch 020] Val loss: 805.8138 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:53:41 - INFO - [Epoch 020] Val loss: 805.8138 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:53:41,401] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 805.8138\n",
      "2025-11-20 00:53:41 - INFO - [Epoch 020] New best val loss: 805.8138\n",
      "[2025-11-20 00:53:49,067] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 800.4621\n",
      "2025-11-20 00:53:49 - INFO - [Epoch 021] New best val loss: 800.4621\n",
      "[2025-11-20 00:54:04,333] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 798.5621\n",
      "2025-11-20 00:54:04 - INFO - [Epoch 023] New best val loss: 798.5621\n",
      "[2025-11-20 00:54:12,005] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 795.8707\n",
      "2025-11-20 00:54:12 - INFO - [Epoch 024] New best val loss: 795.8707\n",
      "[2025-11-20 00:54:26,925] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 795.2638\n",
      "2025-11-20 00:54:26 - INFO - [Epoch 026] New best val loss: 795.2638\n",
      "[2025-11-20 00:54:34,714] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 794.9442\n",
      "2025-11-20 00:54:34 - INFO - [Epoch 027] New best val loss: 794.9442\n",
      "[2025-11-20 00:54:40,701] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 791.9181\n",
      "2025-11-20 00:54:40 - INFO - [Epoch 028] New best val loss: 791.9181\n",
      "[2025-11-20 00:54:48,496] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 790.6446\n",
      "2025-11-20 00:54:48 - INFO - [Epoch 029] New best val loss: 790.6446\n",
      "[2025-11-20 00:54:54,418] [UniVITrainer] [INFO] [Epoch 030] Train loss: 817.1217 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:54:54 - INFO - [Epoch 030] Train loss: 817.1217 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:54:55,228] [UniVITrainer] [INFO] [Epoch 030] Val loss: 789.7338 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:54:55 - INFO - [Epoch 030] Val loss: 789.7338 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:54:55,392] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 789.7338\n",
      "2025-11-20 00:54:55 - INFO - [Epoch 030] New best val loss: 789.7338\n",
      "[2025-11-20 00:55:09,718] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 787.1257\n",
      "2025-11-20 00:55:09 - INFO - [Epoch 032] New best val loss: 787.1257\n",
      "[2025-11-20 00:55:17,095] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 785.8750\n",
      "2025-11-20 00:55:17 - INFO - [Epoch 033] New best val loss: 785.8750\n",
      "[2025-11-20 00:55:24,815] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 784.9735\n",
      "2025-11-20 00:55:24 - INFO - [Epoch 034] New best val loss: 784.9735\n",
      "[2025-11-20 00:55:32,300] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 784.0945\n",
      "2025-11-20 00:55:32 - INFO - [Epoch 035] New best val loss: 784.0945\n",
      "[2025-11-20 00:55:47,035] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 783.1019\n",
      "2025-11-20 00:55:47 - INFO - [Epoch 037] New best val loss: 783.1019\n",
      "[2025-11-20 00:55:54,059] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 782.0747\n",
      "2025-11-20 00:55:54 - INFO - [Epoch 038] New best val loss: 782.0747\n",
      "[2025-11-20 00:56:01,608] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 780.4020\n",
      "2025-11-20 00:56:01 - INFO - [Epoch 039] New best val loss: 780.4020\n",
      "[2025-11-20 00:56:08,313] [UniVITrainer] [INFO] [Epoch 040] Train loss: 798.2141 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:56:08 - INFO - [Epoch 040] Train loss: 798.2141 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:56:09,126] [UniVITrainer] [INFO] [Epoch 040] Val loss: 780.0689 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:56:09 - INFO - [Epoch 040] Val loss: 780.0689 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:56:09,301] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 780.0689\n",
      "2025-11-20 00:56:09 - INFO - [Epoch 040] New best val loss: 780.0689\n",
      "[2025-11-20 00:56:16,892] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 779.9363\n",
      "2025-11-20 00:56:16 - INFO - [Epoch 041] New best val loss: 779.9363\n",
      "[2025-11-20 00:56:24,550] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 779.3094\n",
      "2025-11-20 00:56:24 - INFO - [Epoch 042] New best val loss: 779.3094\n",
      "[2025-11-20 00:56:32,147] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 778.4254\n",
      "2025-11-20 00:56:32 - INFO - [Epoch 043] New best val loss: 778.4254\n",
      "[2025-11-20 00:56:39,531] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 778.3454\n",
      "2025-11-20 00:56:39 - INFO - [Epoch 044] New best val loss: 778.3454\n",
      "[2025-11-20 00:56:45,805] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 778.0484\n",
      "2025-11-20 00:56:45 - INFO - [Epoch 045] New best val loss: 778.0484\n",
      "[2025-11-20 00:56:53,412] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 777.6694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 00:56:53 - INFO - [Epoch 046] New best val loss: 777.6694\n",
      "[2025-11-20 00:57:01,124] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 776.5288\n",
      "2025-11-20 00:57:01 - INFO - [Epoch 047] New best val loss: 776.5288\n",
      "[2025-11-20 00:57:08,545] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 775.4659\n",
      "2025-11-20 00:57:08 - INFO - [Epoch 048] New best val loss: 775.4659\n",
      "[2025-11-20 00:57:22,152] [UniVITrainer] [INFO] [Epoch 050] Train loss: 784.8402 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:57:22 - INFO - [Epoch 050] Train loss: 784.8402 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:57:22,964] [UniVITrainer] [INFO] [Epoch 050] Val loss: 775.1205 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:57:22 - INFO - [Epoch 050] Val loss: 775.1205 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:57:23,142] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 775.1205\n",
      "2025-11-20 00:57:23 - INFO - [Epoch 050] New best val loss: 775.1205\n",
      "[2025-11-20 00:57:30,890] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 774.3340\n",
      "2025-11-20 00:57:30 - INFO - [Epoch 051] New best val loss: 774.3340\n",
      "[2025-11-20 00:57:38,322] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 774.2678\n",
      "2025-11-20 00:57:38 - INFO - [Epoch 052] New best val loss: 774.2678\n",
      "[2025-11-20 00:57:44,625] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 773.7711\n",
      "2025-11-20 00:57:44 - INFO - [Epoch 053] New best val loss: 773.7711\n",
      "[2025-11-20 00:57:59,561] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 773.6530\n",
      "2025-11-20 00:57:59 - INFO - [Epoch 055] New best val loss: 773.6530\n",
      "[2025-11-20 00:58:06,541] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 772.7864\n",
      "2025-11-20 00:58:06 - INFO - [Epoch 056] New best val loss: 772.7864\n",
      "[2025-11-20 00:58:21,466] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 772.6505\n",
      "2025-11-20 00:58:21 - INFO - [Epoch 058] New best val loss: 772.6505\n",
      "[2025-11-20 00:58:28,705] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 771.5083\n",
      "2025-11-20 00:58:28 - INFO - [Epoch 059] New best val loss: 771.5083\n",
      "[2025-11-20 00:58:34,562] [UniVITrainer] [INFO] [Epoch 060] Train loss: 783.5183 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:58:34 - INFO - [Epoch 060] Train loss: 783.5183 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:58:35,403] [UniVITrainer] [INFO] [Epoch 060] Val loss: 771.6749 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:58:35 - INFO - [Epoch 060] Val loss: 771.6749 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:58:42,968] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 771.0004\n",
      "2025-11-20 00:58:42 - INFO - [Epoch 061] New best val loss: 771.0004\n",
      "[2025-11-20 00:58:50,451] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 770.7782\n",
      "2025-11-20 00:58:50 - INFO - [Epoch 062] New best val loss: 770.7782\n",
      "[2025-11-20 00:59:05,030] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 770.4091\n",
      "2025-11-20 00:59:05 - INFO - [Epoch 064] New best val loss: 770.4091\n",
      "[2025-11-20 00:59:13,022] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 769.9707\n",
      "2025-11-20 00:59:13 - INFO - [Epoch 065] New best val loss: 769.9707\n",
      "[2025-11-20 00:59:20,479] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 769.8750\n",
      "2025-11-20 00:59:20 - INFO - [Epoch 066] New best val loss: 769.8750\n",
      "[2025-11-20 00:59:35,159] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 769.4338\n",
      "2025-11-20 00:59:35 - INFO - [Epoch 068] New best val loss: 769.4338\n",
      "[2025-11-20 00:59:49,484] [UniVITrainer] [INFO] [Epoch 070] Train loss: 774.5055 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:59:49 - INFO - [Epoch 070] Train loss: 774.5055 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 00:59:50,314] [UniVITrainer] [INFO] [Epoch 070] Val loss: 769.6501 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 00:59:50 - INFO - [Epoch 070] Val loss: 769.6501 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:00:18,253] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 769.2595\n",
      "2025-11-20 01:00:18 - INFO - [Epoch 074] New best val loss: 769.2595\n",
      "[2025-11-20 01:00:25,813] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 769.2282\n",
      "2025-11-20 01:00:25 - INFO - [Epoch 075] New best val loss: 769.2282\n",
      "[2025-11-20 01:00:32,730] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 768.8728\n",
      "2025-11-20 01:00:32 - INFO - [Epoch 076] New best val loss: 768.8728\n",
      "[2025-11-20 01:00:40,134] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 768.5349\n",
      "2025-11-20 01:00:40 - INFO - [Epoch 077] New best val loss: 768.5349\n",
      "[2025-11-20 01:00:48,005] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 768.3930\n",
      "2025-11-20 01:00:48 - INFO - [Epoch 078] New best val loss: 768.3930\n",
      "[2025-11-20 01:01:02,308] [UniVITrainer] [INFO] [Epoch 080] Train loss: 769.8984 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:01:02 - INFO - [Epoch 080] Train loss: 769.8984 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:01:03,147] [UniVITrainer] [INFO] [Epoch 080] Val loss: 768.3707 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:01:03 - INFO - [Epoch 080] Val loss: 768.3707 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:01:03,192] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 768.3707\n",
      "2025-11-20 01:01:03 - INFO - [Epoch 080] New best val loss: 768.3707\n",
      "[2025-11-20 01:01:11,193] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 768.2099\n",
      "2025-11-20 01:01:11 - INFO - [Epoch 081] New best val loss: 768.2099\n",
      "[2025-11-20 01:01:18,838] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 768.1909\n",
      "2025-11-20 01:01:18 - INFO - [Epoch 082] New best val loss: 768.1909\n",
      "[2025-11-20 01:01:33,916] [UniVITrainer] [INFO] [Epoch 084] New best val loss: 768.1463\n",
      "2025-11-20 01:01:33 - INFO - [Epoch 084] New best val loss: 768.1463\n",
      "[2025-11-20 01:01:41,907] [UniVITrainer] [INFO] [Epoch 085] New best val loss: 767.9231\n",
      "2025-11-20 01:01:41 - INFO - [Epoch 085] New best val loss: 767.9231\n",
      "[2025-11-20 01:01:46,539] [UniVITrainer] [INFO] [Epoch 086] New best val loss: 767.8294\n",
      "2025-11-20 01:01:46 - INFO - [Epoch 086] New best val loss: 767.8294\n",
      "[2025-11-20 01:01:54,485] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 767.8189\n",
      "2025-11-20 01:01:54 - INFO - [Epoch 087] New best val loss: 767.8189\n",
      "[2025-11-20 01:02:02,299] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 767.7983\n",
      "2025-11-20 01:02:02 - INFO - [Epoch 088] New best val loss: 767.7983\n",
      "[2025-11-20 01:02:09,848] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 767.6838\n",
      "2025-11-20 01:02:09 - INFO - [Epoch 089] New best val loss: 767.6838\n",
      "[2025-11-20 01:02:16,750] [UniVITrainer] [INFO] [Epoch 090] Train loss: 770.8485 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:02:16 - INFO - [Epoch 090] Train loss: 770.8485 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:02:17,585] [UniVITrainer] [INFO] [Epoch 090] Val loss: 767.6334 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:02:17 - INFO - [Epoch 090] Val loss: 767.6334 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:02:17,776] [UniVITrainer] [INFO] [Epoch 090] New best val loss: 767.6334\n",
      "2025-11-20 01:02:17 - INFO - [Epoch 090] New best val loss: 767.6334\n",
      "[2025-11-20 01:02:33,010] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 767.6057\n",
      "2025-11-20 01:02:33 - INFO - [Epoch 092] New best val loss: 767.6057\n",
      "[2025-11-20 01:02:40,915] [UniVITrainer] [INFO] [Epoch 093] New best val loss: 767.5010\n",
      "2025-11-20 01:02:40 - INFO - [Epoch 093] New best val loss: 767.5010\n",
      "[2025-11-20 01:03:14,495] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 767.4411\n",
      "2025-11-20 01:03:14 - INFO - [Epoch 098] New best val loss: 767.4411\n",
      "[2025-11-20 01:03:22,332] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 767.4204\n",
      "2025-11-20 01:03:22 - INFO - [Epoch 099] New best val loss: 767.4204\n",
      "[2025-11-20 01:03:29,304] [UniVITrainer] [INFO] [Epoch 100] Train loss: 768.4542 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:03:29 - INFO - [Epoch 100] Train loss: 768.4542 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:03:30,142] [UniVITrainer] [INFO] [Epoch 100] Val loss: 767.2601 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:03:30 - INFO - [Epoch 100] Val loss: 767.2601 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:03:30,336] [UniVITrainer] [INFO] [Epoch 100] New best val loss: 767.2601\n",
      "2025-11-20 01:03:30 - INFO - [Epoch 100] New best val loss: 767.2601\n",
      "[2025-11-20 01:03:44,186] [UniVITrainer] [INFO] [Epoch 102] New best val loss: 767.1903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 01:03:44 - INFO - [Epoch 102] New best val loss: 767.1903\n",
      "[2025-11-20 01:04:27,369] [UniVITrainer] [INFO] [Epoch 108] New best val loss: 767.0944\n",
      "2025-11-20 01:04:27 - INFO - [Epoch 108] New best val loss: 767.0944\n",
      "[2025-11-20 01:04:41,552] [UniVITrainer] [INFO] [Epoch 110] Train loss: 767.1356 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:04:41 - INFO - [Epoch 110] Train loss: 767.1356 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:04:42,389] [UniVITrainer] [INFO] [Epoch 110] Val loss: 767.1335 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:04:42 - INFO - [Epoch 110] Val loss: 767.1335 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:04:50,373] [UniVITrainer] [INFO] [Epoch 111] New best val loss: 767.0328\n",
      "2025-11-20 01:04:50 - INFO - [Epoch 111] New best val loss: 767.0328\n",
      "[2025-11-20 01:05:20,389] [UniVITrainer] [INFO] [Epoch 115] New best val loss: 767.0259\n",
      "2025-11-20 01:05:20 - INFO - [Epoch 115] New best val loss: 767.0259\n",
      "[2025-11-20 01:05:26,527] [UniVITrainer] [INFO] [Epoch 116] New best val loss: 766.9625\n",
      "2025-11-20 01:05:26 - INFO - [Epoch 116] New best val loss: 766.9625\n",
      "[2025-11-20 01:05:34,119] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 766.9439\n",
      "2025-11-20 01:05:34 - INFO - [Epoch 117] New best val loss: 766.9439\n",
      "[2025-11-20 01:05:48,453] [UniVITrainer] [INFO] [Epoch 119] New best val loss: 766.8688\n",
      "2025-11-20 01:05:48 - INFO - [Epoch 119] New best val loss: 766.8688\n",
      "[2025-11-20 01:05:55,007] [UniVITrainer] [INFO] [Epoch 120] Train loss: 768.4157 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:05:55 - INFO - [Epoch 120] Train loss: 768.4157 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:05:55,819] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.8837 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:05:55 - INFO - [Epoch 120] Val loss: 766.8837 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:06:10,769] [UniVITrainer] [INFO] [Epoch 122] New best val loss: 766.8588\n",
      "2025-11-20 01:06:10 - INFO - [Epoch 122] New best val loss: 766.8588\n",
      "[2025-11-20 01:06:18,586] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 766.8114\n",
      "2025-11-20 01:06:18 - INFO - [Epoch 123] New best val loss: 766.8114\n",
      "[2025-11-20 01:06:32,433] [UniVITrainer] [INFO] [Epoch 125] New best val loss: 766.8062\n",
      "2025-11-20 01:06:32 - INFO - [Epoch 125] New best val loss: 766.8062\n",
      "[2025-11-20 01:07:06,917] [UniVITrainer] [INFO] [Epoch 130] Train loss: 767.8907 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:07:06 - INFO - [Epoch 130] Train loss: 767.8907 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:07:07,728] [UniVITrainer] [INFO] [Epoch 130] Val loss: 766.7750 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:07:07 - INFO - [Epoch 130] Val loss: 766.7750 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:07:07,914] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 766.7750\n",
      "2025-11-20 01:07:07 - INFO - [Epoch 130] New best val loss: 766.7750\n",
      "[2025-11-20 01:07:38,142] [UniVITrainer] [INFO] [Epoch 134] New best val loss: 766.7633\n",
      "2025-11-20 01:07:38 - INFO - [Epoch 134] New best val loss: 766.7633\n",
      "[2025-11-20 01:07:45,858] [UniVITrainer] [INFO] [Epoch 135] New best val loss: 766.6756\n",
      "2025-11-20 01:07:45 - INFO - [Epoch 135] New best val loss: 766.6756\n",
      "[2025-11-20 01:08:08,328] [UniVITrainer] [INFO] [Epoch 138] New best val loss: 766.6741\n",
      "2025-11-20 01:08:08 - INFO - [Epoch 138] New best val loss: 766.6741\n",
      "[2025-11-20 01:08:22,542] [UniVITrainer] [INFO] [Epoch 140] Train loss: 766.8905 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:08:22 - INFO - [Epoch 140] Train loss: 766.8905 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:08:23,357] [UniVITrainer] [INFO] [Epoch 140] Val loss: 766.6739 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:08:23 - INFO - [Epoch 140] Val loss: 766.6739 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:08:23,548] [UniVITrainer] [INFO] [Epoch 140] New best val loss: 766.6739\n",
      "2025-11-20 01:08:23 - INFO - [Epoch 140] New best val loss: 766.6739\n",
      "[2025-11-20 01:08:31,169] [UniVITrainer] [INFO] [Epoch 141] New best val loss: 766.6404\n",
      "2025-11-20 01:08:31 - INFO - [Epoch 141] New best val loss: 766.6404\n",
      "[2025-11-20 01:08:56,432] [UniVITrainer] [INFO] [Epoch 145] New best val loss: 766.6331\n",
      "2025-11-20 01:08:56 - INFO - [Epoch 145] New best val loss: 766.6331\n",
      "[2025-11-20 01:09:03,989] [UniVITrainer] [INFO] [Epoch 146] New best val loss: 766.5517\n",
      "2025-11-20 01:09:03 - INFO - [Epoch 146] New best val loss: 766.5517\n",
      "[2025-11-20 01:09:30,896] [UniVITrainer] [INFO] [Epoch 150] Train loss: 766.7246 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:09:30 - INFO - [Epoch 150] Train loss: 766.7246 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:09:31,695] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.5661 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:09:31 - INFO - [Epoch 150] Val loss: 766.5661 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:10:45,089] [UniVITrainer] [INFO] [Epoch 160] Train loss: 770.0773 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:10:45 - INFO - [Epoch 160] Train loss: 770.0773 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:10:45,908] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.5811 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:10:45 - INFO - [Epoch 160] Val loss: 766.5811 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:10:53,254] [UniVITrainer] [INFO] [Epoch 161] New best val loss: 766.5166\n",
      "2025-11-20 01:10:53 - INFO - [Epoch 161] New best val loss: 766.5166\n",
      "[2025-11-20 01:11:00,486] [UniVITrainer] [INFO] [Epoch 162] New best val loss: 766.4845\n",
      "2025-11-20 01:11:00 - INFO - [Epoch 162] New best val loss: 766.4845\n",
      "[2025-11-20 01:11:08,149] [UniVITrainer] [INFO] [Epoch 163] New best val loss: 766.4745\n",
      "2025-11-20 01:11:08 - INFO - [Epoch 163] New best val loss: 766.4745\n",
      "[2025-11-20 01:11:59,099] [UniVITrainer] [INFO] [Epoch 170] Train loss: 770.3567 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:11:59 - INFO - [Epoch 170] Train loss: 770.3567 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:11:59,906] [UniVITrainer] [INFO] [Epoch 170] Val loss: 766.5586 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:11:59 - INFO - [Epoch 170] Val loss: 766.5586 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:12:14,773] [UniVITrainer] [INFO] [Epoch 172] New best val loss: 766.4677\n",
      "2025-11-20 01:12:14 - INFO - [Epoch 172] New best val loss: 766.4677\n",
      "[2025-11-20 01:12:27,426] [UniVITrainer] [INFO] [Epoch 174] New best val loss: 766.4634\n",
      "2025-11-20 01:12:27 - INFO - [Epoch 174] New best val loss: 766.4634\n",
      "[2025-11-20 01:12:35,024] [UniVITrainer] [INFO] [Epoch 175] New best val loss: 766.4631\n",
      "2025-11-20 01:12:35 - INFO - [Epoch 175] New best val loss: 766.4631\n",
      "[2025-11-20 01:12:49,766] [UniVITrainer] [INFO] [Epoch 177] New best val loss: 766.4467\n",
      "2025-11-20 01:12:49 - INFO - [Epoch 177] New best val loss: 766.4467\n",
      "[2025-11-20 01:13:04,267] [UniVITrainer] [INFO] [Epoch 179] New best val loss: 766.4418\n",
      "2025-11-20 01:13:04 - INFO - [Epoch 179] New best val loss: 766.4418\n",
      "[2025-11-20 01:13:11,091] [UniVITrainer] [INFO] [Epoch 180] Train loss: 764.1750 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:13:11 - INFO - [Epoch 180] Train loss: 764.1750 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:13:11,703] [UniVITrainer] [INFO] [Epoch 180] Val loss: 766.4993 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:13:11 - INFO - [Epoch 180] Val loss: 766.4993 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:14:19,456] [UniVITrainer] [INFO] [Epoch 189] New best val loss: 766.4052\n",
      "2025-11-20 01:14:19 - INFO - [Epoch 189] New best val loss: 766.4052\n",
      "[2025-11-20 01:14:25,165] [UniVITrainer] [INFO] [Epoch 190] Train loss: 767.9183 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:14:25 - INFO - [Epoch 190] Train loss: 767.9183 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:14:25,978] [UniVITrainer] [INFO] [Epoch 190] Val loss: 766.4221 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:14:25 - INFO - [Epoch 190] Val loss: 766.4221 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:14:40,672] [UniVITrainer] [INFO] [Epoch 192] New best val loss: 766.3941\n",
      "2025-11-20 01:14:40 - INFO - [Epoch 192] New best val loss: 766.3941\n",
      "[2025-11-20 01:15:37,585] [UniVITrainer] [INFO] [Epoch 200] Train loss: 768.6890 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 01:15:37 - INFO - [Epoch 200] Train loss: 768.6890 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:15:38,376] [UniVITrainer] [INFO] [Epoch 200] Val loss: 766.4101 (beta=100.000, gamma=140.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 01:15:38 - INFO - [Epoch 200] Val loss: 766.4101 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 01:15:38,412] [UniVITrainer] [INFO] Restored best model from epoch 192 (val loss = 766.3941)\n",
      "2025-11-20 01:15:38 - INFO - Restored best model from epoch 192 (val loss = 766.3941)\n",
      "[2025-11-20 01:15:40,896] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 01:15:40 - INFO - TrainingConfig:\n",
      "[2025-11-20 01:15:40,897] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 01:15:40 - INFO -   n_epochs: 200\n",
      "[2025-11-20 01:15:40,905] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 01:15:40 - INFO -   batch_size: 256\n",
      "[2025-11-20 01:15:40,909] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 01:15:40 - INFO -   lr: 0.001\n",
      "[2025-11-20 01:15:40,916] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 01:15:40 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 01:15:40,917] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 01:15:40 - INFO -   device: cuda\n",
      "[2025-11-20 01:15:40,918] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 01:15:40 - INFO -   log_every: 10\n",
      "[2025-11-20 01:15:40,920] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 01:15:40 - INFO -   grad_clip: None\n",
      "[2025-11-20 01:15:40,929] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 01:15:40 - INFO -   num_workers: 0\n",
      "[2025-11-20 01:15:40,931] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 01:15:40 - INFO -   seed: 42\n",
      "[2025-11-20 01:15:40,932] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 01:15:40 - INFO -   early_stopping: True\n",
      "[2025-11-20 01:15:40,933] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 01:15:40 - INFO -   patience: 20\n",
      "[2025-11-20 01:15:40,934] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 01:15:40 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 6] Done in 24.3 min\n",
      "  best_val_loss              = 766.394\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4772\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4847\n",
      "[Config 6] FOSCTTM (ADT vs ATAC, val) = 0.4869\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4829\n",
      "  Modality mixing (k=20)     = 0.0002\n",
      "  Composite score            = 1136.79\n",
      "\n",
      "================================================================================\n",
      "[Config 7] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 156,\n",
      "  \"beta\": 300.0,\n",
      "  \"gamma\": 300.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.0,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8b82e310024a3eb5693380c961d92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 01:15:47,788] [UniVITrainer] [INFO] [Epoch 001] Train loss: 8937.6331 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:15:47 - INFO - [Epoch 001] Train loss: 8937.6331 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:15:48,607] [UniVITrainer] [INFO] [Epoch 001] Val loss: 2409.8827 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:15:48 - INFO - [Epoch 001] Val loss: 2409.8827 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:15:48,877] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 2409.8827\n",
      "2025-11-20 01:15:48 - INFO - [Epoch 001] New best val loss: 2409.8827\n",
      "[2025-11-20 01:15:56,460] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1395.4587\n",
      "2025-11-20 01:15:56 - INFO - [Epoch 002] New best val loss: 1395.4587\n",
      "[2025-11-20 01:16:03,866] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1149.9595\n",
      "2025-11-20 01:16:03 - INFO - [Epoch 003] New best val loss: 1149.9595\n",
      "[2025-11-20 01:16:10,735] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 1052.6732\n",
      "2025-11-20 01:16:10 - INFO - [Epoch 004] New best val loss: 1052.6732\n",
      "[2025-11-20 01:16:18,616] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 990.1625\n",
      "2025-11-20 01:16:18 - INFO - [Epoch 005] New best val loss: 990.1625\n",
      "[2025-11-20 01:16:26,523] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 948.3304\n",
      "2025-11-20 01:16:26 - INFO - [Epoch 006] New best val loss: 948.3304\n",
      "[2025-11-20 01:16:34,060] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 923.5842\n",
      "2025-11-20 01:16:34 - INFO - [Epoch 007] New best val loss: 923.5842\n",
      "[2025-11-20 01:16:41,856] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 903.0325\n",
      "2025-11-20 01:16:41 - INFO - [Epoch 008] New best val loss: 903.0325\n",
      "[2025-11-20 01:16:48,875] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 889.7057\n",
      "2025-11-20 01:16:48 - INFO - [Epoch 009] New best val loss: 889.7057\n",
      "[2025-11-20 01:16:55,733] [UniVITrainer] [INFO] [Epoch 010] Train loss: 871.6445 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:16:55 - INFO - [Epoch 010] Train loss: 871.6445 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:16:56,546] [UniVITrainer] [INFO] [Epoch 010] Val loss: 888.0016 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:16:56 - INFO - [Epoch 010] Val loss: 888.0016 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:16:56,813] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 888.0016\n",
      "2025-11-20 01:16:56 - INFO - [Epoch 010] New best val loss: 888.0016\n",
      "[2025-11-20 01:17:04,725] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 871.2031\n",
      "2025-11-20 01:17:04 - INFO - [Epoch 011] New best val loss: 871.2031\n",
      "[2025-11-20 01:17:12,417] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 863.6764\n",
      "2025-11-20 01:17:12 - INFO - [Epoch 012] New best val loss: 863.6764\n",
      "[2025-11-20 01:17:20,311] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 855.2439\n",
      "2025-11-20 01:17:20 - INFO - [Epoch 013] New best val loss: 855.2439\n",
      "[2025-11-20 01:17:35,217] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 852.2060\n",
      "2025-11-20 01:17:35 - INFO - [Epoch 015] New best val loss: 852.2060\n",
      "[2025-11-20 01:17:42,786] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 840.3772\n",
      "2025-11-20 01:17:42 - INFO - [Epoch 016] New best val loss: 840.3772\n",
      "[2025-11-20 01:17:56,131] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 838.0489\n",
      "2025-11-20 01:17:56 - INFO - [Epoch 018] New best val loss: 838.0489\n",
      "[2025-11-20 01:18:02,836] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 830.9902\n",
      "2025-11-20 01:18:02 - INFO - [Epoch 019] New best val loss: 830.9902\n",
      "[2025-11-20 01:18:08,108] [UniVITrainer] [INFO] [Epoch 020] Train loss: 816.3269 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:18:08 - INFO - [Epoch 020] Train loss: 816.3269 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:18:08,903] [UniVITrainer] [INFO] [Epoch 020] Val loss: 825.9583 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:18:08 - INFO - [Epoch 020] Val loss: 825.9583 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:18:09,181] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 825.9583\n",
      "2025-11-20 01:18:09 - INFO - [Epoch 020] New best val loss: 825.9583\n",
      "[2025-11-20 01:18:29,372] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 823.8454\n",
      "2025-11-20 01:18:29 - INFO - [Epoch 023] New best val loss: 823.8454\n",
      "[2025-11-20 01:18:43,814] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 818.2125\n",
      "2025-11-20 01:18:43 - INFO - [Epoch 025] New best val loss: 818.2125\n",
      "[2025-11-20 01:18:51,359] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 814.2496\n",
      "2025-11-20 01:18:51 - INFO - [Epoch 026] New best val loss: 814.2496\n",
      "[2025-11-20 01:19:18,335] [UniVITrainer] [INFO] [Epoch 030] Train loss: 796.1909 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:19:18 - INFO - [Epoch 030] Train loss: 796.1909 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:19:19,133] [UniVITrainer] [INFO] [Epoch 030] Val loss: 816.1342 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:19:19 - INFO - [Epoch 030] Val loss: 816.1342 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:19:26,784] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 808.6597\n",
      "2025-11-20 01:19:26 - INFO - [Epoch 031] New best val loss: 808.6597\n",
      "[2025-11-20 01:19:40,615] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 805.8426\n",
      "2025-11-20 01:19:40 - INFO - [Epoch 033] New best val loss: 805.8426\n",
      "[2025-11-20 01:20:03,029] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 805.1622\n",
      "2025-11-20 01:20:03 - INFO - [Epoch 036] New best val loss: 805.1622\n",
      "[2025-11-20 01:20:10,419] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 803.9714\n",
      "2025-11-20 01:20:10 - INFO - [Epoch 037] New best val loss: 803.9714\n",
      "[2025-11-20 01:20:18,083] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 801.4544\n",
      "2025-11-20 01:20:18 - INFO - [Epoch 038] New best val loss: 801.4544\n",
      "[2025-11-20 01:20:25,227] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 800.9572\n",
      "2025-11-20 01:20:25 - INFO - [Epoch 039] New best val loss: 800.9572\n",
      "[2025-11-20 01:20:32,089] [UniVITrainer] [INFO] [Epoch 040] Train loss: 780.3066 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:20:32 - INFO - [Epoch 040] Train loss: 780.3066 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:20:32,897] [UniVITrainer] [INFO] [Epoch 040] Val loss: 798.8705 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:20:32 - INFO - [Epoch 040] Val loss: 798.8705 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:20:33,170] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 798.8705\n",
      "2025-11-20 01:20:33 - INFO - [Epoch 040] New best val loss: 798.8705\n",
      "[2025-11-20 01:21:01,584] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 795.6570\n",
      "2025-11-20 01:21:01 - INFO - [Epoch 044] New best val loss: 795.6570\n",
      "[2025-11-20 01:21:23,304] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 795.3919\n",
      "2025-11-20 01:21:23 - INFO - [Epoch 047] New best val loss: 795.3919\n",
      "[2025-11-20 01:21:30,861] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 795.3904\n",
      "2025-11-20 01:21:30 - INFO - [Epoch 048] New best val loss: 795.3904\n",
      "[2025-11-20 01:21:37,942] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 793.7986\n",
      "2025-11-20 01:21:37 - INFO - [Epoch 049] New best val loss: 793.7986\n",
      "[2025-11-20 01:21:44,694] [UniVITrainer] [INFO] [Epoch 050] Train loss: 781.0993 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:21:44 - INFO - [Epoch 050] Train loss: 781.0993 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:21:45,504] [UniVITrainer] [INFO] [Epoch 050] Val loss: 793.4279 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:21:45 - INFO - [Epoch 050] Val loss: 793.4279 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:21:45,526] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 793.4279\n",
      "2025-11-20 01:21:45 - INFO - [Epoch 050] New best val loss: 793.4279\n",
      "[2025-11-20 01:22:00,064] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 791.2561\n",
      "2025-11-20 01:22:00 - INFO - [Epoch 052] New best val loss: 791.2561\n",
      "[2025-11-20 01:22:22,125] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 790.8439\n",
      "2025-11-20 01:22:22 - INFO - [Epoch 055] New best val loss: 790.8439\n",
      "[2025-11-20 01:22:37,086] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 789.7929\n",
      "2025-11-20 01:22:37 - INFO - [Epoch 057] New best val loss: 789.7929\n",
      "[2025-11-20 01:22:58,861] [UniVITrainer] [INFO] [Epoch 060] Train loss: 777.8772 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:22:58 - INFO - [Epoch 060] Train loss: 777.8772 (beta=300.000, gamma=300.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 01:22:59,675] [UniVITrainer] [INFO] [Epoch 060] Val loss: 789.5868 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:22:59 - INFO - [Epoch 060] Val loss: 789.5868 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:22:59,919] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 789.5868\n",
      "2025-11-20 01:22:59 - INFO - [Epoch 060] New best val loss: 789.5868\n",
      "[2025-11-20 01:23:15,322] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 788.8138\n",
      "2025-11-20 01:23:15 - INFO - [Epoch 062] New best val loss: 788.8138\n",
      "[2025-11-20 01:23:22,877] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 787.7903\n",
      "2025-11-20 01:23:22 - INFO - [Epoch 063] New best val loss: 787.7903\n",
      "[2025-11-20 01:23:30,561] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 787.7324\n",
      "2025-11-20 01:23:30 - INFO - [Epoch 064] New best val loss: 787.7324\n",
      "[2025-11-20 01:23:38,415] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 786.3551\n",
      "2025-11-20 01:23:38 - INFO - [Epoch 065] New best val loss: 786.3551\n",
      "[2025-11-20 01:23:53,546] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 786.3351\n",
      "2025-11-20 01:23:53 - INFO - [Epoch 067] New best val loss: 786.3351\n",
      "[2025-11-20 01:24:14,270] [UniVITrainer] [INFO] [Epoch 070] Train loss: 776.9432 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:24:14 - INFO - [Epoch 070] Train loss: 776.9432 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:24:15,105] [UniVITrainer] [INFO] [Epoch 070] Val loss: 785.0087 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:24:15 - INFO - [Epoch 070] Val loss: 785.0087 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:24:15,340] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 785.0087\n",
      "2025-11-20 01:24:15 - INFO - [Epoch 070] New best val loss: 785.0087\n",
      "[2025-11-20 01:24:22,461] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 784.3537\n",
      "2025-11-20 01:24:22 - INFO - [Epoch 071] New best val loss: 784.3537\n",
      "[2025-11-20 01:24:51,321] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 783.7507\n",
      "2025-11-20 01:24:51 - INFO - [Epoch 075] New best val loss: 783.7507\n",
      "[2025-11-20 01:24:59,362] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 782.4564\n",
      "2025-11-20 01:24:59 - INFO - [Epoch 076] New best val loss: 782.4564\n",
      "[2025-11-20 01:25:06,455] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 782.1645\n",
      "2025-11-20 01:25:06 - INFO - [Epoch 077] New best val loss: 782.1645\n",
      "[2025-11-20 01:25:26,717] [UniVITrainer] [INFO] [Epoch 080] Train loss: 772.5021 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:25:26 - INFO - [Epoch 080] Train loss: 772.5021 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:25:27,382] [UniVITrainer] [INFO] [Epoch 080] Val loss: 780.7922 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:25:27 - INFO - [Epoch 080] Val loss: 780.7922 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:25:27,664] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 780.7922\n",
      "2025-11-20 01:25:27 - INFO - [Epoch 080] New best val loss: 780.7922\n",
      "[2025-11-20 01:25:50,340] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 780.7356\n",
      "2025-11-20 01:25:50 - INFO - [Epoch 083] New best val loss: 780.7356\n",
      "[2025-11-20 01:25:58,284] [UniVITrainer] [INFO] [Epoch 084] New best val loss: 779.2172\n",
      "2025-11-20 01:25:58 - INFO - [Epoch 084] New best val loss: 779.2172\n",
      "[2025-11-20 01:26:34,439] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 777.7126\n",
      "2025-11-20 01:26:34 - INFO - [Epoch 089] New best val loss: 777.7126\n",
      "[2025-11-20 01:26:41,408] [UniVITrainer] [INFO] [Epoch 090] Train loss: 774.1200 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:26:41 - INFO - [Epoch 090] Train loss: 774.1200 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:26:42,045] [UniVITrainer] [INFO] [Epoch 090] Val loss: 777.7711 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:26:42 - INFO - [Epoch 090] Val loss: 777.7711 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:27:05,156] [UniVITrainer] [INFO] [Epoch 093] New best val loss: 777.6327\n",
      "2025-11-20 01:27:05 - INFO - [Epoch 093] New best val loss: 777.6327\n",
      "[2025-11-20 01:27:13,258] [UniVITrainer] [INFO] [Epoch 094] New best val loss: 776.7651\n",
      "2025-11-20 01:27:13 - INFO - [Epoch 094] New best val loss: 776.7651\n",
      "[2025-11-20 01:27:42,639] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 776.0151\n",
      "2025-11-20 01:27:42 - INFO - [Epoch 098] New best val loss: 776.0151\n",
      "[2025-11-20 01:27:57,341] [UniVITrainer] [INFO] [Epoch 100] Train loss: 773.1846 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:27:57 - INFO - [Epoch 100] Train loss: 773.1846 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:27:57,947] [UniVITrainer] [INFO] [Epoch 100] Val loss: 776.2295 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:27:57 - INFO - [Epoch 100] Val loss: 776.2295 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:28:12,932] [UniVITrainer] [INFO] [Epoch 102] New best val loss: 775.7975\n",
      "2025-11-20 01:28:12 - INFO - [Epoch 102] New best val loss: 775.7975\n",
      "[2025-11-20 01:28:27,806] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 775.5921\n",
      "2025-11-20 01:28:27 - INFO - [Epoch 104] New best val loss: 775.5921\n",
      "[2025-11-20 01:28:35,699] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 775.0302\n",
      "2025-11-20 01:28:35 - INFO - [Epoch 105] New best val loss: 775.0302\n",
      "[2025-11-20 01:28:58,640] [UniVITrainer] [INFO] [Epoch 108] New best val loss: 774.7216\n",
      "2025-11-20 01:28:58 - INFO - [Epoch 108] New best val loss: 774.7216\n",
      "[2025-11-20 01:29:06,300] [UniVITrainer] [INFO] [Epoch 109] New best val loss: 774.7107\n",
      "2025-11-20 01:29:06 - INFO - [Epoch 109] New best val loss: 774.7107\n",
      "[2025-11-20 01:29:13,222] [UniVITrainer] [INFO] [Epoch 110] Train loss: 770.4807 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:29:13 - INFO - [Epoch 110] Train loss: 770.4807 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:29:14,047] [UniVITrainer] [INFO] [Epoch 110] Val loss: 777.7867 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:29:14 - INFO - [Epoch 110] Val loss: 777.7867 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:29:37,714] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 773.7466\n",
      "2025-11-20 01:29:37 - INFO - [Epoch 113] New best val loss: 773.7466\n",
      "[2025-11-20 01:30:08,257] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 773.6981\n",
      "2025-11-20 01:30:08 - INFO - [Epoch 117] New best val loss: 773.6981\n",
      "[2025-11-20 01:30:16,307] [UniVITrainer] [INFO] [Epoch 118] New best val loss: 773.6237\n",
      "2025-11-20 01:30:16 - INFO - [Epoch 118] New best val loss: 773.6237\n",
      "[2025-11-20 01:30:23,593] [UniVITrainer] [INFO] [Epoch 119] New best val loss: 773.1039\n",
      "2025-11-20 01:30:23 - INFO - [Epoch 119] New best val loss: 773.1039\n",
      "[2025-11-20 01:30:30,168] [UniVITrainer] [INFO] [Epoch 120] Train loss: 772.5238 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:30:30 - INFO - [Epoch 120] Train loss: 772.5238 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:30:30,980] [UniVITrainer] [INFO] [Epoch 120] Val loss: 773.5288 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:30:30 - INFO - [Epoch 120] Val loss: 773.5288 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:31:13,808] [UniVITrainer] [INFO] [Epoch 126] New best val loss: 772.6599\n",
      "2025-11-20 01:31:13 - INFO - [Epoch 126] New best val loss: 772.6599\n",
      "[2025-11-20 01:31:39,223] [UniVITrainer] [INFO] [Epoch 130] Train loss: 767.4363 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:31:39 - INFO - [Epoch 130] Train loss: 767.4363 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:31:40,037] [UniVITrainer] [INFO] [Epoch 130] Val loss: 774.6460 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:31:40 - INFO - [Epoch 130] Val loss: 774.6460 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:32:01,685] [UniVITrainer] [INFO] [Epoch 133] New best val loss: 772.4459\n",
      "2025-11-20 01:32:01 - INFO - [Epoch 133] New best val loss: 772.4459\n",
      "[2025-11-20 01:32:16,744] [UniVITrainer] [INFO] [Epoch 135] New best val loss: 772.1431\n",
      "2025-11-20 01:32:16 - INFO - [Epoch 135] New best val loss: 772.1431\n",
      "[2025-11-20 01:32:45,858] [UniVITrainer] [INFO] [Epoch 139] New best val loss: 772.0342\n",
      "2025-11-20 01:32:45 - INFO - [Epoch 139] New best val loss: 772.0342\n",
      "[2025-11-20 01:32:52,427] [UniVITrainer] [INFO] [Epoch 140] Train loss: 766.6273 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:32:52 - INFO - [Epoch 140] Train loss: 766.6273 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:32:53,240] [UniVITrainer] [INFO] [Epoch 140] Val loss: 772.4710 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:32:53 - INFO - [Epoch 140] Val loss: 772.4710 (beta=300.000, gamma=300.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 01:33:01,067] [UniVITrainer] [INFO] [Epoch 141] New best val loss: 771.7521\n",
      "2025-11-20 01:33:01 - INFO - [Epoch 141] New best val loss: 771.7521\n",
      "[2025-11-20 01:33:08,902] [UniVITrainer] [INFO] [Epoch 142] New best val loss: 771.6725\n",
      "2025-11-20 01:33:08 - INFO - [Epoch 142] New best val loss: 771.6725\n",
      "[2025-11-20 01:33:29,264] [UniVITrainer] [INFO] [Epoch 145] New best val loss: 770.9633\n",
      "2025-11-20 01:33:29 - INFO - [Epoch 145] New best val loss: 770.9633\n",
      "[2025-11-20 01:34:03,761] [UniVITrainer] [INFO] [Epoch 150] Train loss: 770.1188 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:34:03 - INFO - [Epoch 150] Train loss: 770.1188 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:34:04,581] [UniVITrainer] [INFO] [Epoch 150] Val loss: 772.0460 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:34:04 - INFO - [Epoch 150] Val loss: 772.0460 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:34:19,387] [UniVITrainer] [INFO] [Epoch 152] New best val loss: 770.6269\n",
      "2025-11-20 01:34:19 - INFO - [Epoch 152] New best val loss: 770.6269\n",
      "[2025-11-20 01:35:17,387] [UniVITrainer] [INFO] [Epoch 160] Train loss: 769.9174 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:35:17 - INFO - [Epoch 160] Train loss: 769.9174 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:35:18,204] [UniVITrainer] [INFO] [Epoch 160] Val loss: 770.5567 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:35:18 - INFO - [Epoch 160] Val loss: 770.5567 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:35:18,471] [UniVITrainer] [INFO] [Epoch 160] New best val loss: 770.5567\n",
      "2025-11-20 01:35:18 - INFO - [Epoch 160] New best val loss: 770.5567\n",
      "[2025-11-20 01:35:41,689] [UniVITrainer] [INFO] [Epoch 163] New best val loss: 770.3641\n",
      "2025-11-20 01:35:41 - INFO - [Epoch 163] New best val loss: 770.3641\n",
      "[2025-11-20 01:36:19,038] [UniVITrainer] [INFO] [Epoch 168] New best val loss: 769.9248\n",
      "2025-11-20 01:36:19 - INFO - [Epoch 168] New best val loss: 769.9248\n",
      "[2025-11-20 01:36:33,415] [UniVITrainer] [INFO] [Epoch 170] Train loss: 768.4638 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:36:33 - INFO - [Epoch 170] Train loss: 768.4638 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:36:34,231] [UniVITrainer] [INFO] [Epoch 170] Val loss: 771.4901 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:36:34 - INFO - [Epoch 170] Val loss: 771.4901 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:37:37,443] [UniVITrainer] [INFO] [Epoch 179] New best val loss: 769.8908\n",
      "2025-11-20 01:37:37 - INFO - [Epoch 179] New best val loss: 769.8908\n",
      "[2025-11-20 01:37:43,023] [UniVITrainer] [INFO] [Epoch 180] Train loss: 766.5824 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:37:43 - INFO - [Epoch 180] Train loss: 766.5824 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:37:43,859] [UniVITrainer] [INFO] [Epoch 180] Val loss: 769.6190 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:37:43 - INFO - [Epoch 180] Val loss: 769.6190 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:37:44,113] [UniVITrainer] [INFO] [Epoch 180] New best val loss: 769.6190\n",
      "2025-11-20 01:37:44 - INFO - [Epoch 180] New best val loss: 769.6190\n",
      "[2025-11-20 01:37:57,355] [UniVITrainer] [INFO] [Epoch 182] New best val loss: 769.4348\n",
      "2025-11-20 01:37:57 - INFO - [Epoch 182] New best val loss: 769.4348\n",
      "[2025-11-20 01:38:27,070] [UniVITrainer] [INFO] [Epoch 186] New best val loss: 769.3451\n",
      "2025-11-20 01:38:27 - INFO - [Epoch 186] New best val loss: 769.3451\n",
      "[2025-11-20 01:38:56,563] [UniVITrainer] [INFO] [Epoch 190] Train loss: 767.6865 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:38:56 - INFO - [Epoch 190] Train loss: 767.6865 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:38:57,401] [UniVITrainer] [INFO] [Epoch 190] Val loss: 769.4124 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:38:57 - INFO - [Epoch 190] Val loss: 769.4124 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:39:12,299] [UniVITrainer] [INFO] [Epoch 192] New best val loss: 769.1450\n",
      "2025-11-20 01:39:12 - INFO - [Epoch 192] New best val loss: 769.1450\n",
      "[2025-11-20 01:39:19,287] [UniVITrainer] [INFO] [Epoch 193] New best val loss: 769.0751\n",
      "2025-11-20 01:39:19 - INFO - [Epoch 193] New best val loss: 769.0751\n",
      "[2025-11-20 01:39:41,192] [UniVITrainer] [INFO] [Epoch 196] New best val loss: 769.0686\n",
      "2025-11-20 01:39:41 - INFO - [Epoch 196] New best val loss: 769.0686\n",
      "[2025-11-20 01:40:10,979] [UniVITrainer] [INFO] [Epoch 200] Train loss: 768.3073 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:40:10 - INFO - [Epoch 200] Train loss: 768.3073 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:40:11,749] [UniVITrainer] [INFO] [Epoch 200] Val loss: 769.2353 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 01:40:11 - INFO - [Epoch 200] Val loss: 769.2353 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 01:40:11,814] [UniVITrainer] [INFO] Restored best model from epoch 196 (val loss = 769.0686)\n",
      "2025-11-20 01:40:11 - INFO - Restored best model from epoch 196 (val loss = 769.0686)\n",
      "[2025-11-20 01:40:14,332] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 01:40:14 - INFO - TrainingConfig:\n",
      "[2025-11-20 01:40:14,334] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 01:40:14 - INFO -   n_epochs: 200\n",
      "[2025-11-20 01:40:14,342] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 01:40:14 - INFO -   batch_size: 256\n",
      "[2025-11-20 01:40:14,346] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 01:40:14 - INFO -   lr: 0.001\n",
      "[2025-11-20 01:40:14,350] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 01:40:14 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 01:40:14,352] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 01:40:14 - INFO -   device: cuda\n",
      "[2025-11-20 01:40:14,353] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 01:40:14 - INFO -   log_every: 10\n",
      "[2025-11-20 01:40:14,362] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 01:40:14 - INFO -   grad_clip: None\n",
      "[2025-11-20 01:40:14,363] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 01:40:14 - INFO -   num_workers: 0\n",
      "[2025-11-20 01:40:14,364] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 01:40:14 - INFO -   seed: 42\n",
      "[2025-11-20 01:40:14,365] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 01:40:14 - INFO -   early_stopping: True\n",
      "[2025-11-20 01:40:14,366] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 01:40:14 - INFO -   patience: 20\n",
      "[2025-11-20 01:40:14,367] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 01:40:14 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 7] Done in 24.5 min\n",
      "  best_val_loss              = 769.069\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5799\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.5184\n",
      "[Config 7] FOSCTTM (ADT vs ATAC, val) = 0.4877\n",
      "  Mean FOSCTTM (3 pairs)     = 0.5287\n",
      "  Modality mixing (k=20)     = 0.0028\n",
      "  Composite score            = 1178.97\n",
      "\n",
      "================================================================================\n",
      "[Config 8] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 64,\n",
      "  \"beta\": 80.0,\n",
      "  \"gamma\": 140.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6587d8ae403749b98204134c6c3a932c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 01:40:20,903] [UniVITrainer] [INFO] [Epoch 001] Train loss: 2345.9685 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:40:20 - INFO - [Epoch 001] Train loss: 2345.9685 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:40:21,737] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1023.5419 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:40:21 - INFO - [Epoch 001] Val loss: 1023.5419 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:40:21,789] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1023.5419\n",
      "2025-11-20 01:40:21 - INFO - [Epoch 001] New best val loss: 1023.5419\n",
      "[2025-11-20 01:40:28,881] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 855.2831\n",
      "2025-11-20 01:40:28 - INFO - [Epoch 002] New best val loss: 855.2831\n",
      "[2025-11-20 01:40:36,693] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 821.8358\n",
      "2025-11-20 01:40:36 - INFO - [Epoch 003] New best val loss: 821.8358\n",
      "[2025-11-20 01:40:44,275] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 807.3366\n",
      "2025-11-20 01:40:44 - INFO - [Epoch 004] New best val loss: 807.3366\n",
      "[2025-11-20 01:40:52,257] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 799.5511\n",
      "2025-11-20 01:40:52 - INFO - [Epoch 005] New best val loss: 799.5511\n",
      "[2025-11-20 01:41:00,149] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 794.3218\n",
      "2025-11-20 01:41:00 - INFO - [Epoch 006] New best val loss: 794.3218\n",
      "[2025-11-20 01:41:05,766] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 788.9546\n",
      "2025-11-20 01:41:05 - INFO - [Epoch 007] New best val loss: 788.9546\n",
      "[2025-11-20 01:41:12,725] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 785.8143\n",
      "2025-11-20 01:41:12 - INFO - [Epoch 008] New best val loss: 785.8143\n",
      "[2025-11-20 01:41:20,340] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 783.4291\n",
      "2025-11-20 01:41:20 - INFO - [Epoch 009] New best val loss: 783.4291\n",
      "[2025-11-20 01:41:27,291] [UniVITrainer] [INFO] [Epoch 010] Train loss: 824.6643 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:41:27 - INFO - [Epoch 010] Train loss: 824.6643 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:41:28,094] [UniVITrainer] [INFO] [Epoch 010] Val loss: 782.4586 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:41:28 - INFO - [Epoch 010] Val loss: 782.4586 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:41:28,240] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 782.4586\n",
      "2025-11-20 01:41:28 - INFO - [Epoch 010] New best val loss: 782.4586\n",
      "[2025-11-20 01:41:36,206] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 780.0592\n",
      "2025-11-20 01:41:36 - INFO - [Epoch 011] New best val loss: 780.0592\n",
      "[2025-11-20 01:41:43,874] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 779.3717\n",
      "2025-11-20 01:41:43 - INFO - [Epoch 012] New best val loss: 779.3717\n",
      "[2025-11-20 01:41:51,710] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 777.7656\n",
      "2025-11-20 01:41:51 - INFO - [Epoch 013] New best val loss: 777.7656\n",
      "[2025-11-20 01:41:59,238] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 777.5852\n",
      "2025-11-20 01:41:59 - INFO - [Epoch 014] New best val loss: 777.5852\n",
      "[2025-11-20 01:42:07,193] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 775.7800\n",
      "2025-11-20 01:42:07 - INFO - [Epoch 015] New best val loss: 775.7800\n",
      "[2025-11-20 01:42:15,020] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 774.5822\n",
      "2025-11-20 01:42:15 - INFO - [Epoch 016] New best val loss: 774.5822\n",
      "[2025-11-20 01:42:22,788] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 774.1991\n",
      "2025-11-20 01:42:22 - INFO - [Epoch 017] New best val loss: 774.1991\n",
      "[2025-11-20 01:42:30,705] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 773.4041\n",
      "2025-11-20 01:42:30 - INFO - [Epoch 018] New best val loss: 773.4041\n",
      "[2025-11-20 01:42:38,533] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 773.3651\n",
      "2025-11-20 01:42:38 - INFO - [Epoch 019] New best val loss: 773.3651\n",
      "[2025-11-20 01:42:45,430] [UniVITrainer] [INFO] [Epoch 020] Train loss: 788.7046 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:42:45 - INFO - [Epoch 020] Train loss: 788.7046 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:42:46,265] [UniVITrainer] [INFO] [Epoch 020] Val loss: 772.3783 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:42:46 - INFO - [Epoch 020] Val loss: 772.3783 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:42:46,447] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 772.3783\n",
      "2025-11-20 01:42:46 - INFO - [Epoch 020] New best val loss: 772.3783\n",
      "[2025-11-20 01:42:54,330] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 771.9569\n",
      "2025-11-20 01:42:54 - INFO - [Epoch 021] New best val loss: 771.9569\n",
      "[2025-11-20 01:42:59,846] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 771.7959\n",
      "2025-11-20 01:42:59 - INFO - [Epoch 022] New best val loss: 771.7959\n",
      "[2025-11-20 01:43:15,577] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 771.1613\n",
      "2025-11-20 01:43:15 - INFO - [Epoch 024] New best val loss: 771.1613\n",
      "[2025-11-20 01:43:23,531] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 771.1442\n",
      "2025-11-20 01:43:23 - INFO - [Epoch 025] New best val loss: 771.1442\n",
      "[2025-11-20 01:43:31,355] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 771.0489\n",
      "2025-11-20 01:43:31 - INFO - [Epoch 026] New best val loss: 771.0489\n",
      "[2025-11-20 01:43:39,296] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 770.5352\n",
      "2025-11-20 01:43:39 - INFO - [Epoch 027] New best val loss: 770.5352\n",
      "[2025-11-20 01:43:47,204] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 770.3283\n",
      "2025-11-20 01:43:47 - INFO - [Epoch 028] New best val loss: 770.3283\n",
      "[2025-11-20 01:43:55,151] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 770.2239\n",
      "2025-11-20 01:43:55 - INFO - [Epoch 029] New best val loss: 770.2239\n",
      "[2025-11-20 01:44:02,084] [UniVITrainer] [INFO] [Epoch 030] Train loss: 778.3636 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:44:02 - INFO - [Epoch 030] Train loss: 778.3636 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:44:02,642] [UniVITrainer] [INFO] [Epoch 030] Val loss: 769.9693 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:44:02 - INFO - [Epoch 030] Val loss: 769.9693 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:44:02,810] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 769.9693\n",
      "2025-11-20 01:44:02 - INFO - [Epoch 030] New best val loss: 769.9693\n",
      "[2025-11-20 01:44:10,251] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 769.9285\n",
      "2025-11-20 01:44:10 - INFO - [Epoch 031] New best val loss: 769.9285\n",
      "[2025-11-20 01:44:24,412] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 769.7239\n",
      "2025-11-20 01:44:24 - INFO - [Epoch 033] New best val loss: 769.7239\n",
      "[2025-11-20 01:44:31,333] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 769.3408\n",
      "2025-11-20 01:44:31 - INFO - [Epoch 034] New best val loss: 769.3408\n",
      "[2025-11-20 01:44:37,975] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 769.1802\n",
      "2025-11-20 01:44:37 - INFO - [Epoch 035] New best val loss: 769.1802\n",
      "[2025-11-20 01:44:58,251] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 768.9710\n",
      "2025-11-20 01:44:58 - INFO - [Epoch 038] New best val loss: 768.9710\n",
      "[2025-11-20 01:45:05,862] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 768.8265\n",
      "2025-11-20 01:45:05 - INFO - [Epoch 039] New best val loss: 768.8265\n",
      "[2025-11-20 01:45:12,223] [UniVITrainer] [INFO] [Epoch 040] Train loss: 774.2486 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:45:12 - INFO - [Epoch 040] Train loss: 774.2486 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:45:13,055] [UniVITrainer] [INFO] [Epoch 040] Val loss: 768.5218 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:45:13 - INFO - [Epoch 040] Val loss: 768.5218 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:45:13,209] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 768.5218\n",
      "2025-11-20 01:45:13 - INFO - [Epoch 040] New best val loss: 768.5218\n",
      "[2025-11-20 01:45:21,030] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 768.4583\n",
      "2025-11-20 01:45:21 - INFO - [Epoch 041] New best val loss: 768.4583\n",
      "[2025-11-20 01:45:42,031] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 768.0857\n",
      "2025-11-20 01:45:42 - INFO - [Epoch 044] New best val loss: 768.0857\n",
      "[2025-11-20 01:45:48,944] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 767.9369\n",
      "2025-11-20 01:45:48 - INFO - [Epoch 045] New best val loss: 767.9369\n",
      "[2025-11-20 01:45:56,743] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 767.8908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 01:45:56 - INFO - [Epoch 046] New best val loss: 767.8908\n",
      "[2025-11-20 01:46:03,413] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 767.7378\n",
      "2025-11-20 01:46:03 - INFO - [Epoch 047] New best val loss: 767.7378\n",
      "[2025-11-20 01:46:23,769] [UniVITrainer] [INFO] [Epoch 050] Train loss: 770.7273 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:46:23 - INFO - [Epoch 050] Train loss: 770.7273 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:46:23,903] [UniVITrainer] [INFO] [Epoch 050] Val loss: 767.7397 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:46:23 - INFO - [Epoch 050] Val loss: 767.7397 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:46:31,743] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 767.6363\n",
      "2025-11-20 01:46:31 - INFO - [Epoch 051] New best val loss: 767.6363\n",
      "[2025-11-20 01:46:39,561] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 767.4896\n",
      "2025-11-20 01:46:39 - INFO - [Epoch 052] New best val loss: 767.4896\n",
      "[2025-11-20 01:46:46,449] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 767.4118\n",
      "2025-11-20 01:46:46 - INFO - [Epoch 053] New best val loss: 767.4118\n",
      "[2025-11-20 01:47:09,695] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 767.2667\n",
      "2025-11-20 01:47:09 - INFO - [Epoch 056] New best val loss: 767.2667\n",
      "[2025-11-20 01:47:17,562] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 767.2042\n",
      "2025-11-20 01:47:17 - INFO - [Epoch 057] New best val loss: 767.2042\n",
      "[2025-11-20 01:47:25,295] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 767.1795\n",
      "2025-11-20 01:47:25 - INFO - [Epoch 058] New best val loss: 767.1795\n",
      "[2025-11-20 01:47:39,688] [UniVITrainer] [INFO] [Epoch 060] Train loss: 766.0057 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:47:39 - INFO - [Epoch 060] Train loss: 766.0057 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:47:40,501] [UniVITrainer] [INFO] [Epoch 060] Val loss: 767.1295 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:47:40 - INFO - [Epoch 060] Val loss: 767.1295 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:47:40,651] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 767.1295\n",
      "2025-11-20 01:47:40 - INFO - [Epoch 060] New best val loss: 767.1295\n",
      "[2025-11-20 01:47:48,514] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 767.0095\n",
      "2025-11-20 01:47:48 - INFO - [Epoch 061] New best val loss: 767.0095\n",
      "[2025-11-20 01:47:56,422] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 766.9754\n",
      "2025-11-20 01:47:56 - INFO - [Epoch 062] New best val loss: 766.9754\n",
      "[2025-11-20 01:48:04,002] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 766.9631\n",
      "2025-11-20 01:48:04 - INFO - [Epoch 063] New best val loss: 766.9631\n",
      "[2025-11-20 01:48:11,822] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 766.9285\n",
      "2025-11-20 01:48:11 - INFO - [Epoch 064] New best val loss: 766.9285\n",
      "[2025-11-20 01:48:19,618] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 766.8904\n",
      "2025-11-20 01:48:19 - INFO - [Epoch 065] New best val loss: 766.8904\n",
      "[2025-11-20 01:48:26,989] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 766.8470\n",
      "2025-11-20 01:48:26 - INFO - [Epoch 066] New best val loss: 766.8470\n",
      "[2025-11-20 01:48:34,900] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 766.8255\n",
      "2025-11-20 01:48:34 - INFO - [Epoch 067] New best val loss: 766.8255\n",
      "[2025-11-20 01:48:48,905] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 766.7884\n",
      "2025-11-20 01:48:48 - INFO - [Epoch 069] New best val loss: 766.7884\n",
      "[2025-11-20 01:48:55,858] [UniVITrainer] [INFO] [Epoch 070] Train loss: 766.5132 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:48:55 - INFO - [Epoch 070] Train loss: 766.5132 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:48:56,672] [UniVITrainer] [INFO] [Epoch 070] Val loss: 766.8749 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:48:56 - INFO - [Epoch 070] Val loss: 766.8749 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:49:19,962] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 766.7791\n",
      "2025-11-20 01:49:19 - INFO - [Epoch 073] New best val loss: 766.7791\n",
      "[2025-11-20 01:49:27,722] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 766.7048\n",
      "2025-11-20 01:49:27 - INFO - [Epoch 074] New best val loss: 766.7048\n",
      "[2025-11-20 01:49:35,633] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 766.6536\n",
      "2025-11-20 01:49:35 - INFO - [Epoch 075] New best val loss: 766.6536\n",
      "[2025-11-20 01:49:58,908] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 766.6423\n",
      "2025-11-20 01:49:58 - INFO - [Epoch 078] New best val loss: 766.6423\n",
      "[2025-11-20 01:50:13,341] [UniVITrainer] [INFO] [Epoch 080] Train loss: 767.1843 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:50:13 - INFO - [Epoch 080] Train loss: 767.1843 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:50:14,171] [UniVITrainer] [INFO] [Epoch 080] Val loss: 766.6192 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:50:14 - INFO - [Epoch 080] Val loss: 766.6192 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:50:14,343] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 766.6192\n",
      "2025-11-20 01:50:14 - INFO - [Epoch 080] New best val loss: 766.6192\n",
      "[2025-11-20 01:50:29,847] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 766.6003\n",
      "2025-11-20 01:50:29 - INFO - [Epoch 082] New best val loss: 766.6003\n",
      "[2025-11-20 01:50:37,000] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 766.5658\n",
      "2025-11-20 01:50:37 - INFO - [Epoch 083] New best val loss: 766.5658\n",
      "[2025-11-20 01:51:12,323] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 766.5391\n",
      "2025-11-20 01:51:12 - INFO - [Epoch 088] New best val loss: 766.5391\n",
      "[2025-11-20 01:51:25,195] [UniVITrainer] [INFO] [Epoch 090] Train loss: 767.6800 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:51:25 - INFO - [Epoch 090] Train loss: 767.6800 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:51:26,011] [UniVITrainer] [INFO] [Epoch 090] Val loss: 766.5736 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:51:26 - INFO - [Epoch 090] Val loss: 766.5736 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:51:55,306] [UniVITrainer] [INFO] [Epoch 094] New best val loss: 766.4870\n",
      "2025-11-20 01:51:55 - INFO - [Epoch 094] New best val loss: 766.4870\n",
      "[2025-11-20 01:52:02,703] [UniVITrainer] [INFO] [Epoch 095] New best val loss: 766.4670\n",
      "2025-11-20 01:52:02 - INFO - [Epoch 095] New best val loss: 766.4670\n",
      "[2025-11-20 01:52:16,740] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 766.4580\n",
      "2025-11-20 01:52:16 - INFO - [Epoch 097] New best val loss: 766.4580\n",
      "[2025-11-20 01:52:37,984] [UniVITrainer] [INFO] [Epoch 100] Train loss: 769.1651 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:52:37 - INFO - [Epoch 100] Train loss: 769.1651 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:52:38,803] [UniVITrainer] [INFO] [Epoch 100] Val loss: 766.4954 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:52:38 - INFO - [Epoch 100] Val loss: 766.4954 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:53:08,951] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 766.4374\n",
      "2025-11-20 01:53:08 - INFO - [Epoch 104] New best val loss: 766.4374\n",
      "[2025-11-20 01:53:30,679] [UniVITrainer] [INFO] [Epoch 107] New best val loss: 766.4296\n",
      "2025-11-20 01:53:30 - INFO - [Epoch 107] New best val loss: 766.4296\n",
      "[2025-11-20 01:53:38,452] [UniVITrainer] [INFO] [Epoch 108] New best val loss: 766.4245\n",
      "2025-11-20 01:53:38 - INFO - [Epoch 108] New best val loss: 766.4245\n",
      "[2025-11-20 01:53:52,291] [UniVITrainer] [INFO] [Epoch 110] Train loss: 764.9224 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:53:52 - INFO - [Epoch 110] Train loss: 764.9224 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:53:53,109] [UniVITrainer] [INFO] [Epoch 110] Val loss: 766.4371 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:53:53 - INFO - [Epoch 110] Val loss: 766.4371 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:54:00,530] [UniVITrainer] [INFO] [Epoch 111] New best val loss: 766.4243\n",
      "2025-11-20 01:54:00 - INFO - [Epoch 111] New best val loss: 766.4243\n",
      "[2025-11-20 01:54:07,189] [UniVITrainer] [INFO] [Epoch 112] New best val loss: 766.3894\n",
      "2025-11-20 01:54:07 - INFO - [Epoch 112] New best val loss: 766.3894\n",
      "[2025-11-20 01:54:21,892] [UniVITrainer] [INFO] [Epoch 114] New best val loss: 766.3807\n",
      "2025-11-20 01:54:21 - INFO - [Epoch 114] New best val loss: 766.3807\n",
      "[2025-11-20 01:55:04,892] [UniVITrainer] [INFO] [Epoch 120] Train loss: 766.7646 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:55:04 - INFO - [Epoch 120] Train loss: 766.7646 (beta=80.000, gamma=140.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 01:55:05,703] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.4034 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:55:05 - INFO - [Epoch 120] Val loss: 766.4034 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:55:13,448] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 766.3757\n",
      "2025-11-20 01:55:13 - INFO - [Epoch 121] New best val loss: 766.3757\n",
      "[2025-11-20 01:55:20,196] [UniVITrainer] [INFO] [Epoch 122] New best val loss: 766.3545\n",
      "2025-11-20 01:55:20 - INFO - [Epoch 122] New best val loss: 766.3545\n",
      "[2025-11-20 01:56:17,857] [UniVITrainer] [INFO] [Epoch 130] Train loss: 769.0411 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:56:17 - INFO - [Epoch 130] Train loss: 769.0411 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:56:18,667] [UniVITrainer] [INFO] [Epoch 130] Val loss: 766.3407 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:56:18 - INFO - [Epoch 130] Val loss: 766.3407 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:56:18,821] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 766.3407\n",
      "2025-11-20 01:56:18 - INFO - [Epoch 130] New best val loss: 766.3407\n",
      "[2025-11-20 01:57:30,290] [UniVITrainer] [INFO] [Epoch 140] Train loss: 768.0742 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:57:30 - INFO - [Epoch 140] Train loss: 768.0742 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:57:30,896] [UniVITrainer] [INFO] [Epoch 140] Val loss: 766.3549 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:57:30 - INFO - [Epoch 140] Val loss: 766.3549 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:57:49,860] [UniVITrainer] [INFO] [Epoch 143] New best val loss: 766.3217\n",
      "2025-11-20 01:57:49 - INFO - [Epoch 143] New best val loss: 766.3217\n",
      "[2025-11-20 01:58:40,875] [UniVITrainer] [INFO] [Epoch 150] Train loss: 768.0101 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:58:40 - INFO - [Epoch 150] Train loss: 768.0101 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:58:40,959] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.3208 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:58:40 - INFO - [Epoch 150] Val loss: 766.3208 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:58:41,194] [UniVITrainer] [INFO] [Epoch 150] New best val loss: 766.3208\n",
      "2025-11-20 01:58:41 - INFO - [Epoch 150] New best val loss: 766.3208\n",
      "[2025-11-20 01:59:01,627] [UniVITrainer] [INFO] [Epoch 153] New best val loss: 766.3123\n",
      "2025-11-20 01:59:01 - INFO - [Epoch 153] New best val loss: 766.3123\n",
      "[2025-11-20 01:59:51,332] [UniVITrainer] [INFO] [Epoch 160] Train loss: 766.8389 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:59:51 - INFO - [Epoch 160] Train loss: 766.8389 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 01:59:52,170] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.3813 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 01:59:52 - INFO - [Epoch 160] Val loss: 766.3813 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 02:00:07,045] [UniVITrainer] [INFO] [Epoch 162] New best val loss: 766.3004\n",
      "2025-11-20 02:00:07 - INFO - [Epoch 162] New best val loss: 766.3004\n",
      "[2025-11-20 02:01:02,130] [UniVITrainer] [INFO] [Epoch 170] Train loss: 763.9063 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 02:01:02 - INFO - [Epoch 170] Train loss: 763.9063 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 02:01:02,979] [UniVITrainer] [INFO] [Epoch 170] Val loss: 766.3496 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 02:01:02 - INFO - [Epoch 170] Val loss: 766.3496 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 02:02:12,135] [UniVITrainer] [INFO] [Epoch 180] Train loss: 765.8670 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 02:02:12 - INFO - [Epoch 180] Train loss: 765.8670 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 02:02:12,972] [UniVITrainer] [INFO] [Epoch 180] Val loss: 767.4403 (beta=80.000, gamma=140.000)\n",
      "2025-11-20 02:02:12 - INFO - [Epoch 180] Val loss: 767.4403 (beta=80.000, gamma=140.000)\n",
      "[2025-11-20 02:02:28,548] [UniVITrainer] [INFO] Early stopping at epoch 182 (best val loss = 766.3004)\n",
      "2025-11-20 02:02:28 - INFO - Early stopping at epoch 182 (best val loss = 766.3004)\n",
      "[2025-11-20 02:02:28,589] [UniVITrainer] [INFO] Restored best model from epoch 162 (val loss = 766.3004)\n",
      "2025-11-20 02:02:28 - INFO - Restored best model from epoch 162 (val loss = 766.3004)\n",
      "[2025-11-20 02:02:30,860] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 02:02:30 - INFO - TrainingConfig:\n",
      "[2025-11-20 02:02:30,863] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 02:02:30 - INFO -   n_epochs: 200\n",
      "[2025-11-20 02:02:30,865] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 02:02:30 - INFO -   batch_size: 256\n",
      "[2025-11-20 02:02:30,870] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 02:02:30 - INFO -   lr: 0.001\n",
      "[2025-11-20 02:02:30,872] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 02:02:30 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 02:02:30,876] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 02:02:30 - INFO -   device: cuda\n",
      "[2025-11-20 02:02:30,878] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 02:02:30 - INFO -   log_every: 10\n",
      "[2025-11-20 02:02:30,883] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 02:02:30 - INFO -   grad_clip: None\n",
      "[2025-11-20 02:02:30,885] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 02:02:30 - INFO -   num_workers: 0\n",
      "[2025-11-20 02:02:30,889] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 02:02:30 - INFO -   seed: 42\n",
      "[2025-11-20 02:02:30,892] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 02:02:30 - INFO -   early_stopping: True\n",
      "[2025-11-20 02:02:30,894] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 02:02:30 - INFO -   patience: 20\n",
      "[2025-11-20 02:02:30,897] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 02:02:30 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 8] Done in 22.2 min\n",
      "  best_val_loss              = 766.300\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4878\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4649\n",
      "[Config 8] FOSCTTM (ADT vs ATAC, val) = 0.4953\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4827\n",
      "  Modality mixing (k=20)     = 0.0000\n",
      "  Composite score            = 1136.18\n",
      "\n",
      "================================================================================\n",
      "[Config 9] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 100,\n",
      "  \"beta\": 180.0,\n",
      "  \"gamma\": 80.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_wide2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3885ccdcaa48069caab7c86516ba61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 02:02:37,497] [UniVITrainer] [INFO] [Epoch 001] Train loss: 3300.5204 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:02:37 - INFO - [Epoch 001] Train loss: 3300.5204 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:02:38,333] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1159.9046 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:02:38 - INFO - [Epoch 001] Val loss: 1159.9046 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:02:38,500] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1159.9046\n",
      "2025-11-20 02:02:38 - INFO - [Epoch 001] New best val loss: 1159.9046\n",
      "[2025-11-20 02:02:46,481] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 989.6286\n",
      "2025-11-20 02:02:46 - INFO - [Epoch 002] New best val loss: 989.6286\n",
      "[2025-11-20 02:02:54,347] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 919.9830\n",
      "2025-11-20 02:02:54 - INFO - [Epoch 003] New best val loss: 919.9830\n",
      "[2025-11-20 02:03:01,733] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 878.2198\n",
      "2025-11-20 02:03:01 - INFO - [Epoch 004] New best val loss: 878.2198\n",
      "[2025-11-20 02:03:09,184] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 856.4847\n",
      "2025-11-20 02:03:09 - INFO - [Epoch 005] New best val loss: 856.4847\n",
      "[2025-11-20 02:03:17,119] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 834.8456\n",
      "2025-11-20 02:03:17 - INFO - [Epoch 006] New best val loss: 834.8456\n",
      "[2025-11-20 02:03:24,814] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 825.5693\n",
      "2025-11-20 02:03:24 - INFO - [Epoch 007] New best val loss: 825.5693\n",
      "[2025-11-20 02:03:32,759] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 822.7696\n",
      "2025-11-20 02:03:32 - INFO - [Epoch 008] New best val loss: 822.7696\n",
      "[2025-11-20 02:03:39,977] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 815.3288\n",
      "2025-11-20 02:03:39 - INFO - [Epoch 009] New best val loss: 815.3288\n",
      "[2025-11-20 02:03:46,977] [UniVITrainer] [INFO] [Epoch 010] Train loss: 852.3465 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:03:46 - INFO - [Epoch 010] Train loss: 852.3465 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:03:47,826] [UniVITrainer] [INFO] [Epoch 010] Val loss: 813.0154 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:03:47 - INFO - [Epoch 010] Val loss: 813.0154 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:03:47,860] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 813.0154\n",
      "2025-11-20 02:03:47 - INFO - [Epoch 010] New best val loss: 813.0154\n",
      "[2025-11-20 02:03:55,437] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 804.2291\n",
      "2025-11-20 02:03:55 - INFO - [Epoch 011] New best val loss: 804.2291\n",
      "[2025-11-20 02:04:03,308] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 799.6802\n",
      "2025-11-20 02:04:03 - INFO - [Epoch 012] New best val loss: 799.6802\n",
      "[2025-11-20 02:04:10,210] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 797.7387\n",
      "2025-11-20 02:04:10 - INFO - [Epoch 013] New best val loss: 797.7387\n",
      "[2025-11-20 02:04:17,616] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 796.5451\n",
      "2025-11-20 02:04:17 - INFO - [Epoch 014] New best val loss: 796.5451\n",
      "[2025-11-20 02:04:25,204] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 794.2340\n",
      "2025-11-20 02:04:25 - INFO - [Epoch 015] New best val loss: 794.2340\n",
      "[2025-11-20 02:04:30,927] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 791.9948\n",
      "2025-11-20 02:04:30 - INFO - [Epoch 016] New best val loss: 791.9948\n",
      "[2025-11-20 02:04:37,084] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 790.1388\n",
      "2025-11-20 02:04:37 - INFO - [Epoch 017] New best val loss: 790.1388\n",
      "[2025-11-20 02:04:44,656] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 787.5350\n",
      "2025-11-20 02:04:44 - INFO - [Epoch 018] New best val loss: 787.5350\n",
      "[2025-11-20 02:04:57,292] [UniVITrainer] [INFO] [Epoch 020] Train loss: 803.1386 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:04:57 - INFO - [Epoch 020] Train loss: 803.1386 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:04:57,995] [UniVITrainer] [INFO] [Epoch 020] Val loss: 785.4618 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:04:57 - INFO - [Epoch 020] Val loss: 785.4618 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:04:58,226] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 785.4618\n",
      "2025-11-20 02:04:58 - INFO - [Epoch 020] New best val loss: 785.4618\n",
      "[2025-11-20 02:05:05,324] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 784.9540\n",
      "2025-11-20 02:05:05 - INFO - [Epoch 021] New best val loss: 784.9540\n",
      "[2025-11-20 02:05:13,052] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 784.3617\n",
      "2025-11-20 02:05:13 - INFO - [Epoch 022] New best val loss: 784.3617\n",
      "[2025-11-20 02:05:19,581] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 782.2984\n",
      "2025-11-20 02:05:19 - INFO - [Epoch 023] New best val loss: 782.2984\n",
      "[2025-11-20 02:05:27,566] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 779.4593\n",
      "2025-11-20 02:05:27 - INFO - [Epoch 024] New best val loss: 779.4593\n",
      "[2025-11-20 02:05:35,050] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 779.3635\n",
      "2025-11-20 02:05:35 - INFO - [Epoch 025] New best val loss: 779.3635\n",
      "[2025-11-20 02:05:42,533] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 778.6890\n",
      "2025-11-20 02:05:42 - INFO - [Epoch 026] New best val loss: 778.6890\n",
      "[2025-11-20 02:05:50,484] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 778.5411\n",
      "2025-11-20 02:05:50 - INFO - [Epoch 027] New best val loss: 778.5411\n",
      "[2025-11-20 02:05:57,655] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 777.7992\n",
      "2025-11-20 02:05:57 - INFO - [Epoch 028] New best val loss: 777.7992\n",
      "[2025-11-20 02:06:05,554] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 776.9648\n",
      "2025-11-20 02:06:05 - INFO - [Epoch 029] New best val loss: 776.9648\n",
      "[2025-11-20 02:06:11,943] [UniVITrainer] [INFO] [Epoch 030] Train loss: 783.0982 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:06:11 - INFO - [Epoch 030] Train loss: 783.0982 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:06:12,775] [UniVITrainer] [INFO] [Epoch 030] Val loss: 775.8467 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:06:12 - INFO - [Epoch 030] Val loss: 775.8467 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:06:12,903] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 775.8467\n",
      "2025-11-20 02:06:12 - INFO - [Epoch 030] New best val loss: 775.8467\n",
      "[2025-11-20 02:06:26,639] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 775.4487\n",
      "2025-11-20 02:06:26 - INFO - [Epoch 032] New best val loss: 775.4487\n",
      "[2025-11-20 02:06:34,070] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 773.8990\n",
      "2025-11-20 02:06:34 - INFO - [Epoch 033] New best val loss: 773.8990\n",
      "[2025-11-20 02:06:56,672] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 772.9371\n",
      "2025-11-20 02:06:56 - INFO - [Epoch 036] New best val loss: 772.9371\n",
      "[2025-11-20 02:07:04,206] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 772.6499\n",
      "2025-11-20 02:07:04 - INFO - [Epoch 037] New best val loss: 772.6499\n",
      "[2025-11-20 02:07:09,857] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 772.0541\n",
      "2025-11-20 02:07:09 - INFO - [Epoch 038] New best val loss: 772.0541\n",
      "[2025-11-20 02:07:17,847] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 771.9511\n",
      "2025-11-20 02:07:17 - INFO - [Epoch 039] New best val loss: 771.9511\n",
      "[2025-11-20 02:07:24,759] [UniVITrainer] [INFO] [Epoch 040] Train loss: 780.9836 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:07:24 - INFO - [Epoch 040] Train loss: 780.9836 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:07:25,541] [UniVITrainer] [INFO] [Epoch 040] Val loss: 771.6344 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:07:25 - INFO - [Epoch 040] Val loss: 771.6344 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:07:25,628] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 771.6344\n",
      "2025-11-20 02:07:25 - INFO - [Epoch 040] New best val loss: 771.6344\n",
      "[2025-11-20 02:07:33,589] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 771.3016\n",
      "2025-11-20 02:07:33 - INFO - [Epoch 041] New best val loss: 771.3016\n",
      "[2025-11-20 02:07:41,074] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 770.4232\n",
      "2025-11-20 02:07:41 - INFO - [Epoch 042] New best val loss: 770.4232\n",
      "[2025-11-20 02:07:49,080] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 770.1156\n",
      "2025-11-20 02:07:49 - INFO - [Epoch 043] New best val loss: 770.1156\n",
      "[2025-11-20 02:08:18,370] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 769.6745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 02:08:18 - INFO - [Epoch 047] New best val loss: 769.6745\n",
      "[2025-11-20 02:08:26,191] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 769.5408\n",
      "2025-11-20 02:08:26 - INFO - [Epoch 048] New best val loss: 769.5408\n",
      "[2025-11-20 02:08:32,370] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 769.4303\n",
      "2025-11-20 02:08:32 - INFO - [Epoch 049] New best val loss: 769.4303\n",
      "[2025-11-20 02:08:39,277] [UniVITrainer] [INFO] [Epoch 050] Train loss: 775.3228 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:08:39 - INFO - [Epoch 050] Train loss: 775.3228 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:08:40,116] [UniVITrainer] [INFO] [Epoch 050] Val loss: 769.5475 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:08:40 - INFO - [Epoch 050] Val loss: 769.5475 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:08:47,791] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 768.8100\n",
      "2025-11-20 02:08:47 - INFO - [Epoch 051] New best val loss: 768.8100\n",
      "[2025-11-20 02:09:02,976] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 768.6647\n",
      "2025-11-20 02:09:02 - INFO - [Epoch 053] New best val loss: 768.6647\n",
      "[2025-11-20 02:09:18,730] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 768.3180\n",
      "2025-11-20 02:09:18 - INFO - [Epoch 055] New best val loss: 768.3180\n",
      "[2025-11-20 02:09:25,527] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 767.9818\n",
      "2025-11-20 02:09:25 - INFO - [Epoch 056] New best val loss: 767.9818\n",
      "[2025-11-20 02:09:46,591] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 767.9765\n",
      "2025-11-20 02:09:46 - INFO - [Epoch 059] New best val loss: 767.9765\n",
      "[2025-11-20 02:09:53,549] [UniVITrainer] [INFO] [Epoch 060] Train loss: 769.2386 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:09:53 - INFO - [Epoch 060] Train loss: 769.2386 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:09:54,381] [UniVITrainer] [INFO] [Epoch 060] Val loss: 767.8118 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:09:54 - INFO - [Epoch 060] Val loss: 767.8118 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:09:54,532] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 767.8118\n",
      "2025-11-20 02:09:54 - INFO - [Epoch 060] New best val loss: 767.8118\n",
      "[2025-11-20 02:10:09,632] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 767.7815\n",
      "2025-11-20 02:10:09 - INFO - [Epoch 062] New best val loss: 767.7815\n",
      "[2025-11-20 02:10:17,358] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 767.6869\n",
      "2025-11-20 02:10:17 - INFO - [Epoch 063] New best val loss: 767.6869\n",
      "[2025-11-20 02:10:25,196] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 767.5663\n",
      "2025-11-20 02:10:25 - INFO - [Epoch 064] New best val loss: 767.5663\n",
      "[2025-11-20 02:10:40,177] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 767.4502\n",
      "2025-11-20 02:10:40 - INFO - [Epoch 066] New best val loss: 767.4502\n",
      "[2025-11-20 02:10:48,131] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 767.4451\n",
      "2025-11-20 02:10:48 - INFO - [Epoch 067] New best val loss: 767.4451\n",
      "[2025-11-20 02:10:55,765] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 767.4235\n",
      "2025-11-20 02:10:55 - INFO - [Epoch 068] New best val loss: 767.4235\n",
      "[2025-11-20 02:11:03,583] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 767.2016\n",
      "2025-11-20 02:11:03 - INFO - [Epoch 069] New best val loss: 767.2016\n",
      "[2025-11-20 02:11:10,256] [UniVITrainer] [INFO] [Epoch 070] Train loss: 767.2097 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:11:10 - INFO - [Epoch 070] Train loss: 767.2097 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:11:11,091] [UniVITrainer] [INFO] [Epoch 070] Val loss: 767.1704 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:11:11 - INFO - [Epoch 070] Val loss: 767.1704 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:11:11,243] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 767.1704\n",
      "2025-11-20 02:11:11 - INFO - [Epoch 070] New best val loss: 767.1704\n",
      "[2025-11-20 02:11:31,482] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 767.1204\n",
      "2025-11-20 02:11:31 - INFO - [Epoch 073] New best val loss: 767.1204\n",
      "[2025-11-20 02:11:46,500] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 767.0991\n",
      "2025-11-20 02:11:46 - INFO - [Epoch 075] New best val loss: 767.0991\n",
      "[2025-11-20 02:12:06,889] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 766.9753\n",
      "2025-11-20 02:12:06 - INFO - [Epoch 078] New best val loss: 766.9753\n",
      "[2025-11-20 02:12:14,528] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 766.8937\n",
      "2025-11-20 02:12:14 - INFO - [Epoch 079] New best val loss: 766.8937\n",
      "[2025-11-20 02:12:21,240] [UniVITrainer] [INFO] [Epoch 080] Train loss: 767.1049 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:12:21 - INFO - [Epoch 080] Train loss: 767.1049 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:12:22,062] [UniVITrainer] [INFO] [Epoch 080] Val loss: 767.0202 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:12:22 - INFO - [Epoch 080] Val loss: 767.0202 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:12:43,762] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 766.8702\n",
      "2025-11-20 02:12:43 - INFO - [Epoch 083] New best val loss: 766.8702\n",
      "[2025-11-20 02:13:19,375] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 766.8242\n",
      "2025-11-20 02:13:19 - INFO - [Epoch 088] New best val loss: 766.8242\n",
      "[2025-11-20 02:13:27,204] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 766.7468\n",
      "2025-11-20 02:13:27 - INFO - [Epoch 089] New best val loss: 766.7468\n",
      "[2025-11-20 02:13:33,958] [UniVITrainer] [INFO] [Epoch 090] Train loss: 765.9139 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:13:33 - INFO - [Epoch 090] Train loss: 765.9139 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:13:34,777] [UniVITrainer] [INFO] [Epoch 090] Val loss: 766.8499 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:13:34 - INFO - [Epoch 090] Val loss: 766.8499 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:13:42,579] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 766.7273\n",
      "2025-11-20 02:13:42 - INFO - [Epoch 091] New best val loss: 766.7273\n",
      "[2025-11-20 02:14:30,676] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 766.6648\n",
      "2025-11-20 02:14:30 - INFO - [Epoch 098] New best val loss: 766.6648\n",
      "[2025-11-20 02:14:37,947] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 766.6298\n",
      "2025-11-20 02:14:37 - INFO - [Epoch 099] New best val loss: 766.6298\n",
      "[2025-11-20 02:14:44,120] [UniVITrainer] [INFO] [Epoch 100] Train loss: 768.7991 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:14:44 - INFO - [Epoch 100] Train loss: 768.7991 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:14:44,920] [UniVITrainer] [INFO] [Epoch 100] Val loss: 766.7902 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:14:44 - INFO - [Epoch 100] Val loss: 766.7902 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:15:50,757] [UniVITrainer] [INFO] [Epoch 109] New best val loss: 766.6284\n",
      "2025-11-20 02:15:50 - INFO - [Epoch 109] New best val loss: 766.6284\n",
      "[2025-11-20 02:15:57,594] [UniVITrainer] [INFO] [Epoch 110] Train loss: 768.7328 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:15:57 - INFO - [Epoch 110] Train loss: 768.7328 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:15:58,410] [UniVITrainer] [INFO] [Epoch 110] Val loss: 766.6258 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:15:58 - INFO - [Epoch 110] Val loss: 766.6258 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:15:58,562] [UniVITrainer] [INFO] [Epoch 110] New best val loss: 766.6258\n",
      "2025-11-20 02:15:58 - INFO - [Epoch 110] New best val loss: 766.6258\n",
      "[2025-11-20 02:16:21,508] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 766.6060\n",
      "2025-11-20 02:16:21 - INFO - [Epoch 113] New best val loss: 766.6060\n",
      "[2025-11-20 02:17:14,111] [UniVITrainer] [INFO] [Epoch 120] Train loss: 766.7105 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:17:14 - INFO - [Epoch 120] Train loss: 766.7105 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:17:14,925] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.8788 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:17:14 - INFO - [Epoch 120] Val loss: 766.8788 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:17:28,301] [UniVITrainer] [INFO] [Epoch 122] New best val loss: 766.5857\n",
      "2025-11-20 02:17:28 - INFO - [Epoch 122] New best val loss: 766.5857\n",
      "[2025-11-20 02:17:35,628] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 766.5015\n",
      "2025-11-20 02:17:35 - INFO - [Epoch 123] New best val loss: 766.5015\n",
      "[2025-11-20 02:18:24,991] [UniVITrainer] [INFO] [Epoch 130] Train loss: 768.0847 (beta=180.000, gamma=80.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 02:18:24 - INFO - [Epoch 130] Train loss: 768.0847 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:18:25,841] [UniVITrainer] [INFO] [Epoch 130] Val loss: 766.5190 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:18:25 - INFO - [Epoch 130] Val loss: 766.5190 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:18:39,830] [UniVITrainer] [INFO] [Epoch 132] New best val loss: 766.4932\n",
      "2025-11-20 02:18:39 - INFO - [Epoch 132] New best val loss: 766.4932\n",
      "[2025-11-20 02:19:35,728] [UniVITrainer] [INFO] [Epoch 140] Train loss: 764.4784 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:19:35 - INFO - [Epoch 140] Train loss: 764.4784 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:19:36,127] [UniVITrainer] [INFO] [Epoch 140] Val loss: 766.6237 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:19:36 - INFO - [Epoch 140] Val loss: 766.6237 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:19:57,574] [UniVITrainer] [INFO] [Epoch 143] New best val loss: 766.4482\n",
      "2025-11-20 02:19:57 - INFO - [Epoch 143] New best val loss: 766.4482\n",
      "[2025-11-20 02:20:04,194] [UniVITrainer] [INFO] [Epoch 144] New best val loss: 766.4334\n",
      "2025-11-20 02:20:04 - INFO - [Epoch 144] New best val loss: 766.4334\n",
      "[2025-11-20 02:20:27,193] [UniVITrainer] [INFO] [Epoch 147] New best val loss: 766.4011\n",
      "2025-11-20 02:20:27 - INFO - [Epoch 147] New best val loss: 766.4011\n",
      "[2025-11-20 02:20:49,342] [UniVITrainer] [INFO] [Epoch 150] Train loss: 767.4918 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:20:49 - INFO - [Epoch 150] Train loss: 767.4918 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:20:49,542] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.4282 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:20:49 - INFO - [Epoch 150] Val loss: 766.4282 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:22:04,278] [UniVITrainer] [INFO] [Epoch 160] Train loss: 769.0464 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:22:04 - INFO - [Epoch 160] Train loss: 769.0464 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:22:05,090] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.5798 (beta=180.000, gamma=80.000)\n",
      "2025-11-20 02:22:05 - INFO - [Epoch 160] Val loss: 766.5798 (beta=180.000, gamma=80.000)\n",
      "[2025-11-20 02:22:57,577] [UniVITrainer] [INFO] Early stopping at epoch 167 (best val loss = 766.4011)\n",
      "2025-11-20 02:22:57 - INFO - Early stopping at epoch 167 (best val loss = 766.4011)\n",
      "[2025-11-20 02:22:57,630] [UniVITrainer] [INFO] Restored best model from epoch 147 (val loss = 766.4011)\n",
      "2025-11-20 02:22:57 - INFO - Restored best model from epoch 147 (val loss = 766.4011)\n",
      "[2025-11-20 02:23:00,047] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 02:23:00 - INFO - TrainingConfig:\n",
      "[2025-11-20 02:23:00,048] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 02:23:00 - INFO -   n_epochs: 200\n",
      "[2025-11-20 02:23:00,054] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 02:23:00 - INFO -   batch_size: 256\n",
      "[2025-11-20 02:23:00,055] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 02:23:00 - INFO -   lr: 0.001\n",
      "[2025-11-20 02:23:00,056] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 02:23:00 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 02:23:00,056] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 02:23:00 - INFO -   device: cuda\n",
      "[2025-11-20 02:23:00,057] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 02:23:00 - INFO -   log_every: 10\n",
      "[2025-11-20 02:23:00,058] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 02:23:00 - INFO -   grad_clip: None\n",
      "[2025-11-20 02:23:00,059] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 02:23:00 - INFO -   num_workers: 0\n",
      "[2025-11-20 02:23:00,060] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 02:23:00 - INFO -   seed: 42\n",
      "[2025-11-20 02:23:00,060] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 02:23:00 - INFO -   early_stopping: True\n",
      "[2025-11-20 02:23:00,061] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 02:23:00 - INFO -   patience: 20\n",
      "[2025-11-20 02:23:00,062] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 02:23:00 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 9] Done in 20.4 min\n",
      "  best_val_loss              = 766.401\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5038\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4367\n",
      "[Config 9] FOSCTTM (ADT vs ATAC, val) = 0.4917\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4774\n",
      "  Modality mixing (k=20)     = 0.0001\n",
      "  Composite score            = 1132.35\n",
      "\n",
      "================================================================================\n",
      "[Config 10] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 50,\n",
      "  \"beta\": 500.0,\n",
      "  \"gamma\": 80.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_med2\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_wide2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a394d1646049a69ca566c72266f63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 02:23:07,000] [UniVITrainer] [INFO] [Epoch 001] Train loss: 3839.6963 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:23:07 - INFO - [Epoch 001] Train loss: 3839.6963 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:23:07,836] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1206.8608 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:23:07 - INFO - [Epoch 001] Val loss: 1206.8608 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:23:08,038] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1206.8608\n",
      "2025-11-20 02:23:08 - INFO - [Epoch 001] New best val loss: 1206.8608\n",
      "[2025-11-20 02:23:15,826] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 936.4517\n",
      "2025-11-20 02:23:15 - INFO - [Epoch 002] New best val loss: 936.4517\n",
      "[2025-11-20 02:23:23,648] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 859.1669\n",
      "2025-11-20 02:23:23 - INFO - [Epoch 003] New best val loss: 859.1669\n",
      "[2025-11-20 02:23:30,803] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 835.9442\n",
      "2025-11-20 02:23:30 - INFO - [Epoch 004] New best val loss: 835.9442\n",
      "[2025-11-20 02:23:38,737] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 817.1088\n",
      "2025-11-20 02:23:38 - INFO - [Epoch 005] New best val loss: 817.1088\n",
      "[2025-11-20 02:23:46,727] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 811.3547\n",
      "2025-11-20 02:23:46 - INFO - [Epoch 006] New best val loss: 811.3547\n",
      "[2025-11-20 02:23:54,690] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 804.6600\n",
      "2025-11-20 02:23:54 - INFO - [Epoch 007] New best val loss: 804.6600\n",
      "[2025-11-20 02:24:02,029] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 802.3534\n",
      "2025-11-20 02:24:02 - INFO - [Epoch 008] New best val loss: 802.3534\n",
      "[2025-11-20 02:24:09,966] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 798.2718\n",
      "2025-11-20 02:24:09 - INFO - [Epoch 009] New best val loss: 798.2718\n",
      "[2025-11-20 02:24:16,889] [UniVITrainer] [INFO] [Epoch 010] Train loss: 836.8503 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:24:16 - INFO - [Epoch 010] Train loss: 836.8503 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:24:17,696] [UniVITrainer] [INFO] [Epoch 010] Val loss: 796.2917 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:24:17 - INFO - [Epoch 010] Val loss: 796.2917 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:24:17,882] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 796.2917\n",
      "2025-11-20 02:24:17 - INFO - [Epoch 010] New best val loss: 796.2917\n",
      "[2025-11-20 02:24:33,598] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 791.4480\n",
      "2025-11-20 02:24:33 - INFO - [Epoch 012] New best val loss: 791.4480\n",
      "[2025-11-20 02:24:49,185] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 791.4396\n",
      "2025-11-20 02:24:49 - INFO - [Epoch 014] New best val loss: 791.4396\n",
      "[2025-11-20 02:24:57,200] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 788.4596\n",
      "2025-11-20 02:24:57 - INFO - [Epoch 015] New best val loss: 788.4596\n",
      "[2025-11-20 02:25:04,151] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 787.6294\n",
      "2025-11-20 02:25:04 - INFO - [Epoch 016] New best val loss: 787.6294\n",
      "[2025-11-20 02:25:11,897] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 786.4762\n",
      "2025-11-20 02:25:11 - INFO - [Epoch 017] New best val loss: 786.4762\n",
      "[2025-11-20 02:25:19,684] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 785.8196\n",
      "2025-11-20 02:25:19 - INFO - [Epoch 018] New best val loss: 785.8196\n",
      "[2025-11-20 02:25:33,874] [UniVITrainer] [INFO] [Epoch 020] Train loss: 795.1489 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:25:33 - INFO - [Epoch 020] Train loss: 795.1489 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:25:34,708] [UniVITrainer] [INFO] [Epoch 020] Val loss: 785.3812 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:25:34 - INFO - [Epoch 020] Val loss: 785.3812 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:25:34,907] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 785.3812\n",
      "2025-11-20 02:25:34 - INFO - [Epoch 020] New best val loss: 785.3812\n",
      "[2025-11-20 02:25:42,438] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 783.8336\n",
      "2025-11-20 02:25:42 - INFO - [Epoch 021] New best val loss: 783.8336\n",
      "[2025-11-20 02:25:56,364] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 783.5556\n",
      "2025-11-20 02:25:56 - INFO - [Epoch 023] New best val loss: 783.5556\n",
      "[2025-11-20 02:26:02,945] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 783.0373\n",
      "2025-11-20 02:26:02 - INFO - [Epoch 024] New best val loss: 783.0373\n",
      "[2025-11-20 02:26:17,927] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 781.2883\n",
      "2025-11-20 02:26:17 - INFO - [Epoch 026] New best val loss: 781.2883\n",
      "[2025-11-20 02:26:32,662] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 781.0347\n",
      "2025-11-20 02:26:32 - INFO - [Epoch 028] New best val loss: 781.0347\n",
      "[2025-11-20 02:26:40,083] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 780.5923\n",
      "2025-11-20 02:26:40 - INFO - [Epoch 029] New best val loss: 780.5923\n",
      "[2025-11-20 02:26:47,025] [UniVITrainer] [INFO] [Epoch 030] Train loss: 780.5061 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:26:47 - INFO - [Epoch 030] Train loss: 780.5061 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:26:47,878] [UniVITrainer] [INFO] [Epoch 030] Val loss: 780.3374 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:26:47 - INFO - [Epoch 030] Val loss: 780.3374 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:26:48,078] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 780.3374\n",
      "2025-11-20 02:26:48 - INFO - [Epoch 030] New best val loss: 780.3374\n",
      "[2025-11-20 02:27:09,344] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 779.9486\n",
      "2025-11-20 02:27:09 - INFO - [Epoch 033] New best val loss: 779.9486\n",
      "[2025-11-20 02:27:15,963] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 779.1964\n",
      "2025-11-20 02:27:15 - INFO - [Epoch 034] New best val loss: 779.1964\n",
      "[2025-11-20 02:27:29,864] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 778.4514\n",
      "2025-11-20 02:27:29 - INFO - [Epoch 036] New best val loss: 778.4514\n",
      "[2025-11-20 02:27:45,250] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 778.0239\n",
      "2025-11-20 02:27:45 - INFO - [Epoch 038] New best val loss: 778.0239\n",
      "[2025-11-20 02:27:51,597] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 777.8927\n",
      "2025-11-20 02:27:51 - INFO - [Epoch 039] New best val loss: 777.8927\n",
      "[2025-11-20 02:27:57,932] [UniVITrainer] [INFO] [Epoch 040] Train loss: 773.3549 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:27:57 - INFO - [Epoch 040] Train loss: 773.3549 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:27:58,036] [UniVITrainer] [INFO] [Epoch 040] Val loss: 776.8498 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:27:58 - INFO - [Epoch 040] Val loss: 776.8498 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:27:58,287] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 776.8498\n",
      "2025-11-20 02:27:58 - INFO - [Epoch 040] New best val loss: 776.8498\n",
      "[2025-11-20 02:28:12,899] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 776.5268\n",
      "2025-11-20 02:28:12 - INFO - [Epoch 042] New best val loss: 776.5268\n",
      "[2025-11-20 02:28:19,278] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 776.1725\n",
      "2025-11-20 02:28:19 - INFO - [Epoch 043] New best val loss: 776.1725\n",
      "[2025-11-20 02:28:34,860] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 775.9039\n",
      "2025-11-20 02:28:34 - INFO - [Epoch 045] New best val loss: 775.9039\n",
      "[2025-11-20 02:28:40,903] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 775.3452\n",
      "2025-11-20 02:28:40 - INFO - [Epoch 046] New best val loss: 775.3452\n",
      "[2025-11-20 02:28:48,903] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 775.1775\n",
      "2025-11-20 02:28:48 - INFO - [Epoch 047] New best val loss: 775.1775\n",
      "[2025-11-20 02:29:10,933] [UniVITrainer] [INFO] [Epoch 050] Train loss: 772.5610 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:29:10 - INFO - [Epoch 050] Train loss: 772.5610 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:29:11,771] [UniVITrainer] [INFO] [Epoch 050] Val loss: 774.6072 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:29:11 - INFO - [Epoch 050] Val loss: 774.6072 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:29:11,781] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 774.6072\n",
      "2025-11-20 02:29:11 - INFO - [Epoch 050] New best val loss: 774.6072\n",
      "[2025-11-20 02:29:34,361] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 773.6100\n",
      "2025-11-20 02:29:34 - INFO - [Epoch 053] New best val loss: 773.6100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 02:29:42,318] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 773.3922\n",
      "2025-11-20 02:29:42 - INFO - [Epoch 054] New best val loss: 773.3922\n",
      "[2025-11-20 02:30:27,599] [UniVITrainer] [INFO] [Epoch 060] Train loss: 772.1972 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:30:27 - INFO - [Epoch 060] Train loss: 772.1972 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:30:28,404] [UniVITrainer] [INFO] [Epoch 060] Val loss: 773.3474 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:30:28 - INFO - [Epoch 060] Val loss: 773.3474 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:30:28,592] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 773.3474\n",
      "2025-11-20 02:30:28 - INFO - [Epoch 060] New best val loss: 773.3474\n",
      "[2025-11-20 02:30:44,200] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 773.2745\n",
      "2025-11-20 02:30:44 - INFO - [Epoch 062] New best val loss: 773.2745\n",
      "[2025-11-20 02:30:58,323] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 773.2562\n",
      "2025-11-20 02:30:58 - INFO - [Epoch 064] New best val loss: 773.2562\n",
      "[2025-11-20 02:31:06,371] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 772.8064\n",
      "2025-11-20 02:31:06 - INFO - [Epoch 065] New best val loss: 772.8064\n",
      "[2025-11-20 02:31:29,839] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 772.6625\n",
      "2025-11-20 02:31:29 - INFO - [Epoch 068] New best val loss: 772.6625\n",
      "[2025-11-20 02:31:44,576] [UniVITrainer] [INFO] [Epoch 070] Train loss: 770.6665 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:31:44 - INFO - [Epoch 070] Train loss: 770.6665 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:31:45,382] [UniVITrainer] [INFO] [Epoch 070] Val loss: 773.4163 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:31:45 - INFO - [Epoch 070] Val loss: 773.4163 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:31:59,560] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 772.6478\n",
      "2025-11-20 02:31:59 - INFO - [Epoch 072] New best val loss: 772.6478\n",
      "[2025-11-20 02:32:12,867] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 772.1509\n",
      "2025-11-20 02:32:12 - INFO - [Epoch 074] New best val loss: 772.1509\n",
      "[2025-11-20 02:32:20,588] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 771.8419\n",
      "2025-11-20 02:32:20 - INFO - [Epoch 075] New best val loss: 771.8419\n",
      "[2025-11-20 02:32:48,733] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 771.5856\n",
      "2025-11-20 02:32:48 - INFO - [Epoch 079] New best val loss: 771.5856\n",
      "[2025-11-20 02:32:55,533] [UniVITrainer] [INFO] [Epoch 080] Train loss: 771.9492 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:32:55 - INFO - [Epoch 080] Train loss: 771.9492 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:32:56,359] [UniVITrainer] [INFO] [Epoch 080] Val loss: 772.1847 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:32:56 - INFO - [Epoch 080] Val loss: 772.1847 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:33:03,663] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 771.3460\n",
      "2025-11-20 02:33:03 - INFO - [Epoch 081] New best val loss: 771.3460\n",
      "[2025-11-20 02:33:10,335] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 771.1553\n",
      "2025-11-20 02:33:10 - INFO - [Epoch 082] New best val loss: 771.1553\n",
      "[2025-11-20 02:34:04,905] [UniVITrainer] [INFO] [Epoch 090] Train loss: 768.9230 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:34:04 - INFO - [Epoch 090] Train loss: 768.9230 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:34:05,735] [UniVITrainer] [INFO] [Epoch 090] Val loss: 773.1130 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:34:05 - INFO - [Epoch 090] Val loss: 773.1130 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:35:15,438] [UniVITrainer] [INFO] [Epoch 100] Train loss: 768.4134 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:35:15 - INFO - [Epoch 100] Train loss: 768.4134 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:35:16,259] [UniVITrainer] [INFO] [Epoch 100] Val loss: 773.0762 (beta=500.000, gamma=80.000)\n",
      "2025-11-20 02:35:16 - INFO - [Epoch 100] Val loss: 773.0762 (beta=500.000, gamma=80.000)\n",
      "[2025-11-20 02:35:30,344] [UniVITrainer] [INFO] Early stopping at epoch 102 (best val loss = 771.1553)\n",
      "2025-11-20 02:35:30 - INFO - Early stopping at epoch 102 (best val loss = 771.1553)\n",
      "[2025-11-20 02:35:30,376] [UniVITrainer] [INFO] Restored best model from epoch 82 (val loss = 771.1553)\n",
      "2025-11-20 02:35:30 - INFO - Restored best model from epoch 82 (val loss = 771.1553)\n",
      "[2025-11-20 02:35:32,820] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 02:35:32 - INFO - TrainingConfig:\n",
      "[2025-11-20 02:35:32,822] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 02:35:32 - INFO -   n_epochs: 200\n",
      "[2025-11-20 02:35:32,827] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 02:35:32 - INFO -   batch_size: 256\n",
      "[2025-11-20 02:35:32,833] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 02:35:32 - INFO -   lr: 0.001\n",
      "[2025-11-20 02:35:32,839] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 02:35:32 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 02:35:32,840] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 02:35:32 - INFO -   device: cuda\n",
      "[2025-11-20 02:35:32,846] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 02:35:32 - INFO -   log_every: 10\n",
      "[2025-11-20 02:35:32,847] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 02:35:32 - INFO -   grad_clip: None\n",
      "[2025-11-20 02:35:32,848] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 02:35:32 - INFO -   num_workers: 0\n",
      "[2025-11-20 02:35:32,849] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 02:35:32 - INFO -   seed: 42\n",
      "[2025-11-20 02:35:32,850] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 02:35:32 - INFO -   early_stopping: True\n",
      "[2025-11-20 02:35:32,851] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 02:35:32 - INFO -   patience: 20\n",
      "[2025-11-20 02:35:32,853] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 02:35:32 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 10] Done in 12.5 min\n",
      "  best_val_loss              = 771.155\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5031\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4757\n",
      "[Config 10] FOSCTTM (ADT vs ATAC, val) = 0.4989\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4926\n",
      "  Modality mixing (k=20)     = 0.0300\n",
      "  Composite score            = 1185.48\n",
      "\n",
      "================================================================================\n",
      "[Config 11] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 64,\n",
      "  \"beta\": 400.0,\n",
      "  \"gamma\": 80.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_med2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03fbd33048a4b328fe75f9b24d45cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 02:35:39,736] [UniVITrainer] [INFO] [Epoch 001] Train loss: 3862.3606 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:35:39 - INFO - [Epoch 001] Train loss: 3862.3606 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:35:40,558] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1160.6260 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:35:40 - INFO - [Epoch 001] Val loss: 1160.6260 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:35:40,654] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1160.6260\n",
      "2025-11-20 02:35:40 - INFO - [Epoch 001] New best val loss: 1160.6260\n",
      "[2025-11-20 02:35:48,467] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 962.4774\n",
      "2025-11-20 02:35:48 - INFO - [Epoch 002] New best val loss: 962.4774\n",
      "[2025-11-20 02:35:55,576] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 866.5616\n",
      "2025-11-20 02:35:55 - INFO - [Epoch 003] New best val loss: 866.5616\n",
      "[2025-11-20 02:36:03,424] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 842.7882\n",
      "2025-11-20 02:36:03 - INFO - [Epoch 004] New best val loss: 842.7882\n",
      "[2025-11-20 02:36:10,903] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 825.6905\n",
      "2025-11-20 02:36:10 - INFO - [Epoch 005] New best val loss: 825.6905\n",
      "[2025-11-20 02:36:18,298] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 818.8064\n",
      "2025-11-20 02:36:18 - INFO - [Epoch 006] New best val loss: 818.8064\n",
      "[2025-11-20 02:36:26,068] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 818.0682\n",
      "2025-11-20 02:36:26 - INFO - [Epoch 007] New best val loss: 818.0682\n",
      "[2025-11-20 02:36:33,737] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 809.1706\n",
      "2025-11-20 02:36:33 - INFO - [Epoch 008] New best val loss: 809.1706\n",
      "[2025-11-20 02:36:46,475] [UniVITrainer] [INFO] [Epoch 010] Train loss: 844.8041 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:36:46 - INFO - [Epoch 010] Train loss: 844.8041 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:36:47,310] [UniVITrainer] [INFO] [Epoch 010] Val loss: 806.8043 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:36:47 - INFO - [Epoch 010] Val loss: 806.8043 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:36:47,406] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 806.8043\n",
      "2025-11-20 02:36:47 - INFO - [Epoch 010] New best val loss: 806.8043\n",
      "[2025-11-20 02:36:55,231] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 801.6597\n",
      "2025-11-20 02:36:55 - INFO - [Epoch 011] New best val loss: 801.6597\n",
      "[2025-11-20 02:37:02,417] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 799.3122\n",
      "2025-11-20 02:37:02 - INFO - [Epoch 012] New best val loss: 799.3122\n",
      "[2025-11-20 02:37:10,201] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 797.4003\n",
      "2025-11-20 02:37:10 - INFO - [Epoch 013] New best val loss: 797.4003\n",
      "[2025-11-20 02:37:25,724] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 794.7662\n",
      "2025-11-20 02:37:25 - INFO - [Epoch 015] New best val loss: 794.7662\n",
      "[2025-11-20 02:37:40,750] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 790.3657\n",
      "2025-11-20 02:37:40 - INFO - [Epoch 017] New best val loss: 790.3657\n",
      "[2025-11-20 02:37:56,223] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 789.7564\n",
      "2025-11-20 02:37:56 - INFO - [Epoch 019] New best val loss: 789.7564\n",
      "[2025-11-20 02:38:03,011] [UniVITrainer] [INFO] [Epoch 020] Train loss: 809.2307 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:38:03 - INFO - [Epoch 020] Train loss: 809.2307 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:38:03,830] [UniVITrainer] [INFO] [Epoch 020] Val loss: 789.3610 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:38:03 - INFO - [Epoch 020] Val loss: 789.3610 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:38:03,931] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 789.3610\n",
      "2025-11-20 02:38:03 - INFO - [Epoch 020] New best val loss: 789.3610\n",
      "[2025-11-20 02:38:11,545] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 788.6281\n",
      "2025-11-20 02:38:11 - INFO - [Epoch 021] New best val loss: 788.6281\n",
      "[2025-11-20 02:38:34,408] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 785.2736\n",
      "2025-11-20 02:38:34 - INFO - [Epoch 024] New best val loss: 785.2736\n",
      "[2025-11-20 02:39:04,288] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 784.1495\n",
      "2025-11-20 02:39:04 - INFO - [Epoch 028] New best val loss: 784.1495\n",
      "[2025-11-20 02:39:17,656] [UniVITrainer] [INFO] [Epoch 030] Train loss: 789.5033 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:39:17 - INFO - [Epoch 030] Train loss: 789.5033 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:39:18,359] [UniVITrainer] [INFO] [Epoch 030] Val loss: 785.3171 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:39:18 - INFO - [Epoch 030] Val loss: 785.3171 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:39:58,575] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 781.9457\n",
      "2025-11-20 02:39:58 - INFO - [Epoch 036] New best val loss: 781.9457\n",
      "[2025-11-20 02:40:13,058] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 780.7145\n",
      "2025-11-20 02:40:13 - INFO - [Epoch 038] New best val loss: 780.7145\n",
      "[2025-11-20 02:40:26,198] [UniVITrainer] [INFO] [Epoch 040] Train loss: 788.2092 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:40:26 - INFO - [Epoch 040] Train loss: 788.2092 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:40:27,014] [UniVITrainer] [INFO] [Epoch 040] Val loss: 783.4700 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:40:27 - INFO - [Epoch 040] Val loss: 783.4700 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:40:40,600] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 780.3376\n",
      "2025-11-20 02:40:40 - INFO - [Epoch 042] New best val loss: 780.3376\n",
      "[2025-11-20 02:41:15,484] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 779.2699\n",
      "2025-11-20 02:41:15 - INFO - [Epoch 047] New best val loss: 779.2699\n",
      "[2025-11-20 02:41:34,888] [UniVITrainer] [INFO] [Epoch 050] Train loss: 780.6303 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:41:34 - INFO - [Epoch 050] Train loss: 780.6303 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:41:35,705] [UniVITrainer] [INFO] [Epoch 050] Val loss: 777.8320 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:41:35 - INFO - [Epoch 050] Val loss: 777.8320 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:41:35,803] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 777.8320\n",
      "2025-11-20 02:41:35 - INFO - [Epoch 050] New best val loss: 777.8320\n",
      "[2025-11-20 02:41:41,823] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 777.1653\n",
      "2025-11-20 02:41:41 - INFO - [Epoch 051] New best val loss: 777.1653\n",
      "[2025-11-20 02:41:56,328] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 776.8055\n",
      "2025-11-20 02:41:56 - INFO - [Epoch 053] New best val loss: 776.8055\n",
      "[2025-11-20 02:42:18,047] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 776.5192\n",
      "2025-11-20 02:42:18 - INFO - [Epoch 056] New best val loss: 776.5192\n",
      "[2025-11-20 02:42:25,942] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 775.7484\n",
      "2025-11-20 02:42:25 - INFO - [Epoch 057] New best val loss: 775.7484\n",
      "[2025-11-20 02:42:38,185] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 774.5030\n",
      "2025-11-20 02:42:38 - INFO - [Epoch 059] New best val loss: 774.5030\n",
      "[2025-11-20 02:42:44,528] [UniVITrainer] [INFO] [Epoch 060] Train loss: 775.5448 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:42:44 - INFO - [Epoch 060] Train loss: 775.5448 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:42:45,342] [UniVITrainer] [INFO] [Epoch 060] Val loss: 774.6504 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:42:45 - INFO - [Epoch 060] Val loss: 774.6504 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:42:52,806] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 774.0511\n",
      "2025-11-20 02:42:52 - INFO - [Epoch 061] New best val loss: 774.0511\n",
      "[2025-11-20 02:42:58,541] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 773.8895\n",
      "2025-11-20 02:42:58 - INFO - [Epoch 062] New best val loss: 773.8895\n",
      "[2025-11-20 02:43:06,085] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 773.5239\n",
      "2025-11-20 02:43:06 - INFO - [Epoch 063] New best val loss: 773.5239\n",
      "[2025-11-20 02:43:13,736] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 773.3324\n",
      "2025-11-20 02:43:13 - INFO - [Epoch 064] New best val loss: 773.3324\n",
      "[2025-11-20 02:43:21,081] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 773.1771\n",
      "2025-11-20 02:43:21 - INFO - [Epoch 065] New best val loss: 773.1771\n",
      "[2025-11-20 02:43:28,465] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 772.7369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 02:43:28 - INFO - [Epoch 066] New best val loss: 772.7369\n",
      "[2025-11-20 02:43:50,476] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 772.4170\n",
      "2025-11-20 02:43:50 - INFO - [Epoch 069] New best val loss: 772.4170\n",
      "[2025-11-20 02:43:57,066] [UniVITrainer] [INFO] [Epoch 070] Train loss: 774.5637 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:43:57 - INFO - [Epoch 070] Train loss: 774.5637 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:43:57,859] [UniVITrainer] [INFO] [Epoch 070] Val loss: 771.6141 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:43:57 - INFO - [Epoch 070] Val loss: 771.6141 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:43:57,946] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 771.6141\n",
      "2025-11-20 02:43:57 - INFO - [Epoch 070] New best val loss: 771.6141\n",
      "[2025-11-20 02:44:05,586] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 771.2326\n",
      "2025-11-20 02:44:05 - INFO - [Epoch 071] New best val loss: 771.2326\n",
      "[2025-11-20 02:44:20,103] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 770.4498\n",
      "2025-11-20 02:44:20 - INFO - [Epoch 073] New best val loss: 770.4498\n",
      "[2025-11-20 02:44:34,565] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 770.2019\n",
      "2025-11-20 02:44:34 - INFO - [Epoch 075] New best val loss: 770.2019\n",
      "[2025-11-20 02:44:49,730] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 769.3538\n",
      "2025-11-20 02:44:49 - INFO - [Epoch 077] New best val loss: 769.3538\n",
      "[2025-11-20 02:45:11,647] [UniVITrainer] [INFO] [Epoch 080] Train loss: 770.1587 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:45:11 - INFO - [Epoch 080] Train loss: 770.1587 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:45:12,455] [UniVITrainer] [INFO] [Epoch 080] Val loss: 769.2399 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:45:12 - INFO - [Epoch 080] Val loss: 769.2399 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:45:12,568] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 769.2399\n",
      "2025-11-20 02:45:12 - INFO - [Epoch 080] New best val loss: 769.2399\n",
      "[2025-11-20 02:45:20,221] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 769.1441\n",
      "2025-11-20 02:45:20 - INFO - [Epoch 081] New best val loss: 769.1441\n",
      "[2025-11-20 02:45:27,815] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 768.7470\n",
      "2025-11-20 02:45:27 - INFO - [Epoch 082] New best val loss: 768.7470\n",
      "[2025-11-20 02:45:48,141] [UniVITrainer] [INFO] [Epoch 085] New best val loss: 768.4187\n",
      "2025-11-20 02:45:48 - INFO - [Epoch 085] New best val loss: 768.4187\n",
      "[2025-11-20 02:45:55,827] [UniVITrainer] [INFO] [Epoch 086] New best val loss: 768.3258\n",
      "2025-11-20 02:45:55 - INFO - [Epoch 086] New best val loss: 768.3258\n",
      "[2025-11-20 02:46:07,863] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 768.1208\n",
      "2025-11-20 02:46:07 - INFO - [Epoch 088] New best val loss: 768.1208\n",
      "[2025-11-20 02:46:13,530] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 768.0743\n",
      "2025-11-20 02:46:13 - INFO - [Epoch 089] New best val loss: 768.0743\n",
      "[2025-11-20 02:46:20,268] [UniVITrainer] [INFO] [Epoch 090] Train loss: 770.1530 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:46:20 - INFO - [Epoch 090] Train loss: 770.1530 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:46:21,075] [UniVITrainer] [INFO] [Epoch 090] Val loss: 768.0039 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:46:21 - INFO - [Epoch 090] Val loss: 768.0039 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:46:21,175] [UniVITrainer] [INFO] [Epoch 090] New best val loss: 768.0039\n",
      "2025-11-20 02:46:21 - INFO - [Epoch 090] New best val loss: 768.0039\n",
      "[2025-11-20 02:46:28,800] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 767.7888\n",
      "2025-11-20 02:46:28 - INFO - [Epoch 091] New best val loss: 767.7888\n",
      "[2025-11-20 02:46:34,853] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 767.7424\n",
      "2025-11-20 02:46:34 - INFO - [Epoch 092] New best val loss: 767.7424\n",
      "[2025-11-20 02:46:49,464] [UniVITrainer] [INFO] [Epoch 094] New best val loss: 767.4497\n",
      "2025-11-20 02:46:49 - INFO - [Epoch 094] New best val loss: 767.4497\n",
      "[2025-11-20 02:46:56,481] [UniVITrainer] [INFO] [Epoch 095] New best val loss: 767.4405\n",
      "2025-11-20 02:46:56 - INFO - [Epoch 095] New best val loss: 767.4405\n",
      "[2025-11-20 02:47:04,110] [UniVITrainer] [INFO] [Epoch 096] New best val loss: 767.4295\n",
      "2025-11-20 02:47:04 - INFO - [Epoch 096] New best val loss: 767.4295\n",
      "[2025-11-20 02:47:11,581] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 767.3484\n",
      "2025-11-20 02:47:11 - INFO - [Epoch 097] New best val loss: 767.3484\n",
      "[2025-11-20 02:47:18,849] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 767.2368\n",
      "2025-11-20 02:47:18 - INFO - [Epoch 098] New best val loss: 767.2368\n",
      "[2025-11-20 02:47:25,395] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 767.1643\n",
      "2025-11-20 02:47:25 - INFO - [Epoch 099] New best val loss: 767.1643\n",
      "[2025-11-20 02:47:32,147] [UniVITrainer] [INFO] [Epoch 100] Train loss: 766.0155 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:47:32 - INFO - [Epoch 100] Train loss: 766.0155 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:47:32,943] [UniVITrainer] [INFO] [Epoch 100] Val loss: 767.2155 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:47:32 - INFO - [Epoch 100] Val loss: 767.2155 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:47:40,459] [UniVITrainer] [INFO] [Epoch 101] New best val loss: 767.1459\n",
      "2025-11-20 02:47:40 - INFO - [Epoch 101] New best val loss: 767.1459\n",
      "[2025-11-20 02:47:47,791] [UniVITrainer] [INFO] [Epoch 102] New best val loss: 767.1080\n",
      "2025-11-20 02:47:47 - INFO - [Epoch 102] New best val loss: 767.1080\n",
      "[2025-11-20 02:47:53,447] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 767.0552\n",
      "2025-11-20 02:47:53 - INFO - [Epoch 103] New best val loss: 767.0552\n",
      "[2025-11-20 02:48:08,403] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 766.9778\n",
      "2025-11-20 02:48:08 - INFO - [Epoch 105] New best val loss: 766.9778\n",
      "[2025-11-20 02:48:15,883] [UniVITrainer] [INFO] [Epoch 106] New best val loss: 766.9131\n",
      "2025-11-20 02:48:15 - INFO - [Epoch 106] New best val loss: 766.9131\n",
      "[2025-11-20 02:48:45,061] [UniVITrainer] [INFO] [Epoch 110] Train loss: 770.2028 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:48:45 - INFO - [Epoch 110] Train loss: 770.2028 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:48:45,875] [UniVITrainer] [INFO] [Epoch 110] Val loss: 766.8687 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:48:45 - INFO - [Epoch 110] Val loss: 766.8687 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:48:45,973] [UniVITrainer] [INFO] [Epoch 110] New best val loss: 766.8687\n",
      "2025-11-20 02:48:45 - INFO - [Epoch 110] New best val loss: 766.8687\n",
      "[2025-11-20 02:48:59,438] [UniVITrainer] [INFO] [Epoch 112] New best val loss: 766.8232\n",
      "2025-11-20 02:48:59 - INFO - [Epoch 112] New best val loss: 766.8232\n",
      "[2025-11-20 02:49:07,050] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 766.7865\n",
      "2025-11-20 02:49:07 - INFO - [Epoch 113] New best val loss: 766.7865\n",
      "[2025-11-20 02:49:13,134] [UniVITrainer] [INFO] [Epoch 114] New best val loss: 766.7838\n",
      "2025-11-20 02:49:13 - INFO - [Epoch 114] New best val loss: 766.7838\n",
      "[2025-11-20 02:49:27,515] [UniVITrainer] [INFO] [Epoch 116] New best val loss: 766.7436\n",
      "2025-11-20 02:49:27 - INFO - [Epoch 116] New best val loss: 766.7436\n",
      "[2025-11-20 02:49:35,110] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 766.7118\n",
      "2025-11-20 02:49:35 - INFO - [Epoch 117] New best val loss: 766.7118\n",
      "[2025-11-20 02:49:56,460] [UniVITrainer] [INFO] [Epoch 120] Train loss: 769.7882 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:49:56 - INFO - [Epoch 120] Train loss: 769.7882 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:49:57,265] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.6993 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:49:57 - INFO - [Epoch 120] Val loss: 766.6993 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:49:57,362] [UniVITrainer] [INFO] [Epoch 120] New best val loss: 766.6993\n",
      "2025-11-20 02:49:57 - INFO - [Epoch 120] New best val loss: 766.6993\n",
      "[2025-11-20 02:50:04,903] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 766.6850\n",
      "2025-11-20 02:50:04 - INFO - [Epoch 121] New best val loss: 766.6850\n",
      "[2025-11-20 02:50:12,530] [UniVITrainer] [INFO] [Epoch 122] New best val loss: 766.6690\n",
      "2025-11-20 02:50:12 - INFO - [Epoch 122] New best val loss: 766.6690\n",
      "[2025-11-20 02:50:19,665] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 766.6147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 02:50:19 - INFO - [Epoch 123] New best val loss: 766.6147\n",
      "[2025-11-20 02:50:42,342] [UniVITrainer] [INFO] [Epoch 126] New best val loss: 766.5751\n",
      "2025-11-20 02:50:42 - INFO - [Epoch 126] New best val loss: 766.5751\n",
      "[2025-11-20 02:51:11,374] [UniVITrainer] [INFO] [Epoch 130] Train loss: 766.7717 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:51:11 - INFO - [Epoch 130] Train loss: 766.7717 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:51:12,182] [UniVITrainer] [INFO] [Epoch 130] Val loss: 766.5674 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:51:12 - INFO - [Epoch 130] Val loss: 766.5674 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:51:12,245] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 766.5674\n",
      "2025-11-20 02:51:12 - INFO - [Epoch 130] New best val loss: 766.5674\n",
      "[2025-11-20 02:51:34,598] [UniVITrainer] [INFO] [Epoch 133] New best val loss: 766.5673\n",
      "2025-11-20 02:51:34 - INFO - [Epoch 133] New best val loss: 766.5673\n",
      "[2025-11-20 02:51:49,622] [UniVITrainer] [INFO] [Epoch 135] New best val loss: 766.5564\n",
      "2025-11-20 02:51:49 - INFO - [Epoch 135] New best val loss: 766.5564\n",
      "[2025-11-20 02:51:57,042] [UniVITrainer] [INFO] [Epoch 136] New best val loss: 766.5358\n",
      "2025-11-20 02:51:57 - INFO - [Epoch 136] New best val loss: 766.5358\n",
      "[2025-11-20 02:52:04,669] [UniVITrainer] [INFO] [Epoch 137] New best val loss: 766.5094\n",
      "2025-11-20 02:52:04 - INFO - [Epoch 137] New best val loss: 766.5094\n",
      "[2025-11-20 02:52:24,970] [UniVITrainer] [INFO] [Epoch 140] Train loss: 769.5982 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:52:24 - INFO - [Epoch 140] Train loss: 769.5982 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:52:25,778] [UniVITrainer] [INFO] [Epoch 140] Val loss: 766.5849 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:52:25 - INFO - [Epoch 140] Val loss: 766.5849 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:52:32,216] [UniVITrainer] [INFO] [Epoch 141] New best val loss: 766.4795\n",
      "2025-11-20 02:52:32 - INFO - [Epoch 141] New best val loss: 766.4795\n",
      "[2025-11-20 02:53:33,385] [UniVITrainer] [INFO] [Epoch 150] Train loss: 768.3258 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:53:33 - INFO - [Epoch 150] Train loss: 768.3258 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:53:34,516] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.4728 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:53:34 - INFO - [Epoch 150] Val loss: 766.4728 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:53:34,609] [UniVITrainer] [INFO] [Epoch 150] New best val loss: 766.4728\n",
      "2025-11-20 02:53:34 - INFO - [Epoch 150] New best val loss: 766.4728\n",
      "[2025-11-20 02:53:41,916] [UniVITrainer] [INFO] [Epoch 151] New best val loss: 766.4531\n",
      "2025-11-20 02:53:41 - INFO - [Epoch 151] New best val loss: 766.4531\n",
      "[2025-11-20 02:53:48,700] [UniVITrainer] [INFO] [Epoch 152] New best val loss: 766.4522\n",
      "2025-11-20 02:53:48 - INFO - [Epoch 152] New best val loss: 766.4522\n",
      "[2025-11-20 02:54:18,311] [UniVITrainer] [INFO] [Epoch 156] New best val loss: 766.4470\n",
      "2025-11-20 02:54:18 - INFO - [Epoch 156] New best val loss: 766.4470\n",
      "[2025-11-20 02:54:45,999] [UniVITrainer] [INFO] [Epoch 160] Train loss: 770.6159 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:54:45 - INFO - [Epoch 160] Train loss: 770.6159 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:54:46,808] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.6643 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:54:46 - INFO - [Epoch 160] Val loss: 766.6643 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:55:08,565] [UniVITrainer] [INFO] [Epoch 163] New best val loss: 766.4337\n",
      "2025-11-20 02:55:08 - INFO - [Epoch 163] New best val loss: 766.4337\n",
      "[2025-11-20 02:55:22,907] [UniVITrainer] [INFO] [Epoch 165] New best val loss: 766.3749\n",
      "2025-11-20 02:55:22 - INFO - [Epoch 165] New best val loss: 766.3749\n",
      "[2025-11-20 02:55:57,451] [UniVITrainer] [INFO] [Epoch 170] Train loss: 767.0888 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:55:57 - INFO - [Epoch 170] Train loss: 767.0888 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:55:58,260] [UniVITrainer] [INFO] [Epoch 170] Val loss: 766.4298 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:55:58 - INFO - [Epoch 170] Val loss: 766.4298 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:57:10,923] [UniVITrainer] [INFO] [Epoch 180] Train loss: 768.2140 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:57:10 - INFO - [Epoch 180] Train loss: 768.2140 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:57:11,405] [UniVITrainer] [INFO] [Epoch 180] Val loss: 766.3791 (beta=400.000, gamma=80.000)\n",
      "2025-11-20 02:57:11 - INFO - [Epoch 180] Val loss: 766.3791 (beta=400.000, gamma=80.000)\n",
      "[2025-11-20 02:57:48,514] [UniVITrainer] [INFO] Early stopping at epoch 185 (best val loss = 766.3749)\n",
      "2025-11-20 02:57:48 - INFO - Early stopping at epoch 185 (best val loss = 766.3749)\n",
      "[2025-11-20 02:57:48,544] [UniVITrainer] [INFO] Restored best model from epoch 165 (val loss = 766.3749)\n",
      "2025-11-20 02:57:48 - INFO - Restored best model from epoch 165 (val loss = 766.3749)\n",
      "[2025-11-20 02:57:50,902] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 02:57:50 - INFO - TrainingConfig:\n",
      "[2025-11-20 02:57:50,905] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 02:57:50 - INFO -   n_epochs: 200\n",
      "[2025-11-20 02:57:50,907] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 02:57:50 - INFO -   batch_size: 256\n",
      "[2025-11-20 02:57:50,913] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 02:57:50 - INFO -   lr: 0.001\n",
      "[2025-11-20 02:57:50,916] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 02:57:50 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 02:57:50,919] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 02:57:50 - INFO -   device: cuda\n",
      "[2025-11-20 02:57:50,922] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 02:57:50 - INFO -   log_every: 10\n",
      "[2025-11-20 02:57:50,923] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 02:57:50 - INFO -   grad_clip: None\n",
      "[2025-11-20 02:57:50,924] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 02:57:50 - INFO -   num_workers: 0\n",
      "[2025-11-20 02:57:50,925] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 02:57:50 - INFO -   seed: 42\n",
      "[2025-11-20 02:57:50,926] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 02:57:50 - INFO -   early_stopping: True\n",
      "[2025-11-20 02:57:50,927] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 02:57:50 - INFO -   patience: 20\n",
      "[2025-11-20 02:57:50,928] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 02:57:50 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 11] Done in 22.3 min\n",
      "  best_val_loss              = 766.375\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5204\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.5112\n",
      "[Config 11] FOSCTTM (ADT vs ATAC, val) = 0.5148\n",
      "  Mean FOSCTTM (3 pairs)     = 0.5155\n",
      "  Modality mixing (k=20)     = 0.0000\n",
      "  Composite score            = 1161.42\n",
      "\n",
      "================================================================================\n",
      "[Config 12] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 86,\n",
      "  \"beta\": 40.0,\n",
      "  \"gamma\": 500.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_med2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_small2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c405353d5a24273a39e1c92786845bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 02:57:57,710] [UniVITrainer] [INFO] [Epoch 001] Train loss: 6842.1815 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 02:57:57 - INFO - [Epoch 001] Train loss: 6842.1815 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 02:57:58,524] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1845.0099 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 02:57:58 - INFO - [Epoch 001] Val loss: 1845.0099 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 02:57:58,662] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1845.0099\n",
      "2025-11-20 02:57:58 - INFO - [Epoch 001] New best val loss: 1845.0099\n",
      "[2025-11-20 02:58:05,901] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1164.0013\n",
      "2025-11-20 02:58:05 - INFO - [Epoch 002] New best val loss: 1164.0013\n",
      "[2025-11-20 02:58:13,591] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 997.6691\n",
      "2025-11-20 02:58:13 - INFO - [Epoch 003] New best val loss: 997.6691\n",
      "[2025-11-20 02:58:21,159] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 933.7699\n",
      "2025-11-20 02:58:21 - INFO - [Epoch 004] New best val loss: 933.7699\n",
      "[2025-11-20 02:58:28,803] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 886.0054\n",
      "2025-11-20 02:58:28 - INFO - [Epoch 005] New best val loss: 886.0054\n",
      "[2025-11-20 02:58:36,451] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 863.8212\n",
      "2025-11-20 02:58:36 - INFO - [Epoch 006] New best val loss: 863.8212\n",
      "[2025-11-20 02:58:44,166] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 848.7613\n",
      "2025-11-20 02:58:44 - INFO - [Epoch 007] New best val loss: 848.7613\n",
      "[2025-11-20 02:58:50,177] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 832.9549\n",
      "2025-11-20 02:58:50 - INFO - [Epoch 008] New best val loss: 832.9549\n",
      "[2025-11-20 02:58:57,714] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 823.3413\n",
      "2025-11-20 02:58:57 - INFO - [Epoch 009] New best val loss: 823.3413\n",
      "[2025-11-20 02:59:03,835] [UniVITrainer] [INFO] [Epoch 010] Train loss: 974.7151 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 02:59:03 - INFO - [Epoch 010] Train loss: 974.7151 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 02:59:04,527] [UniVITrainer] [INFO] [Epoch 010] Val loss: 816.1266 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 02:59:04 - INFO - [Epoch 010] Val loss: 816.1266 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 02:59:04,611] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 816.1266\n",
      "2025-11-20 02:59:04 - INFO - [Epoch 010] New best val loss: 816.1266\n",
      "[2025-11-20 02:59:11,665] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 811.0432\n",
      "2025-11-20 02:59:11 - INFO - [Epoch 011] New best val loss: 811.0432\n",
      "[2025-11-20 02:59:18,355] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 803.8463\n",
      "2025-11-20 02:59:18 - INFO - [Epoch 012] New best val loss: 803.8463\n",
      "[2025-11-20 02:59:25,976] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 799.6826\n",
      "2025-11-20 02:59:25 - INFO - [Epoch 013] New best val loss: 799.6826\n",
      "[2025-11-20 02:59:33,585] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 797.8154\n",
      "2025-11-20 02:59:33 - INFO - [Epoch 014] New best val loss: 797.8154\n",
      "[2025-11-20 02:59:41,485] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 793.8215\n",
      "2025-11-20 02:59:41 - INFO - [Epoch 015] New best val loss: 793.8215\n",
      "[2025-11-20 02:59:47,901] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 791.0041\n",
      "2025-11-20 02:59:47 - INFO - [Epoch 016] New best val loss: 791.0041\n",
      "[2025-11-20 02:59:55,440] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 788.2608\n",
      "2025-11-20 02:59:55 - INFO - [Epoch 017] New best val loss: 788.2608\n",
      "[2025-11-20 03:00:02,970] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 788.2302\n",
      "2025-11-20 03:00:02 - INFO - [Epoch 018] New best val loss: 788.2302\n",
      "[2025-11-20 03:00:10,518] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 785.1400\n",
      "2025-11-20 03:00:10 - INFO - [Epoch 019] New best val loss: 785.1400\n",
      "[2025-11-20 03:00:17,090] [UniVITrainer] [INFO] [Epoch 020] Train loss: 837.6371 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:00:17 - INFO - [Epoch 020] Train loss: 837.6371 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:00:17,926] [UniVITrainer] [INFO] [Epoch 020] Val loss: 783.1693 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:00:17 - INFO - [Epoch 020] Val loss: 783.1693 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:00:18,032] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 783.1693\n",
      "2025-11-20 03:00:18 - INFO - [Epoch 020] New best val loss: 783.1693\n",
      "[2025-11-20 03:00:25,304] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 782.2008\n",
      "2025-11-20 03:00:25 - INFO - [Epoch 021] New best val loss: 782.2008\n",
      "[2025-11-20 03:00:32,207] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 781.3931\n",
      "2025-11-20 03:00:32 - INFO - [Epoch 022] New best val loss: 781.3931\n",
      "[2025-11-20 03:00:40,052] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 780.3239\n",
      "2025-11-20 03:00:40 - INFO - [Epoch 023] New best val loss: 780.3239\n",
      "[2025-11-20 03:00:47,438] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 778.8164\n",
      "2025-11-20 03:00:47 - INFO - [Epoch 024] New best val loss: 778.8164\n",
      "[2025-11-20 03:00:55,294] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 778.4785\n",
      "2025-11-20 03:00:55 - INFO - [Epoch 025] New best val loss: 778.4785\n",
      "[2025-11-20 03:01:01,818] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 777.1836\n",
      "2025-11-20 03:01:01 - INFO - [Epoch 026] New best val loss: 777.1836\n",
      "[2025-11-20 03:01:09,163] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 776.6278\n",
      "2025-11-20 03:01:09 - INFO - [Epoch 027] New best val loss: 776.6278\n",
      "[2025-11-20 03:01:16,909] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 775.7940\n",
      "2025-11-20 03:01:16 - INFO - [Epoch 028] New best val loss: 775.7940\n",
      "[2025-11-20 03:01:31,418] [UniVITrainer] [INFO] [Epoch 030] Train loss: 798.9730 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:01:31 - INFO - [Epoch 030] Train loss: 798.9730 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:01:32,214] [UniVITrainer] [INFO] [Epoch 030] Val loss: 776.5260 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:01:32 - INFO - [Epoch 030] Val loss: 776.5260 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:01:39,698] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 774.6403\n",
      "2025-11-20 03:01:39 - INFO - [Epoch 031] New best val loss: 774.6403\n",
      "[2025-11-20 03:01:47,204] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 774.0875\n",
      "2025-11-20 03:01:47 - INFO - [Epoch 032] New best val loss: 774.0875\n",
      "[2025-11-20 03:01:54,546] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 773.5311\n",
      "2025-11-20 03:01:54 - INFO - [Epoch 033] New best val loss: 773.5311\n",
      "[2025-11-20 03:02:02,109] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 773.0041\n",
      "2025-11-20 03:02:02 - INFO - [Epoch 034] New best val loss: 773.0041\n",
      "[2025-11-20 03:02:17,324] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 772.1829\n",
      "2025-11-20 03:02:17 - INFO - [Epoch 036] New best val loss: 772.1829\n",
      "[2025-11-20 03:02:25,111] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 771.9867\n",
      "2025-11-20 03:02:25 - INFO - [Epoch 037] New best val loss: 771.9867\n",
      "[2025-11-20 03:02:32,022] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 771.9118\n",
      "2025-11-20 03:02:32 - INFO - [Epoch 038] New best val loss: 771.9118\n",
      "[2025-11-20 03:02:46,290] [UniVITrainer] [INFO] [Epoch 040] Train loss: 785.7659 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:02:46 - INFO - [Epoch 040] Train loss: 785.7659 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:02:47,111] [UniVITrainer] [INFO] [Epoch 040] Val loss: 771.1549 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:02:47 - INFO - [Epoch 040] Val loss: 771.1549 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:02:47,134] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 771.1549\n",
      "2025-11-20 03:02:47 - INFO - [Epoch 040] New best val loss: 771.1549\n",
      "[2025-11-20 03:02:54,969] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 771.0208\n",
      "2025-11-20 03:02:54 - INFO - [Epoch 041] New best val loss: 771.0208\n",
      "[2025-11-20 03:03:01,884] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 770.3492\n",
      "2025-11-20 03:03:01 - INFO - [Epoch 042] New best val loss: 770.3492\n",
      "[2025-11-20 03:03:17,530] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 770.0459\n",
      "2025-11-20 03:03:17 - INFO - [Epoch 044] New best val loss: 770.0459\n",
      "[2025-11-20 03:03:25,431] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 769.9369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 03:03:25 - INFO - [Epoch 045] New best val loss: 769.9369\n",
      "[2025-11-20 03:03:40,953] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 769.4641\n",
      "2025-11-20 03:03:40 - INFO - [Epoch 047] New best val loss: 769.4641\n",
      "[2025-11-20 03:03:56,178] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 769.4073\n",
      "2025-11-20 03:03:56 - INFO - [Epoch 049] New best val loss: 769.4073\n",
      "[2025-11-20 03:04:02,996] [UniVITrainer] [INFO] [Epoch 050] Train loss: 776.8928 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:04:02 - INFO - [Epoch 050] Train loss: 776.8928 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:04:03,875] [UniVITrainer] [INFO] [Epoch 050] Val loss: 769.7122 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:04:03 - INFO - [Epoch 050] Val loss: 769.7122 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:04:11,823] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 769.2517\n",
      "2025-11-20 03:04:11 - INFO - [Epoch 051] New best val loss: 769.2517\n",
      "[2025-11-20 03:04:18,656] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 769.0236\n",
      "2025-11-20 03:04:18 - INFO - [Epoch 052] New best val loss: 769.0236\n",
      "[2025-11-20 03:04:33,962] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 768.6983\n",
      "2025-11-20 03:04:33 - INFO - [Epoch 054] New best val loss: 768.6983\n",
      "[2025-11-20 03:04:49,325] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 768.3274\n",
      "2025-11-20 03:04:49 - INFO - [Epoch 056] New best val loss: 768.3274\n",
      "[2025-11-20 03:04:57,539] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 768.2293\n",
      "2025-11-20 03:04:57 - INFO - [Epoch 057] New best val loss: 768.2293\n",
      "[2025-11-20 03:05:19,666] [UniVITrainer] [INFO] [Epoch 060] Train loss: 772.1069 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:05:19 - INFO - [Epoch 060] Train loss: 772.1069 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:05:20,483] [UniVITrainer] [INFO] [Epoch 060] Val loss: 768.5132 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:05:20 - INFO - [Epoch 060] Val loss: 768.5132 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:05:43,613] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 767.9647\n",
      "2025-11-20 03:05:43 - INFO - [Epoch 063] New best val loss: 767.9647\n",
      "[2025-11-20 03:05:57,274] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 767.8487\n",
      "2025-11-20 03:05:57 - INFO - [Epoch 065] New best val loss: 767.8487\n",
      "[2025-11-20 03:06:02,986] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 767.8441\n",
      "2025-11-20 03:06:02 - INFO - [Epoch 066] New best val loss: 767.8441\n",
      "[2025-11-20 03:06:10,685] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 767.6433\n",
      "2025-11-20 03:06:10 - INFO - [Epoch 067] New best val loss: 767.6433\n",
      "[2025-11-20 03:06:30,687] [UniVITrainer] [INFO] [Epoch 070] Train loss: 769.0836 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:06:30 - INFO - [Epoch 070] Train loss: 769.0836 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:06:31,517] [UniVITrainer] [INFO] [Epoch 070] Val loss: 767.9723 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:06:31 - INFO - [Epoch 070] Val loss: 767.9723 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:06:45,438] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 767.4924\n",
      "2025-11-20 03:06:45 - INFO - [Epoch 072] New best val loss: 767.4924\n",
      "[2025-11-20 03:06:59,912] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 767.4680\n",
      "2025-11-20 03:06:59 - INFO - [Epoch 074] New best val loss: 767.4680\n",
      "[2025-11-20 03:07:12,914] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 767.2726\n",
      "2025-11-20 03:07:12 - INFO - [Epoch 076] New best val loss: 767.2726\n",
      "[2025-11-20 03:07:35,134] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 767.2474\n",
      "2025-11-20 03:07:35 - INFO - [Epoch 079] New best val loss: 767.2474\n",
      "[2025-11-20 03:07:42,070] [UniVITrainer] [INFO] [Epoch 080] Train loss: 769.2532 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:07:42 - INFO - [Epoch 080] Train loss: 769.2532 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:07:42,891] [UniVITrainer] [INFO] [Epoch 080] Val loss: 767.1378 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:07:42 - INFO - [Epoch 080] Val loss: 767.1378 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:07:43,005] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 767.1378\n",
      "2025-11-20 03:07:43 - INFO - [Epoch 080] New best val loss: 767.1378\n",
      "[2025-11-20 03:07:57,884] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 767.0160\n",
      "2025-11-20 03:07:57 - INFO - [Epoch 082] New best val loss: 767.0160\n",
      "[2025-11-20 03:08:43,731] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 766.9425\n",
      "2025-11-20 03:08:43 - INFO - [Epoch 088] New best val loss: 766.9425\n",
      "[2025-11-20 03:08:55,522] [UniVITrainer] [INFO] [Epoch 090] Train loss: 766.9303 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:08:55 - INFO - [Epoch 090] Train loss: 766.9303 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:08:55,582] [UniVITrainer] [INFO] [Epoch 090] Val loss: 767.0564 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:08:55 - INFO - [Epoch 090] Val loss: 767.0564 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:09:10,330] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 766.7957\n",
      "2025-11-20 03:09:10 - INFO - [Epoch 092] New best val loss: 766.7957\n",
      "[2025-11-20 03:10:08,582] [UniVITrainer] [INFO] [Epoch 100] Train loss: 766.9168 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:10:08 - INFO - [Epoch 100] Train loss: 766.9168 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:10:09,413] [UniVITrainer] [INFO] [Epoch 100] Val loss: 766.8605 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:10:09 - INFO - [Epoch 100] Val loss: 766.8605 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:10:40,082] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 766.7340\n",
      "2025-11-20 03:10:40 - INFO - [Epoch 104] New best val loss: 766.7340\n",
      "[2025-11-20 03:11:18,470] [UniVITrainer] [INFO] [Epoch 109] New best val loss: 766.6964\n",
      "2025-11-20 03:11:18 - INFO - [Epoch 109] New best val loss: 766.6964\n",
      "[2025-11-20 03:11:25,150] [UniVITrainer] [INFO] [Epoch 110] Train loss: 765.9320 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:11:25 - INFO - [Epoch 110] Train loss: 765.9320 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:11:25,979] [UniVITrainer] [INFO] [Epoch 110] Val loss: 766.7668 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:11:25 - INFO - [Epoch 110] Val loss: 766.7668 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:11:33,902] [UniVITrainer] [INFO] [Epoch 111] New best val loss: 766.6649\n",
      "2025-11-20 03:11:33 - INFO - [Epoch 111] New best val loss: 766.6649\n",
      "[2025-11-20 03:11:56,745] [UniVITrainer] [INFO] [Epoch 114] New best val loss: 766.6565\n",
      "2025-11-20 03:11:56 - INFO - [Epoch 114] New best val loss: 766.6565\n",
      "[2025-11-20 03:12:04,051] [UniVITrainer] [INFO] [Epoch 115] New best val loss: 766.6341\n",
      "2025-11-20 03:12:04 - INFO - [Epoch 115] New best val loss: 766.6341\n",
      "[2025-11-20 03:12:24,798] [UniVITrainer] [INFO] [Epoch 118] New best val loss: 766.6158\n",
      "2025-11-20 03:12:24 - INFO - [Epoch 118] New best val loss: 766.6158\n",
      "[2025-11-20 03:12:38,609] [UniVITrainer] [INFO] [Epoch 120] Train loss: 767.5689 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:12:38 - INFO - [Epoch 120] Train loss: 767.5689 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:12:39,413] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.4937 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:12:39 - INFO - [Epoch 120] Val loss: 766.4937 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:12:39,573] [UniVITrainer] [INFO] [Epoch 120] New best val loss: 766.4937\n",
      "2025-11-20 03:12:39 - INFO - [Epoch 120] New best val loss: 766.4937\n",
      "[2025-11-20 03:13:46,580] [UniVITrainer] [INFO] [Epoch 130] Train loss: 768.7081 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:13:46 - INFO - [Epoch 130] Train loss: 768.7081 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:13:47,391] [UniVITrainer] [INFO] [Epoch 130] Val loss: 766.5291 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:13:47 - INFO - [Epoch 130] Val loss: 766.5291 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:14:00,739] [UniVITrainer] [INFO] [Epoch 132] New best val loss: 766.4824\n",
      "2025-11-20 03:14:00 - INFO - [Epoch 132] New best val loss: 766.4824\n",
      "[2025-11-20 03:14:14,798] [UniVITrainer] [INFO] [Epoch 134] New best val loss: 766.4527\n",
      "2025-11-20 03:14:14 - INFO - [Epoch 134] New best val loss: 766.4527\n",
      "[2025-11-20 03:14:53,990] [UniVITrainer] [INFO] [Epoch 140] Train loss: 766.6539 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:14:53 - INFO - [Epoch 140] Train loss: 766.6539 (beta=40.000, gamma=500.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 03:14:54,801] [UniVITrainer] [INFO] [Epoch 140] Val loss: 766.5759 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:14:54 - INFO - [Epoch 140] Val loss: 766.5759 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:15:31,292] [UniVITrainer] [INFO] [Epoch 145] New best val loss: 766.4356\n",
      "2025-11-20 03:15:31 - INFO - [Epoch 145] New best val loss: 766.4356\n",
      "[2025-11-20 03:16:05,933] [UniVITrainer] [INFO] [Epoch 150] Train loss: 764.7147 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:16:05 - INFO - [Epoch 150] Train loss: 764.7147 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:16:06,740] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.6903 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:16:06 - INFO - [Epoch 150] Val loss: 766.6903 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:16:21,690] [UniVITrainer] [INFO] [Epoch 152] New best val loss: 766.3920\n",
      "2025-11-20 03:16:21 - INFO - [Epoch 152] New best val loss: 766.3920\n",
      "[2025-11-20 03:16:50,176] [UniVITrainer] [INFO] [Epoch 156] New best val loss: 766.3887\n",
      "2025-11-20 03:16:50 - INFO - [Epoch 156] New best val loss: 766.3887\n",
      "[2025-11-20 03:17:18,225] [UniVITrainer] [INFO] [Epoch 160] Train loss: 766.8114 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:17:18 - INFO - [Epoch 160] Train loss: 766.8114 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:17:19,035] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.9934 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:17:19 - INFO - [Epoch 160] Val loss: 766.9934 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:18:07,922] [UniVITrainer] [INFO] [Epoch 167] New best val loss: 766.3607\n",
      "2025-11-20 03:18:07 - INFO - [Epoch 167] New best val loss: 766.3607\n",
      "[2025-11-20 03:18:28,441] [UniVITrainer] [INFO] [Epoch 170] Train loss: 771.2982 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:18:28 - INFO - [Epoch 170] Train loss: 771.2982 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:18:29,244] [UniVITrainer] [INFO] [Epoch 170] Val loss: 766.4445 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:18:29 - INFO - [Epoch 170] Val loss: 766.4445 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:19:39,843] [UniVITrainer] [INFO] [Epoch 180] Train loss: 771.0710 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:19:39 - INFO - [Epoch 180] Train loss: 771.0710 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:19:40,616] [UniVITrainer] [INFO] [Epoch 180] Val loss: 766.4166 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:19:40 - INFO - [Epoch 180] Val loss: 766.4166 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:20:20,856] [UniVITrainer] [INFO] [Epoch 186] New best val loss: 766.3441\n",
      "2025-11-20 03:20:20 - INFO - [Epoch 186] New best val loss: 766.3441\n",
      "[2025-11-20 03:20:49,391] [UniVITrainer] [INFO] [Epoch 190] Train loss: 769.5168 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:20:49 - INFO - [Epoch 190] Train loss: 769.5168 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:20:50,200] [UniVITrainer] [INFO] [Epoch 190] Val loss: 766.3420 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:20:50 - INFO - [Epoch 190] Val loss: 766.3420 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:20:50,297] [UniVITrainer] [INFO] [Epoch 190] New best val loss: 766.3420\n",
      "2025-11-20 03:20:50 - INFO - [Epoch 190] New best val loss: 766.3420\n",
      "[2025-11-20 03:21:11,265] [UniVITrainer] [INFO] [Epoch 193] New best val loss: 766.3387\n",
      "2025-11-20 03:21:11 - INFO - [Epoch 193] New best val loss: 766.3387\n",
      "[2025-11-20 03:22:00,229] [UniVITrainer] [INFO] [Epoch 200] Train loss: 767.5341 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:22:00 - INFO - [Epoch 200] Train loss: 767.5341 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:22:01,038] [UniVITrainer] [INFO] [Epoch 200] Val loss: 766.4689 (beta=40.000, gamma=500.000)\n",
      "2025-11-20 03:22:01 - INFO - [Epoch 200] Val loss: 766.4689 (beta=40.000, gamma=500.000)\n",
      "[2025-11-20 03:22:01,077] [UniVITrainer] [INFO] Restored best model from epoch 193 (val loss = 766.3387)\n",
      "2025-11-20 03:22:01 - INFO - Restored best model from epoch 193 (val loss = 766.3387)\n",
      "[2025-11-20 03:22:03,660] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 03:22:03 - INFO - TrainingConfig:\n",
      "[2025-11-20 03:22:03,663] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 03:22:03 - INFO -   n_epochs: 200\n",
      "[2025-11-20 03:22:03,665] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 03:22:03 - INFO -   batch_size: 256\n",
      "[2025-11-20 03:22:03,669] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 03:22:03 - INFO -   lr: 0.001\n",
      "[2025-11-20 03:22:03,672] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 03:22:03 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 03:22:03,674] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 03:22:03 - INFO -   device: cuda\n",
      "[2025-11-20 03:22:03,675] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 03:22:03 - INFO -   log_every: 10\n",
      "[2025-11-20 03:22:03,676] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 03:22:03 - INFO -   grad_clip: None\n",
      "[2025-11-20 03:22:03,676] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 03:22:03 - INFO -   num_workers: 0\n",
      "[2025-11-20 03:22:03,677] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 03:22:03 - INFO -   seed: 42\n",
      "[2025-11-20 03:22:03,678] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 03:22:03 - INFO -   early_stopping: True\n",
      "[2025-11-20 03:22:03,678] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 03:22:03 - INFO -   patience: 20\n",
      "[2025-11-20 03:22:03,679] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 03:22:03 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 12] Done in 24.2 min\n",
      "  best_val_loss              = 766.339\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5020\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.1281\n",
      "[Config 12] FOSCTTM (ADT vs ATAC, val) = 0.1180\n",
      "  Mean FOSCTTM (3 pairs)     = 0.2493\n",
      "  Modality mixing (k=20)     = 0.0001\n",
      "  Composite score            = 957.55\n",
      "\n",
      "================================================================================\n",
      "[Config 13] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 86,\n",
      "  \"beta\": 100.0,\n",
      "  \"gamma\": 1000.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.0,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_wide2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_small2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0e16f7908c485daec1a60645001655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 03:22:10,435] [UniVITrainer] [INFO] [Epoch 001] Train loss: 9377.3006 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:22:10 - INFO - [Epoch 001] Train loss: 9377.3006 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:22:11,250] [UniVITrainer] [INFO] [Epoch 001] Val loss: 2789.3747 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:22:11 - INFO - [Epoch 001] Val loss: 2789.3747 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:22:11,408] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 2789.3747\n",
      "2025-11-20 03:22:11 - INFO - [Epoch 001] New best val loss: 2789.3747\n",
      "[2025-11-20 03:22:19,062] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1514.6497\n",
      "2025-11-20 03:22:19 - INFO - [Epoch 002] New best val loss: 1514.6497\n",
      "[2025-11-20 03:22:25,881] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1244.8735\n",
      "2025-11-20 03:22:25 - INFO - [Epoch 003] New best val loss: 1244.8735\n",
      "[2025-11-20 03:22:33,584] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 1086.3174\n",
      "2025-11-20 03:22:33 - INFO - [Epoch 004] New best val loss: 1086.3174\n",
      "[2025-11-20 03:22:41,135] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 1036.5486\n",
      "2025-11-20 03:22:41 - INFO - [Epoch 005] New best val loss: 1036.5486\n",
      "[2025-11-20 03:22:47,857] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 991.6756\n",
      "2025-11-20 03:22:47 - INFO - [Epoch 006] New best val loss: 991.6756\n",
      "[2025-11-20 03:22:55,588] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 955.4348\n",
      "2025-11-20 03:22:55 - INFO - [Epoch 007] New best val loss: 955.4348\n",
      "[2025-11-20 03:23:03,088] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 928.2375\n",
      "2025-11-20 03:23:03 - INFO - [Epoch 008] New best val loss: 928.2375\n",
      "[2025-11-20 03:23:10,044] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 908.1083\n",
      "2025-11-20 03:23:10 - INFO - [Epoch 009] New best val loss: 908.1083\n",
      "[2025-11-20 03:23:16,789] [UniVITrainer] [INFO] [Epoch 010] Train loss: 896.8819 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:23:16 - INFO - [Epoch 010] Train loss: 896.8819 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:23:17,600] [UniVITrainer] [INFO] [Epoch 010] Val loss: 893.7670 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:23:17 - INFO - [Epoch 010] Val loss: 893.7670 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:23:17,766] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 893.7670\n",
      "2025-11-20 03:23:17 - INFO - [Epoch 010] New best val loss: 893.7670\n",
      "[2025-11-20 03:23:25,527] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 887.0842\n",
      "2025-11-20 03:23:25 - INFO - [Epoch 011] New best val loss: 887.0842\n",
      "[2025-11-20 03:23:33,078] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 873.7285\n",
      "2025-11-20 03:23:33 - INFO - [Epoch 012] New best val loss: 873.7285\n",
      "[2025-11-20 03:23:40,807] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 870.3566\n",
      "2025-11-20 03:23:40 - INFO - [Epoch 013] New best val loss: 870.3566\n",
      "[2025-11-20 03:23:48,457] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 854.1083\n",
      "2025-11-20 03:23:48 - INFO - [Epoch 014] New best val loss: 854.1083\n",
      "[2025-11-20 03:23:56,160] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 853.4023\n",
      "2025-11-20 03:23:56 - INFO - [Epoch 015] New best val loss: 853.4023\n",
      "[2025-11-20 03:24:03,888] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 841.2471\n",
      "2025-11-20 03:24:03 - INFO - [Epoch 016] New best val loss: 841.2471\n",
      "[2025-11-20 03:24:11,594] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 839.5412\n",
      "2025-11-20 03:24:11 - INFO - [Epoch 017] New best val loss: 839.5412\n",
      "[2025-11-20 03:24:19,363] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 836.4762\n",
      "2025-11-20 03:24:19 - INFO - [Epoch 018] New best val loss: 836.4762\n",
      "[2025-11-20 03:24:26,047] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 832.3160\n",
      "2025-11-20 03:24:26 - INFO - [Epoch 019] New best val loss: 832.3160\n",
      "[2025-11-20 03:24:32,844] [UniVITrainer] [INFO] [Epoch 020] Train loss: 822.1723 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:24:32 - INFO - [Epoch 020] Train loss: 822.1723 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:24:33,656] [UniVITrainer] [INFO] [Epoch 020] Val loss: 828.2122 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:24:33 - INFO - [Epoch 020] Val loss: 828.2122 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:24:33,688] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 828.2122\n",
      "2025-11-20 03:24:33 - INFO - [Epoch 020] New best val loss: 828.2122\n",
      "[2025-11-20 03:24:40,726] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 824.2916\n",
      "2025-11-20 03:24:40 - INFO - [Epoch 021] New best val loss: 824.2916\n",
      "[2025-11-20 03:24:47,691] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 818.4133\n",
      "2025-11-20 03:24:47 - INFO - [Epoch 022] New best val loss: 818.4133\n",
      "[2025-11-20 03:24:53,545] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 815.5770\n",
      "2025-11-20 03:24:53 - INFO - [Epoch 023] New best val loss: 815.5770\n",
      "[2025-11-20 03:25:04,545] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 813.6919\n",
      "2025-11-20 03:25:04 - INFO - [Epoch 025] New best val loss: 813.6919\n",
      "[2025-11-20 03:25:12,103] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 809.2664\n",
      "2025-11-20 03:25:12 - INFO - [Epoch 026] New best val loss: 809.2664\n",
      "[2025-11-20 03:25:19,402] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 803.9235\n",
      "2025-11-20 03:25:19 - INFO - [Epoch 027] New best val loss: 803.9235\n",
      "[2025-11-20 03:25:39,909] [UniVITrainer] [INFO] [Epoch 030] Train loss: 796.6229 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:25:39 - INFO - [Epoch 030] Train loss: 796.6229 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:25:40,691] [UniVITrainer] [INFO] [Epoch 030] Val loss: 802.2250 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:25:40 - INFO - [Epoch 030] Val loss: 802.2250 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:25:40,726] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 802.2250\n",
      "2025-11-20 03:25:40 - INFO - [Epoch 030] New best val loss: 802.2250\n",
      "[2025-11-20 03:25:47,850] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 801.1498\n",
      "2025-11-20 03:25:47 - INFO - [Epoch 031] New best val loss: 801.1498\n",
      "[2025-11-20 03:25:55,300] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 800.0700\n",
      "2025-11-20 03:25:55 - INFO - [Epoch 032] New best val loss: 800.0700\n",
      "[2025-11-20 03:26:02,469] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 796.5107\n",
      "2025-11-20 03:26:02 - INFO - [Epoch 033] New best val loss: 796.5107\n",
      "[2025-11-20 03:26:09,358] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 795.8657\n",
      "2025-11-20 03:26:09 - INFO - [Epoch 034] New best val loss: 795.8657\n",
      "[2025-11-20 03:26:15,056] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 793.6276\n",
      "2025-11-20 03:26:15 - INFO - [Epoch 035] New best val loss: 793.6276\n",
      "[2025-11-20 03:26:37,319] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 791.2908\n",
      "2025-11-20 03:26:37 - INFO - [Epoch 038] New best val loss: 791.2908\n",
      "[2025-11-20 03:26:44,484] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 789.7471\n",
      "2025-11-20 03:26:44 - INFO - [Epoch 039] New best val loss: 789.7471\n",
      "[2025-11-20 03:26:49,479] [UniVITrainer] [INFO] [Epoch 040] Train loss: 788.5937 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:26:49 - INFO - [Epoch 040] Train loss: 788.5937 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:26:50,314] [UniVITrainer] [INFO] [Epoch 040] Val loss: 789.2514 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:26:50 - INFO - [Epoch 040] Val loss: 789.2514 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:26:50,354] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 789.2514\n",
      "2025-11-20 03:26:50 - INFO - [Epoch 040] New best val loss: 789.2514\n",
      "[2025-11-20 03:26:57,757] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 788.8809\n",
      "2025-11-20 03:26:57 - INFO - [Epoch 041] New best val loss: 788.8809\n",
      "[2025-11-20 03:27:20,956] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 787.0609\n",
      "2025-11-20 03:27:20 - INFO - [Epoch 044] New best val loss: 787.0609\n",
      "[2025-11-20 03:27:36,313] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 786.7682\n",
      "2025-11-20 03:27:36 - INFO - [Epoch 046] New best val loss: 786.7682\n",
      "[2025-11-20 03:27:43,878] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 785.2324\n",
      "2025-11-20 03:27:43 - INFO - [Epoch 047] New best val loss: 785.2324\n",
      "[2025-11-20 03:27:59,216] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 784.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 03:27:59 - INFO - [Epoch 049] New best val loss: 784.0862\n",
      "[2025-11-20 03:28:05,882] [UniVITrainer] [INFO] [Epoch 050] Train loss: 781.0376 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:28:05 - INFO - [Epoch 050] Train loss: 781.0376 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:28:06,690] [UniVITrainer] [INFO] [Epoch 050] Val loss: 785.4004 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:28:06 - INFO - [Epoch 050] Val loss: 785.4004 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:28:22,215] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 783.0244\n",
      "2025-11-20 03:28:22 - INFO - [Epoch 052] New best val loss: 783.0244\n",
      "[2025-11-20 03:28:37,643] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 781.1301\n",
      "2025-11-20 03:28:37 - INFO - [Epoch 054] New best val loss: 781.1301\n",
      "[2025-11-20 03:29:00,850] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 780.1903\n",
      "2025-11-20 03:29:00 - INFO - [Epoch 057] New best val loss: 780.1903\n",
      "[2025-11-20 03:29:21,858] [UniVITrainer] [INFO] [Epoch 060] Train loss: 777.8832 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:29:21 - INFO - [Epoch 060] Train loss: 777.8832 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:29:22,685] [UniVITrainer] [INFO] [Epoch 060] Val loss: 781.0947 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:29:22 - INFO - [Epoch 060] Val loss: 781.0947 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:29:30,302] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 779.5958\n",
      "2025-11-20 03:29:30 - INFO - [Epoch 061] New best val loss: 779.5958\n",
      "[2025-11-20 03:29:38,259] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 778.9147\n",
      "2025-11-20 03:29:38 - INFO - [Epoch 062] New best val loss: 778.9147\n",
      "[2025-11-20 03:29:44,813] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 778.7740\n",
      "2025-11-20 03:29:44 - INFO - [Epoch 063] New best val loss: 778.7740\n",
      "[2025-11-20 03:29:52,618] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 778.6384\n",
      "2025-11-20 03:29:52 - INFO - [Epoch 064] New best val loss: 778.6384\n",
      "[2025-11-20 03:30:08,262] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 777.7217\n",
      "2025-11-20 03:30:08 - INFO - [Epoch 066] New best val loss: 777.7217\n",
      "[2025-11-20 03:30:23,971] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 777.4087\n",
      "2025-11-20 03:30:23 - INFO - [Epoch 068] New best val loss: 777.4087\n",
      "[2025-11-20 03:30:38,142] [UniVITrainer] [INFO] [Epoch 070] Train loss: 775.8057 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:30:38 - INFO - [Epoch 070] Train loss: 775.8057 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:30:38,982] [UniVITrainer] [INFO] [Epoch 070] Val loss: 777.1325 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:30:38 - INFO - [Epoch 070] Val loss: 777.1325 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:30:39,136] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 777.1325\n",
      "2025-11-20 03:30:39 - INFO - [Epoch 070] New best val loss: 777.1325\n",
      "[2025-11-20 03:30:46,990] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 777.0546\n",
      "2025-11-20 03:30:46 - INFO - [Epoch 071] New best val loss: 777.0546\n",
      "[2025-11-20 03:31:02,679] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 776.2009\n",
      "2025-11-20 03:31:02 - INFO - [Epoch 073] New best val loss: 776.2009\n",
      "[2025-11-20 03:31:18,168] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 776.0006\n",
      "2025-11-20 03:31:18 - INFO - [Epoch 075] New best val loss: 776.0006\n",
      "[2025-11-20 03:31:39,193] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 775.9404\n",
      "2025-11-20 03:31:39 - INFO - [Epoch 078] New best val loss: 775.9404\n",
      "[2025-11-20 03:31:52,334] [UniVITrainer] [INFO] [Epoch 080] Train loss: 774.5053 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:31:52 - INFO - [Epoch 080] Train loss: 774.5053 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:31:53,146] [UniVITrainer] [INFO] [Epoch 080] Val loss: 778.7585 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:31:53 - INFO - [Epoch 080] Val loss: 778.7585 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:32:20,110] [UniVITrainer] [INFO] [Epoch 084] New best val loss: 775.6233\n",
      "2025-11-20 03:32:20 - INFO - [Epoch 084] New best val loss: 775.6233\n",
      "[2025-11-20 03:32:34,841] [UniVITrainer] [INFO] [Epoch 086] New best val loss: 774.5996\n",
      "2025-11-20 03:32:34 - INFO - [Epoch 086] New best val loss: 774.5996\n",
      "[2025-11-20 03:32:42,690] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 774.2697\n",
      "2025-11-20 03:32:42 - INFO - [Epoch 087] New best val loss: 774.2697\n",
      "[2025-11-20 03:33:03,563] [UniVITrainer] [INFO] [Epoch 090] Train loss: 772.0572 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:33:03 - INFO - [Epoch 090] Train loss: 772.0572 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:33:04,363] [UniVITrainer] [INFO] [Epoch 090] Val loss: 775.2988 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:33:04 - INFO - [Epoch 090] Val loss: 775.2988 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:33:47,481] [UniVITrainer] [INFO] [Epoch 096] New best val loss: 774.0706\n",
      "2025-11-20 03:33:47 - INFO - [Epoch 096] New best val loss: 774.0706\n",
      "[2025-11-20 03:34:12,726] [UniVITrainer] [INFO] [Epoch 100] Train loss: 771.8489 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:34:12 - INFO - [Epoch 100] Train loss: 771.8489 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:34:13,539] [UniVITrainer] [INFO] [Epoch 100] Val loss: 775.9597 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:34:13 - INFO - [Epoch 100] Val loss: 775.9597 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:34:50,649] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 773.2814\n",
      "2025-11-20 03:34:50 - INFO - [Epoch 105] New best val loss: 773.2814\n",
      "[2025-11-20 03:35:26,781] [UniVITrainer] [INFO] [Epoch 110] Train loss: 773.5035 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:35:26 - INFO - [Epoch 110] Train loss: 773.5035 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:35:27,593] [UniVITrainer] [INFO] [Epoch 110] Val loss: 773.7665 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:35:27 - INFO - [Epoch 110] Val loss: 773.7665 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:36:03,075] [UniVITrainer] [INFO] [Epoch 115] New best val loss: 772.6460\n",
      "2025-11-20 03:36:03 - INFO - [Epoch 115] New best val loss: 772.6460\n",
      "[2025-11-20 03:36:17,734] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 772.4898\n",
      "2025-11-20 03:36:17 - INFO - [Epoch 117] New best val loss: 772.4898\n",
      "[2025-11-20 03:36:25,510] [UniVITrainer] [INFO] [Epoch 118] New best val loss: 771.9584\n",
      "2025-11-20 03:36:25 - INFO - [Epoch 118] New best val loss: 771.9584\n",
      "[2025-11-20 03:36:39,851] [UniVITrainer] [INFO] [Epoch 120] Train loss: 774.1536 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:36:39 - INFO - [Epoch 120] Train loss: 774.1536 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:36:40,654] [UniVITrainer] [INFO] [Epoch 120] Val loss: 772.5121 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:36:40 - INFO - [Epoch 120] Val loss: 772.5121 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:37:17,535] [UniVITrainer] [INFO] [Epoch 125] New best val loss: 771.9217\n",
      "2025-11-20 03:37:17 - INFO - [Epoch 125] New best val loss: 771.9217\n",
      "[2025-11-20 03:37:40,277] [UniVITrainer] [INFO] [Epoch 128] New best val loss: 771.6927\n",
      "2025-11-20 03:37:40 - INFO - [Epoch 128] New best val loss: 771.6927\n",
      "[2025-11-20 03:37:52,728] [UniVITrainer] [INFO] [Epoch 130] Train loss: 772.2913 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:37:52 - INFO - [Epoch 130] Train loss: 772.2913 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:37:53,538] [UniVITrainer] [INFO] [Epoch 130] Val loss: 772.6647 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:37:53 - INFO - [Epoch 130] Val loss: 772.6647 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:38:36,183] [UniVITrainer] [INFO] [Epoch 136] New best val loss: 771.1502\n",
      "2025-11-20 03:38:36 - INFO - [Epoch 136] New best val loss: 771.1502\n",
      "[2025-11-20 03:39:03,940] [UniVITrainer] [INFO] [Epoch 140] Train loss: 767.1718 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:39:03 - INFO - [Epoch 140] Train loss: 767.1718 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:39:04,775] [UniVITrainer] [INFO] [Epoch 140] Val loss: 772.1950 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:39:04 - INFO - [Epoch 140] Val loss: 772.1950 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:39:18,358] [UniVITrainer] [INFO] [Epoch 142] New best val loss: 771.0361\n",
      "2025-11-20 03:39:18 - INFO - [Epoch 142] New best val loss: 771.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 03:39:32,413] [UniVITrainer] [INFO] [Epoch 144] New best val loss: 770.8977\n",
      "2025-11-20 03:39:32 - INFO - [Epoch 144] New best val loss: 770.8977\n",
      "[2025-11-20 03:40:17,090] [UniVITrainer] [INFO] [Epoch 150] Train loss: 771.1219 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:40:17 - INFO - [Epoch 150] Train loss: 771.1219 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:40:17,961] [UniVITrainer] [INFO] [Epoch 150] Val loss: 773.0557 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:40:17 - INFO - [Epoch 150] Val loss: 773.0557 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:41:31,574] [UniVITrainer] [INFO] [Epoch 160] Train loss: 773.2674 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:41:31 - INFO - [Epoch 160] Train loss: 773.2674 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:41:32,406] [UniVITrainer] [INFO] [Epoch 160] Val loss: 771.4453 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:41:32 - INFO - [Epoch 160] Val loss: 771.4453 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:41:55,136] [UniVITrainer] [INFO] [Epoch 163] New best val loss: 769.7234\n",
      "2025-11-20 03:41:55 - INFO - [Epoch 163] New best val loss: 769.7234\n",
      "[2025-11-20 03:42:48,330] [UniVITrainer] [INFO] [Epoch 170] Train loss: 771.9012 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:42:48 - INFO - [Epoch 170] Train loss: 771.9012 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:42:49,162] [UniVITrainer] [INFO] [Epoch 170] Val loss: 771.3629 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:42:49 - INFO - [Epoch 170] Val loss: 771.3629 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:44:01,143] [UniVITrainer] [INFO] [Epoch 180] Train loss: 769.5271 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:44:01 - INFO - [Epoch 180] Train loss: 769.5271 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:44:01,974] [UniVITrainer] [INFO] [Epoch 180] Val loss: 771.2164 (beta=100.000, gamma=1000.000)\n",
      "2025-11-20 03:44:01 - INFO - [Epoch 180] Val loss: 771.2164 (beta=100.000, gamma=1000.000)\n",
      "[2025-11-20 03:44:24,850] [UniVITrainer] [INFO] Early stopping at epoch 183 (best val loss = 769.7234)\n",
      "2025-11-20 03:44:24 - INFO - Early stopping at epoch 183 (best val loss = 769.7234)\n",
      "[2025-11-20 03:44:24,904] [UniVITrainer] [INFO] Restored best model from epoch 163 (val loss = 769.7234)\n",
      "2025-11-20 03:44:24 - INFO - Restored best model from epoch 163 (val loss = 769.7234)\n",
      "[2025-11-20 03:44:26,895] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 03:44:26 - INFO - TrainingConfig:\n",
      "[2025-11-20 03:44:26,897] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 03:44:26 - INFO -   n_epochs: 200\n",
      "[2025-11-20 03:44:26,900] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 03:44:26 - INFO -   batch_size: 256\n",
      "[2025-11-20 03:44:26,902] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 03:44:26 - INFO -   lr: 0.001\n",
      "[2025-11-20 03:44:26,904] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 03:44:26 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 03:44:26,908] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 03:44:26 - INFO -   device: cuda\n",
      "[2025-11-20 03:44:26,912] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 03:44:26 - INFO -   log_every: 10\n",
      "[2025-11-20 03:44:26,914] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 03:44:26 - INFO -   grad_clip: None\n",
      "[2025-11-20 03:44:26,917] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 03:44:26 - INFO -   num_workers: 0\n",
      "[2025-11-20 03:44:26,921] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 03:44:26 - INFO -   seed: 42\n",
      "[2025-11-20 03:44:26,922] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 03:44:26 - INFO -   early_stopping: True\n",
      "[2025-11-20 03:44:26,924] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 03:44:26 - INFO -   patience: 20\n",
      "[2025-11-20 03:44:26,925] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 03:44:26 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 13] Done in 22.4 min\n",
      "  best_val_loss              = 769.723\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5518\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4869\n",
      "[Config 13] FOSCTTM (ADT vs ATAC, val) = 0.4775\n",
      "  Mean FOSCTTM (3 pairs)     = 0.5054\n",
      "  Modality mixing (k=20)     = 0.0162\n",
      "  Composite score            = 1177.45\n",
      "\n",
      "================================================================================\n",
      "[Config 14] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 156,\n",
      "  \"beta\": 300.0,\n",
      "  \"gamma\": 500.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_small2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5d563388914b5b8587025a6ce5bbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 03:44:33,582] [UniVITrainer] [INFO] [Epoch 001] Train loss: 15461.9050 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:44:33 - INFO - [Epoch 001] Train loss: 15461.9050 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:44:34,257] [UniVITrainer] [INFO] [Epoch 001] Val loss: 3330.2022 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:44:34 - INFO - [Epoch 001] Val loss: 3330.2022 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:44:34,424] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 3330.2022\n",
      "2025-11-20 03:44:34 - INFO - [Epoch 001] New best val loss: 3330.2022\n",
      "[2025-11-20 03:44:41,998] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1729.6381\n",
      "2025-11-20 03:44:41 - INFO - [Epoch 002] New best val loss: 1729.6381\n",
      "[2025-11-20 03:44:49,576] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1366.0947\n",
      "2025-11-20 03:44:49 - INFO - [Epoch 003] New best val loss: 1366.0947\n",
      "[2025-11-20 03:44:57,037] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 1210.5511\n",
      "2025-11-20 03:44:57 - INFO - [Epoch 004] New best val loss: 1210.5511\n",
      "[2025-11-20 03:45:04,862] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 1096.5523\n",
      "2025-11-20 03:45:04 - INFO - [Epoch 005] New best val loss: 1096.5523\n",
      "[2025-11-20 03:45:12,757] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 1047.7862\n",
      "2025-11-20 03:45:12 - INFO - [Epoch 006] New best val loss: 1047.7862\n",
      "[2025-11-20 03:45:19,109] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 1005.5607\n",
      "2025-11-20 03:45:19 - INFO - [Epoch 007] New best val loss: 1005.5607\n",
      "[2025-11-20 03:45:26,564] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 958.7574\n",
      "2025-11-20 03:45:26 - INFO - [Epoch 008] New best val loss: 958.7574\n",
      "[2025-11-20 03:45:32,850] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 949.6956\n",
      "2025-11-20 03:45:32 - INFO - [Epoch 009] New best val loss: 949.6956\n",
      "[2025-11-20 03:45:39,437] [UniVITrainer] [INFO] [Epoch 010] Train loss: 1269.4424 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:45:39 - INFO - [Epoch 010] Train loss: 1269.4424 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:45:40,242] [UniVITrainer] [INFO] [Epoch 010] Val loss: 907.6133 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:45:40 - INFO - [Epoch 010] Val loss: 907.6133 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:45:40,486] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 907.6133\n",
      "2025-11-20 03:45:40 - INFO - [Epoch 010] New best val loss: 907.6133\n",
      "[2025-11-20 03:45:47,665] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 887.6710\n",
      "2025-11-20 03:45:47 - INFO - [Epoch 011] New best val loss: 887.6710\n",
      "[2025-11-20 03:45:55,294] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 884.0865\n",
      "2025-11-20 03:45:55 - INFO - [Epoch 012] New best val loss: 884.0865\n",
      "[2025-11-20 03:46:03,008] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 853.0723\n",
      "2025-11-20 03:46:03 - INFO - [Epoch 013] New best val loss: 853.0723\n",
      "[2025-11-20 03:46:10,278] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 841.5746\n",
      "2025-11-20 03:46:10 - INFO - [Epoch 014] New best val loss: 841.5746\n",
      "[2025-11-20 03:46:17,833] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 837.6991\n",
      "2025-11-20 03:46:17 - INFO - [Epoch 015] New best val loss: 837.6991\n",
      "[2025-11-20 03:46:25,596] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 826.8078\n",
      "2025-11-20 03:46:25 - INFO - [Epoch 016] New best val loss: 826.8078\n",
      "[2025-11-20 03:46:31,599] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 815.9374\n",
      "2025-11-20 03:46:31 - INFO - [Epoch 017] New best val loss: 815.9374\n",
      "[2025-11-20 03:46:39,408] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 809.6287\n",
      "2025-11-20 03:46:39 - INFO - [Epoch 018] New best val loss: 809.6287\n",
      "[2025-11-20 03:46:47,025] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 807.1440\n",
      "2025-11-20 03:46:47 - INFO - [Epoch 019] New best val loss: 807.1440\n",
      "[2025-11-20 03:46:53,116] [UniVITrainer] [INFO] [Epoch 020] Train loss: 932.7781 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:46:53 - INFO - [Epoch 020] Train loss: 932.7781 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:46:53,934] [UniVITrainer] [INFO] [Epoch 020] Val loss: 804.2668 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:46:53 - INFO - [Epoch 020] Val loss: 804.2668 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:46:54,096] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 804.2668\n",
      "2025-11-20 03:46:54 - INFO - [Epoch 020] New best val loss: 804.2668\n",
      "[2025-11-20 03:47:01,849] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 796.2678\n",
      "2025-11-20 03:47:01 - INFO - [Epoch 021] New best val loss: 796.2678\n",
      "[2025-11-20 03:47:24,362] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 793.4883\n",
      "2025-11-20 03:47:24 - INFO - [Epoch 024] New best val loss: 793.4883\n",
      "[2025-11-20 03:47:31,986] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 790.0812\n",
      "2025-11-20 03:47:31 - INFO - [Epoch 025] New best val loss: 790.0812\n",
      "[2025-11-20 03:47:47,185] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 786.4718\n",
      "2025-11-20 03:47:47 - INFO - [Epoch 027] New best val loss: 786.4718\n",
      "[2025-11-20 03:47:54,739] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 784.4547\n",
      "2025-11-20 03:47:54 - INFO - [Epoch 028] New best val loss: 784.4547\n",
      "[2025-11-20 03:48:09,050] [UniVITrainer] [INFO] [Epoch 030] Train loss: 837.7085 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:48:09 - INFO - [Epoch 030] Train loss: 837.7085 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:48:09,869] [UniVITrainer] [INFO] [Epoch 030] Val loss: 783.1860 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:48:09 - INFO - [Epoch 030] Val loss: 783.1860 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:48:09,917] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 783.1860\n",
      "2025-11-20 03:48:09 - INFO - [Epoch 030] New best val loss: 783.1860\n",
      "[2025-11-20 03:48:17,622] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 781.7566\n",
      "2025-11-20 03:48:17 - INFO - [Epoch 031] New best val loss: 781.7566\n",
      "[2025-11-20 03:48:32,433] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 779.8914\n",
      "2025-11-20 03:48:32 - INFO - [Epoch 033] New best val loss: 779.8914\n",
      "[2025-11-20 03:48:40,175] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 779.4462\n",
      "2025-11-20 03:48:40 - INFO - [Epoch 034] New best val loss: 779.4462\n",
      "[2025-11-20 03:48:55,253] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 777.4695\n",
      "2025-11-20 03:48:55 - INFO - [Epoch 036] New best val loss: 777.4695\n",
      "[2025-11-20 03:49:02,836] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 777.2476\n",
      "2025-11-20 03:49:02 - INFO - [Epoch 037] New best val loss: 777.2476\n",
      "[2025-11-20 03:49:17,647] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 776.4592\n",
      "2025-11-20 03:49:17 - INFO - [Epoch 039] New best val loss: 776.4592\n",
      "[2025-11-20 03:49:24,426] [UniVITrainer] [INFO] [Epoch 040] Train loss: 818.5300 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:49:24 - INFO - [Epoch 040] Train loss: 818.5300 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:49:25,241] [UniVITrainer] [INFO] [Epoch 040] Val loss: 777.6056 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:49:25 - INFO - [Epoch 040] Val loss: 777.6056 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:49:40,512] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 775.9910\n",
      "2025-11-20 03:49:40 - INFO - [Epoch 042] New best val loss: 775.9910\n",
      "[2025-11-20 03:49:48,271] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 775.7140\n",
      "2025-11-20 03:49:48 - INFO - [Epoch 043] New best val loss: 775.7140\n",
      "[2025-11-20 03:50:11,113] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 773.7002\n",
      "2025-11-20 03:50:11 - INFO - [Epoch 046] New best val loss: 773.7002\n",
      "[2025-11-20 03:50:39,569] [UniVITrainer] [INFO] [Epoch 050] Train loss: 796.1353 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:50:39 - INFO - [Epoch 050] Train loss: 796.1353 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:50:40,379] [UniVITrainer] [INFO] [Epoch 050] Val loss: 773.9246 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:50:40 - INFO - [Epoch 050] Val loss: 773.9246 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:50:54,605] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 772.6613\n",
      "2025-11-20 03:50:54 - INFO - [Epoch 052] New best val loss: 772.6613\n",
      "[2025-11-20 03:51:02,057] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 772.1273\n",
      "2025-11-20 03:51:02 - INFO - [Epoch 053] New best val loss: 772.1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 03:51:08,903] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 771.7796\n",
      "2025-11-20 03:51:08 - INFO - [Epoch 054] New best val loss: 771.7796\n",
      "[2025-11-20 03:51:36,079] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 771.7263\n",
      "2025-11-20 03:51:36 - INFO - [Epoch 058] New best val loss: 771.7263\n",
      "[2025-11-20 03:51:48,501] [UniVITrainer] [INFO] [Epoch 060] Train loss: 781.7937 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:51:48 - INFO - [Epoch 060] Train loss: 781.7937 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:51:49,182] [UniVITrainer] [INFO] [Epoch 060] Val loss: 771.5208 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:51:49 - INFO - [Epoch 060] Val loss: 771.5208 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:51:49,348] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 771.5208\n",
      "2025-11-20 03:51:49 - INFO - [Epoch 060] New best val loss: 771.5208\n",
      "[2025-11-20 03:51:56,843] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 771.5095\n",
      "2025-11-20 03:51:56 - INFO - [Epoch 061] New best val loss: 771.5095\n",
      "[2025-11-20 03:52:10,442] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 770.9056\n",
      "2025-11-20 03:52:10 - INFO - [Epoch 063] New best val loss: 770.9056\n",
      "[2025-11-20 03:52:32,608] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 770.4839\n",
      "2025-11-20 03:52:32 - INFO - [Epoch 066] New best val loss: 770.4839\n",
      "[2025-11-20 03:52:40,171] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 770.1445\n",
      "2025-11-20 03:52:40 - INFO - [Epoch 067] New best val loss: 770.1445\n",
      "[2025-11-20 03:52:46,840] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 769.8472\n",
      "2025-11-20 03:52:46 - INFO - [Epoch 068] New best val loss: 769.8472\n",
      "[2025-11-20 03:53:01,106] [UniVITrainer] [INFO] [Epoch 070] Train loss: 775.7310 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:53:01 - INFO - [Epoch 070] Train loss: 775.7310 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:53:01,911] [UniVITrainer] [INFO] [Epoch 070] Val loss: 770.4158 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:53:01 - INFO - [Epoch 070] Val loss: 770.4158 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:53:30,341] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 769.7837\n",
      "2025-11-20 03:53:30 - INFO - [Epoch 074] New best val loss: 769.7837\n",
      "[2025-11-20 03:53:35,388] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 769.4900\n",
      "2025-11-20 03:53:35 - INFO - [Epoch 075] New best val loss: 769.4900\n",
      "[2025-11-20 03:53:57,362] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 769.4160\n",
      "2025-11-20 03:53:57 - INFO - [Epoch 078] New best val loss: 769.4160\n",
      "[2025-11-20 03:54:04,810] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 769.2931\n",
      "2025-11-20 03:54:04 - INFO - [Epoch 079] New best val loss: 769.2931\n",
      "[2025-11-20 03:54:11,335] [UniVITrainer] [INFO] [Epoch 080] Train loss: 778.7754 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:54:11 - INFO - [Epoch 080] Train loss: 778.7754 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:54:12,126] [UniVITrainer] [INFO] [Epoch 080] Val loss: 769.5338 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:54:12 - INFO - [Epoch 080] Val loss: 769.5338 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:54:27,036] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 769.0451\n",
      "2025-11-20 03:54:27 - INFO - [Epoch 082] New best val loss: 769.0451\n",
      "[2025-11-20 03:54:48,145] [UniVITrainer] [INFO] [Epoch 085] New best val loss: 768.7432\n",
      "2025-11-20 03:54:48 - INFO - [Epoch 085] New best val loss: 768.7432\n",
      "[2025-11-20 03:55:01,327] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 768.5522\n",
      "2025-11-20 03:55:01 - INFO - [Epoch 087] New best val loss: 768.5522\n",
      "[2025-11-20 03:55:15,569] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 768.5211\n",
      "2025-11-20 03:55:15 - INFO - [Epoch 089] New best val loss: 768.5211\n",
      "[2025-11-20 03:55:22,255] [UniVITrainer] [INFO] [Epoch 090] Train loss: 773.9095 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:55:22 - INFO - [Epoch 090] Train loss: 773.9095 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:55:23,041] [UniVITrainer] [INFO] [Epoch 090] Val loss: 770.0300 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:55:23 - INFO - [Epoch 090] Val loss: 770.0300 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:55:59,935] [UniVITrainer] [INFO] [Epoch 095] New best val loss: 768.4009\n",
      "2025-11-20 03:55:59 - INFO - [Epoch 095] New best val loss: 768.4009\n",
      "[2025-11-20 03:56:14,939] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 768.1452\n",
      "2025-11-20 03:56:14 - INFO - [Epoch 097] New best val loss: 768.1452\n",
      "[2025-11-20 03:56:30,112] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 768.0046\n",
      "2025-11-20 03:56:30 - INFO - [Epoch 099] New best val loss: 768.0046\n",
      "[2025-11-20 03:56:36,638] [UniVITrainer] [INFO] [Epoch 100] Train loss: 772.8657 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:56:36 - INFO - [Epoch 100] Train loss: 772.8657 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:56:37,445] [UniVITrainer] [INFO] [Epoch 100] Val loss: 768.5863 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:56:37 - INFO - [Epoch 100] Val loss: 768.5863 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:57:12,750] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 767.9143\n",
      "2025-11-20 03:57:12 - INFO - [Epoch 105] New best val loss: 767.9143\n",
      "[2025-11-20 03:57:47,757] [UniVITrainer] [INFO] [Epoch 110] Train loss: 768.9331 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:57:47 - INFO - [Epoch 110] Train loss: 768.9331 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:57:48,571] [UniVITrainer] [INFO] [Epoch 110] Val loss: 768.5992 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:57:48 - INFO - [Epoch 110] Val loss: 768.5992 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:58:08,687] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 767.7056\n",
      "2025-11-20 03:58:08 - INFO - [Epoch 113] New best val loss: 767.7056\n",
      "[2025-11-20 03:58:23,382] [UniVITrainer] [INFO] [Epoch 115] New best val loss: 767.5331\n",
      "2025-11-20 03:58:23 - INFO - [Epoch 115] New best val loss: 767.5331\n",
      "[2025-11-20 03:58:58,828] [UniVITrainer] [INFO] [Epoch 120] Train loss: 769.1831 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:58:58 - INFO - [Epoch 120] Train loss: 769.1831 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:58:59,656] [UniVITrainer] [INFO] [Epoch 120] Val loss: 767.7158 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 03:58:59 - INFO - [Epoch 120] Val loss: 767.7158 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 03:59:07,410] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 767.3197\n",
      "2025-11-20 03:59:07 - INFO - [Epoch 121] New best val loss: 767.3197\n",
      "[2025-11-20 04:00:06,254] [UniVITrainer] [INFO] [Epoch 129] New best val loss: 767.2324\n",
      "2025-11-20 04:00:06 - INFO - [Epoch 129] New best val loss: 767.2324\n",
      "[2025-11-20 04:00:13,038] [UniVITrainer] [INFO] [Epoch 130] Train loss: 768.0364 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 04:00:13 - INFO - [Epoch 130] Train loss: 768.0364 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 04:00:13,543] [UniVITrainer] [INFO] [Epoch 130] Val loss: 767.3685 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 04:00:13 - INFO - [Epoch 130] Val loss: 767.3685 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 04:00:58,168] [UniVITrainer] [INFO] [Epoch 136] New best val loss: 767.1382\n",
      "2025-11-20 04:00:58 - INFO - [Epoch 136] New best val loss: 767.1382\n",
      "[2025-11-20 04:01:27,393] [UniVITrainer] [INFO] [Epoch 140] Train loss: 770.7079 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 04:01:27 - INFO - [Epoch 140] Train loss: 770.7079 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 04:01:28,212] [UniVITrainer] [INFO] [Epoch 140] Val loss: 767.7440 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 04:01:28 - INFO - [Epoch 140] Val loss: 767.7440 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 04:02:19,706] [UniVITrainer] [INFO] [Epoch 147] New best val loss: 767.1181\n",
      "2025-11-20 04:02:19 - INFO - [Epoch 147] New best val loss: 767.1181\n",
      "[2025-11-20 04:02:27,464] [UniVITrainer] [INFO] [Epoch 148] New best val loss: 767.0813\n",
      "2025-11-20 04:02:27 - INFO - [Epoch 148] New best val loss: 767.0813\n",
      "[2025-11-20 04:02:41,534] [UniVITrainer] [INFO] [Epoch 150] Train loss: 767.3257 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 04:02:41 - INFO - [Epoch 150] Train loss: 767.3257 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 04:02:42,353] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.9038 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 04:02:42 - INFO - [Epoch 150] Val loss: 766.9038 (beta=300.000, gamma=500.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 04:02:42,388] [UniVITrainer] [INFO] [Epoch 150] New best val loss: 766.9038\n",
      "2025-11-20 04:02:42 - INFO - [Epoch 150] New best val loss: 766.9038\n",
      "[2025-11-20 04:02:49,996] [UniVITrainer] [INFO] [Epoch 151] New best val loss: 766.8493\n",
      "2025-11-20 04:02:49 - INFO - [Epoch 151] New best val loss: 766.8493\n",
      "[2025-11-20 04:03:54,806] [UniVITrainer] [INFO] [Epoch 160] Train loss: 766.8905 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 04:03:54 - INFO - [Epoch 160] Train loss: 766.8905 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 04:03:55,643] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.9240 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 04:03:55 - INFO - [Epoch 160] Val loss: 766.9240 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 04:05:04,543] [UniVITrainer] [INFO] [Epoch 170] Train loss: 766.8541 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 04:05:04 - INFO - [Epoch 170] Train loss: 766.8541 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 04:05:04,657] [UniVITrainer] [INFO] [Epoch 170] Val loss: 767.2031 (beta=300.000, gamma=500.000)\n",
      "2025-11-20 04:05:04 - INFO - [Epoch 170] Val loss: 767.2031 (beta=300.000, gamma=500.000)\n",
      "[2025-11-20 04:05:11,733] [UniVITrainer] [INFO] Early stopping at epoch 171 (best val loss = 766.8493)\n",
      "2025-11-20 04:05:11 - INFO - Early stopping at epoch 171 (best val loss = 766.8493)\n",
      "[2025-11-20 04:05:11,767] [UniVITrainer] [INFO] Restored best model from epoch 151 (val loss = 766.8493)\n",
      "2025-11-20 04:05:11 - INFO - Restored best model from epoch 151 (val loss = 766.8493)\n",
      "[2025-11-20 04:05:14,346] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 04:05:14 - INFO - TrainingConfig:\n",
      "[2025-11-20 04:05:14,349] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 04:05:14 - INFO -   n_epochs: 200\n",
      "[2025-11-20 04:05:14,356] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 04:05:14 - INFO -   batch_size: 256\n",
      "[2025-11-20 04:05:14,362] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 04:05:14 - INFO -   lr: 0.0005\n",
      "[2025-11-20 04:05:14,364] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 04:05:14 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 04:05:14,366] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 04:05:14 - INFO -   device: cuda\n",
      "[2025-11-20 04:05:14,367] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 04:05:14 - INFO -   log_every: 10\n",
      "[2025-11-20 04:05:14,369] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 04:05:14 - INFO -   grad_clip: None\n",
      "[2025-11-20 04:05:14,370] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 04:05:14 - INFO -   num_workers: 0\n",
      "[2025-11-20 04:05:14,371] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 04:05:14 - INFO -   seed: 42\n",
      "[2025-11-20 04:05:14,372] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 04:05:14 - INFO -   early_stopping: True\n",
      "[2025-11-20 04:05:14,374] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 04:05:14 - INFO -   patience: 20\n",
      "[2025-11-20 04:05:14,375] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 04:05:14 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 14] Done in 20.7 min\n",
      "  best_val_loss              = 766.849\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5376\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.0633\n",
      "[Config 14] FOSCTTM (ADT vs ATAC, val) = 0.0920\n",
      "  Mean FOSCTTM (3 pairs)     = 0.2310\n",
      "  Modality mixing (k=20)     = 0.0000\n",
      "  Composite score            = 943.96\n",
      "\n",
      "================================================================================\n",
      "[Config 15] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 72,\n",
      "  \"beta\": 240.0,\n",
      "  \"gamma\": 400.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.0,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb78ca130e4e47d48508b2d6fc72e9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 04:05:21,287] [UniVITrainer] [INFO] [Epoch 001] Train loss: 7574.5838 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:05:21 - INFO - [Epoch 001] Train loss: 7574.5838 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:05:22,119] [UniVITrainer] [INFO] [Epoch 001] Val loss: 3522.7370 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:05:22 - INFO - [Epoch 001] Val loss: 3522.7370 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:05:22,312] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 3522.7370\n",
      "2025-11-20 04:05:22 - INFO - [Epoch 001] New best val loss: 3522.7370\n",
      "[2025-11-20 04:05:30,029] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1886.8941\n",
      "2025-11-20 04:05:30 - INFO - [Epoch 002] New best val loss: 1886.8941\n",
      "[2025-11-20 04:05:37,867] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1306.4879\n",
      "2025-11-20 04:05:37 - INFO - [Epoch 003] New best val loss: 1306.4879\n",
      "[2025-11-20 04:05:45,586] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 1103.2411\n",
      "2025-11-20 04:05:45 - INFO - [Epoch 004] New best val loss: 1103.2411\n",
      "[2025-11-20 04:05:53,120] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 1012.9312\n",
      "2025-11-20 04:05:53 - INFO - [Epoch 005] New best val loss: 1012.9312\n",
      "[2025-11-20 04:06:01,011] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 967.4682\n",
      "2025-11-20 04:06:01 - INFO - [Epoch 006] New best val loss: 967.4682\n",
      "[2025-11-20 04:06:07,974] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 936.0128\n",
      "2025-11-20 04:06:07 - INFO - [Epoch 007] New best val loss: 936.0128\n",
      "[2025-11-20 04:06:15,819] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 912.5573\n",
      "2025-11-20 04:06:15 - INFO - [Epoch 008] New best val loss: 912.5573\n",
      "[2025-11-20 04:06:23,697] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 894.0342\n",
      "2025-11-20 04:06:23 - INFO - [Epoch 009] New best val loss: 894.0342\n",
      "[2025-11-20 04:06:30,229] [UniVITrainer] [INFO] [Epoch 010] Train loss: 879.2844 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:06:30 - INFO - [Epoch 010] Train loss: 879.2844 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:06:31,031] [UniVITrainer] [INFO] [Epoch 010] Val loss: 882.8391 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:06:31 - INFO - [Epoch 010] Val loss: 882.8391 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:06:31,067] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 882.8391\n",
      "2025-11-20 04:06:31 - INFO - [Epoch 010] New best val loss: 882.8391\n",
      "[2025-11-20 04:06:38,974] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 871.7475\n",
      "2025-11-20 04:06:38 - INFO - [Epoch 011] New best val loss: 871.7475\n",
      "[2025-11-20 04:06:46,839] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 862.4188\n",
      "2025-11-20 04:06:46 - INFO - [Epoch 012] New best val loss: 862.4188\n",
      "[2025-11-20 04:06:54,723] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 855.3000\n",
      "2025-11-20 04:06:54 - INFO - [Epoch 013] New best val loss: 855.3000\n",
      "[2025-11-20 04:07:02,463] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 848.0252\n",
      "2025-11-20 04:07:02 - INFO - [Epoch 014] New best val loss: 848.0252\n",
      "[2025-11-20 04:07:10,160] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 841.9478\n",
      "2025-11-20 04:07:10 - INFO - [Epoch 015] New best val loss: 841.9478\n",
      "[2025-11-20 04:07:17,486] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 838.1411\n",
      "2025-11-20 04:07:17 - INFO - [Epoch 016] New best val loss: 838.1411\n",
      "[2025-11-20 04:07:25,298] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 834.1326\n",
      "2025-11-20 04:07:25 - INFO - [Epoch 017] New best val loss: 834.1326\n",
      "[2025-11-20 04:07:32,180] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 831.1130\n",
      "2025-11-20 04:07:32 - INFO - [Epoch 018] New best val loss: 831.1130\n",
      "[2025-11-20 04:07:40,119] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 830.0785\n",
      "2025-11-20 04:07:40 - INFO - [Epoch 019] New best val loss: 830.0785\n",
      "[2025-11-20 04:07:46,895] [UniVITrainer] [INFO] [Epoch 020] Train loss: 815.0184 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:07:46 - INFO - [Epoch 020] Train loss: 815.0184 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:07:47,704] [UniVITrainer] [INFO] [Epoch 020] Val loss: 825.5880 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:07:47 - INFO - [Epoch 020] Val loss: 825.5880 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:07:47,857] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 825.5880\n",
      "2025-11-20 04:07:47 - INFO - [Epoch 020] New best val loss: 825.5880\n",
      "[2025-11-20 04:07:55,742] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 823.1396\n",
      "2025-11-20 04:07:55 - INFO - [Epoch 021] New best val loss: 823.1396\n",
      "[2025-11-20 04:08:11,096] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 819.6784\n",
      "2025-11-20 04:08:11 - INFO - [Epoch 023] New best val loss: 819.6784\n",
      "[2025-11-20 04:08:18,940] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 817.9961\n",
      "2025-11-20 04:08:18 - INFO - [Epoch 024] New best val loss: 817.9961\n",
      "[2025-11-20 04:08:26,832] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 815.5616\n",
      "2025-11-20 04:08:26 - INFO - [Epoch 025] New best val loss: 815.5616\n",
      "[2025-11-20 04:08:34,560] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 814.1715\n",
      "2025-11-20 04:08:34 - INFO - [Epoch 026] New best val loss: 814.1715\n",
      "[2025-11-20 04:08:42,389] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 814.1291\n",
      "2025-11-20 04:08:42 - INFO - [Epoch 027] New best val loss: 814.1291\n",
      "[2025-11-20 04:08:50,113] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 812.4734\n",
      "2025-11-20 04:08:50 - INFO - [Epoch 028] New best val loss: 812.4734\n",
      "[2025-11-20 04:09:03,441] [UniVITrainer] [INFO] [Epoch 030] Train loss: 795.7914 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:09:03 - INFO - [Epoch 030] Train loss: 795.7914 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:09:03,549] [UniVITrainer] [INFO] [Epoch 030] Val loss: 810.1227 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:09:03 - INFO - [Epoch 030] Val loss: 810.1227 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:09:03,741] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 810.1227\n",
      "2025-11-20 04:09:03 - INFO - [Epoch 030] New best val loss: 810.1227\n",
      "[2025-11-20 04:09:11,570] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 810.0581\n",
      "2025-11-20 04:09:11 - INFO - [Epoch 031] New best val loss: 810.0581\n",
      "[2025-11-20 04:09:19,480] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 808.7733\n",
      "2025-11-20 04:09:19 - INFO - [Epoch 032] New best val loss: 808.7733\n",
      "[2025-11-20 04:09:27,367] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 807.7658\n",
      "2025-11-20 04:09:27 - INFO - [Epoch 033] New best val loss: 807.7658\n",
      "[2025-11-20 04:09:34,663] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 806.6332\n",
      "2025-11-20 04:09:34 - INFO - [Epoch 034] New best val loss: 806.6332\n",
      "[2025-11-20 04:09:42,534] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 805.5444\n",
      "2025-11-20 04:09:42 - INFO - [Epoch 035] New best val loss: 805.5444\n",
      "[2025-11-20 04:09:50,293] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 805.0676\n",
      "2025-11-20 04:09:50 - INFO - [Epoch 036] New best val loss: 805.0676\n",
      "[2025-11-20 04:09:58,177] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 803.9416\n",
      "2025-11-20 04:09:58 - INFO - [Epoch 037] New best val loss: 803.9416\n",
      "[2025-11-20 04:10:05,870] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 803.0303\n",
      "2025-11-20 04:10:05 - INFO - [Epoch 038] New best val loss: 803.0303\n",
      "[2025-11-20 04:10:20,125] [UniVITrainer] [INFO] [Epoch 040] Train loss: 784.6032 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:10:20 - INFO - [Epoch 040] Train loss: 784.6032 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:10:20,959] [UniVITrainer] [INFO] [Epoch 040] Val loss: 806.0118 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:10:20 - INFO - [Epoch 040] Val loss: 806.0118 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:10:28,561] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 802.1648\n",
      "2025-11-20 04:10:28 - INFO - [Epoch 041] New best val loss: 802.1648\n",
      "[2025-11-20 04:10:34,807] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 801.0446\n",
      "2025-11-20 04:10:34 - INFO - [Epoch 042] New best val loss: 801.0446\n",
      "[2025-11-20 04:10:42,416] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 800.7255\n",
      "2025-11-20 04:10:42 - INFO - [Epoch 043] New best val loss: 800.7255\n",
      "[2025-11-20 04:10:49,725] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 800.6073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 04:10:49 - INFO - [Epoch 044] New best val loss: 800.6073\n",
      "[2025-11-20 04:10:57,438] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 799.4038\n",
      "2025-11-20 04:10:57 - INFO - [Epoch 045] New best val loss: 799.4038\n",
      "[2025-11-20 04:11:12,034] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 799.2847\n",
      "2025-11-20 04:11:12 - INFO - [Epoch 047] New best val loss: 799.2847\n",
      "[2025-11-20 04:11:19,412] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 798.4652\n",
      "2025-11-20 04:11:19 - INFO - [Epoch 048] New best val loss: 798.4652\n",
      "[2025-11-20 04:11:27,306] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 797.9280\n",
      "2025-11-20 04:11:27 - INFO - [Epoch 049] New best val loss: 797.9280\n",
      "[2025-11-20 04:11:34,313] [UniVITrainer] [INFO] [Epoch 050] Train loss: 778.6434 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:11:34 - INFO - [Epoch 050] Train loss: 778.6434 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:11:35,124] [UniVITrainer] [INFO] [Epoch 050] Val loss: 798.2448 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:11:35 - INFO - [Epoch 050] Val loss: 798.2448 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:11:50,460] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 797.3901\n",
      "2025-11-20 04:11:50 - INFO - [Epoch 052] New best val loss: 797.3901\n",
      "[2025-11-20 04:11:58,212] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 796.9757\n",
      "2025-11-20 04:11:58 - INFO - [Epoch 053] New best val loss: 796.9757\n",
      "[2025-11-20 04:12:04,229] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 796.6420\n",
      "2025-11-20 04:12:04 - INFO - [Epoch 054] New best val loss: 796.6420\n",
      "[2025-11-20 04:12:18,824] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 795.8954\n",
      "2025-11-20 04:12:18 - INFO - [Epoch 056] New best val loss: 795.8954\n",
      "[2025-11-20 04:12:26,773] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 795.2646\n",
      "2025-11-20 04:12:26 - INFO - [Epoch 057] New best val loss: 795.2646\n",
      "[2025-11-20 04:12:48,337] [UniVITrainer] [INFO] [Epoch 060] Train loss: 780.6900 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:12:48 - INFO - [Epoch 060] Train loss: 780.6900 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:12:49,146] [UniVITrainer] [INFO] [Epoch 060] Val loss: 795.4784 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:12:49 - INFO - [Epoch 060] Val loss: 795.4784 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:12:56,287] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 795.0837\n",
      "2025-11-20 04:12:56 - INFO - [Epoch 061] New best val loss: 795.0837\n",
      "[2025-11-20 04:13:03,769] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 794.4926\n",
      "2025-11-20 04:13:03 - INFO - [Epoch 062] New best val loss: 794.4926\n",
      "[2025-11-20 04:13:10,297] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 793.6979\n",
      "2025-11-20 04:13:10 - INFO - [Epoch 063] New best val loss: 793.6979\n",
      "[2025-11-20 04:13:17,945] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 793.5387\n",
      "2025-11-20 04:13:17 - INFO - [Epoch 064] New best val loss: 793.5387\n",
      "[2025-11-20 04:13:23,108] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 793.2702\n",
      "2025-11-20 04:13:23 - INFO - [Epoch 065] New best val loss: 793.2702\n",
      "[2025-11-20 04:13:45,454] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 792.9684\n",
      "2025-11-20 04:13:45 - INFO - [Epoch 068] New best val loss: 792.9684\n",
      "[2025-11-20 04:13:52,983] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 792.6927\n",
      "2025-11-20 04:13:52 - INFO - [Epoch 069] New best val loss: 792.6927\n",
      "[2025-11-20 04:13:59,284] [UniVITrainer] [INFO] [Epoch 070] Train loss: 774.5349 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:13:59 - INFO - [Epoch 070] Train loss: 774.5349 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:14:00,114] [UniVITrainer] [INFO] [Epoch 070] Val loss: 793.2127 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:14:00 - INFO - [Epoch 070] Val loss: 793.2127 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:14:08,011] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 792.0473\n",
      "2025-11-20 04:14:08 - INFO - [Epoch 071] New best val loss: 792.0473\n",
      "[2025-11-20 04:14:23,325] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 791.5733\n",
      "2025-11-20 04:14:23 - INFO - [Epoch 073] New best val loss: 791.5733\n",
      "[2025-11-20 04:14:30,900] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 791.5489\n",
      "2025-11-20 04:14:30 - INFO - [Epoch 074] New best val loss: 791.5489\n",
      "[2025-11-20 04:14:44,594] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 791.4439\n",
      "2025-11-20 04:14:44 - INFO - [Epoch 076] New best val loss: 791.4439\n",
      "[2025-11-20 04:14:59,548] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 791.3843\n",
      "2025-11-20 04:14:59 - INFO - [Epoch 078] New best val loss: 791.3843\n",
      "[2025-11-20 04:15:06,737] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 790.7321\n",
      "2025-11-20 04:15:06 - INFO - [Epoch 079] New best val loss: 790.7321\n",
      "[2025-11-20 04:15:13,643] [UniVITrainer] [INFO] [Epoch 080] Train loss: 774.3906 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:15:13 - INFO - [Epoch 080] Train loss: 774.3906 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:15:14,474] [UniVITrainer] [INFO] [Epoch 080] Val loss: 790.2951 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:15:14 - INFO - [Epoch 080] Val loss: 790.2951 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:15:14,670] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 790.2951\n",
      "2025-11-20 04:15:14 - INFO - [Epoch 080] New best val loss: 790.2951\n",
      "[2025-11-20 04:15:22,208] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 789.9152\n",
      "2025-11-20 04:15:22 - INFO - [Epoch 081] New best val loss: 789.9152\n",
      "[2025-11-20 04:15:30,115] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 789.5159\n",
      "2025-11-20 04:15:30 - INFO - [Epoch 082] New best val loss: 789.5159\n",
      "[2025-11-20 04:15:49,872] [UniVITrainer] [INFO] [Epoch 085] New best val loss: 789.3675\n",
      "2025-11-20 04:15:49 - INFO - [Epoch 085] New best val loss: 789.3675\n",
      "[2025-11-20 04:16:05,505] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 789.0487\n",
      "2025-11-20 04:16:05 - INFO - [Epoch 087] New best val loss: 789.0487\n",
      "[2025-11-20 04:16:27,812] [UniVITrainer] [INFO] [Epoch 090] Train loss: 773.6754 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:16:27 - INFO - [Epoch 090] Train loss: 773.6754 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:16:28,640] [UniVITrainer] [INFO] [Epoch 090] Val loss: 788.4751 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:16:28 - INFO - [Epoch 090] Val loss: 788.4751 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:16:28,825] [UniVITrainer] [INFO] [Epoch 090] New best val loss: 788.4751\n",
      "2025-11-20 04:16:28 - INFO - [Epoch 090] New best val loss: 788.4751\n",
      "[2025-11-20 04:17:20,854] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 788.1155\n",
      "2025-11-20 04:17:20 - INFO - [Epoch 097] New best val loss: 788.1155\n",
      "[2025-11-20 04:17:27,450] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 787.4016\n",
      "2025-11-20 04:17:27 - INFO - [Epoch 098] New best val loss: 787.4016\n",
      "[2025-11-20 04:17:35,127] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 787.0419\n",
      "2025-11-20 04:17:35 - INFO - [Epoch 099] New best val loss: 787.0419\n",
      "[2025-11-20 04:17:41,235] [UniVITrainer] [INFO] [Epoch 100] Train loss: 771.6077 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:17:41 - INFO - [Epoch 100] Train loss: 771.6077 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:17:41,780] [UniVITrainer] [INFO] [Epoch 100] Val loss: 787.1139 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:17:41 - INFO - [Epoch 100] Val loss: 787.1139 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:17:49,364] [UniVITrainer] [INFO] [Epoch 101] New best val loss: 786.9233\n",
      "2025-11-20 04:17:49 - INFO - [Epoch 101] New best val loss: 786.9233\n",
      "[2025-11-20 04:18:02,861] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 786.3887\n",
      "2025-11-20 04:18:02 - INFO - [Epoch 103] New best val loss: 786.3887\n",
      "[2025-11-20 04:18:09,480] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 786.1080\n",
      "2025-11-20 04:18:09 - INFO - [Epoch 104] New best val loss: 786.1080\n",
      "[2025-11-20 04:18:52,373] [UniVITrainer] [INFO] [Epoch 110] Train loss: 768.8673 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:18:52 - INFO - [Epoch 110] Train loss: 768.8673 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:18:53,171] [UniVITrainer] [INFO] [Epoch 110] Val loss: 786.2159 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:18:53 - INFO - [Epoch 110] Val loss: 786.2159 (beta=240.000, gamma=400.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 04:19:08,144] [UniVITrainer] [INFO] [Epoch 112] New best val loss: 785.7546\n",
      "2025-11-20 04:19:08 - INFO - [Epoch 112] New best val loss: 785.7546\n",
      "[2025-11-20 04:19:15,741] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 785.6065\n",
      "2025-11-20 04:19:15 - INFO - [Epoch 113] New best val loss: 785.6065\n",
      "[2025-11-20 04:19:28,880] [UniVITrainer] [INFO] [Epoch 115] New best val loss: 784.9755\n",
      "2025-11-20 04:19:28 - INFO - [Epoch 115] New best val loss: 784.9755\n",
      "[2025-11-20 04:19:57,738] [UniVITrainer] [INFO] [Epoch 119] New best val loss: 784.6952\n",
      "2025-11-20 04:19:57 - INFO - [Epoch 119] New best val loss: 784.6952\n",
      "[2025-11-20 04:20:04,533] [UniVITrainer] [INFO] [Epoch 120] Train loss: 767.7931 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:20:04 - INFO - [Epoch 120] Train loss: 767.7931 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:20:05,349] [UniVITrainer] [INFO] [Epoch 120] Val loss: 784.7262 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:20:05 - INFO - [Epoch 120] Val loss: 784.7262 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:20:26,786] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 784.6875\n",
      "2025-11-20 04:20:26 - INFO - [Epoch 123] New best val loss: 784.6875\n",
      "[2025-11-20 04:20:42,198] [UniVITrainer] [INFO] [Epoch 125] New best val loss: 784.5144\n",
      "2025-11-20 04:20:42 - INFO - [Epoch 125] New best val loss: 784.5144\n",
      "[2025-11-20 04:20:57,313] [UniVITrainer] [INFO] [Epoch 127] New best val loss: 784.0177\n",
      "2025-11-20 04:20:57 - INFO - [Epoch 127] New best val loss: 784.0177\n",
      "[2025-11-20 04:21:18,596] [UniVITrainer] [INFO] [Epoch 130] Train loss: 769.5809 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:21:18 - INFO - [Epoch 130] Train loss: 769.5809 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:21:18,970] [UniVITrainer] [INFO] [Epoch 130] Val loss: 783.7686 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:21:18 - INFO - [Epoch 130] Val loss: 783.7686 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:21:19,151] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 783.7686\n",
      "2025-11-20 04:21:19 - INFO - [Epoch 130] New best val loss: 783.7686\n",
      "[2025-11-20 04:21:49,249] [UniVITrainer] [INFO] [Epoch 134] New best val loss: 783.5753\n",
      "2025-11-20 04:21:49 - INFO - [Epoch 134] New best val loss: 783.5753\n",
      "[2025-11-20 04:22:03,695] [UniVITrainer] [INFO] [Epoch 136] New best val loss: 783.1947\n",
      "2025-11-20 04:22:03 - INFO - [Epoch 136] New best val loss: 783.1947\n",
      "[2025-11-20 04:22:32,879] [UniVITrainer] [INFO] [Epoch 140] Train loss: 768.4677 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:22:32 - INFO - [Epoch 140] Train loss: 768.4677 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:22:33,678] [UniVITrainer] [INFO] [Epoch 140] Val loss: 783.3787 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:22:33 - INFO - [Epoch 140] Val loss: 783.3787 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:22:48,891] [UniVITrainer] [INFO] [Epoch 142] New best val loss: 783.0189\n",
      "2025-11-20 04:22:48 - INFO - [Epoch 142] New best val loss: 783.0189\n",
      "[2025-11-20 04:23:11,756] [UniVITrainer] [INFO] [Epoch 145] New best val loss: 782.8391\n",
      "2025-11-20 04:23:11 - INFO - [Epoch 145] New best val loss: 782.8391\n",
      "[2025-11-20 04:23:18,893] [UniVITrainer] [INFO] [Epoch 146] New best val loss: 782.2948\n",
      "2025-11-20 04:23:18 - INFO - [Epoch 146] New best val loss: 782.2948\n",
      "[2025-11-20 04:23:34,121] [UniVITrainer] [INFO] [Epoch 148] New best val loss: 782.1516\n",
      "2025-11-20 04:23:34 - INFO - [Epoch 148] New best val loss: 782.1516\n",
      "[2025-11-20 04:23:48,365] [UniVITrainer] [INFO] [Epoch 150] Train loss: 771.2470 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:23:48 - INFO - [Epoch 150] Train loss: 771.2470 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:23:49,178] [UniVITrainer] [INFO] [Epoch 150] Val loss: 782.5899 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:23:49 - INFO - [Epoch 150] Val loss: 782.5899 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:24:02,965] [UniVITrainer] [INFO] [Epoch 152] New best val loss: 782.0304\n",
      "2025-11-20 04:24:02 - INFO - [Epoch 152] New best val loss: 782.0304\n",
      "[2025-11-20 04:24:17,929] [UniVITrainer] [INFO] [Epoch 154] New best val loss: 781.7306\n",
      "2025-11-20 04:24:17 - INFO - [Epoch 154] New best val loss: 781.7306\n",
      "[2025-11-20 04:24:30,812] [UniVITrainer] [INFO] [Epoch 156] New best val loss: 781.6288\n",
      "2025-11-20 04:24:30 - INFO - [Epoch 156] New best val loss: 781.6288\n",
      "[2025-11-20 04:24:45,787] [UniVITrainer] [INFO] [Epoch 158] New best val loss: 781.3621\n",
      "2025-11-20 04:24:45 - INFO - [Epoch 158] New best val loss: 781.3621\n",
      "[2025-11-20 04:24:53,334] [UniVITrainer] [INFO] [Epoch 159] New best val loss: 781.1307\n",
      "2025-11-20 04:24:53 - INFO - [Epoch 159] New best val loss: 781.1307\n",
      "[2025-11-20 04:24:58,821] [UniVITrainer] [INFO] [Epoch 160] Train loss: 767.5036 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:24:58 - INFO - [Epoch 160] Train loss: 767.5036 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:24:59,652] [UniVITrainer] [INFO] [Epoch 160] Val loss: 781.2162 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:24:59 - INFO - [Epoch 160] Val loss: 781.2162 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:25:21,502] [UniVITrainer] [INFO] [Epoch 163] New best val loss: 780.6877\n",
      "2025-11-20 04:25:21 - INFO - [Epoch 163] New best val loss: 780.6877\n",
      "[2025-11-20 04:25:35,371] [UniVITrainer] [INFO] [Epoch 165] New best val loss: 780.5703\n",
      "2025-11-20 04:25:35 - INFO - [Epoch 165] New best val loss: 780.5703\n",
      "[2025-11-20 04:25:43,143] [UniVITrainer] [INFO] [Epoch 166] New best val loss: 780.5400\n",
      "2025-11-20 04:25:43 - INFO - [Epoch 166] New best val loss: 780.5400\n",
      "[2025-11-20 04:25:58,074] [UniVITrainer] [INFO] [Epoch 168] New best val loss: 780.2833\n",
      "2025-11-20 04:25:58 - INFO - [Epoch 168] New best val loss: 780.2833\n",
      "[2025-11-20 04:26:10,165] [UniVITrainer] [INFO] [Epoch 170] Train loss: 766.9052 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:26:10 - INFO - [Epoch 170] Train loss: 766.9052 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:26:10,602] [UniVITrainer] [INFO] [Epoch 170] Val loss: 781.0147 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:26:10 - INFO - [Epoch 170] Val loss: 781.0147 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:26:40,507] [UniVITrainer] [INFO] [Epoch 174] New best val loss: 780.1212\n",
      "2025-11-20 04:26:40 - INFO - [Epoch 174] New best val loss: 780.1212\n",
      "[2025-11-20 04:26:48,027] [UniVITrainer] [INFO] [Epoch 175] New best val loss: 780.0251\n",
      "2025-11-20 04:26:48 - INFO - [Epoch 175] New best val loss: 780.0251\n",
      "[2025-11-20 04:26:55,639] [UniVITrainer] [INFO] [Epoch 176] New best val loss: 780.0021\n",
      "2025-11-20 04:26:55 - INFO - [Epoch 176] New best val loss: 780.0021\n",
      "[2025-11-20 04:27:10,508] [UniVITrainer] [INFO] [Epoch 178] New best val loss: 779.9175\n",
      "2025-11-20 04:27:10 - INFO - [Epoch 178] New best val loss: 779.9175\n",
      "[2025-11-20 04:27:24,804] [UniVITrainer] [INFO] [Epoch 180] Train loss: 767.0212 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:27:24 - INFO - [Epoch 180] Train loss: 767.0212 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:27:25,635] [UniVITrainer] [INFO] [Epoch 180] Val loss: 779.6514 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:27:25 - INFO - [Epoch 180] Val loss: 779.6514 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:27:25,794] [UniVITrainer] [INFO] [Epoch 180] New best val loss: 779.6514\n",
      "2025-11-20 04:27:25 - INFO - [Epoch 180] New best val loss: 779.6514\n",
      "[2025-11-20 04:27:40,159] [UniVITrainer] [INFO] [Epoch 182] New best val loss: 779.4207\n",
      "2025-11-20 04:27:40 - INFO - [Epoch 182] New best val loss: 779.4207\n",
      "[2025-11-20 04:27:54,364] [UniVITrainer] [INFO] [Epoch 184] New best val loss: 779.2040\n",
      "2025-11-20 04:27:54 - INFO - [Epoch 184] New best val loss: 779.2040\n",
      "[2025-11-20 04:28:23,103] [UniVITrainer] [INFO] [Epoch 188] New best val loss: 779.1647\n",
      "2025-11-20 04:28:23 - INFO - [Epoch 188] New best val loss: 779.1647\n",
      "[2025-11-20 04:28:37,095] [UniVITrainer] [INFO] [Epoch 190] Train loss: 767.9304 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:28:37 - INFO - [Epoch 190] Train loss: 767.9304 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:28:37,899] [UniVITrainer] [INFO] [Epoch 190] Val loss: 779.2234 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:28:37 - INFO - [Epoch 190] Val loss: 779.2234 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:28:45,655] [UniVITrainer] [INFO] [Epoch 191] New best val loss: 778.7564\n",
      "2025-11-20 04:28:45 - INFO - [Epoch 191] New best val loss: 778.7564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 04:29:45,810] [UniVITrainer] [INFO] [Epoch 199] New best val loss: 778.6556\n",
      "2025-11-20 04:29:45 - INFO - [Epoch 199] New best val loss: 778.6556\n",
      "[2025-11-20 04:29:52,707] [UniVITrainer] [INFO] [Epoch 200] Train loss: 769.2086 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:29:52 - INFO - [Epoch 200] Train loss: 769.2086 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:29:53,511] [UniVITrainer] [INFO] [Epoch 200] Val loss: 778.5659 (beta=240.000, gamma=400.000)\n",
      "2025-11-20 04:29:53 - INFO - [Epoch 200] Val loss: 778.5659 (beta=240.000, gamma=400.000)\n",
      "[2025-11-20 04:29:53,660] [UniVITrainer] [INFO] [Epoch 200] New best val loss: 778.5659\n",
      "2025-11-20 04:29:53 - INFO - [Epoch 200] New best val loss: 778.5659\n",
      "[2025-11-20 04:29:53,700] [UniVITrainer] [INFO] Restored best model from epoch 200 (val loss = 778.5659)\n",
      "2025-11-20 04:29:53 - INFO - Restored best model from epoch 200 (val loss = 778.5659)\n",
      "[2025-11-20 04:29:56,195] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 04:29:56 - INFO - TrainingConfig:\n",
      "[2025-11-20 04:29:56,198] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 04:29:56 - INFO -   n_epochs: 200\n",
      "[2025-11-20 04:29:56,200] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 04:29:56 - INFO -   batch_size: 256\n",
      "[2025-11-20 04:29:56,204] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 04:29:56 - INFO -   lr: 0.0005\n",
      "[2025-11-20 04:29:56,208] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 04:29:56 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 04:29:56,213] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 04:29:56 - INFO -   device: cuda\n",
      "[2025-11-20 04:29:56,218] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 04:29:56 - INFO -   log_every: 10\n",
      "[2025-11-20 04:29:56,219] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 04:29:56 - INFO -   grad_clip: None\n",
      "[2025-11-20 04:29:56,224] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 04:29:56 - INFO -   num_workers: 0\n",
      "[2025-11-20 04:29:56,227] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 04:29:56 - INFO -   seed: 42\n",
      "[2025-11-20 04:29:56,228] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 04:29:56 - INFO -   early_stopping: True\n",
      "[2025-11-20 04:29:56,229] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 04:29:56 - INFO -   patience: 20\n",
      "[2025-11-20 04:29:56,230] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 04:29:56 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 15] Done in 24.7 min\n",
      "  best_val_loss              = 778.566\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5131\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.5114\n",
      "[Config 15] FOSCTTM (ADT vs ATAC, val) = 0.4986\n",
      "  Mean FOSCTTM (3 pairs)     = 0.5077\n",
      "  Modality mixing (k=20)     = 0.0424\n",
      "  Composite score            = 1223.61\n",
      "\n",
      "================================================================================\n",
      "[Config 16] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 20,\n",
      "  \"beta\": 140.0,\n",
      "  \"gamma\": 1000.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710ee9717fe748c4ba527f885498953f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 04:30:02,172] [UniVITrainer] [INFO] [Epoch 001] Train loss: 4963.0020 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:30:02 - INFO - [Epoch 001] Train loss: 4963.0020 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:30:02,918] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1781.3182 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:30:02 - INFO - [Epoch 001] Val loss: 1781.3182 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:30:03,067] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1781.3182\n",
      "2025-11-20 04:30:03 - INFO - [Epoch 001] New best val loss: 1781.3182\n",
      "[2025-11-20 04:30:11,035] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1376.5470\n",
      "2025-11-20 04:30:11 - INFO - [Epoch 002] New best val loss: 1376.5470\n",
      "[2025-11-20 04:30:18,947] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1119.5001\n",
      "2025-11-20 04:30:18 - INFO - [Epoch 003] New best val loss: 1119.5001\n",
      "[2025-11-20 04:30:26,522] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 994.0175\n",
      "2025-11-20 04:30:26 - INFO - [Epoch 004] New best val loss: 994.0175\n",
      "[2025-11-20 04:30:34,443] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 930.4958\n",
      "2025-11-20 04:30:34 - INFO - [Epoch 005] New best val loss: 930.4958\n",
      "[2025-11-20 04:30:42,314] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 898.8667\n",
      "2025-11-20 04:30:42 - INFO - [Epoch 006] New best val loss: 898.8667\n",
      "[2025-11-20 04:30:50,146] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 868.7853\n",
      "2025-11-20 04:30:50 - INFO - [Epoch 007] New best val loss: 868.7853\n",
      "[2025-11-20 04:30:57,404] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 851.8779\n",
      "2025-11-20 04:30:57 - INFO - [Epoch 008] New best val loss: 851.8779\n",
      "[2025-11-20 04:31:05,293] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 837.5046\n",
      "2025-11-20 04:31:05 - INFO - [Epoch 009] New best val loss: 837.5046\n",
      "[2025-11-20 04:31:11,896] [UniVITrainer] [INFO] [Epoch 010] Train loss: 1036.9643 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:31:11 - INFO - [Epoch 010] Train loss: 1036.9643 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:31:12,709] [UniVITrainer] [INFO] [Epoch 010] Val loss: 832.2527 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:31:12 - INFO - [Epoch 010] Val loss: 832.2527 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:31:12,874] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 832.2527\n",
      "2025-11-20 04:31:12 - INFO - [Epoch 010] New best val loss: 832.2527\n",
      "[2025-11-20 04:31:19,754] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 822.4325\n",
      "2025-11-20 04:31:19 - INFO - [Epoch 011] New best val loss: 822.4325\n",
      "[2025-11-20 04:31:27,480] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 815.5740\n",
      "2025-11-20 04:31:27 - INFO - [Epoch 012] New best val loss: 815.5740\n",
      "[2025-11-20 04:31:33,578] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 812.1779\n",
      "2025-11-20 04:31:33 - INFO - [Epoch 013] New best val loss: 812.1779\n",
      "[2025-11-20 04:31:40,543] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 807.0303\n",
      "2025-11-20 04:31:40 - INFO - [Epoch 014] New best val loss: 807.0303\n",
      "[2025-11-20 04:31:55,411] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 801.1069\n",
      "2025-11-20 04:31:55 - INFO - [Epoch 016] New best val loss: 801.1069\n",
      "[2025-11-20 04:32:02,132] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 799.5051\n",
      "2025-11-20 04:32:02 - INFO - [Epoch 017] New best val loss: 799.5051\n",
      "[2025-11-20 04:32:09,896] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 796.3907\n",
      "2025-11-20 04:32:09 - INFO - [Epoch 018] New best val loss: 796.3907\n",
      "[2025-11-20 04:32:16,470] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 795.1000\n",
      "2025-11-20 04:32:16 - INFO - [Epoch 019] New best val loss: 795.1000\n",
      "[2025-11-20 04:32:22,568] [UniVITrainer] [INFO] [Epoch 020] Train loss: 879.0535 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:32:22 - INFO - [Epoch 020] Train loss: 879.0535 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:32:23,383] [UniVITrainer] [INFO] [Epoch 020] Val loss: 794.4315 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:32:23 - INFO - [Epoch 020] Val loss: 794.4315 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:32:23,528] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 794.4315\n",
      "2025-11-20 04:32:23 - INFO - [Epoch 020] New best val loss: 794.4315\n",
      "[2025-11-20 04:32:31,130] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 792.8717\n",
      "2025-11-20 04:32:31 - INFO - [Epoch 021] New best val loss: 792.8717\n",
      "[2025-11-20 04:32:38,563] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 790.4414\n",
      "2025-11-20 04:32:38 - INFO - [Epoch 022] New best val loss: 790.4414\n",
      "[2025-11-20 04:32:46,280] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 787.7584\n",
      "2025-11-20 04:32:46 - INFO - [Epoch 023] New best val loss: 787.7584\n",
      "[2025-11-20 04:33:01,635] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 787.5747\n",
      "2025-11-20 04:33:01 - INFO - [Epoch 025] New best val loss: 787.5747\n",
      "[2025-11-20 04:33:08,914] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 786.3889\n",
      "2025-11-20 04:33:08 - INFO - [Epoch 026] New best val loss: 786.3889\n",
      "[2025-11-20 04:33:14,745] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 784.3203\n",
      "2025-11-20 04:33:14 - INFO - [Epoch 027] New best val loss: 784.3203\n",
      "[2025-11-20 04:33:29,605] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 783.3911\n",
      "2025-11-20 04:33:29 - INFO - [Epoch 029] New best val loss: 783.3911\n",
      "[2025-11-20 04:33:36,413] [UniVITrainer] [INFO] [Epoch 030] Train loss: 824.6416 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:33:36 - INFO - [Epoch 030] Train loss: 824.6416 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:33:36,928] [UniVITrainer] [INFO] [Epoch 030] Val loss: 783.4321 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:33:36 - INFO - [Epoch 030] Val loss: 783.4321 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:33:44,401] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 782.0123\n",
      "2025-11-20 04:33:44 - INFO - [Epoch 031] New best val loss: 782.0123\n",
      "[2025-11-20 04:33:52,158] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 781.6856\n",
      "2025-11-20 04:33:52 - INFO - [Epoch 032] New best val loss: 781.6856\n",
      "[2025-11-20 04:33:59,434] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 781.5267\n",
      "2025-11-20 04:33:59 - INFO - [Epoch 033] New best val loss: 781.5267\n",
      "[2025-11-20 04:34:07,124] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 780.2168\n",
      "2025-11-20 04:34:07 - INFO - [Epoch 034] New best val loss: 780.2168\n",
      "[2025-11-20 04:34:14,245] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 779.4675\n",
      "2025-11-20 04:34:14 - INFO - [Epoch 035] New best val loss: 779.4675\n",
      "[2025-11-20 04:34:22,010] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 779.1147\n",
      "2025-11-20 04:34:22 - INFO - [Epoch 036] New best val loss: 779.1147\n",
      "[2025-11-20 04:34:28,643] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 778.7052\n",
      "2025-11-20 04:34:28 - INFO - [Epoch 037] New best val loss: 778.7052\n",
      "[2025-11-20 04:34:43,210] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 777.3222\n",
      "2025-11-20 04:34:43 - INFO - [Epoch 039] New best val loss: 777.3222\n",
      "[2025-11-20 04:34:49,684] [UniVITrainer] [INFO] [Epoch 040] Train loss: 803.4798 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:34:49 - INFO - [Epoch 040] Train loss: 803.4798 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:34:50,496] [UniVITrainer] [INFO] [Epoch 040] Val loss: 777.7685 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:34:50 - INFO - [Epoch 040] Val loss: 777.7685 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:34:57,385] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 776.6524\n",
      "2025-11-20 04:34:57 - INFO - [Epoch 041] New best val loss: 776.6524\n",
      "[2025-11-20 04:35:05,056] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 776.2399\n",
      "2025-11-20 04:35:05 - INFO - [Epoch 042] New best val loss: 776.2399\n",
      "[2025-11-20 04:35:11,840] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 775.9747\n",
      "2025-11-20 04:35:11 - INFO - [Epoch 043] New best val loss: 775.9747\n",
      "[2025-11-20 04:35:27,079] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 775.4479\n",
      "2025-11-20 04:35:27 - INFO - [Epoch 045] New best val loss: 775.4479\n",
      "[2025-11-20 04:35:34,508] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 775.3202\n",
      "2025-11-20 04:35:34 - INFO - [Epoch 046] New best val loss: 775.3202\n",
      "[2025-11-20 04:35:41,860] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 774.6148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 04:35:41 - INFO - [Epoch 047] New best val loss: 774.6148\n",
      "[2025-11-20 04:35:49,618] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 774.5492\n",
      "2025-11-20 04:35:49 - INFO - [Epoch 048] New best val loss: 774.5492\n",
      "[2025-11-20 04:35:57,091] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 773.9579\n",
      "2025-11-20 04:35:57 - INFO - [Epoch 049] New best val loss: 773.9579\n",
      "[2025-11-20 04:36:03,906] [UniVITrainer] [INFO] [Epoch 050] Train loss: 794.1900 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:36:03 - INFO - [Epoch 050] Train loss: 794.1900 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:36:04,716] [UniVITrainer] [INFO] [Epoch 050] Val loss: 773.5939 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:36:04 - INFO - [Epoch 050] Val loss: 773.5939 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:36:04,859] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 773.5939\n",
      "2025-11-20 04:36:04 - INFO - [Epoch 050] New best val loss: 773.5939\n",
      "[2025-11-20 04:36:19,775] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 773.3895\n",
      "2025-11-20 04:36:19 - INFO - [Epoch 052] New best val loss: 773.3895\n",
      "[2025-11-20 04:36:27,493] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 773.2649\n",
      "2025-11-20 04:36:27 - INFO - [Epoch 053] New best val loss: 773.2649\n",
      "[2025-11-20 04:36:34,569] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 772.8125\n",
      "2025-11-20 04:36:34 - INFO - [Epoch 054] New best val loss: 772.8125\n",
      "[2025-11-20 04:36:41,864] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 772.6788\n",
      "2025-11-20 04:36:41 - INFO - [Epoch 055] New best val loss: 772.6788\n",
      "[2025-11-20 04:36:49,618] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 772.5895\n",
      "2025-11-20 04:36:49 - INFO - [Epoch 056] New best val loss: 772.5895\n",
      "[2025-11-20 04:36:57,280] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 772.0270\n",
      "2025-11-20 04:36:57 - INFO - [Epoch 057] New best val loss: 772.0270\n",
      "[2025-11-20 04:37:05,042] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 771.9934\n",
      "2025-11-20 04:37:05 - INFO - [Epoch 058] New best val loss: 771.9934\n",
      "[2025-11-20 04:37:12,705] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 771.7575\n",
      "2025-11-20 04:37:12 - INFO - [Epoch 059] New best val loss: 771.7575\n",
      "[2025-11-20 04:37:19,500] [UniVITrainer] [INFO] [Epoch 060] Train loss: 781.6204 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:37:19 - INFO - [Epoch 060] Train loss: 781.6204 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:37:20,314] [UniVITrainer] [INFO] [Epoch 060] Val loss: 771.4105 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:37:20 - INFO - [Epoch 060] Val loss: 771.4105 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:37:20,357] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 771.4105\n",
      "2025-11-20 04:37:20 - INFO - [Epoch 060] New best val loss: 771.4105\n",
      "[2025-11-20 04:37:28,064] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 771.3527\n",
      "2025-11-20 04:37:28 - INFO - [Epoch 061] New best val loss: 771.3527\n",
      "[2025-11-20 04:37:41,736] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 770.8245\n",
      "2025-11-20 04:37:41 - INFO - [Epoch 063] New best val loss: 770.8245\n",
      "[2025-11-20 04:38:03,458] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 770.7723\n",
      "2025-11-20 04:38:03 - INFO - [Epoch 066] New best val loss: 770.7723\n",
      "[2025-11-20 04:38:10,600] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 770.5005\n",
      "2025-11-20 04:38:10 - INFO - [Epoch 067] New best val loss: 770.5005\n",
      "[2025-11-20 04:38:30,926] [UniVITrainer] [INFO] [Epoch 070] Train loss: 776.1413 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:38:30 - INFO - [Epoch 070] Train loss: 776.1413 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:38:31,730] [UniVITrainer] [INFO] [Epoch 070] Val loss: 770.2357 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:38:31 - INFO - [Epoch 070] Val loss: 770.2357 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:38:31,874] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 770.2357\n",
      "2025-11-20 04:38:31 - INFO - [Epoch 070] New best val loss: 770.2357\n",
      "[2025-11-20 04:38:39,643] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 769.8852\n",
      "2025-11-20 04:38:39 - INFO - [Epoch 071] New best val loss: 769.8852\n",
      "[2025-11-20 04:38:47,089] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 769.8086\n",
      "2025-11-20 04:38:47 - INFO - [Epoch 072] New best val loss: 769.8086\n",
      "[2025-11-20 04:38:54,777] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 769.7364\n",
      "2025-11-20 04:38:54 - INFO - [Epoch 073] New best val loss: 769.7364\n",
      "[2025-11-20 04:39:17,247] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 769.6272\n",
      "2025-11-20 04:39:17 - INFO - [Epoch 076] New best val loss: 769.6272\n",
      "[2025-11-20 04:39:24,771] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 769.1758\n",
      "2025-11-20 04:39:24 - INFO - [Epoch 077] New best val loss: 769.1758\n",
      "[2025-11-20 04:39:44,588] [UniVITrainer] [INFO] [Epoch 080] Train loss: 773.4070 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:39:44 - INFO - [Epoch 080] Train loss: 773.4070 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:39:45,406] [UniVITrainer] [INFO] [Epoch 080] Val loss: 769.3123 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:39:45 - INFO - [Epoch 080] Val loss: 769.3123 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:39:53,117] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 768.6991\n",
      "2025-11-20 04:39:53 - INFO - [Epoch 081] New best val loss: 768.6991\n",
      "[2025-11-20 04:40:14,690] [UniVITrainer] [INFO] [Epoch 084] New best val loss: 768.5706\n",
      "2025-11-20 04:40:14 - INFO - [Epoch 084] New best val loss: 768.5706\n",
      "[2025-11-20 04:40:22,231] [UniVITrainer] [INFO] [Epoch 085] New best val loss: 768.5592\n",
      "2025-11-20 04:40:22 - INFO - [Epoch 085] New best val loss: 768.5592\n",
      "[2025-11-20 04:40:37,099] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 768.4938\n",
      "2025-11-20 04:40:37 - INFO - [Epoch 087] New best val loss: 768.4938\n",
      "[2025-11-20 04:40:51,949] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 768.4637\n",
      "2025-11-20 04:40:51 - INFO - [Epoch 089] New best val loss: 768.4637\n",
      "[2025-11-20 04:40:58,369] [UniVITrainer] [INFO] [Epoch 090] Train loss: 774.2729 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:40:58 - INFO - [Epoch 090] Train loss: 774.2729 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:40:59,183] [UniVITrainer] [INFO] [Epoch 090] Val loss: 768.2596 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:40:59 - INFO - [Epoch 090] Val loss: 768.2596 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:40:59,332] [UniVITrainer] [INFO] [Epoch 090] New best val loss: 768.2596\n",
      "2025-11-20 04:40:59 - INFO - [Epoch 090] New best val loss: 768.2596\n",
      "[2025-11-20 04:41:44,467] [UniVITrainer] [INFO] [Epoch 096] New best val loss: 768.1199\n",
      "2025-11-20 04:41:44 - INFO - [Epoch 096] New best val loss: 768.1199\n",
      "[2025-11-20 04:41:59,718] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 768.0293\n",
      "2025-11-20 04:41:59 - INFO - [Epoch 098] New best val loss: 768.0293\n",
      "[2025-11-20 04:42:14,128] [UniVITrainer] [INFO] [Epoch 100] Train loss: 771.8093 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:42:14 - INFO - [Epoch 100] Train loss: 771.8093 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:42:14,943] [UniVITrainer] [INFO] [Epoch 100] Val loss: 767.9379 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:42:14 - INFO - [Epoch 100] Val loss: 767.9379 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:42:15,088] [UniVITrainer] [INFO] [Epoch 100] New best val loss: 767.9379\n",
      "2025-11-20 04:42:15 - INFO - [Epoch 100] New best val loss: 767.9379\n",
      "[2025-11-20 04:42:22,675] [UniVITrainer] [INFO] [Epoch 101] New best val loss: 767.8846\n",
      "2025-11-20 04:42:22 - INFO - [Epoch 101] New best val loss: 767.8846\n",
      "[2025-11-20 04:42:29,902] [UniVITrainer] [INFO] [Epoch 102] New best val loss: 767.8400\n",
      "2025-11-20 04:42:29 - INFO - [Epoch 102] New best val loss: 767.8400\n",
      "[2025-11-20 04:42:37,491] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 767.7274\n",
      "2025-11-20 04:42:37 - INFO - [Epoch 103] New best val loss: 767.7274\n",
      "[2025-11-20 04:43:06,277] [UniVITrainer] [INFO] [Epoch 107] New best val loss: 767.6270\n",
      "2025-11-20 04:43:06 - INFO - [Epoch 107] New best val loss: 767.6270\n",
      "[2025-11-20 04:43:13,778] [UniVITrainer] [INFO] [Epoch 108] New best val loss: 767.5839\n",
      "2025-11-20 04:43:13 - INFO - [Epoch 108] New best val loss: 767.5839\n",
      "[2025-11-20 04:43:21,504] [UniVITrainer] [INFO] [Epoch 109] New best val loss: 767.4904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 04:43:21 - INFO - [Epoch 109] New best val loss: 767.4904\n",
      "[2025-11-20 04:43:28,325] [UniVITrainer] [INFO] [Epoch 110] Train loss: 768.9355 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:43:28 - INFO - [Epoch 110] Train loss: 768.9355 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:43:29,136] [UniVITrainer] [INFO] [Epoch 110] Val loss: 767.4761 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:43:29 - INFO - [Epoch 110] Val loss: 767.4761 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:43:29,298] [UniVITrainer] [INFO] [Epoch 110] New best val loss: 767.4761\n",
      "2025-11-20 04:43:29 - INFO - [Epoch 110] New best val loss: 767.4761\n",
      "[2025-11-20 04:43:52,187] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 767.4667\n",
      "2025-11-20 04:43:52 - INFO - [Epoch 113] New best val loss: 767.4667\n",
      "[2025-11-20 04:44:15,055] [UniVITrainer] [INFO] [Epoch 116] New best val loss: 767.3659\n",
      "2025-11-20 04:44:15 - INFO - [Epoch 116] New best val loss: 767.3659\n",
      "[2025-11-20 04:44:35,208] [UniVITrainer] [INFO] [Epoch 119] New best val loss: 767.3099\n",
      "2025-11-20 04:44:35 - INFO - [Epoch 119] New best val loss: 767.3099\n",
      "[2025-11-20 04:44:41,112] [UniVITrainer] [INFO] [Epoch 120] Train loss: 768.5224 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:44:41 - INFO - [Epoch 120] Train loss: 768.5224 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:44:41,929] [UniVITrainer] [INFO] [Epoch 120] Val loss: 767.2027 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:44:41 - INFO - [Epoch 120] Val loss: 767.2027 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:44:42,068] [UniVITrainer] [INFO] [Epoch 120] New best val loss: 767.2027\n",
      "2025-11-20 04:44:42 - INFO - [Epoch 120] New best val loss: 767.2027\n",
      "[2025-11-20 04:44:48,294] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 767.1872\n",
      "2025-11-20 04:44:48 - INFO - [Epoch 121] New best val loss: 767.1872\n",
      "[2025-11-20 04:45:10,975] [UniVITrainer] [INFO] [Epoch 124] New best val loss: 767.1583\n",
      "2025-11-20 04:45:10 - INFO - [Epoch 124] New best val loss: 767.1583\n",
      "[2025-11-20 04:45:25,573] [UniVITrainer] [INFO] [Epoch 126] New best val loss: 767.1566\n",
      "2025-11-20 04:45:25 - INFO - [Epoch 126] New best val loss: 767.1566\n",
      "[2025-11-20 04:45:53,495] [UniVITrainer] [INFO] [Epoch 130] Train loss: 766.7813 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:45:53 - INFO - [Epoch 130] Train loss: 766.7813 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:45:54,313] [UniVITrainer] [INFO] [Epoch 130] Val loss: 767.1636 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:45:54 - INFO - [Epoch 130] Val loss: 767.1636 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:46:09,349] [UniVITrainer] [INFO] [Epoch 132] New best val loss: 767.0490\n",
      "2025-11-20 04:46:09 - INFO - [Epoch 132] New best val loss: 767.0490\n",
      "[2025-11-20 04:46:37,592] [UniVITrainer] [INFO] [Epoch 136] New best val loss: 766.9895\n",
      "2025-11-20 04:46:37 - INFO - [Epoch 136] New best val loss: 766.9895\n",
      "[2025-11-20 04:46:52,746] [UniVITrainer] [INFO] [Epoch 138] New best val loss: 766.9815\n",
      "2025-11-20 04:46:52 - INFO - [Epoch 138] New best val loss: 766.9815\n",
      "[2025-11-20 04:47:07,041] [UniVITrainer] [INFO] [Epoch 140] Train loss: 765.5281 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:47:07 - INFO - [Epoch 140] Train loss: 765.5281 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:47:07,860] [UniVITrainer] [INFO] [Epoch 140] Val loss: 766.9075 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:47:07 - INFO - [Epoch 140] Val loss: 766.9075 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:47:07,980] [UniVITrainer] [INFO] [Epoch 140] New best val loss: 766.9075\n",
      "2025-11-20 04:47:07 - INFO - [Epoch 140] New best val loss: 766.9075\n",
      "[2025-11-20 04:47:23,097] [UniVITrainer] [INFO] [Epoch 142] New best val loss: 766.8513\n",
      "2025-11-20 04:47:23 - INFO - [Epoch 142] New best val loss: 766.8513\n",
      "[2025-11-20 04:47:45,280] [UniVITrainer] [INFO] [Epoch 145] New best val loss: 766.8231\n",
      "2025-11-20 04:47:45 - INFO - [Epoch 145] New best val loss: 766.8231\n",
      "[2025-11-20 04:48:20,920] [UniVITrainer] [INFO] [Epoch 150] Train loss: 768.0654 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:48:20 - INFO - [Epoch 150] Train loss: 768.0654 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:48:21,723] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.8178 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:48:21 - INFO - [Epoch 150] Val loss: 766.8178 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:48:21,867] [UniVITrainer] [INFO] [Epoch 150] New best val loss: 766.8178\n",
      "2025-11-20 04:48:21 - INFO - [Epoch 150] New best val loss: 766.8178\n",
      "[2025-11-20 04:49:21,356] [UniVITrainer] [INFO] [Epoch 158] New best val loss: 766.8045\n",
      "2025-11-20 04:49:21 - INFO - [Epoch 158] New best val loss: 766.8045\n",
      "[2025-11-20 04:49:35,740] [UniVITrainer] [INFO] [Epoch 160] Train loss: 766.8413 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:49:35 - INFO - [Epoch 160] Train loss: 766.8413 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:49:36,528] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.8196 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:49:36 - INFO - [Epoch 160] Val loss: 766.8196 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:49:44,238] [UniVITrainer] [INFO] [Epoch 161] New best val loss: 766.7691\n",
      "2025-11-20 04:49:44 - INFO - [Epoch 161] New best val loss: 766.7691\n",
      "[2025-11-20 04:49:51,444] [UniVITrainer] [INFO] [Epoch 162] New best val loss: 766.7204\n",
      "2025-11-20 04:49:51 - INFO - [Epoch 162] New best val loss: 766.7204\n",
      "[2025-11-20 04:50:29,286] [UniVITrainer] [INFO] [Epoch 167] New best val loss: 766.6513\n",
      "2025-11-20 04:50:29 - INFO - [Epoch 167] New best val loss: 766.6513\n",
      "[2025-11-20 04:50:50,767] [UniVITrainer] [INFO] [Epoch 170] Train loss: 768.4995 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:50:50 - INFO - [Epoch 170] Train loss: 768.4995 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:50:51,583] [UniVITrainer] [INFO] [Epoch 170] Val loss: 766.6797 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:50:51 - INFO - [Epoch 170] Val loss: 766.6797 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:51:14,426] [UniVITrainer] [INFO] [Epoch 173] New best val loss: 766.6389\n",
      "2025-11-20 04:51:14 - INFO - [Epoch 173] New best val loss: 766.6389\n",
      "[2025-11-20 04:51:49,467] [UniVITrainer] [INFO] [Epoch 178] New best val loss: 766.5832\n",
      "2025-11-20 04:51:49 - INFO - [Epoch 178] New best val loss: 766.5832\n",
      "[2025-11-20 04:52:03,102] [UniVITrainer] [INFO] [Epoch 180] Train loss: 767.2916 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:52:03 - INFO - [Epoch 180] Train loss: 767.2916 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:52:03,914] [UniVITrainer] [INFO] [Epoch 180] Val loss: 766.6570 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:52:03 - INFO - [Epoch 180] Val loss: 766.6570 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:52:26,554] [UniVITrainer] [INFO] [Epoch 183] New best val loss: 766.5776\n",
      "2025-11-20 04:52:26 - INFO - [Epoch 183] New best val loss: 766.5776\n",
      "[2025-11-20 04:52:54,532] [UniVITrainer] [INFO] [Epoch 187] New best val loss: 766.5396\n",
      "2025-11-20 04:52:54 - INFO - [Epoch 187] New best val loss: 766.5396\n",
      "[2025-11-20 04:53:14,964] [UniVITrainer] [INFO] [Epoch 190] Train loss: 767.5394 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:53:14 - INFO - [Epoch 190] Train loss: 767.5394 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:53:15,778] [UniVITrainer] [INFO] [Epoch 190] Val loss: 766.6041 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:53:15 - INFO - [Epoch 190] Val loss: 766.6041 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:53:22,287] [UniVITrainer] [INFO] [Epoch 191] New best val loss: 766.5215\n",
      "2025-11-20 04:53:22 - INFO - [Epoch 191] New best val loss: 766.5215\n",
      "[2025-11-20 04:54:24,396] [UniVITrainer] [INFO] [Epoch 200] Train loss: 766.2203 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:54:24 - INFO - [Epoch 200] Train loss: 766.2203 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:54:25,204] [UniVITrainer] [INFO] [Epoch 200] Val loss: 766.5205 (beta=140.000, gamma=1000.000)\n",
      "2025-11-20 04:54:25 - INFO - [Epoch 200] Val loss: 766.5205 (beta=140.000, gamma=1000.000)\n",
      "[2025-11-20 04:54:25,373] [UniVITrainer] [INFO] [Epoch 200] New best val loss: 766.5205\n",
      "2025-11-20 04:54:25 - INFO - [Epoch 200] New best val loss: 766.5205\n",
      "[2025-11-20 04:54:25,427] [UniVITrainer] [INFO] Restored best model from epoch 200 (val loss = 766.5205)\n",
      "2025-11-20 04:54:25 - INFO - Restored best model from epoch 200 (val loss = 766.5205)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 04:54:27,952] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 04:54:27 - INFO - TrainingConfig:\n",
      "[2025-11-20 04:54:27,954] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 04:54:27 - INFO -   n_epochs: 200\n",
      "[2025-11-20 04:54:27,961] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 04:54:27 - INFO -   batch_size: 256\n",
      "[2025-11-20 04:54:27,965] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 04:54:27 - INFO -   lr: 0.001\n",
      "[2025-11-20 04:54:27,969] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 04:54:27 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 04:54:27,971] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 04:54:27 - INFO -   device: cuda\n",
      "[2025-11-20 04:54:27,972] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 04:54:27 - INFO -   log_every: 10\n",
      "[2025-11-20 04:54:27,980] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 04:54:27 - INFO -   grad_clip: None\n",
      "[2025-11-20 04:54:27,981] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 04:54:27 - INFO -   num_workers: 0\n",
      "[2025-11-20 04:54:27,982] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 04:54:27 - INFO -   seed: 42\n",
      "[2025-11-20 04:54:27,987] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 04:54:27 - INFO -   early_stopping: True\n",
      "[2025-11-20 04:54:27,989] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 04:54:27 - INFO -   patience: 20\n",
      "[2025-11-20 04:54:27,992] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 04:54:27 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 16] Done in 24.5 min\n",
      "  best_val_loss              = 766.520\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4305\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4869\n",
      "[Config 16] FOSCTTM (ADT vs ATAC, val) = 0.4883\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4686\n",
      "  Modality mixing (k=20)     = 0.1023\n",
      "  Composite score            = 1240.88\n",
      "\n",
      "================================================================================\n",
      "[Config 17] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 156,\n",
      "  \"beta\": 400.0,\n",
      "  \"gamma\": 100.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9713bbec8b43c5af251e0f49234cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 04:54:34,375] [UniVITrainer] [INFO] [Epoch 001] Train loss: 9907.5175 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 04:54:34 - INFO - [Epoch 001] Train loss: 9907.5175 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 04:54:35,184] [UniVITrainer] [INFO] [Epoch 001] Val loss: 2949.1383 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 04:54:35 - INFO - [Epoch 001] Val loss: 2949.1383 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 04:54:35,436] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 2949.1383\n",
      "2025-11-20 04:54:35 - INFO - [Epoch 001] New best val loss: 2949.1383\n",
      "[2025-11-20 04:54:43,192] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1400.1966\n",
      "2025-11-20 04:54:43 - INFO - [Epoch 002] New best val loss: 1400.1966\n",
      "[2025-11-20 04:54:50,674] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1090.1801\n",
      "2025-11-20 04:54:50 - INFO - [Epoch 003] New best val loss: 1090.1801\n",
      "[2025-11-20 04:54:57,964] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 988.8232\n",
      "2025-11-20 04:54:57 - INFO - [Epoch 004] New best val loss: 988.8232\n",
      "[2025-11-20 04:55:04,096] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 950.6354\n",
      "2025-11-20 04:55:04 - INFO - [Epoch 005] New best val loss: 950.6354\n",
      "[2025-11-20 04:55:11,783] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 909.3053\n",
      "2025-11-20 04:55:11 - INFO - [Epoch 006] New best val loss: 909.3053\n",
      "[2025-11-20 04:55:18,928] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 888.4943\n",
      "2025-11-20 04:55:18 - INFO - [Epoch 007] New best val loss: 888.4943\n",
      "[2025-11-20 04:55:26,232] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 880.6684\n",
      "2025-11-20 04:55:26 - INFO - [Epoch 008] New best val loss: 880.6684\n",
      "[2025-11-20 04:55:33,900] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 874.8830\n",
      "2025-11-20 04:55:33 - INFO - [Epoch 009] New best val loss: 874.8830\n",
      "[2025-11-20 04:55:40,682] [UniVITrainer] [INFO] [Epoch 010] Train loss: 985.4340 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 04:55:40 - INFO - [Epoch 010] Train loss: 985.4340 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 04:55:41,496] [UniVITrainer] [INFO] [Epoch 010] Val loss: 865.0088 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 04:55:41 - INFO - [Epoch 010] Val loss: 865.0088 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 04:55:41,726] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 865.0088\n",
      "2025-11-20 04:55:41 - INFO - [Epoch 010] New best val loss: 865.0088\n",
      "[2025-11-20 04:55:48,883] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 863.5598\n",
      "2025-11-20 04:55:48 - INFO - [Epoch 011] New best val loss: 863.5598\n",
      "[2025-11-20 04:55:56,681] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 855.4429\n",
      "2025-11-20 04:55:56 - INFO - [Epoch 012] New best val loss: 855.4429\n",
      "[2025-11-20 04:56:03,595] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 852.0159\n",
      "2025-11-20 04:56:03 - INFO - [Epoch 013] New best val loss: 852.0159\n",
      "[2025-11-20 04:56:11,446] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 849.1568\n",
      "2025-11-20 04:56:11 - INFO - [Epoch 014] New best val loss: 849.1568\n",
      "[2025-11-20 04:56:17,961] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 841.9379\n",
      "2025-11-20 04:56:17 - INFO - [Epoch 015] New best val loss: 841.9379\n",
      "[2025-11-20 04:56:25,550] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 839.7568\n",
      "2025-11-20 04:56:25 - INFO - [Epoch 016] New best val loss: 839.7568\n",
      "[2025-11-20 04:56:33,161] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 836.5852\n",
      "2025-11-20 04:56:33 - INFO - [Epoch 017] New best val loss: 836.5852\n",
      "[2025-11-20 04:56:51,363] [UniVITrainer] [INFO] [Epoch 020] Train loss: 868.8682 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 04:56:51 - INFO - [Epoch 020] Train loss: 868.8682 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 04:56:52,174] [UniVITrainer] [INFO] [Epoch 020] Val loss: 831.3140 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 04:56:52 - INFO - [Epoch 020] Val loss: 831.3140 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 04:56:52,414] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 831.3140\n",
      "2025-11-20 04:56:52 - INFO - [Epoch 020] New best val loss: 831.3140\n",
      "[2025-11-20 04:57:00,009] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 830.9412\n",
      "2025-11-20 04:57:00 - INFO - [Epoch 021] New best val loss: 830.9412\n",
      "[2025-11-20 04:57:07,652] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 826.2427\n",
      "2025-11-20 04:57:07 - INFO - [Epoch 022] New best val loss: 826.2427\n",
      "[2025-11-20 04:57:28,205] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 825.4657\n",
      "2025-11-20 04:57:28 - INFO - [Epoch 025] New best val loss: 825.4657\n",
      "[2025-11-20 04:57:36,016] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 823.5879\n",
      "2025-11-20 04:57:36 - INFO - [Epoch 026] New best val loss: 823.5879\n",
      "[2025-11-20 04:57:43,280] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 820.4438\n",
      "2025-11-20 04:57:43 - INFO - [Epoch 027] New best val loss: 820.4438\n",
      "[2025-11-20 04:58:02,796] [UniVITrainer] [INFO] [Epoch 030] Train loss: 828.4711 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 04:58:02 - INFO - [Epoch 030] Train loss: 828.4711 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 04:58:03,632] [UniVITrainer] [INFO] [Epoch 030] Val loss: 816.6880 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 04:58:03 - INFO - [Epoch 030] Val loss: 816.6880 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 04:58:03,862] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 816.6880\n",
      "2025-11-20 04:58:03 - INFO - [Epoch 030] New best val loss: 816.6880\n",
      "[2025-11-20 04:58:24,131] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 815.5652\n",
      "2025-11-20 04:58:24 - INFO - [Epoch 033] New best val loss: 815.5652\n",
      "[2025-11-20 04:58:37,304] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 810.2073\n",
      "2025-11-20 04:58:37 - INFO - [Epoch 035] New best val loss: 810.2073\n",
      "[2025-11-20 04:58:58,669] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 805.6918\n",
      "2025-11-20 04:58:58 - INFO - [Epoch 038] New best val loss: 805.6918\n",
      "[2025-11-20 04:59:12,621] [UniVITrainer] [INFO] [Epoch 040] Train loss: 804.1877 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 04:59:12 - INFO - [Epoch 040] Train loss: 804.1877 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 04:59:12,781] [UniVITrainer] [INFO] [Epoch 040] Val loss: 807.1477 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 04:59:12 - INFO - [Epoch 040] Val loss: 807.1477 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 04:59:41,788] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 804.5280\n",
      "2025-11-20 04:59:41 - INFO - [Epoch 044] New best val loss: 804.5280\n",
      "[2025-11-20 04:59:49,566] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 803.8980\n",
      "2025-11-20 04:59:49 - INFO - [Epoch 045] New best val loss: 803.8980\n",
      "[2025-11-20 05:00:12,262] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 799.2579\n",
      "2025-11-20 05:00:12 - INFO - [Epoch 048] New best val loss: 799.2579\n",
      "[2025-11-20 05:00:19,946] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 798.7776\n",
      "2025-11-20 05:00:19 - INFO - [Epoch 049] New best val loss: 798.7776\n",
      "[2025-11-20 05:00:26,625] [UniVITrainer] [INFO] [Epoch 050] Train loss: 790.7311 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:00:26 - INFO - [Epoch 050] Train loss: 790.7311 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:00:27,448] [UniVITrainer] [INFO] [Epoch 050] Val loss: 801.9505 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:00:27 - INFO - [Epoch 050] Val loss: 801.9505 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:00:34,218] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 798.3648\n",
      "2025-11-20 05:00:34 - INFO - [Epoch 051] New best val loss: 798.3648\n",
      "[2025-11-20 05:00:49,045] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 797.5079\n",
      "2025-11-20 05:00:49 - INFO - [Epoch 053] New best val loss: 797.5079\n",
      "[2025-11-20 05:01:20,042] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 794.4561\n",
      "2025-11-20 05:01:20 - INFO - [Epoch 057] New best val loss: 794.4561\n",
      "[2025-11-20 05:01:34,112] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 794.3083\n",
      "2025-11-20 05:01:34 - INFO - [Epoch 059] New best val loss: 794.3083\n",
      "[2025-11-20 05:01:41,026] [UniVITrainer] [INFO] [Epoch 060] Train loss: 787.9031 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:01:41 - INFO - [Epoch 060] Train loss: 787.9031 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:01:41,838] [UniVITrainer] [INFO] [Epoch 060] Val loss: 798.2920 (beta=400.000, gamma=100.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 05:01:41 - INFO - [Epoch 060] Val loss: 798.2920 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:01:49,744] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 792.8147\n",
      "2025-11-20 05:01:49 - INFO - [Epoch 061] New best val loss: 792.8147\n",
      "[2025-11-20 05:02:12,339] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 790.8530\n",
      "2025-11-20 05:02:12 - INFO - [Epoch 064] New best val loss: 790.8530\n",
      "[2025-11-20 05:02:20,126] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 790.1571\n",
      "2025-11-20 05:02:20 - INFO - [Epoch 065] New best val loss: 790.1571\n",
      "[2025-11-20 05:02:55,628] [UniVITrainer] [INFO] [Epoch 070] Train loss: 781.1760 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:02:55 - INFO - [Epoch 070] Train loss: 781.1760 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:02:56,452] [UniVITrainer] [INFO] [Epoch 070] Val loss: 792.9806 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:02:56 - INFO - [Epoch 070] Val loss: 792.9806 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:03:04,113] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 789.6221\n",
      "2025-11-20 05:03:04 - INFO - [Epoch 071] New best val loss: 789.6221\n",
      "[2025-11-20 05:03:19,633] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 788.6685\n",
      "2025-11-20 05:03:19 - INFO - [Epoch 073] New best val loss: 788.6685\n",
      "[2025-11-20 05:03:35,196] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 788.3170\n",
      "2025-11-20 05:03:35 - INFO - [Epoch 075] New best val loss: 788.3170\n",
      "[2025-11-20 05:03:41,975] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 786.8964\n",
      "2025-11-20 05:03:41 - INFO - [Epoch 076] New best val loss: 786.8964\n",
      "[2025-11-20 05:03:49,971] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 786.1246\n",
      "2025-11-20 05:03:49 - INFO - [Epoch 077] New best val loss: 786.1246\n",
      "[2025-11-20 05:03:57,715] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 785.7859\n",
      "2025-11-20 05:03:57 - INFO - [Epoch 078] New best val loss: 785.7859\n",
      "[2025-11-20 05:04:05,736] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 784.1700\n",
      "2025-11-20 05:04:05 - INFO - [Epoch 079] New best val loss: 784.1700\n",
      "[2025-11-20 05:04:12,650] [UniVITrainer] [INFO] [Epoch 080] Train loss: 774.8815 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:04:12 - INFO - [Epoch 080] Train loss: 774.8815 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:04:13,481] [UniVITrainer] [INFO] [Epoch 080] Val loss: 787.0077 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:04:13 - INFO - [Epoch 080] Val loss: 787.0077 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:04:20,362] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 783.2814\n",
      "2025-11-20 05:04:20 - INFO - [Epoch 081] New best val loss: 783.2814\n",
      "[2025-11-20 05:04:28,233] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 782.8730\n",
      "2025-11-20 05:04:28 - INFO - [Epoch 082] New best val loss: 782.8730\n",
      "[2025-11-20 05:04:36,255] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 780.9059\n",
      "2025-11-20 05:04:36 - INFO - [Epoch 083] New best val loss: 780.9059\n",
      "[2025-11-20 05:05:18,949] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 779.2536\n",
      "2025-11-20 05:05:18 - INFO - [Epoch 089] New best val loss: 779.2536\n",
      "[2025-11-20 05:05:25,123] [UniVITrainer] [INFO] [Epoch 090] Train loss: 773.0820 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:05:25 - INFO - [Epoch 090] Train loss: 773.0820 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:05:25,936] [UniVITrainer] [INFO] [Epoch 090] Val loss: 779.4256 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:05:25 - INFO - [Epoch 090] Val loss: 779.4256 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:05:33,093] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 779.1802\n",
      "2025-11-20 05:05:33 - INFO - [Epoch 091] New best val loss: 779.1802\n",
      "[2025-11-20 05:05:40,139] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 778.6223\n",
      "2025-11-20 05:05:40 - INFO - [Epoch 092] New best val loss: 778.6223\n",
      "[2025-11-20 05:05:54,513] [UniVITrainer] [INFO] [Epoch 094] New best val loss: 778.2222\n",
      "2025-11-20 05:05:54 - INFO - [Epoch 094] New best val loss: 778.2222\n",
      "[2025-11-20 05:06:15,870] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 777.8521\n",
      "2025-11-20 05:06:15 - INFO - [Epoch 097] New best val loss: 777.8521\n",
      "[2025-11-20 05:06:37,170] [UniVITrainer] [INFO] [Epoch 100] Train loss: 769.5644 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:06:37 - INFO - [Epoch 100] Train loss: 769.5644 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:06:37,984] [UniVITrainer] [INFO] [Epoch 100] Val loss: 777.3272 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:06:37 - INFO - [Epoch 100] Val loss: 777.3272 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:06:38,163] [UniVITrainer] [INFO] [Epoch 100] New best val loss: 777.3272\n",
      "2025-11-20 05:06:38 - INFO - [Epoch 100] New best val loss: 777.3272\n",
      "[2025-11-20 05:06:45,799] [UniVITrainer] [INFO] [Epoch 101] New best val loss: 776.6426\n",
      "2025-11-20 05:06:45 - INFO - [Epoch 101] New best val loss: 776.6426\n",
      "[2025-11-20 05:07:37,190] [UniVITrainer] [INFO] [Epoch 108] New best val loss: 775.8567\n",
      "2025-11-20 05:07:37 - INFO - [Epoch 108] New best val loss: 775.8567\n",
      "[2025-11-20 05:07:51,566] [UniVITrainer] [INFO] [Epoch 110] Train loss: 768.8150 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:07:51 - INFO - [Epoch 110] Train loss: 768.8150 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:07:52,387] [UniVITrainer] [INFO] [Epoch 110] Val loss: 776.9321 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:07:52 - INFO - [Epoch 110] Val loss: 776.9321 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:08:00,293] [UniVITrainer] [INFO] [Epoch 111] New best val loss: 775.8561\n",
      "2025-11-20 05:08:00 - INFO - [Epoch 111] New best val loss: 775.8561\n",
      "[2025-11-20 05:08:08,140] [UniVITrainer] [INFO] [Epoch 112] New best val loss: 775.2498\n",
      "2025-11-20 05:08:08 - INFO - [Epoch 112] New best val loss: 775.2498\n",
      "[2025-11-20 05:09:00,531] [UniVITrainer] [INFO] [Epoch 119] New best val loss: 772.5639\n",
      "2025-11-20 05:09:00 - INFO - [Epoch 119] New best val loss: 772.5639\n",
      "[2025-11-20 05:09:07,355] [UniVITrainer] [INFO] [Epoch 120] Train loss: 769.8577 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:09:07 - INFO - [Epoch 120] Train loss: 769.8577 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:09:08,171] [UniVITrainer] [INFO] [Epoch 120] Val loss: 773.2734 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:09:08 - INFO - [Epoch 120] Val loss: 773.2734 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:09:30,937] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 772.3880\n",
      "2025-11-20 05:09:30 - INFO - [Epoch 123] New best val loss: 772.3880\n",
      "[2025-11-20 05:10:22,248] [UniVITrainer] [INFO] [Epoch 130] Train loss: 771.5498 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:10:22 - INFO - [Epoch 130] Train loss: 771.5498 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:10:23,065] [UniVITrainer] [INFO] [Epoch 130] Val loss: 777.8168 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:10:23 - INFO - [Epoch 130] Val loss: 777.8168 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:11:37,394] [UniVITrainer] [INFO] [Epoch 140] Train loss: 770.6574 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:11:37 - INFO - [Epoch 140] Train loss: 770.6574 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:11:38,229] [UniVITrainer] [INFO] [Epoch 140] Val loss: 792.2603 (beta=400.000, gamma=100.000)\n",
      "2025-11-20 05:11:38 - INFO - [Epoch 140] Val loss: 792.2603 (beta=400.000, gamma=100.000)\n",
      "[2025-11-20 05:12:00,076] [UniVITrainer] [INFO] Early stopping at epoch 143 (best val loss = 772.3880)\n",
      "2025-11-20 05:12:00 - INFO - Early stopping at epoch 143 (best val loss = 772.3880)\n",
      "[2025-11-20 05:12:00,116] [UniVITrainer] [INFO] Restored best model from epoch 123 (val loss = 772.3880)\n",
      "2025-11-20 05:12:00 - INFO - Restored best model from epoch 123 (val loss = 772.3880)\n",
      "[2025-11-20 05:12:02,300] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 05:12:02 - INFO - TrainingConfig:\n",
      "[2025-11-20 05:12:02,302] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 05:12:02 - INFO -   n_epochs: 200\n",
      "[2025-11-20 05:12:02,307] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 05:12:02 - INFO -   batch_size: 256\n",
      "[2025-11-20 05:12:02,316] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 05:12:02 - INFO -   lr: 0.0005\n",
      "[2025-11-20 05:12:02,317] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 05:12:02 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 05:12:02,325] [UniVITrainer] [INFO]   device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 05:12:02 - INFO -   device: cuda\n",
      "[2025-11-20 05:12:02,326] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 05:12:02 - INFO -   log_every: 10\n",
      "[2025-11-20 05:12:02,327] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 05:12:02 - INFO -   grad_clip: None\n",
      "[2025-11-20 05:12:02,328] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 05:12:02 - INFO -   num_workers: 0\n",
      "[2025-11-20 05:12:02,330] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 05:12:02 - INFO -   seed: 42\n",
      "[2025-11-20 05:12:02,331] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 05:12:02 - INFO -   early_stopping: True\n",
      "[2025-11-20 05:12:02,332] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 05:12:02 - INFO -   patience: 20\n",
      "[2025-11-20 05:12:02,334] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 05:12:02 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 17] Done in 17.5 min\n",
      "  best_val_loss              = 772.388\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.6448\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4868\n",
      "[Config 17] FOSCTTM (ADT vs ATAC, val) = 0.5055\n",
      "  Mean FOSCTTM (3 pairs)     = 0.5457\n",
      "  Modality mixing (k=20)     = 0.0003\n",
      "  Composite score            = 1194.29\n",
      "\n",
      "================================================================================\n",
      "[Config 18] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 50,\n",
      "  \"beta\": 300.0,\n",
      "  \"gamma\": 300.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_med2\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_wide2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8c42bc1be6452f823b2475afa7daa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 05:12:08,585] [UniVITrainer] [INFO] [Epoch 001] Train loss: 5734.4715 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:12:08 - INFO - [Epoch 001] Train loss: 5734.4715 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:12:09,421] [UniVITrainer] [INFO] [Epoch 001] Val loss: 2641.1670 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:12:09 - INFO - [Epoch 001] Val loss: 2641.1670 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:12:09,620] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 2641.1670\n",
      "2025-11-20 05:12:09 - INFO - [Epoch 001] New best val loss: 2641.1670\n",
      "[2025-11-20 05:12:15,944] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1348.9335\n",
      "2025-11-20 05:12:15 - INFO - [Epoch 002] New best val loss: 1348.9335\n",
      "[2025-11-20 05:12:21,846] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1070.5120\n",
      "2025-11-20 05:12:21 - INFO - [Epoch 003] New best val loss: 1070.5120\n",
      "[2025-11-20 05:12:29,268] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 961.1479\n",
      "2025-11-20 05:12:29 - INFO - [Epoch 004] New best val loss: 961.1479\n",
      "[2025-11-20 05:12:36,477] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 917.2750\n",
      "2025-11-20 05:12:36 - INFO - [Epoch 005] New best val loss: 917.2750\n",
      "[2025-11-20 05:12:43,482] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 886.8890\n",
      "2025-11-20 05:12:43 - INFO - [Epoch 006] New best val loss: 886.8890\n",
      "[2025-11-20 05:12:51,378] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 869.9447\n",
      "2025-11-20 05:12:51 - INFO - [Epoch 007] New best val loss: 869.9447\n",
      "[2025-11-20 05:12:58,493] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 856.3043\n",
      "2025-11-20 05:12:58 - INFO - [Epoch 008] New best val loss: 856.3043\n",
      "[2025-11-20 05:13:05,620] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 846.3114\n",
      "2025-11-20 05:13:05 - INFO - [Epoch 009] New best val loss: 846.3114\n",
      "[2025-11-20 05:13:12,035] [UniVITrainer] [INFO] [Epoch 010] Train loss: 1005.9072 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:13:12 - INFO - [Epoch 010] Train loss: 1005.9072 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:13:12,491] [UniVITrainer] [INFO] [Epoch 010] Val loss: 838.4973 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:13:12 - INFO - [Epoch 010] Val loss: 838.4973 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:13:12,506] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 838.4973\n",
      "2025-11-20 05:13:12 - INFO - [Epoch 010] New best val loss: 838.4973\n",
      "[2025-11-20 05:13:20,312] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 834.2851\n",
      "2025-11-20 05:13:20 - INFO - [Epoch 011] New best val loss: 834.2851\n",
      "[2025-11-20 05:13:28,001] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 828.0716\n",
      "2025-11-20 05:13:28 - INFO - [Epoch 012] New best val loss: 828.0716\n",
      "[2025-11-20 05:13:35,706] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 824.6127\n",
      "2025-11-20 05:13:35 - INFO - [Epoch 013] New best val loss: 824.6127\n",
      "[2025-11-20 05:13:43,288] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 820.0699\n",
      "2025-11-20 05:13:43 - INFO - [Epoch 014] New best val loss: 820.0699\n",
      "[2025-11-20 05:13:51,300] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 816.1620\n",
      "2025-11-20 05:13:51 - INFO - [Epoch 015] New best val loss: 816.1620\n",
      "[2025-11-20 05:13:58,851] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 815.5846\n",
      "2025-11-20 05:13:58 - INFO - [Epoch 016] New best val loss: 815.5846\n",
      "[2025-11-20 05:14:06,379] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 814.4069\n",
      "2025-11-20 05:14:06 - INFO - [Epoch 017] New best val loss: 814.4069\n",
      "[2025-11-20 05:14:14,029] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 810.3577\n",
      "2025-11-20 05:14:14 - INFO - [Epoch 018] New best val loss: 810.3577\n",
      "[2025-11-20 05:14:21,225] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 809.6174\n",
      "2025-11-20 05:14:21 - INFO - [Epoch 019] New best val loss: 809.6174\n",
      "[2025-11-20 05:14:28,149] [UniVITrainer] [INFO] [Epoch 020] Train loss: 875.6079 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:14:28 - INFO - [Epoch 020] Train loss: 875.6079 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:14:28,989] [UniVITrainer] [INFO] [Epoch 020] Val loss: 808.7237 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:14:28 - INFO - [Epoch 020] Val loss: 808.7237 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:14:29,197] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 808.7237\n",
      "2025-11-20 05:14:29 - INFO - [Epoch 020] New best val loss: 808.7237\n",
      "[2025-11-20 05:14:36,878] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 804.3173\n",
      "2025-11-20 05:14:36 - INFO - [Epoch 021] New best val loss: 804.3173\n",
      "[2025-11-20 05:14:44,817] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 803.4207\n",
      "2025-11-20 05:14:44 - INFO - [Epoch 022] New best val loss: 803.4207\n",
      "[2025-11-20 05:15:00,044] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 801.6535\n",
      "2025-11-20 05:15:00 - INFO - [Epoch 024] New best val loss: 801.6535\n",
      "[2025-11-20 05:15:08,015] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 801.1270\n",
      "2025-11-20 05:15:08 - INFO - [Epoch 025] New best val loss: 801.1270\n",
      "[2025-11-20 05:15:15,862] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 798.5175\n",
      "2025-11-20 05:15:15 - INFO - [Epoch 026] New best val loss: 798.5175\n",
      "[2025-11-20 05:15:23,642] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 796.5869\n",
      "2025-11-20 05:15:23 - INFO - [Epoch 027] New best val loss: 796.5869\n",
      "[2025-11-20 05:15:39,363] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 796.5131\n",
      "2025-11-20 05:15:39 - INFO - [Epoch 029] New best val loss: 796.5131\n",
      "[2025-11-20 05:15:45,652] [UniVITrainer] [INFO] [Epoch 030] Train loss: 827.4712 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:15:45 - INFO - [Epoch 030] Train loss: 827.4712 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:15:46,488] [UniVITrainer] [INFO] [Epoch 030] Val loss: 794.1388 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:15:46 - INFO - [Epoch 030] Val loss: 794.1388 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:15:46,707] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 794.1388\n",
      "2025-11-20 05:15:46 - INFO - [Epoch 030] New best val loss: 794.1388\n",
      "[2025-11-20 05:16:10,107] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 793.9540\n",
      "2025-11-20 05:16:10 - INFO - [Epoch 033] New best val loss: 793.9540\n",
      "[2025-11-20 05:16:17,983] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 792.8731\n",
      "2025-11-20 05:16:17 - INFO - [Epoch 034] New best val loss: 792.8731\n",
      "[2025-11-20 05:16:25,984] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 792.7222\n",
      "2025-11-20 05:16:25 - INFO - [Epoch 035] New best val loss: 792.7222\n",
      "[2025-11-20 05:16:33,838] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 791.0069\n",
      "2025-11-20 05:16:33 - INFO - [Epoch 036] New best val loss: 791.0069\n",
      "[2025-11-20 05:16:49,104] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 789.8257\n",
      "2025-11-20 05:16:49 - INFO - [Epoch 038] New best val loss: 789.8257\n",
      "[2025-11-20 05:16:56,931] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 789.6390\n",
      "2025-11-20 05:16:56 - INFO - [Epoch 039] New best val loss: 789.6390\n",
      "[2025-11-20 05:17:03,456] [UniVITrainer] [INFO] [Epoch 040] Train loss: 804.2016 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:17:03 - INFO - [Epoch 040] Train loss: 804.2016 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:17:04,212] [UniVITrainer] [INFO] [Epoch 040] Val loss: 788.4830 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:17:04 - INFO - [Epoch 040] Val loss: 788.4830 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:17:04,408] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 788.4830\n",
      "2025-11-20 05:17:04 - INFO - [Epoch 040] New best val loss: 788.4830\n",
      "[2025-11-20 05:17:19,169] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 787.5989\n",
      "2025-11-20 05:17:19 - INFO - [Epoch 042] New best val loss: 787.5989\n",
      "[2025-11-20 05:17:49,756] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 787.0971\n",
      "2025-11-20 05:17:49 - INFO - [Epoch 046] New best val loss: 787.0971\n",
      "[2025-11-20 05:18:05,358] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 785.6143\n",
      "2025-11-20 05:18:05 - INFO - [Epoch 048] New best val loss: 785.6143\n",
      "[2025-11-20 05:18:19,596] [UniVITrainer] [INFO] [Epoch 050] Train loss: 792.1282 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:18:19 - INFO - [Epoch 050] Train loss: 792.1282 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:18:20,429] [UniVITrainer] [INFO] [Epoch 050] Val loss: 785.4802 (beta=300.000, gamma=300.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 05:18:20 - INFO - [Epoch 050] Val loss: 785.4802 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:18:20,638] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 785.4802\n",
      "2025-11-20 05:18:20 - INFO - [Epoch 050] New best val loss: 785.4802\n",
      "[2025-11-20 05:18:42,686] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 784.2936\n",
      "2025-11-20 05:18:42 - INFO - [Epoch 053] New best val loss: 784.2936\n",
      "[2025-11-20 05:19:02,703] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 783.7566\n",
      "2025-11-20 05:19:02 - INFO - [Epoch 056] New best val loss: 783.7566\n",
      "[2025-11-20 05:19:17,166] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 783.1834\n",
      "2025-11-20 05:19:17 - INFO - [Epoch 058] New best val loss: 783.1834\n",
      "[2025-11-20 05:19:24,707] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 783.1524\n",
      "2025-11-20 05:19:24 - INFO - [Epoch 059] New best val loss: 783.1524\n",
      "[2025-11-20 05:19:31,433] [UniVITrainer] [INFO] [Epoch 060] Train loss: 787.3987 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:19:31 - INFO - [Epoch 060] Train loss: 787.3987 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:19:32,233] [UniVITrainer] [INFO] [Epoch 060] Val loss: 783.5279 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:19:32 - INFO - [Epoch 060] Val loss: 783.5279 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:19:38,999] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 782.1431\n",
      "2025-11-20 05:19:38 - INFO - [Epoch 061] New best val loss: 782.1431\n",
      "[2025-11-20 05:20:14,069] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 782.0584\n",
      "2025-11-20 05:20:14 - INFO - [Epoch 066] New best val loss: 782.0584\n",
      "[2025-11-20 05:20:35,184] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 781.7170\n",
      "2025-11-20 05:20:35 - INFO - [Epoch 069] New best val loss: 781.7170\n",
      "[2025-11-20 05:20:41,743] [UniVITrainer] [INFO] [Epoch 070] Train loss: 783.1903 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:20:41 - INFO - [Epoch 070] Train loss: 783.1903 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:20:42,550] [UniVITrainer] [INFO] [Epoch 070] Val loss: 781.5187 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:20:42 - INFO - [Epoch 070] Val loss: 781.5187 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:20:42,749] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 781.5187\n",
      "2025-11-20 05:20:42 - INFO - [Epoch 070] New best val loss: 781.5187\n",
      "[2025-11-20 05:20:50,155] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 781.3821\n",
      "2025-11-20 05:20:50 - INFO - [Epoch 071] New best val loss: 781.3821\n",
      "[2025-11-20 05:21:12,170] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 780.6264\n",
      "2025-11-20 05:21:12 - INFO - [Epoch 074] New best val loss: 780.6264\n",
      "[2025-11-20 05:21:40,725] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 780.6221\n",
      "2025-11-20 05:21:40 - INFO - [Epoch 078] New best val loss: 780.6221\n",
      "[2025-11-20 05:21:48,188] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 780.3596\n",
      "2025-11-20 05:21:48 - INFO - [Epoch 079] New best val loss: 780.3596\n",
      "[2025-11-20 05:21:54,934] [UniVITrainer] [INFO] [Epoch 080] Train loss: 778.9097 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:21:54 - INFO - [Epoch 080] Train loss: 778.9097 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:21:55,741] [UniVITrainer] [INFO] [Epoch 080] Val loss: 781.1792 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:21:55 - INFO - [Epoch 080] Val loss: 781.1792 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:22:17,844] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 780.2270\n",
      "2025-11-20 05:22:17 - INFO - [Epoch 083] New best val loss: 780.2270\n",
      "[2025-11-20 05:22:38,680] [UniVITrainer] [INFO] [Epoch 086] New best val loss: 779.3023\n",
      "2025-11-20 05:22:38 - INFO - [Epoch 086] New best val loss: 779.3023\n",
      "[2025-11-20 05:22:53,761] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 779.0340\n",
      "2025-11-20 05:22:53 - INFO - [Epoch 088] New best val loss: 779.0340\n",
      "[2025-11-20 05:23:07,875] [UniVITrainer] [INFO] [Epoch 090] Train loss: 773.1306 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:23:07 - INFO - [Epoch 090] Train loss: 773.1306 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:23:08,683] [UniVITrainer] [INFO] [Epoch 090] Val loss: 779.3425 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:23:08 - INFO - [Epoch 090] Val loss: 779.3425 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:23:30,341] [UniVITrainer] [INFO] [Epoch 093] New best val loss: 778.7402\n",
      "2025-11-20 05:23:30 - INFO - [Epoch 093] New best val loss: 778.7402\n",
      "[2025-11-20 05:23:52,015] [UniVITrainer] [INFO] [Epoch 096] New best val loss: 778.4752\n",
      "2025-11-20 05:23:52 - INFO - [Epoch 096] New best val loss: 778.4752\n",
      "[2025-11-20 05:23:59,746] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 778.2961\n",
      "2025-11-20 05:23:59 - INFO - [Epoch 097] New best val loss: 778.2961\n",
      "[2025-11-20 05:24:21,472] [UniVITrainer] [INFO] [Epoch 100] Train loss: 774.4647 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:24:21 - INFO - [Epoch 100] Train loss: 774.4647 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:24:22,283] [UniVITrainer] [INFO] [Epoch 100] Val loss: 778.3991 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:24:22 - INFO - [Epoch 100] Val loss: 778.3991 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:24:52,079] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 778.0999\n",
      "2025-11-20 05:24:52 - INFO - [Epoch 104] New best val loss: 778.0999\n",
      "[2025-11-20 05:25:06,638] [UniVITrainer] [INFO] [Epoch 106] New best val loss: 777.8884\n",
      "2025-11-20 05:25:06 - INFO - [Epoch 106] New best val loss: 777.8884\n",
      "[2025-11-20 05:25:19,592] [UniVITrainer] [INFO] [Epoch 108] New best val loss: 777.4383\n",
      "2025-11-20 05:25:19 - INFO - [Epoch 108] New best val loss: 777.4383\n",
      "[2025-11-20 05:25:32,397] [UniVITrainer] [INFO] [Epoch 110] Train loss: 770.7927 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:25:32 - INFO - [Epoch 110] Train loss: 770.7927 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:25:33,200] [UniVITrainer] [INFO] [Epoch 110] Val loss: 777.8543 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:25:33 - INFO - [Epoch 110] Val loss: 777.8543 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:25:48,126] [UniVITrainer] [INFO] [Epoch 112] New best val loss: 777.3337\n",
      "2025-11-20 05:25:48 - INFO - [Epoch 112] New best val loss: 777.3337\n",
      "[2025-11-20 05:25:55,468] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 777.2824\n",
      "2025-11-20 05:25:55 - INFO - [Epoch 113] New best val loss: 777.2824\n",
      "[2025-11-20 05:26:02,093] [UniVITrainer] [INFO] [Epoch 114] New best val loss: 777.2417\n",
      "2025-11-20 05:26:02 - INFO - [Epoch 114] New best val loss: 777.2417\n",
      "[2025-11-20 05:26:31,731] [UniVITrainer] [INFO] [Epoch 118] New best val loss: 776.7133\n",
      "2025-11-20 05:26:31 - INFO - [Epoch 118] New best val loss: 776.7133\n",
      "[2025-11-20 05:26:45,615] [UniVITrainer] [INFO] [Epoch 120] Train loss: 767.5041 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:26:45 - INFO - [Epoch 120] Train loss: 767.5041 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:26:46,415] [UniVITrainer] [INFO] [Epoch 120] Val loss: 777.1264 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:26:46 - INFO - [Epoch 120] Val loss: 777.1264 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:26:53,959] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 776.6490\n",
      "2025-11-20 05:26:53 - INFO - [Epoch 121] New best val loss: 776.6490\n",
      "[2025-11-20 05:27:16,519] [UniVITrainer] [INFO] [Epoch 124] New best val loss: 776.6375\n",
      "2025-11-20 05:27:16 - INFO - [Epoch 124] New best val loss: 776.6375\n",
      "[2025-11-20 05:27:38,555] [UniVITrainer] [INFO] [Epoch 127] New best val loss: 776.6096\n",
      "2025-11-20 05:27:38 - INFO - [Epoch 127] New best val loss: 776.6096\n",
      "[2025-11-20 05:27:46,242] [UniVITrainer] [INFO] [Epoch 128] New best val loss: 776.3677\n",
      "2025-11-20 05:27:46 - INFO - [Epoch 128] New best val loss: 776.3677\n",
      "[2025-11-20 05:27:59,533] [UniVITrainer] [INFO] [Epoch 130] Train loss: 768.5462 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:27:59 - INFO - [Epoch 130] Train loss: 768.5462 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:28:00,335] [UniVITrainer] [INFO] [Epoch 130] Val loss: 776.5190 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:28:00 - INFO - [Epoch 130] Val loss: 776.5190 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:28:07,754] [UniVITrainer] [INFO] [Epoch 131] New best val loss: 776.1614\n",
      "2025-11-20 05:28:07 - INFO - [Epoch 131] New best val loss: 776.1614\n",
      "[2025-11-20 05:28:43,887] [UniVITrainer] [INFO] [Epoch 136] New best val loss: 775.4063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 05:28:43 - INFO - [Epoch 136] New best val loss: 775.4063\n",
      "[2025-11-20 05:29:12,253] [UniVITrainer] [INFO] [Epoch 140] Train loss: 771.0152 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:29:12 - INFO - [Epoch 140] Train loss: 771.0152 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:29:13,055] [UniVITrainer] [INFO] [Epoch 140] Val loss: 776.1035 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:29:13 - INFO - [Epoch 140] Val loss: 776.1035 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:29:50,431] [UniVITrainer] [INFO] [Epoch 145] New best val loss: 775.0332\n",
      "2025-11-20 05:29:50 - INFO - [Epoch 145] New best val loss: 775.0332\n",
      "[2025-11-20 05:30:26,046] [UniVITrainer] [INFO] [Epoch 150] Train loss: 767.6386 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:30:26 - INFO - [Epoch 150] Train loss: 767.6386 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:30:26,854] [UniVITrainer] [INFO] [Epoch 150] Val loss: 776.4685 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:30:26 - INFO - [Epoch 150] Val loss: 776.4685 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:30:48,479] [UniVITrainer] [INFO] [Epoch 153] New best val loss: 774.7656\n",
      "2025-11-20 05:30:48 - INFO - [Epoch 153] New best val loss: 774.7656\n",
      "[2025-11-20 05:31:39,641] [UniVITrainer] [INFO] [Epoch 160] Train loss: 770.7633 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:31:39 - INFO - [Epoch 160] Train loss: 770.7633 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:31:40,441] [UniVITrainer] [INFO] [Epoch 160] Val loss: 774.2055 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:31:40 - INFO - [Epoch 160] Val loss: 774.2055 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:31:40,636] [UniVITrainer] [INFO] [Epoch 160] New best val loss: 774.2055\n",
      "2025-11-20 05:31:40 - INFO - [Epoch 160] New best val loss: 774.2055\n",
      "[2025-11-20 05:32:01,369] [UniVITrainer] [INFO] [Epoch 163] New best val loss: 773.5495\n",
      "2025-11-20 05:32:01 - INFO - [Epoch 163] New best val loss: 773.5495\n",
      "[2025-11-20 05:32:35,652] [UniVITrainer] [INFO] [Epoch 168] New best val loss: 773.5409\n",
      "2025-11-20 05:32:35 - INFO - [Epoch 168] New best val loss: 773.5409\n",
      "[2025-11-20 05:32:43,112] [UniVITrainer] [INFO] [Epoch 169] New best val loss: 773.4400\n",
      "2025-11-20 05:32:43 - INFO - [Epoch 169] New best val loss: 773.4400\n",
      "[2025-11-20 05:32:49,813] [UniVITrainer] [INFO] [Epoch 170] Train loss: 766.3263 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:32:49 - INFO - [Epoch 170] Train loss: 766.3263 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:32:50,615] [UniVITrainer] [INFO] [Epoch 170] Val loss: 774.0593 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:32:50 - INFO - [Epoch 170] Val loss: 774.0593 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:33:25,665] [UniVITrainer] [INFO] [Epoch 175] New best val loss: 773.1859\n",
      "2025-11-20 05:33:25 - INFO - [Epoch 175] New best val loss: 773.1859\n",
      "[2025-11-20 05:34:00,668] [UniVITrainer] [INFO] [Epoch 180] Train loss: 767.2097 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:34:00 - INFO - [Epoch 180] Train loss: 767.2097 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:34:01,459] [UniVITrainer] [INFO] [Epoch 180] Val loss: 773.1318 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:34:01 - INFO - [Epoch 180] Val loss: 773.1318 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:34:01,665] [UniVITrainer] [INFO] [Epoch 180] New best val loss: 773.1318\n",
      "2025-11-20 05:34:01 - INFO - [Epoch 180] New best val loss: 773.1318\n",
      "[2025-11-20 05:34:09,352] [UniVITrainer] [INFO] [Epoch 181] New best val loss: 773.0154\n",
      "2025-11-20 05:34:09 - INFO - [Epoch 181] New best val loss: 773.0154\n",
      "[2025-11-20 05:34:30,450] [UniVITrainer] [INFO] [Epoch 184] New best val loss: 772.2376\n",
      "2025-11-20 05:34:30 - INFO - [Epoch 184] New best val loss: 772.2376\n",
      "[2025-11-20 05:35:12,889] [UniVITrainer] [INFO] [Epoch 190] Train loss: 765.9149 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:35:12 - INFO - [Epoch 190] Train loss: 765.9149 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:35:13,699] [UniVITrainer] [INFO] [Epoch 190] Val loss: 772.5700 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:35:13 - INFO - [Epoch 190] Val loss: 772.5700 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:35:41,360] [UniVITrainer] [INFO] [Epoch 194] New best val loss: 772.0684\n",
      "2025-11-20 05:35:41 - INFO - [Epoch 194] New best val loss: 772.0684\n",
      "[2025-11-20 05:35:48,707] [UniVITrainer] [INFO] [Epoch 195] New best val loss: 772.0273\n",
      "2025-11-20 05:35:48 - INFO - [Epoch 195] New best val loss: 772.0273\n",
      "[2025-11-20 05:36:17,062] [UniVITrainer] [INFO] [Epoch 199] New best val loss: 771.8677\n",
      "2025-11-20 05:36:17 - INFO - [Epoch 199] New best val loss: 771.8677\n",
      "[2025-11-20 05:36:23,602] [UniVITrainer] [INFO] [Epoch 200] Train loss: 766.1963 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:36:23 - INFO - [Epoch 200] Train loss: 766.1963 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:36:24,408] [UniVITrainer] [INFO] [Epoch 200] Val loss: 772.9853 (beta=300.000, gamma=300.000)\n",
      "2025-11-20 05:36:24 - INFO - [Epoch 200] Val loss: 772.9853 (beta=300.000, gamma=300.000)\n",
      "[2025-11-20 05:36:24,437] [UniVITrainer] [INFO] Restored best model from epoch 199 (val loss = 771.8677)\n",
      "2025-11-20 05:36:24 - INFO - Restored best model from epoch 199 (val loss = 771.8677)\n",
      "[2025-11-20 05:36:26,886] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 05:36:26 - INFO - TrainingConfig:\n",
      "[2025-11-20 05:36:26,889] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 05:36:26 - INFO -   n_epochs: 200\n",
      "[2025-11-20 05:36:26,894] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 05:36:26 - INFO -   batch_size: 256\n",
      "[2025-11-20 05:36:26,901] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 05:36:26 - INFO -   lr: 0.0005\n",
      "[2025-11-20 05:36:26,905] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 05:36:26 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 05:36:26,911] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 05:36:26 - INFO -   device: cuda\n",
      "[2025-11-20 05:36:26,913] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 05:36:26 - INFO -   log_every: 10\n",
      "[2025-11-20 05:36:26,915] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 05:36:26 - INFO -   grad_clip: None\n",
      "[2025-11-20 05:36:26,917] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 05:36:26 - INFO -   num_workers: 0\n",
      "[2025-11-20 05:36:26,919] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 05:36:26 - INFO -   seed: 42\n",
      "[2025-11-20 05:36:26,921] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 05:36:26 - INFO -   early_stopping: True\n",
      "[2025-11-20 05:36:26,922] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 05:36:26 - INFO -   patience: 20\n",
      "[2025-11-20 05:36:26,924] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 05:36:26 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 18] Done in 24.4 min\n",
      "  best_val_loss              = 771.868\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4995\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4898\n",
      "[Config 18] FOSCTTM (ADT vs ATAC, val) = 0.4922\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4938\n",
      "  Modality mixing (k=20)     = 0.0088\n",
      "  Composite score            = 1163.23\n",
      "\n",
      "================================================================================\n",
      "[Config 19] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 200,\n",
      "  \"beta\": 1000.0,\n",
      "  \"gamma\": 300.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.0,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_wide2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa6f395f6774ac9955ee1126dcf50cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 05:36:33,518] [UniVITrainer] [INFO] [Epoch 001] Train loss: 37377.3228 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:36:33 - INFO - [Epoch 001] Train loss: 37377.3228 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:36:34,312] [UniVITrainer] [INFO] [Epoch 001] Val loss: 16094.8968 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:36:34 - INFO - [Epoch 001] Val loss: 16094.8968 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:36:34,655] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 16094.8968\n",
      "2025-11-20 05:36:34 - INFO - [Epoch 001] New best val loss: 16094.8968\n",
      "[2025-11-20 05:36:42,305] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 4472.1134\n",
      "2025-11-20 05:36:42 - INFO - [Epoch 002] New best val loss: 4472.1134\n",
      "[2025-11-20 05:36:49,565] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 2546.8315\n",
      "2025-11-20 05:36:49 - INFO - [Epoch 003] New best val loss: 2546.8315\n",
      "[2025-11-20 05:36:57,456] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 1931.2391\n",
      "2025-11-20 05:36:57 - INFO - [Epoch 004] New best val loss: 1931.2391\n",
      "[2025-11-20 05:37:04,448] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 1666.6809\n",
      "2025-11-20 05:37:04 - INFO - [Epoch 005] New best val loss: 1666.6809\n",
      "[2025-11-20 05:37:11,889] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 1496.4749\n",
      "2025-11-20 05:37:11 - INFO - [Epoch 006] New best val loss: 1496.4749\n",
      "[2025-11-20 05:37:19,559] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 1378.0500\n",
      "2025-11-20 05:37:19 - INFO - [Epoch 007] New best val loss: 1378.0500\n",
      "[2025-11-20 05:37:26,272] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 1318.8993\n",
      "2025-11-20 05:37:26 - INFO - [Epoch 008] New best val loss: 1318.8993\n",
      "[2025-11-20 05:37:34,171] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 1258.4990\n",
      "2025-11-20 05:37:34 - INFO - [Epoch 009] New best val loss: 1258.4990\n",
      "[2025-11-20 05:37:40,682] [UniVITrainer] [INFO] [Epoch 010] Train loss: 1130.1561 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:37:40 - INFO - [Epoch 010] Train loss: 1130.1561 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:37:41,490] [UniVITrainer] [INFO] [Epoch 010] Val loss: 1215.5246 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:37:41 - INFO - [Epoch 010] Val loss: 1215.5246 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:37:41,853] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 1215.5246\n",
      "2025-11-20 05:37:41 - INFO - [Epoch 010] New best val loss: 1215.5246\n",
      "[2025-11-20 05:37:49,448] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 1184.1235\n",
      "2025-11-20 05:37:49 - INFO - [Epoch 011] New best val loss: 1184.1235\n",
      "[2025-11-20 05:37:57,094] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 1154.8909\n",
      "2025-11-20 05:37:57 - INFO - [Epoch 012] New best val loss: 1154.8909\n",
      "[2025-11-20 05:38:05,006] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 1142.8835\n",
      "2025-11-20 05:38:05 - INFO - [Epoch 013] New best val loss: 1142.8835\n",
      "[2025-11-20 05:38:12,631] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 1122.1045\n",
      "2025-11-20 05:38:12 - INFO - [Epoch 014] New best val loss: 1122.1045\n",
      "[2025-11-20 05:38:19,425] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 1116.4293\n",
      "2025-11-20 05:38:19 - INFO - [Epoch 015] New best val loss: 1116.4293\n",
      "[2025-11-20 05:38:26,856] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 1101.6470\n",
      "2025-11-20 05:38:26 - INFO - [Epoch 016] New best val loss: 1101.6470\n",
      "[2025-11-20 05:38:34,185] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 1079.5597\n",
      "2025-11-20 05:38:34 - INFO - [Epoch 017] New best val loss: 1079.5597\n",
      "[2025-11-20 05:38:47,119] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 1065.5451\n",
      "2025-11-20 05:38:47 - INFO - [Epoch 019] New best val loss: 1065.5451\n",
      "[2025-11-20 05:38:53,774] [UniVITrainer] [INFO] [Epoch 020] Train loss: 917.5278 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:38:53 - INFO - [Epoch 020] Train loss: 917.5278 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:38:54,538] [UniVITrainer] [INFO] [Epoch 020] Val loss: 1059.9712 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:38:54 - INFO - [Epoch 020] Val loss: 1059.9712 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:38:54,984] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 1059.9712\n",
      "2025-11-20 05:38:54 - INFO - [Epoch 020] New best val loss: 1059.9712\n",
      "[2025-11-20 05:39:03,215] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 1039.2183\n",
      "2025-11-20 05:39:03 - INFO - [Epoch 021] New best val loss: 1039.2183\n",
      "[2025-11-20 05:39:18,333] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 1037.8528\n",
      "2025-11-20 05:39:18 - INFO - [Epoch 023] New best val loss: 1037.8528\n",
      "[2025-11-20 05:39:26,087] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 1025.1167\n",
      "2025-11-20 05:39:26 - INFO - [Epoch 024] New best val loss: 1025.1167\n",
      "[2025-11-20 05:39:33,107] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 1019.7641\n",
      "2025-11-20 05:39:33 - INFO - [Epoch 025] New best val loss: 1019.7641\n",
      "[2025-11-20 05:39:40,730] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 1008.5498\n",
      "2025-11-20 05:39:40 - INFO - [Epoch 026] New best val loss: 1008.5498\n",
      "[2025-11-20 05:39:48,500] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 1005.8988\n",
      "2025-11-20 05:39:48 - INFO - [Epoch 027] New best val loss: 1005.8988\n",
      "[2025-11-20 05:39:55,944] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 1004.6635\n",
      "2025-11-20 05:39:55 - INFO - [Epoch 028] New best val loss: 1004.6635\n",
      "[2025-11-20 05:40:03,797] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 1003.5095\n",
      "2025-11-20 05:40:03 - INFO - [Epoch 029] New best val loss: 1003.5095\n",
      "[2025-11-20 05:40:10,808] [UniVITrainer] [INFO] [Epoch 030] Train loss: 857.6821 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:40:10 - INFO - [Epoch 030] Train loss: 857.6821 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:40:11,644] [UniVITrainer] [INFO] [Epoch 030] Val loss: 996.1914 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:40:11 - INFO - [Epoch 030] Val loss: 996.1914 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:40:11,989] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 996.1914\n",
      "2025-11-20 05:40:11 - INFO - [Epoch 030] New best val loss: 996.1914\n",
      "[2025-11-20 05:40:18,038] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 993.9719\n",
      "2025-11-20 05:40:18 - INFO - [Epoch 031] New best val loss: 993.9719\n",
      "[2025-11-20 05:40:32,454] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 987.0593\n",
      "2025-11-20 05:40:32 - INFO - [Epoch 033] New best val loss: 987.0593\n",
      "[2025-11-20 05:40:39,940] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 981.7755\n",
      "2025-11-20 05:40:39 - INFO - [Epoch 034] New best val loss: 981.7755\n",
      "[2025-11-20 05:40:47,806] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 980.2686\n",
      "2025-11-20 05:40:47 - INFO - [Epoch 035] New best val loss: 980.2686\n",
      "[2025-11-20 05:40:55,969] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 979.6408\n",
      "2025-11-20 05:40:55 - INFO - [Epoch 036] New best val loss: 979.6408\n",
      "[2025-11-20 05:41:04,077] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 974.7327\n",
      "2025-11-20 05:41:04 - INFO - [Epoch 037] New best val loss: 974.7327\n",
      "[2025-11-20 05:41:19,710] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 968.7266\n",
      "2025-11-20 05:41:19 - INFO - [Epoch 039] New best val loss: 968.7266\n",
      "[2025-11-20 05:41:26,615] [UniVITrainer] [INFO] [Epoch 040] Train loss: 825.9745 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:41:26 - INFO - [Epoch 040] Train loss: 825.9745 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:41:27,448] [UniVITrainer] [INFO] [Epoch 040] Val loss: 967.1619 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:41:27 - INFO - [Epoch 040] Val loss: 967.1619 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:41:27,483] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 967.1619\n",
      "2025-11-20 05:41:27 - INFO - [Epoch 040] New best val loss: 967.1619\n",
      "[2025-11-20 05:41:41,909] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 957.5295\n",
      "2025-11-20 05:41:41 - INFO - [Epoch 042] New best val loss: 957.5295\n",
      "[2025-11-20 05:42:04,701] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 953.0980\n",
      "2025-11-20 05:42:04 - INFO - [Epoch 045] New best val loss: 953.0980\n",
      "[2025-11-20 05:42:20,416] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 950.7940\n",
      "2025-11-20 05:42:20 - INFO - [Epoch 047] New best val loss: 950.7940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 05:42:27,596] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 944.4327\n",
      "2025-11-20 05:42:27 - INFO - [Epoch 048] New best val loss: 944.4327\n",
      "[2025-11-20 05:42:41,581] [UniVITrainer] [INFO] [Epoch 050] Train loss: 810.7212 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:42:41 - INFO - [Epoch 050] Train loss: 810.7212 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:42:42,417] [UniVITrainer] [INFO] [Epoch 050] Val loss: 944.7485 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:42:42 - INFO - [Epoch 050] Val loss: 944.7485 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:42:57,825] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 939.9303\n",
      "2025-11-20 05:42:57 - INFO - [Epoch 052] New best val loss: 939.9303\n",
      "[2025-11-20 05:43:05,947] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 939.8447\n",
      "2025-11-20 05:43:05 - INFO - [Epoch 053] New best val loss: 939.8447\n",
      "[2025-11-20 05:43:14,103] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 936.9316\n",
      "2025-11-20 05:43:14 - INFO - [Epoch 054] New best val loss: 936.9316\n",
      "[2025-11-20 05:43:21,902] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 931.0699\n",
      "2025-11-20 05:43:21 - INFO - [Epoch 055] New best val loss: 931.0699\n",
      "[2025-11-20 05:43:36,966] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 929.5532\n",
      "2025-11-20 05:43:36 - INFO - [Epoch 057] New best val loss: 929.5532\n",
      "[2025-11-20 05:43:52,842] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 928.8281\n",
      "2025-11-20 05:43:52 - INFO - [Epoch 059] New best val loss: 928.8281\n",
      "[2025-11-20 05:43:59,582] [UniVITrainer] [INFO] [Epoch 060] Train loss: 802.8364 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:43:59 - INFO - [Epoch 060] Train loss: 802.8364 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:44:00,399] [UniVITrainer] [INFO] [Epoch 060] Val loss: 928.6463 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:44:00 - INFO - [Epoch 060] Val loss: 928.6463 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:44:00,439] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 928.6463\n",
      "2025-11-20 05:44:00 - INFO - [Epoch 060] New best val loss: 928.6463\n",
      "[2025-11-20 05:44:08,566] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 928.5777\n",
      "2025-11-20 05:44:08 - INFO - [Epoch 061] New best val loss: 928.5777\n",
      "[2025-11-20 05:44:16,763] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 927.9148\n",
      "2025-11-20 05:44:16 - INFO - [Epoch 062] New best val loss: 927.9148\n",
      "[2025-11-20 05:44:30,327] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 923.7164\n",
      "2025-11-20 05:44:30 - INFO - [Epoch 064] New best val loss: 923.7164\n",
      "[2025-11-20 05:44:44,614] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 922.0088\n",
      "2025-11-20 05:44:44 - INFO - [Epoch 066] New best val loss: 922.0088\n",
      "[2025-11-20 05:44:52,751] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 918.3865\n",
      "2025-11-20 05:44:52 - INFO - [Epoch 067] New best val loss: 918.3865\n",
      "[2025-11-20 05:45:06,773] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 912.7414\n",
      "2025-11-20 05:45:06 - INFO - [Epoch 069] New best val loss: 912.7414\n",
      "[2025-11-20 05:45:13,092] [UniVITrainer] [INFO] [Epoch 070] Train loss: 799.4041 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:45:13 - INFO - [Epoch 070] Train loss: 799.4041 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:45:13,906] [UniVITrainer] [INFO] [Epoch 070] Val loss: 912.8355 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:45:13 - INFO - [Epoch 070] Val loss: 912.8355 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:45:34,150] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 909.9716\n",
      "2025-11-20 05:45:34 - INFO - [Epoch 073] New best val loss: 909.9716\n",
      "[2025-11-20 05:45:41,900] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 903.4806\n",
      "2025-11-20 05:45:41 - INFO - [Epoch 074] New best val loss: 903.4806\n",
      "[2025-11-20 05:46:23,818] [UniVITrainer] [INFO] [Epoch 080] Train loss: 792.9660 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:46:23 - INFO - [Epoch 080] Train loss: 792.9660 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:46:24,436] [UniVITrainer] [INFO] [Epoch 080] Val loss: 905.9675 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:46:24 - INFO - [Epoch 080] Val loss: 905.9675 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:46:32,291] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 899.9115\n",
      "2025-11-20 05:46:32 - INFO - [Epoch 081] New best val loss: 899.9115\n",
      "[2025-11-20 05:46:46,673] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 899.6685\n",
      "2025-11-20 05:46:46 - INFO - [Epoch 083] New best val loss: 899.6685\n",
      "[2025-11-20 05:46:54,510] [UniVITrainer] [INFO] [Epoch 084] New best val loss: 893.0686\n",
      "2025-11-20 05:46:54 - INFO - [Epoch 084] New best val loss: 893.0686\n",
      "[2025-11-20 05:47:33,734] [UniVITrainer] [INFO] [Epoch 090] Train loss: 783.7619 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:47:33 - INFO - [Epoch 090] Train loss: 783.7619 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:47:34,554] [UniVITrainer] [INFO] [Epoch 090] Val loss: 895.1238 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:47:34 - INFO - [Epoch 090] Val loss: 895.1238 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:47:42,361] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 888.7472\n",
      "2025-11-20 05:47:42 - INFO - [Epoch 091] New best val loss: 888.7472\n",
      "[2025-11-20 05:47:50,375] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 887.2044\n",
      "2025-11-20 05:47:50 - INFO - [Epoch 092] New best val loss: 887.2044\n",
      "[2025-11-20 05:47:57,289] [UniVITrainer] [INFO] [Epoch 093] New best val loss: 886.5928\n",
      "2025-11-20 05:47:57 - INFO - [Epoch 093] New best val loss: 886.5928\n",
      "[2025-11-20 05:48:12,492] [UniVITrainer] [INFO] [Epoch 095] New best val loss: 885.8359\n",
      "2025-11-20 05:48:12 - INFO - [Epoch 095] New best val loss: 885.8359\n",
      "[2025-11-20 05:48:26,324] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 885.6063\n",
      "2025-11-20 05:48:26 - INFO - [Epoch 097] New best val loss: 885.6063\n",
      "[2025-11-20 05:48:34,080] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 878.0438\n",
      "2025-11-20 05:48:34 - INFO - [Epoch 098] New best val loss: 878.0438\n",
      "[2025-11-20 05:48:48,259] [UniVITrainer] [INFO] [Epoch 100] Train loss: 783.4274 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:48:48 - INFO - [Epoch 100] Train loss: 783.4274 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:48:49,076] [UniVITrainer] [INFO] [Epoch 100] Val loss: 876.1486 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:48:49 - INFO - [Epoch 100] Val loss: 876.1486 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:48:49,437] [UniVITrainer] [INFO] [Epoch 100] New best val loss: 876.1486\n",
      "2025-11-20 05:48:49 - INFO - [Epoch 100] New best val loss: 876.1486\n",
      "[2025-11-20 05:49:17,761] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 871.9959\n",
      "2025-11-20 05:49:17 - INFO - [Epoch 104] New best val loss: 871.9959\n",
      "[2025-11-20 05:49:37,588] [UniVITrainer] [INFO] [Epoch 107] New best val loss: 870.3322\n",
      "2025-11-20 05:49:37 - INFO - [Epoch 107] New best val loss: 870.3322\n",
      "[2025-11-20 05:49:59,537] [UniVITrainer] [INFO] [Epoch 110] Train loss: 779.5629 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:49:59 - INFO - [Epoch 110] Train loss: 779.5629 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:50:00,354] [UniVITrainer] [INFO] [Epoch 110] Val loss: 870.3111 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:50:00 - INFO - [Epoch 110] Val loss: 870.3111 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:50:00,726] [UniVITrainer] [INFO] [Epoch 110] New best val loss: 870.3111\n",
      "2025-11-20 05:50:00 - INFO - [Epoch 110] New best val loss: 870.3111\n",
      "[2025-11-20 05:50:08,183] [UniVITrainer] [INFO] [Epoch 111] New best val loss: 866.9540\n",
      "2025-11-20 05:50:08 - INFO - [Epoch 111] New best val loss: 866.9540\n",
      "[2025-11-20 05:50:15,573] [UniVITrainer] [INFO] [Epoch 112] New best val loss: 865.1064\n",
      "2025-11-20 05:50:15 - INFO - [Epoch 112] New best val loss: 865.1064\n",
      "[2025-11-20 05:50:51,400] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 862.1533\n",
      "2025-11-20 05:50:51 - INFO - [Epoch 117] New best val loss: 862.1533\n",
      "[2025-11-20 05:51:11,769] [UniVITrainer] [INFO] [Epoch 120] Train loss: 806.8132 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:51:11 - INFO - [Epoch 120] Train loss: 806.8132 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:51:12,587] [UniVITrainer] [INFO] [Epoch 120] Val loss: 860.5443 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:51:12 - INFO - [Epoch 120] Val loss: 860.5443 (beta=1000.000, gamma=300.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 05:51:12,941] [UniVITrainer] [INFO] [Epoch 120] New best val loss: 860.5443\n",
      "2025-11-20 05:51:12 - INFO - [Epoch 120] New best val loss: 860.5443\n",
      "[2025-11-20 05:51:19,315] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 856.1553\n",
      "2025-11-20 05:51:19 - INFO - [Epoch 121] New best val loss: 856.1553\n",
      "[2025-11-20 05:51:34,843] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 848.7888\n",
      "2025-11-20 05:51:34 - INFO - [Epoch 123] New best val loss: 848.7888\n",
      "[2025-11-20 05:51:42,596] [UniVITrainer] [INFO] [Epoch 124] New best val loss: 847.8397\n",
      "2025-11-20 05:51:42 - INFO - [Epoch 124] New best val loss: 847.8397\n",
      "[2025-11-20 05:52:18,783] [UniVITrainer] [INFO] [Epoch 129] New best val loss: 841.6419\n",
      "2025-11-20 05:52:18 - INFO - [Epoch 129] New best val loss: 841.6419\n",
      "[2025-11-20 05:52:25,097] [UniVITrainer] [INFO] [Epoch 130] Train loss: 777.9441 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:52:25 - INFO - [Epoch 130] Train loss: 777.9441 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:52:25,911] [UniVITrainer] [INFO] [Epoch 130] Val loss: 846.7844 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:52:25 - INFO - [Epoch 130] Val loss: 846.7844 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:52:40,523] [UniVITrainer] [INFO] [Epoch 132] New best val loss: 841.4836\n",
      "2025-11-20 05:52:40 - INFO - [Epoch 132] New best val loss: 841.4836\n",
      "[2025-11-20 05:52:47,216] [UniVITrainer] [INFO] [Epoch 133] New best val loss: 840.0045\n",
      "2025-11-20 05:52:47 - INFO - [Epoch 133] New best val loss: 840.0045\n",
      "[2025-11-20 05:52:54,753] [UniVITrainer] [INFO] [Epoch 134] New best val loss: 839.1446\n",
      "2025-11-20 05:52:54 - INFO - [Epoch 134] New best val loss: 839.1446\n",
      "[2025-11-20 05:53:01,538] [UniVITrainer] [INFO] [Epoch 135] New best val loss: 838.4028\n",
      "2025-11-20 05:53:01 - INFO - [Epoch 135] New best val loss: 838.4028\n",
      "[2025-11-20 05:53:21,097] [UniVITrainer] [INFO] [Epoch 138] New best val loss: 837.8516\n",
      "2025-11-20 05:53:21 - INFO - [Epoch 138] New best val loss: 837.8516\n",
      "[2025-11-20 05:53:28,218] [UniVITrainer] [INFO] [Epoch 139] New best val loss: 834.5294\n",
      "2025-11-20 05:53:28 - INFO - [Epoch 139] New best val loss: 834.5294\n",
      "[2025-11-20 05:53:35,004] [UniVITrainer] [INFO] [Epoch 140] Train loss: 775.4552 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:53:35 - INFO - [Epoch 140] Train loss: 775.4552 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:53:35,805] [UniVITrainer] [INFO] [Epoch 140] Val loss: 833.6352 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:53:35 - INFO - [Epoch 140] Val loss: 833.6352 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:53:36,154] [UniVITrainer] [INFO] [Epoch 140] New best val loss: 833.6352\n",
      "2025-11-20 05:53:36 - INFO - [Epoch 140] New best val loss: 833.6352\n",
      "[2025-11-20 05:53:43,814] [UniVITrainer] [INFO] [Epoch 141] New best val loss: 833.5140\n",
      "2025-11-20 05:53:43 - INFO - [Epoch 141] New best val loss: 833.5140\n",
      "[2025-11-20 05:53:51,582] [UniVITrainer] [INFO] [Epoch 142] New best val loss: 833.0353\n",
      "2025-11-20 05:53:51 - INFO - [Epoch 142] New best val loss: 833.0353\n",
      "[2025-11-20 05:54:06,502] [UniVITrainer] [INFO] [Epoch 144] New best val loss: 830.4005\n",
      "2025-11-20 05:54:06 - INFO - [Epoch 144] New best val loss: 830.4005\n",
      "[2025-11-20 05:54:35,055] [UniVITrainer] [INFO] [Epoch 148] New best val loss: 829.7778\n",
      "2025-11-20 05:54:35 - INFO - [Epoch 148] New best val loss: 829.7778\n",
      "[2025-11-20 05:54:48,733] [UniVITrainer] [INFO] [Epoch 150] Train loss: 773.1116 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:54:48 - INFO - [Epoch 150] Train loss: 773.1116 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:54:49,545] [UniVITrainer] [INFO] [Epoch 150] Val loss: 828.8523 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:54:49 - INFO - [Epoch 150] Val loss: 828.8523 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:54:49,921] [UniVITrainer] [INFO] [Epoch 150] New best val loss: 828.8523\n",
      "2025-11-20 05:54:49 - INFO - [Epoch 150] New best val loss: 828.8523\n",
      "[2025-11-20 05:54:57,449] [UniVITrainer] [INFO] [Epoch 151] New best val loss: 828.3400\n",
      "2025-11-20 05:54:57 - INFO - [Epoch 151] New best val loss: 828.3400\n",
      "[2025-11-20 05:55:04,503] [UniVITrainer] [INFO] [Epoch 152] New best val loss: 827.4057\n",
      "2025-11-20 05:55:04 - INFO - [Epoch 152] New best val loss: 827.4057\n",
      "[2025-11-20 05:55:27,088] [UniVITrainer] [INFO] [Epoch 155] New best val loss: 825.9570\n",
      "2025-11-20 05:55:27 - INFO - [Epoch 155] New best val loss: 825.9570\n",
      "[2025-11-20 05:55:34,716] [UniVITrainer] [INFO] [Epoch 156] New best val loss: 824.8292\n",
      "2025-11-20 05:55:34 - INFO - [Epoch 156] New best val loss: 824.8292\n",
      "[2025-11-20 05:56:02,436] [UniVITrainer] [INFO] [Epoch 160] Train loss: 770.1987 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:56:02 - INFO - [Epoch 160] Train loss: 770.1987 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:56:03,248] [UniVITrainer] [INFO] [Epoch 160] Val loss: 823.8988 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:56:03 - INFO - [Epoch 160] Val loss: 823.8988 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:56:03,624] [UniVITrainer] [INFO] [Epoch 160] New best val loss: 823.8988\n",
      "2025-11-20 05:56:03 - INFO - [Epoch 160] New best val loss: 823.8988\n",
      "[2025-11-20 05:56:10,652] [UniVITrainer] [INFO] [Epoch 161] New best val loss: 823.6435\n",
      "2025-11-20 05:56:10 - INFO - [Epoch 161] New best val loss: 823.6435\n",
      "[2025-11-20 05:56:18,853] [UniVITrainer] [INFO] [Epoch 162] New best val loss: 822.7234\n",
      "2025-11-20 05:56:18 - INFO - [Epoch 162] New best val loss: 822.7234\n",
      "[2025-11-20 05:56:26,497] [UniVITrainer] [INFO] [Epoch 163] New best val loss: 821.9747\n",
      "2025-11-20 05:56:26 - INFO - [Epoch 163] New best val loss: 821.9747\n",
      "[2025-11-20 05:56:34,406] [UniVITrainer] [INFO] [Epoch 164] New best val loss: 821.4773\n",
      "2025-11-20 05:56:34 - INFO - [Epoch 164] New best val loss: 821.4773\n",
      "[2025-11-20 05:56:42,127] [UniVITrainer] [INFO] [Epoch 165] New best val loss: 820.8480\n",
      "2025-11-20 05:56:42 - INFO - [Epoch 165] New best val loss: 820.8480\n",
      "[2025-11-20 05:56:50,023] [UniVITrainer] [INFO] [Epoch 166] New best val loss: 818.3528\n",
      "2025-11-20 05:56:50 - INFO - [Epoch 166] New best val loss: 818.3528\n",
      "[2025-11-20 05:57:12,998] [UniVITrainer] [INFO] [Epoch 169] New best val loss: 817.2984\n",
      "2025-11-20 05:57:12 - INFO - [Epoch 169] New best val loss: 817.2984\n",
      "[2025-11-20 05:57:19,572] [UniVITrainer] [INFO] [Epoch 170] Train loss: 775.4199 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:57:19 - INFO - [Epoch 170] Train loss: 775.4199 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:57:20,218] [UniVITrainer] [INFO] [Epoch 170] Val loss: 816.3515 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:57:20 - INFO - [Epoch 170] Val loss: 816.3515 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:57:20,545] [UniVITrainer] [INFO] [Epoch 170] New best val loss: 816.3515\n",
      "2025-11-20 05:57:20 - INFO - [Epoch 170] New best val loss: 816.3515\n",
      "[2025-11-20 05:57:41,227] [UniVITrainer] [INFO] [Epoch 173] New best val loss: 815.5682\n",
      "2025-11-20 05:57:41 - INFO - [Epoch 173] New best val loss: 815.5682\n",
      "[2025-11-20 05:57:49,057] [UniVITrainer] [INFO] [Epoch 174] New best val loss: 815.3710\n",
      "2025-11-20 05:57:49 - INFO - [Epoch 174] New best val loss: 815.3710\n",
      "[2025-11-20 05:57:56,522] [UniVITrainer] [INFO] [Epoch 175] New best val loss: 813.1533\n",
      "2025-11-20 05:57:56 - INFO - [Epoch 175] New best val loss: 813.1533\n",
      "[2025-11-20 05:58:10,661] [UniVITrainer] [INFO] [Epoch 177] New best val loss: 812.2576\n",
      "2025-11-20 05:58:10 - INFO - [Epoch 177] New best val loss: 812.2576\n",
      "[2025-11-20 05:58:18,133] [UniVITrainer] [INFO] [Epoch 178] New best val loss: 812.1026\n",
      "2025-11-20 05:58:18 - INFO - [Epoch 178] New best val loss: 812.1026\n",
      "[2025-11-20 05:58:32,255] [UniVITrainer] [INFO] [Epoch 180] Train loss: 772.5438 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:58:32 - INFO - [Epoch 180] Train loss: 772.5438 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:58:33,067] [UniVITrainer] [INFO] [Epoch 180] Val loss: 815.7331 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:58:33 - INFO - [Epoch 180] Val loss: 815.7331 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:58:48,102] [UniVITrainer] [INFO] [Epoch 182] New best val loss: 811.2075\n",
      "2025-11-20 05:58:48 - INFO - [Epoch 182] New best val loss: 811.2075\n",
      "[2025-11-20 05:58:54,267] [UniVITrainer] [INFO] [Epoch 183] New best val loss: 810.6752\n",
      "2025-11-20 05:58:54 - INFO - [Epoch 183] New best val loss: 810.6752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 05:59:01,869] [UniVITrainer] [INFO] [Epoch 184] New best val loss: 810.1832\n",
      "2025-11-20 05:59:01 - INFO - [Epoch 184] New best val loss: 810.1832\n",
      "[2025-11-20 05:59:17,075] [UniVITrainer] [INFO] [Epoch 186] New best val loss: 808.9061\n",
      "2025-11-20 05:59:17 - INFO - [Epoch 186] New best val loss: 808.9061\n",
      "[2025-11-20 05:59:45,013] [UniVITrainer] [INFO] [Epoch 190] Train loss: 777.3308 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:59:45 - INFO - [Epoch 190] Train loss: 777.3308 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:59:45,818] [UniVITrainer] [INFO] [Epoch 190] Val loss: 806.9960 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 05:59:45 - INFO - [Epoch 190] Val loss: 806.9960 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 05:59:46,269] [UniVITrainer] [INFO] [Epoch 190] New best val loss: 806.9960\n",
      "2025-11-20 05:59:46 - INFO - [Epoch 190] New best val loss: 806.9960\n",
      "[2025-11-20 05:59:53,253] [UniVITrainer] [INFO] [Epoch 191] New best val loss: 805.7068\n",
      "2025-11-20 05:59:53 - INFO - [Epoch 191] New best val loss: 805.7068\n",
      "[2025-11-20 06:00:00,947] [UniVITrainer] [INFO] [Epoch 192] New best val loss: 805.5484\n",
      "2025-11-20 06:00:00 - INFO - [Epoch 192] New best val loss: 805.5484\n",
      "[2025-11-20 06:00:08,828] [UniVITrainer] [INFO] [Epoch 193] New best val loss: 804.2608\n",
      "2025-11-20 06:00:08 - INFO - [Epoch 193] New best val loss: 804.2608\n",
      "[2025-11-20 06:00:37,883] [UniVITrainer] [INFO] [Epoch 197] New best val loss: 803.7490\n",
      "2025-11-20 06:00:37 - INFO - [Epoch 197] New best val loss: 803.7490\n",
      "[2025-11-20 06:00:45,412] [UniVITrainer] [INFO] [Epoch 198] New best val loss: 802.4400\n",
      "2025-11-20 06:00:45 - INFO - [Epoch 198] New best val loss: 802.4400\n",
      "[2025-11-20 06:00:59,614] [UniVITrainer] [INFO] [Epoch 200] Train loss: 776.0605 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 06:00:59 - INFO - [Epoch 200] Train loss: 776.0605 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 06:01:00,424] [UniVITrainer] [INFO] [Epoch 200] Val loss: 805.7022 (beta=1000.000, gamma=300.000)\n",
      "2025-11-20 06:01:00 - INFO - [Epoch 200] Val loss: 805.7022 (beta=1000.000, gamma=300.000)\n",
      "[2025-11-20 06:01:00,462] [UniVITrainer] [INFO] Restored best model from epoch 198 (val loss = 802.4400)\n",
      "2025-11-20 06:01:00 - INFO - Restored best model from epoch 198 (val loss = 802.4400)\n",
      "[2025-11-20 06:01:02,621] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 06:01:02 - INFO - TrainingConfig:\n",
      "[2025-11-20 06:01:02,623] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 06:01:02 - INFO -   n_epochs: 200\n",
      "[2025-11-20 06:01:02,626] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 06:01:02 - INFO -   batch_size: 256\n",
      "[2025-11-20 06:01:02,629] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 06:01:02 - INFO -   lr: 0.001\n",
      "[2025-11-20 06:01:02,634] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 06:01:02 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 06:01:02,636] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 06:01:02 - INFO -   device: cuda\n",
      "[2025-11-20 06:01:02,639] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 06:01:02 - INFO -   log_every: 10\n",
      "[2025-11-20 06:01:02,643] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 06:01:02 - INFO -   grad_clip: None\n",
      "[2025-11-20 06:01:02,647] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 06:01:02 - INFO -   num_workers: 0\n",
      "[2025-11-20 06:01:02,648] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 06:01:02 - INFO -   seed: 42\n",
      "[2025-11-20 06:01:02,654] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 06:01:02 - INFO -   early_stopping: True\n",
      "[2025-11-20 06:01:02,655] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 06:01:02 - INFO -   patience: 20\n",
      "[2025-11-20 06:01:02,658] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 06:01:02 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 19] Done in 24.6 min\n",
      "  best_val_loss              = 802.440\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4837\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.5046\n",
      "[Config 19] FOSCTTM (ADT vs ATAC, val) = 0.4953\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4945\n",
      "  Modality mixing (k=20)     = 0.0106\n",
      "  Composite score            = 1212.00\n",
      "\n",
      "================================================================================\n",
      "[Config 20] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 156,\n",
      "  \"beta\": 1000.0,\n",
      "  \"gamma\": 100.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_wide2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeadba105bf44622be2eff87ba727e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 06:01:09,165] [UniVITrainer] [INFO] [Epoch 001] Train loss: 17408.9101 (beta=1000.000, gamma=100.000)\n",
      "2025-11-20 06:01:09 - INFO - [Epoch 001] Train loss: 17408.9101 (beta=1000.000, gamma=100.000)\n",
      "[2025-11-20 06:01:09,971] [UniVITrainer] [INFO] [Epoch 001] Val loss: 3217.0339 (beta=1000.000, gamma=100.000)\n",
      "2025-11-20 06:01:09 - INFO - [Epoch 001] Val loss: 3217.0339 (beta=1000.000, gamma=100.000)\n",
      "[2025-11-20 06:01:10,327] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 3217.0339\n",
      "2025-11-20 06:01:10 - INFO - [Epoch 001] New best val loss: 3217.0339\n",
      "[2025-11-20 06:01:17,661] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1563.6121\n",
      "2025-11-20 06:01:17 - INFO - [Epoch 002] New best val loss: 1563.6121\n",
      "[2025-11-20 06:01:25,277] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1236.1479\n",
      "2025-11-20 06:01:25 - INFO - [Epoch 003] New best val loss: 1236.1479\n",
      "[2025-11-20 06:01:33,210] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 1128.3312\n",
      "2025-11-20 06:01:33 - INFO - [Epoch 004] New best val loss: 1128.3312\n",
      "[2025-11-20 06:01:40,775] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 1107.0825\n",
      "2025-11-20 06:01:40 - INFO - [Epoch 005] New best val loss: 1107.0825\n",
      "[2025-11-20 06:01:48,709] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 1054.9871\n",
      "2025-11-20 06:01:48 - INFO - [Epoch 006] New best val loss: 1054.9871\n",
      "[2025-11-20 06:01:56,656] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 1043.1345\n",
      "2025-11-20 06:01:56 - INFO - [Epoch 007] New best val loss: 1043.1345\n",
      "[2025-11-20 06:02:12,123] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 1037.6401\n",
      "2025-11-20 06:02:12 - INFO - [Epoch 009] New best val loss: 1037.6401\n",
      "[2025-11-20 06:02:18,537] [UniVITrainer] [INFO] [Epoch 010] Train loss: 1119.4569 (beta=1000.000, gamma=100.000)\n",
      "2025-11-20 06:02:18 - INFO - [Epoch 010] Train loss: 1119.4569 (beta=1000.000, gamma=100.000)\n",
      "[2025-11-20 06:02:19,348] [UniVITrainer] [INFO] [Epoch 010] Val loss: 1028.3955 (beta=1000.000, gamma=100.000)\n",
      "2025-11-20 06:02:19 - INFO - [Epoch 010] Val loss: 1028.3955 (beta=1000.000, gamma=100.000)\n",
      "[2025-11-20 06:02:19,436] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 1028.3955\n",
      "2025-11-20 06:02:19 - INFO - [Epoch 010] New best val loss: 1028.3955\n",
      "[2025-11-20 06:02:27,151] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 1026.6062\n",
      "2025-11-20 06:02:27 - INFO - [Epoch 011] New best val loss: 1026.6062\n",
      "[2025-11-20 06:02:42,366] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 1019.6628\n",
      "2025-11-20 06:02:42 - INFO - [Epoch 013] New best val loss: 1019.6628\n",
      "[2025-11-20 06:03:04,822] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 1016.0427\n",
      "2025-11-20 06:03:04 - INFO - [Epoch 016] New best val loss: 1016.0427\n",
      "[2025-11-20 06:03:12,546] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 1011.7540\n",
      "2025-11-20 06:03:12 - INFO - [Epoch 017] New best val loss: 1011.7540\n",
      "[2025-11-20 06:03:33,158] [UniVITrainer] [INFO] [Epoch 020] Train loss: 910.5410 (beta=1000.000, gamma=100.000)\n",
      "2025-11-20 06:03:33 - INFO - [Epoch 020] Train loss: 910.5410 (beta=1000.000, gamma=100.000)\n",
      "[2025-11-20 06:03:33,970] [UniVITrainer] [INFO] [Epoch 020] Val loss: 1056.5698 (beta=1000.000, gamma=100.000)\n",
      "2025-11-20 06:03:33 - INFO - [Epoch 020] Val loss: 1056.5698 (beta=1000.000, gamma=100.000)\n",
      "[2025-11-20 06:04:40,794] [UniVITrainer] [INFO] [Epoch 030] Train loss: 870.1073 (beta=1000.000, gamma=100.000)\n",
      "2025-11-20 06:04:40 - INFO - [Epoch 030] Train loss: 870.1073 (beta=1000.000, gamma=100.000)\n",
      "[2025-11-20 06:04:40,878] [UniVITrainer] [INFO] [Epoch 030] Val loss: 1111.7281 (beta=1000.000, gamma=100.000)\n",
      "2025-11-20 06:04:40 - INFO - [Epoch 030] Val loss: 1111.7281 (beta=1000.000, gamma=100.000)\n",
      "[2025-11-20 06:05:27,769] [UniVITrainer] [INFO] Early stopping at epoch 37 (best val loss = 1011.7540)\n",
      "2025-11-20 06:05:27 - INFO - Early stopping at epoch 37 (best val loss = 1011.7540)\n",
      "[2025-11-20 06:05:27,812] [UniVITrainer] [INFO] Restored best model from epoch 17 (val loss = 1011.7540)\n",
      "2025-11-20 06:05:27 - INFO - Restored best model from epoch 17 (val loss = 1011.7540)\n",
      "[2025-11-20 06:05:30,276] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 06:05:30 - INFO - TrainingConfig:\n",
      "[2025-11-20 06:05:30,279] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 06:05:30 - INFO -   n_epochs: 200\n",
      "[2025-11-20 06:05:30,281] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 06:05:30 - INFO -   batch_size: 256\n",
      "[2025-11-20 06:05:30,286] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 06:05:30 - INFO -   lr: 0.001\n",
      "[2025-11-20 06:05:30,288] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 06:05:30 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 06:05:30,291] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 06:05:30 - INFO -   device: cuda\n",
      "[2025-11-20 06:05:30,294] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 06:05:30 - INFO -   log_every: 10\n",
      "[2025-11-20 06:05:30,297] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 06:05:30 - INFO -   grad_clip: None\n",
      "[2025-11-20 06:05:30,301] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 06:05:30 - INFO -   num_workers: 0\n",
      "[2025-11-20 06:05:30,304] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 06:05:30 - INFO -   seed: 42\n",
      "[2025-11-20 06:05:30,308] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 06:05:30 - INFO -   early_stopping: True\n",
      "[2025-11-20 06:05:30,311] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 06:05:30 - INFO -   patience: 20\n",
      "[2025-11-20 06:05:30,312] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 06:05:30 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 20] Done in 4.4 min\n",
      "  best_val_loss              = 1011.754\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4616\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.5163\n",
      "[Config 20] FOSCTTM (ADT vs ATAC, val) = 0.4955\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4911\n",
      "  Modality mixing (k=20)     = 0.1604\n",
      "  Composite score            = 1750.67\n",
      "\n",
      "================================================================================\n",
      "[Config 21] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 40,\n",
      "  \"beta\": 140.0,\n",
      "  \"gamma\": 80.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_small2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281ac21915c64694a8334733c2ba31f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 06:05:37,046] [UniVITrainer] [INFO] [Epoch 001] Train loss: 1790.9643 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:05:37 - INFO - [Epoch 001] Train loss: 1790.9643 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:05:37,707] [UniVITrainer] [INFO] [Epoch 001] Val loss: 976.7466 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:05:37 - INFO - [Epoch 001] Val loss: 976.7466 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:05:37,875] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 976.7466\n",
      "2025-11-20 06:05:37 - INFO - [Epoch 001] New best val loss: 976.7466\n",
      "[2025-11-20 06:05:44,699] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 821.3446\n",
      "2025-11-20 06:05:44 - INFO - [Epoch 002] New best val loss: 821.3446\n",
      "[2025-11-20 06:05:50,244] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 803.1092\n",
      "2025-11-20 06:05:50 - INFO - [Epoch 003] New best val loss: 803.1092\n",
      "[2025-11-20 06:05:58,053] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 794.1638\n",
      "2025-11-20 06:05:58 - INFO - [Epoch 004] New best val loss: 794.1638\n",
      "[2025-11-20 06:06:05,289] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 789.1214\n",
      "2025-11-20 06:06:05 - INFO - [Epoch 005] New best val loss: 789.1214\n",
      "[2025-11-20 06:06:13,041] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 786.0608\n",
      "2025-11-20 06:06:13 - INFO - [Epoch 006] New best val loss: 786.0608\n",
      "[2025-11-20 06:06:20,454] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 781.8044\n",
      "2025-11-20 06:06:20 - INFO - [Epoch 007] New best val loss: 781.8044\n",
      "[2025-11-20 06:06:28,152] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 779.3033\n",
      "2025-11-20 06:06:28 - INFO - [Epoch 008] New best val loss: 779.3033\n",
      "[2025-11-20 06:06:35,750] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 778.1203\n",
      "2025-11-20 06:06:35 - INFO - [Epoch 009] New best val loss: 778.1203\n",
      "[2025-11-20 06:06:42,552] [UniVITrainer] [INFO] [Epoch 010] Train loss: 797.0369 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:06:42 - INFO - [Epoch 010] Train loss: 797.0369 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:06:43,370] [UniVITrainer] [INFO] [Epoch 010] Val loss: 776.7910 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:06:43 - INFO - [Epoch 010] Val loss: 776.7910 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:06:43,411] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 776.7910\n",
      "2025-11-20 06:06:43 - INFO - [Epoch 010] New best val loss: 776.7910\n",
      "[2025-11-20 06:06:51,025] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 775.6820\n",
      "2025-11-20 06:06:51 - INFO - [Epoch 011] New best val loss: 775.6820\n",
      "[2025-11-20 06:06:58,346] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 774.8683\n",
      "2025-11-20 06:06:58 - INFO - [Epoch 012] New best val loss: 774.8683\n",
      "[2025-11-20 06:07:05,667] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 773.8473\n",
      "2025-11-20 06:07:05 - INFO - [Epoch 013] New best val loss: 773.8473\n",
      "[2025-11-20 06:07:12,936] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 773.1213\n",
      "2025-11-20 06:07:12 - INFO - [Epoch 014] New best val loss: 773.1213\n",
      "[2025-11-20 06:07:20,601] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 772.8438\n",
      "2025-11-20 06:07:20 - INFO - [Epoch 015] New best val loss: 772.8438\n",
      "[2025-11-20 06:07:28,361] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 772.8008\n",
      "2025-11-20 06:07:28 - INFO - [Epoch 016] New best val loss: 772.8008\n",
      "[2025-11-20 06:07:36,047] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 771.8091\n",
      "2025-11-20 06:07:36 - INFO - [Epoch 017] New best val loss: 771.8091\n",
      "[2025-11-20 06:07:44,150] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 771.0783\n",
      "2025-11-20 06:07:44 - INFO - [Epoch 018] New best val loss: 771.0783\n",
      "[2025-11-20 06:07:51,983] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 771.0209\n",
      "2025-11-20 06:07:51 - INFO - [Epoch 019] New best val loss: 771.0209\n",
      "[2025-11-20 06:07:58,454] [UniVITrainer] [INFO] [Epoch 020] Train loss: 778.4296 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:07:58 - INFO - [Epoch 020] Train loss: 778.4296 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:07:59,197] [UniVITrainer] [INFO] [Epoch 020] Val loss: 771.3535 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:07:59 - INFO - [Epoch 020] Val loss: 771.3535 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:08:06,924] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 770.1565\n",
      "2025-11-20 06:08:06 - INFO - [Epoch 021] New best val loss: 770.1565\n",
      "[2025-11-20 06:08:14,685] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 769.8984\n",
      "2025-11-20 06:08:14 - INFO - [Epoch 022] New best val loss: 769.8984\n",
      "[2025-11-20 06:08:22,288] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 769.6847\n",
      "2025-11-20 06:08:22 - INFO - [Epoch 023] New best val loss: 769.6847\n",
      "[2025-11-20 06:08:30,128] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 769.6649\n",
      "2025-11-20 06:08:30 - INFO - [Epoch 024] New best val loss: 769.6649\n",
      "[2025-11-20 06:08:37,782] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 769.6385\n",
      "2025-11-20 06:08:37 - INFO - [Epoch 025] New best val loss: 769.6385\n",
      "[2025-11-20 06:08:45,265] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 769.2211\n",
      "2025-11-20 06:08:45 - INFO - [Epoch 026] New best val loss: 769.2211\n",
      "[2025-11-20 06:09:00,335] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 768.6837\n",
      "2025-11-20 06:09:00 - INFO - [Epoch 028] New best val loss: 768.6837\n",
      "[2025-11-20 06:09:07,630] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 768.5739\n",
      "2025-11-20 06:09:07 - INFO - [Epoch 029] New best val loss: 768.5739\n",
      "[2025-11-20 06:09:14,448] [UniVITrainer] [INFO] [Epoch 030] Train loss: 770.6043 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:09:14 - INFO - [Epoch 030] Train loss: 770.6043 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:09:14,925] [UniVITrainer] [INFO] [Epoch 030] Val loss: 768.5871 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:09:14 - INFO - [Epoch 030] Val loss: 768.5871 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:09:22,479] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 768.4147\n",
      "2025-11-20 06:09:22 - INFO - [Epoch 031] New best val loss: 768.4147\n",
      "[2025-11-20 06:09:30,212] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 768.1705\n",
      "2025-11-20 06:09:30 - INFO - [Epoch 032] New best val loss: 768.1705\n",
      "[2025-11-20 06:09:37,969] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 767.9902\n",
      "2025-11-20 06:09:37 - INFO - [Epoch 033] New best val loss: 767.9902\n",
      "[2025-11-20 06:09:45,647] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 767.9319\n",
      "2025-11-20 06:09:45 - INFO - [Epoch 034] New best val loss: 767.9319\n",
      "[2025-11-20 06:09:53,233] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 767.7343\n",
      "2025-11-20 06:09:53 - INFO - [Epoch 035] New best val loss: 767.7343\n",
      "[2025-11-20 06:10:00,985] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 767.6359\n",
      "2025-11-20 06:10:00 - INFO - [Epoch 036] New best val loss: 767.6359\n",
      "[2025-11-20 06:10:08,214] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 767.5215\n",
      "2025-11-20 06:10:08 - INFO - [Epoch 037] New best val loss: 767.5215\n",
      "[2025-11-20 06:10:28,188] [UniVITrainer] [INFO] [Epoch 040] Train loss: 771.0607 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:10:28 - INFO - [Epoch 040] Train loss: 771.0607 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:10:29,002] [UniVITrainer] [INFO] [Epoch 040] Val loss: 767.3218 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:10:29 - INFO - [Epoch 040] Val loss: 767.3218 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:10:29,122] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 767.3218\n",
      "2025-11-20 06:10:29 - INFO - [Epoch 040] New best val loss: 767.3218\n",
      "[2025-11-20 06:10:36,610] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 767.2238\n",
      "2025-11-20 06:10:36 - INFO - [Epoch 041] New best val loss: 767.2238\n",
      "[2025-11-20 06:10:57,977] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 767.0350\n",
      "2025-11-20 06:10:57 - INFO - [Epoch 044] New best val loss: 767.0350\n",
      "[2025-11-20 06:11:05,280] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 766.9787\n",
      "2025-11-20 06:11:05 - INFO - [Epoch 045] New best val loss: 766.9787\n",
      "[2025-11-20 06:11:20,328] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 766.9277\n",
      "2025-11-20 06:11:20 - INFO - [Epoch 047] New best val loss: 766.9277\n",
      "[2025-11-20 06:11:42,215] [UniVITrainer] [INFO] [Epoch 050] Train loss: 768.6560 (beta=140.000, gamma=80.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 06:11:42 - INFO - [Epoch 050] Train loss: 768.6560 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:11:43,046] [UniVITrainer] [INFO] [Epoch 050] Val loss: 766.8261 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:11:43 - INFO - [Epoch 050] Val loss: 766.8261 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:11:43,188] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 766.8261\n",
      "2025-11-20 06:11:43 - INFO - [Epoch 050] New best val loss: 766.8261\n",
      "[2025-11-20 06:11:50,150] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 766.7563\n",
      "2025-11-20 06:11:50 - INFO - [Epoch 051] New best val loss: 766.7563\n",
      "[2025-11-20 06:12:03,451] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 766.7423\n",
      "2025-11-20 06:12:03 - INFO - [Epoch 053] New best val loss: 766.7423\n",
      "[2025-11-20 06:12:11,390] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 766.7115\n",
      "2025-11-20 06:12:11 - INFO - [Epoch 054] New best val loss: 766.7115\n",
      "[2025-11-20 06:12:17,134] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 766.6848\n",
      "2025-11-20 06:12:17 - INFO - [Epoch 055] New best val loss: 766.6848\n",
      "[2025-11-20 06:12:24,565] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 766.6418\n",
      "2025-11-20 06:12:24 - INFO - [Epoch 056] New best val loss: 766.6418\n",
      "[2025-11-20 06:12:39,010] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 766.6063\n",
      "2025-11-20 06:12:39 - INFO - [Epoch 058] New best val loss: 766.6063\n",
      "[2025-11-20 06:12:43,921] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 766.5598\n",
      "2025-11-20 06:12:43 - INFO - [Epoch 059] New best val loss: 766.5598\n",
      "[2025-11-20 06:12:50,900] [UniVITrainer] [INFO] [Epoch 060] Train loss: 765.7019 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:12:50 - INFO - [Epoch 060] Train loss: 765.7019 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:12:51,739] [UniVITrainer] [INFO] [Epoch 060] Val loss: 766.6298 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:12:51 - INFO - [Epoch 060] Val loss: 766.6298 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:13:06,176] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 766.5223\n",
      "2025-11-20 06:13:06 - INFO - [Epoch 062] New best val loss: 766.5223\n",
      "[2025-11-20 06:13:14,153] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 766.5188\n",
      "2025-11-20 06:13:14 - INFO - [Epoch 063] New best val loss: 766.5188\n",
      "[2025-11-20 06:13:19,511] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 766.4854\n",
      "2025-11-20 06:13:19 - INFO - [Epoch 064] New best val loss: 766.4854\n",
      "[2025-11-20 06:13:42,014] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 766.4773\n",
      "2025-11-20 06:13:42 - INFO - [Epoch 067] New best val loss: 766.4773\n",
      "[2025-11-20 06:13:47,822] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 766.4516\n",
      "2025-11-20 06:13:47 - INFO - [Epoch 068] New best val loss: 766.4516\n",
      "[2025-11-20 06:14:02,385] [UniVITrainer] [INFO] [Epoch 070] Train loss: 767.1616 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:14:02 - INFO - [Epoch 070] Train loss: 767.1616 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:14:03,238] [UniVITrainer] [INFO] [Epoch 070] Val loss: 766.4410 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:14:03 - INFO - [Epoch 070] Val loss: 766.4410 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:14:03,378] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 766.4410\n",
      "2025-11-20 06:14:03 - INFO - [Epoch 070] New best val loss: 766.4410\n",
      "[2025-11-20 06:14:34,755] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 766.4101\n",
      "2025-11-20 06:14:34 - INFO - [Epoch 074] New best val loss: 766.4101\n",
      "[2025-11-20 06:14:42,617] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 766.4014\n",
      "2025-11-20 06:14:42 - INFO - [Epoch 075] New best val loss: 766.4014\n",
      "[2025-11-20 06:15:12,714] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 766.3882\n",
      "2025-11-20 06:15:12 - INFO - [Epoch 079] New best val loss: 766.3882\n",
      "[2025-11-20 06:15:19,646] [UniVITrainer] [INFO] [Epoch 080] Train loss: 764.0784 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:15:19 - INFO - [Epoch 080] Train loss: 764.0784 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:15:19,748] [UniVITrainer] [INFO] [Epoch 080] Val loss: 766.3873 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:15:19 - INFO - [Epoch 080] Val loss: 766.3873 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:15:19,934] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 766.3873\n",
      "2025-11-20 06:15:19 - INFO - [Epoch 080] New best val loss: 766.3873\n",
      "[2025-11-20 06:15:35,487] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 766.3822\n",
      "2025-11-20 06:15:35 - INFO - [Epoch 082] New best val loss: 766.3822\n",
      "[2025-11-20 06:15:50,753] [UniVITrainer] [INFO] [Epoch 084] New best val loss: 766.3654\n",
      "2025-11-20 06:15:50 - INFO - [Epoch 084] New best val loss: 766.3654\n",
      "[2025-11-20 06:16:21,482] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 766.3604\n",
      "2025-11-20 06:16:21 - INFO - [Epoch 088] New best val loss: 766.3604\n",
      "[2025-11-20 06:16:36,288] [UniVITrainer] [INFO] [Epoch 090] Train loss: 768.3215 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:16:36 - INFO - [Epoch 090] Train loss: 768.3215 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:16:37,101] [UniVITrainer] [INFO] [Epoch 090] Val loss: 766.3547 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:16:37 - INFO - [Epoch 090] Val loss: 766.3547 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:16:37,277] [UniVITrainer] [INFO] [Epoch 090] New best val loss: 766.3547\n",
      "2025-11-20 06:16:37 - INFO - [Epoch 090] New best val loss: 766.3547\n",
      "[2025-11-20 06:16:44,943] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 766.3527\n",
      "2025-11-20 06:16:44 - INFO - [Epoch 091] New best val loss: 766.3527\n",
      "[2025-11-20 06:16:52,870] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 766.3470\n",
      "2025-11-20 06:16:52 - INFO - [Epoch 092] New best val loss: 766.3470\n",
      "[2025-11-20 06:17:36,995] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 766.3273\n",
      "2025-11-20 06:17:36 - INFO - [Epoch 098] New best val loss: 766.3273\n",
      "[2025-11-20 06:17:50,014] [UniVITrainer] [INFO] [Epoch 100] Train loss: 766.9004 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:17:50 - INFO - [Epoch 100] Train loss: 766.9004 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:17:50,822] [UniVITrainer] [INFO] [Epoch 100] Val loss: 766.3210 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:17:50 - INFO - [Epoch 100] Val loss: 766.3210 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:17:50,991] [UniVITrainer] [INFO] [Epoch 100] New best val loss: 766.3210\n",
      "2025-11-20 06:17:50 - INFO - [Epoch 100] New best val loss: 766.3210\n",
      "[2025-11-20 06:18:13,245] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 766.3094\n",
      "2025-11-20 06:18:13 - INFO - [Epoch 103] New best val loss: 766.3094\n",
      "[2025-11-20 06:18:20,231] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 766.3044\n",
      "2025-11-20 06:18:20 - INFO - [Epoch 104] New best val loss: 766.3044\n",
      "[2025-11-20 06:19:03,988] [UniVITrainer] [INFO] [Epoch 110] Train loss: 768.2275 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:19:03 - INFO - [Epoch 110] Train loss: 768.2275 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:19:04,799] [UniVITrainer] [INFO] [Epoch 110] Val loss: 766.3339 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:19:04 - INFO - [Epoch 110] Val loss: 766.3339 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:19:42,218] [UniVITrainer] [INFO] [Epoch 115] New best val loss: 766.3008\n",
      "2025-11-20 06:19:42 - INFO - [Epoch 115] New best val loss: 766.3008\n",
      "[2025-11-20 06:19:49,795] [UniVITrainer] [INFO] [Epoch 116] New best val loss: 766.2912\n",
      "2025-11-20 06:19:49 - INFO - [Epoch 116] New best val loss: 766.2912\n",
      "[2025-11-20 06:20:17,348] [UniVITrainer] [INFO] [Epoch 120] Train loss: 764.8475 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:20:17 - INFO - [Epoch 120] Train loss: 764.8475 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:20:18,154] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.3100 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:20:18 - INFO - [Epoch 120] Val loss: 766.3100 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:21:32,112] [UniVITrainer] [INFO] [Epoch 130] Train loss: 766.7484 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:21:32 - INFO - [Epoch 130] Train loss: 766.7484 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:21:32,920] [UniVITrainer] [INFO] [Epoch 130] Val loss: 766.3036 (beta=140.000, gamma=80.000)\n",
      "2025-11-20 06:21:32 - INFO - [Epoch 130] Val loss: 766.3036 (beta=140.000, gamma=80.000)\n",
      "[2025-11-20 06:22:15,886] [UniVITrainer] [INFO] Early stopping at epoch 136 (best val loss = 766.2912)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 06:22:15 - INFO - Early stopping at epoch 136 (best val loss = 766.2912)\n",
      "[2025-11-20 06:22:15,914] [UniVITrainer] [INFO] Restored best model from epoch 116 (val loss = 766.2912)\n",
      "2025-11-20 06:22:15 - INFO - Restored best model from epoch 116 (val loss = 766.2912)\n",
      "[2025-11-20 06:22:18,462] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 06:22:18 - INFO - TrainingConfig:\n",
      "[2025-11-20 06:22:18,465] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 06:22:18 - INFO -   n_epochs: 200\n",
      "[2025-11-20 06:22:18,467] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 06:22:18 - INFO -   batch_size: 256\n",
      "[2025-11-20 06:22:18,471] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 06:22:18 - INFO -   lr: 0.001\n",
      "[2025-11-20 06:22:18,474] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 06:22:18 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 06:22:18,476] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 06:22:18 - INFO -   device: cuda\n",
      "[2025-11-20 06:22:18,479] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 06:22:18 - INFO -   log_every: 10\n",
      "[2025-11-20 06:22:18,482] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 06:22:18 - INFO -   grad_clip: None\n",
      "[2025-11-20 06:22:18,483] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 06:22:18 - INFO -   num_workers: 0\n",
      "[2025-11-20 06:22:18,484] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 06:22:18 - INFO -   seed: 42\n",
      "[2025-11-20 06:22:18,485] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 06:22:18 - INFO -   early_stopping: True\n",
      "[2025-11-20 06:22:18,486] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 06:22:18 - INFO -   patience: 20\n",
      "[2025-11-20 06:22:18,487] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 06:22:18 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 21] Done in 16.8 min\n",
      "  best_val_loss              = 766.291\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5126\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4876\n",
      "[Config 21] FOSCTTM (ADT vs ATAC, val) = 0.4901\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4968\n",
      "  Modality mixing (k=20)     = 0.0007\n",
      "  Composite score            = 1147.81\n",
      "\n",
      "================================================================================\n",
      "[Config 22] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 64,\n",
      "  \"beta\": 180.0,\n",
      "  \"gamma\": 240.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_med2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_wide2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a51fc96d1814fec9448ca06153d7961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 06:22:25,012] [UniVITrainer] [INFO] [Epoch 001] Train loss: 3632.8436 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:22:25 - INFO - [Epoch 001] Train loss: 3632.8436 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:22:25,705] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1201.8418 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:22:25 - INFO - [Epoch 001] Val loss: 1201.8418 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:22:25,901] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1201.8418\n",
      "2025-11-20 06:22:25 - INFO - [Epoch 001] New best val loss: 1201.8418\n",
      "[2025-11-20 06:22:33,507] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 978.3422\n",
      "2025-11-20 06:22:33 - INFO - [Epoch 002] New best val loss: 978.3422\n",
      "[2025-11-20 06:22:40,960] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 905.2354\n",
      "2025-11-20 06:22:40 - INFO - [Epoch 003] New best val loss: 905.2354\n",
      "[2025-11-20 06:22:48,603] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 870.9789\n",
      "2025-11-20 06:22:48 - INFO - [Epoch 004] New best val loss: 870.9789\n",
      "[2025-11-20 06:22:56,152] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 849.7142\n",
      "2025-11-20 06:22:56 - INFO - [Epoch 005] New best val loss: 849.7142\n",
      "[2025-11-20 06:23:03,906] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 839.2778\n",
      "2025-11-20 06:23:03 - INFO - [Epoch 006] New best val loss: 839.2778\n",
      "[2025-11-20 06:23:11,612] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 827.0728\n",
      "2025-11-20 06:23:11 - INFO - [Epoch 007] New best val loss: 827.0728\n",
      "[2025-11-20 06:23:19,327] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 822.2179\n",
      "2025-11-20 06:23:19 - INFO - [Epoch 008] New best val loss: 822.2179\n",
      "[2025-11-20 06:23:27,061] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 814.5637\n",
      "2025-11-20 06:23:27 - INFO - [Epoch 009] New best val loss: 814.5637\n",
      "[2025-11-20 06:23:33,828] [UniVITrainer] [INFO] [Epoch 010] Train loss: 878.6299 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:23:33 - INFO - [Epoch 010] Train loss: 878.6299 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:23:34,627] [UniVITrainer] [INFO] [Epoch 010] Val loss: 808.1678 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:23:34 - INFO - [Epoch 010] Val loss: 808.1678 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:23:34,846] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 808.1678\n",
      "2025-11-20 06:23:34 - INFO - [Epoch 010] New best val loss: 808.1678\n",
      "[2025-11-20 06:23:41,427] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 804.1223\n",
      "2025-11-20 06:23:41 - INFO - [Epoch 011] New best val loss: 804.1223\n",
      "[2025-11-20 06:23:55,205] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 798.1499\n",
      "2025-11-20 06:23:55 - INFO - [Epoch 013] New best val loss: 798.1499\n",
      "[2025-11-20 06:24:02,740] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 795.1054\n",
      "2025-11-20 06:24:02 - INFO - [Epoch 014] New best val loss: 795.1054\n",
      "[2025-11-20 06:24:10,784] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 794.6474\n",
      "2025-11-20 06:24:10 - INFO - [Epoch 015] New best val loss: 794.6474\n",
      "[2025-11-20 06:24:18,158] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 794.3659\n",
      "2025-11-20 06:24:18 - INFO - [Epoch 016] New best val loss: 794.3659\n",
      "[2025-11-20 06:24:26,157] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 793.9967\n",
      "2025-11-20 06:24:26 - INFO - [Epoch 017] New best val loss: 793.9967\n",
      "[2025-11-20 06:24:33,390] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 790.3245\n",
      "2025-11-20 06:24:33 - INFO - [Epoch 018] New best val loss: 790.3245\n",
      "[2025-11-20 06:24:41,373] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 789.8733\n",
      "2025-11-20 06:24:41 - INFO - [Epoch 019] New best val loss: 789.8733\n",
      "[2025-11-20 06:24:48,054] [UniVITrainer] [INFO] [Epoch 020] Train loss: 811.2412 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:24:48 - INFO - [Epoch 020] Train loss: 811.2412 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:24:48,883] [UniVITrainer] [INFO] [Epoch 020] Val loss: 787.0158 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:24:48 - INFO - [Epoch 020] Val loss: 787.0158 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:24:49,079] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 787.0158\n",
      "2025-11-20 06:24:49 - INFO - [Epoch 020] New best val loss: 787.0158\n",
      "[2025-11-20 06:24:57,020] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 785.8424\n",
      "2025-11-20 06:24:57 - INFO - [Epoch 021] New best val loss: 785.8424\n",
      "[2025-11-20 06:25:26,092] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 785.3793\n",
      "2025-11-20 06:25:26 - INFO - [Epoch 025] New best val loss: 785.3793\n",
      "[2025-11-20 06:25:41,755] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 782.5123\n",
      "2025-11-20 06:25:41 - INFO - [Epoch 027] New best val loss: 782.5123\n",
      "[2025-11-20 06:25:49,270] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 781.1841\n",
      "2025-11-20 06:25:49 - INFO - [Epoch 028] New best val loss: 781.1841\n",
      "[2025-11-20 06:25:57,104] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 780.4008\n",
      "2025-11-20 06:25:57 - INFO - [Epoch 029] New best val loss: 780.4008\n",
      "[2025-11-20 06:26:02,210] [UniVITrainer] [INFO] [Epoch 030] Train loss: 789.3537 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:26:02 - INFO - [Epoch 030] Train loss: 789.3537 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:26:03,048] [UniVITrainer] [INFO] [Epoch 030] Val loss: 780.4109 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:26:03 - INFO - [Epoch 030] Val loss: 780.4109 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:26:10,407] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 779.8552\n",
      "2025-11-20 06:26:10 - INFO - [Epoch 031] New best val loss: 779.8552\n",
      "[2025-11-20 06:26:18,297] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 778.0644\n",
      "2025-11-20 06:26:18 - INFO - [Epoch 032] New best val loss: 778.0644\n",
      "[2025-11-20 06:26:32,041] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 777.2688\n",
      "2025-11-20 06:26:32 - INFO - [Epoch 034] New best val loss: 777.2688\n",
      "[2025-11-20 06:27:00,719] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 776.3233\n",
      "2025-11-20 06:27:00 - INFO - [Epoch 038] New best val loss: 776.3233\n",
      "[2025-11-20 06:27:07,365] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 775.5780\n",
      "2025-11-20 06:27:07 - INFO - [Epoch 039] New best val loss: 775.5780\n",
      "[2025-11-20 06:27:14,335] [UniVITrainer] [INFO] [Epoch 040] Train loss: 784.3720 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:27:14 - INFO - [Epoch 040] Train loss: 784.3720 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:27:15,174] [UniVITrainer] [INFO] [Epoch 040] Val loss: 775.1445 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:27:15 - INFO - [Epoch 040] Val loss: 775.1445 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:27:15,194] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 775.1445\n",
      "2025-11-20 06:27:15 - INFO - [Epoch 040] New best val loss: 775.1445\n",
      "[2025-11-20 06:27:46,370] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 774.6308\n",
      "2025-11-20 06:27:46 - INFO - [Epoch 044] New best val loss: 774.6308\n",
      "[2025-11-20 06:28:02,136] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 773.5293\n",
      "2025-11-20 06:28:02 - INFO - [Epoch 046] New best val loss: 773.5293\n",
      "[2025-11-20 06:28:09,915] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 773.2911\n",
      "2025-11-20 06:28:09 - INFO - [Epoch 047] New best val loss: 773.2911\n",
      "[2025-11-20 06:28:25,690] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 772.6293\n",
      "2025-11-20 06:28:25 - INFO - [Epoch 049] New best val loss: 772.6293\n",
      "[2025-11-20 06:28:32,503] [UniVITrainer] [INFO] [Epoch 050] Train loss: 778.4327 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:28:32 - INFO - [Epoch 050] Train loss: 778.4327 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:28:33,334] [UniVITrainer] [INFO] [Epoch 050] Val loss: 773.1844 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:28:33 - INFO - [Epoch 050] Val loss: 773.1844 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:28:41,364] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 772.2740\n",
      "2025-11-20 06:28:41 - INFO - [Epoch 051] New best val loss: 772.2740\n",
      "[2025-11-20 06:29:04,840] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 771.8812\n",
      "2025-11-20 06:29:04 - INFO - [Epoch 054] New best val loss: 771.8812\n",
      "[2025-11-20 06:29:12,809] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 771.8359\n",
      "2025-11-20 06:29:12 - INFO - [Epoch 055] New best val loss: 771.8359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 06:29:20,835] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 771.3457\n",
      "2025-11-20 06:29:20 - INFO - [Epoch 056] New best val loss: 771.3457\n",
      "[2025-11-20 06:29:28,635] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 771.2859\n",
      "2025-11-20 06:29:28 - INFO - [Epoch 057] New best val loss: 771.2859\n",
      "[2025-11-20 06:29:42,681] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 770.8811\n",
      "2025-11-20 06:29:42 - INFO - [Epoch 059] New best val loss: 770.8811\n",
      "[2025-11-20 06:29:49,590] [UniVITrainer] [INFO] [Epoch 060] Train loss: 773.9175 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:29:49 - INFO - [Epoch 060] Train loss: 773.9175 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:29:50,428] [UniVITrainer] [INFO] [Epoch 060] Val loss: 771.9095 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:29:50 - INFO - [Epoch 060] Val loss: 771.9095 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:29:58,386] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 770.7283\n",
      "2025-11-20 06:29:58 - INFO - [Epoch 061] New best val loss: 770.7283\n",
      "[2025-11-20 06:30:06,119] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 770.1195\n",
      "2025-11-20 06:30:06 - INFO - [Epoch 062] New best val loss: 770.1195\n",
      "[2025-11-20 06:30:13,886] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 770.0386\n",
      "2025-11-20 06:30:13 - INFO - [Epoch 063] New best val loss: 770.0386\n",
      "[2025-11-20 06:30:35,956] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 769.5941\n",
      "2025-11-20 06:30:35 - INFO - [Epoch 066] New best val loss: 769.5941\n",
      "[2025-11-20 06:30:50,442] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 769.4627\n",
      "2025-11-20 06:30:50 - INFO - [Epoch 068] New best val loss: 769.4627\n",
      "[2025-11-20 06:30:58,075] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 769.3093\n",
      "2025-11-20 06:30:58 - INFO - [Epoch 069] New best val loss: 769.3093\n",
      "[2025-11-20 06:31:04,837] [UniVITrainer] [INFO] [Epoch 070] Train loss: 771.8995 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:31:04 - INFO - [Epoch 070] Train loss: 771.8995 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:31:05,650] [UniVITrainer] [INFO] [Epoch 070] Val loss: 769.0102 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:31:05 - INFO - [Epoch 070] Val loss: 769.0102 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:31:05,841] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 769.0102\n",
      "2025-11-20 06:31:05 - INFO - [Epoch 070] New best val loss: 769.0102\n",
      "[2025-11-20 06:31:19,918] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 768.9929\n",
      "2025-11-20 06:31:19 - INFO - [Epoch 072] New best val loss: 768.9929\n",
      "[2025-11-20 06:31:26,178] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 768.7987\n",
      "2025-11-20 06:31:26 - INFO - [Epoch 073] New best val loss: 768.7987\n",
      "[2025-11-20 06:31:32,643] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 768.6906\n",
      "2025-11-20 06:31:32 - INFO - [Epoch 074] New best val loss: 768.6906\n",
      "[2025-11-20 06:31:39,464] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 768.4696\n",
      "2025-11-20 06:31:39 - INFO - [Epoch 075] New best val loss: 768.4696\n",
      "[2025-11-20 06:31:53,292] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 768.3370\n",
      "2025-11-20 06:31:53 - INFO - [Epoch 077] New best val loss: 768.3370\n",
      "[2025-11-20 06:32:06,818] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 768.1724\n",
      "2025-11-20 06:32:06 - INFO - [Epoch 079] New best val loss: 768.1724\n",
      "[2025-11-20 06:32:11,260] [UniVITrainer] [INFO] [Epoch 080] Train loss: 767.8357 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:32:11 - INFO - [Epoch 080] Train loss: 767.8357 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:32:12,073] [UniVITrainer] [INFO] [Epoch 080] Val loss: 768.3710 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:32:12 - INFO - [Epoch 080] Val loss: 768.3710 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:32:19,637] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 768.1568\n",
      "2025-11-20 06:32:19 - INFO - [Epoch 081] New best val loss: 768.1568\n",
      "[2025-11-20 06:32:26,969] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 767.8512\n",
      "2025-11-20 06:32:26 - INFO - [Epoch 082] New best val loss: 767.8512\n",
      "[2025-11-20 06:32:34,375] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 767.8148\n",
      "2025-11-20 06:32:34 - INFO - [Epoch 083] New best val loss: 767.8148\n",
      "[2025-11-20 06:33:04,528] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 767.4113\n",
      "2025-11-20 06:33:04 - INFO - [Epoch 087] New best val loss: 767.4113\n",
      "[2025-11-20 06:33:24,647] [UniVITrainer] [INFO] [Epoch 090] Train loss: 769.8252 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:33:24 - INFO - [Epoch 090] Train loss: 769.8252 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:33:25,461] [UniVITrainer] [INFO] [Epoch 090] Val loss: 767.6817 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:33:25 - INFO - [Epoch 090] Val loss: 767.6817 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:33:54,353] [UniVITrainer] [INFO] [Epoch 094] New best val loss: 767.3716\n",
      "2025-11-20 06:33:54 - INFO - [Epoch 094] New best val loss: 767.3716\n",
      "[2025-11-20 06:34:01,952] [UniVITrainer] [INFO] [Epoch 095] New best val loss: 767.2456\n",
      "2025-11-20 06:34:01 - INFO - [Epoch 095] New best val loss: 767.2456\n",
      "[2025-11-20 06:34:17,136] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 767.2043\n",
      "2025-11-20 06:34:17 - INFO - [Epoch 097] New best val loss: 767.2043\n",
      "[2025-11-20 06:34:24,395] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 767.1306\n",
      "2025-11-20 06:34:24 - INFO - [Epoch 098] New best val loss: 767.1306\n",
      "[2025-11-20 06:34:32,239] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 767.0941\n",
      "2025-11-20 06:34:32 - INFO - [Epoch 099] New best val loss: 767.0941\n",
      "[2025-11-20 06:34:38,707] [UniVITrainer] [INFO] [Epoch 100] Train loss: 766.5222 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:34:38 - INFO - [Epoch 100] Train loss: 766.5222 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:34:39,506] [UniVITrainer] [INFO] [Epoch 100] Val loss: 767.0441 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:34:39 - INFO - [Epoch 100] Val loss: 767.0441 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:34:39,547] [UniVITrainer] [INFO] [Epoch 100] New best val loss: 767.0441\n",
      "2025-11-20 06:34:39 - INFO - [Epoch 100] New best val loss: 767.0441\n",
      "[2025-11-20 06:34:54,877] [UniVITrainer] [INFO] [Epoch 102] New best val loss: 767.0395\n",
      "2025-11-20 06:34:54 - INFO - [Epoch 102] New best val loss: 767.0395\n",
      "[2025-11-20 06:35:02,631] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 767.0143\n",
      "2025-11-20 06:35:02 - INFO - [Epoch 103] New best val loss: 767.0143\n",
      "[2025-11-20 06:35:09,335] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 766.9642\n",
      "2025-11-20 06:35:09 - INFO - [Epoch 104] New best val loss: 766.9642\n",
      "[2025-11-20 06:35:17,067] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 766.9024\n",
      "2025-11-20 06:35:17 - INFO - [Epoch 105] New best val loss: 766.9024\n",
      "[2025-11-20 06:35:24,216] [UniVITrainer] [INFO] [Epoch 106] New best val loss: 766.8979\n",
      "2025-11-20 06:35:24 - INFO - [Epoch 106] New best val loss: 766.8979\n",
      "[2025-11-20 06:35:31,995] [UniVITrainer] [INFO] [Epoch 107] New best val loss: 766.8753\n",
      "2025-11-20 06:35:31 - INFO - [Epoch 107] New best val loss: 766.8753\n",
      "[2025-11-20 06:35:39,784] [UniVITrainer] [INFO] [Epoch 108] New best val loss: 766.8544\n",
      "2025-11-20 06:35:39 - INFO - [Epoch 108] New best val loss: 766.8544\n",
      "[2025-11-20 06:35:53,836] [UniVITrainer] [INFO] [Epoch 110] Train loss: 771.3745 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:35:53 - INFO - [Epoch 110] Train loss: 771.3745 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:35:54,646] [UniVITrainer] [INFO] [Epoch 110] Val loss: 766.8753 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:35:54 - INFO - [Epoch 110] Val loss: 766.8753 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:36:31,926] [UniVITrainer] [INFO] [Epoch 115] New best val loss: 766.8440\n",
      "2025-11-20 06:36:31 - INFO - [Epoch 115] New best val loss: 766.8440\n",
      "[2025-11-20 06:36:39,135] [UniVITrainer] [INFO] [Epoch 116] New best val loss: 766.8124\n",
      "2025-11-20 06:36:39 - INFO - [Epoch 116] New best val loss: 766.8124\n",
      "[2025-11-20 06:36:46,877] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 766.7388\n",
      "2025-11-20 06:36:46 - INFO - [Epoch 117] New best val loss: 766.7388\n",
      "[2025-11-20 06:37:08,289] [UniVITrainer] [INFO] [Epoch 120] Train loss: 768.7434 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:37:08 - INFO - [Epoch 120] Train loss: 768.7434 (beta=180.000, gamma=240.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 06:37:09,101] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.7021 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:37:09 - INFO - [Epoch 120] Val loss: 766.7021 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:37:09,308] [UniVITrainer] [INFO] [Epoch 120] New best val loss: 766.7021\n",
      "2025-11-20 06:37:09 - INFO - [Epoch 120] New best val loss: 766.7021\n",
      "[2025-11-20 06:37:16,398] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 766.6596\n",
      "2025-11-20 06:37:16 - INFO - [Epoch 121] New best val loss: 766.6596\n",
      "[2025-11-20 06:37:52,240] [UniVITrainer] [INFO] [Epoch 126] New best val loss: 766.6383\n",
      "2025-11-20 06:37:52 - INFO - [Epoch 126] New best val loss: 766.6383\n",
      "[2025-11-20 06:38:00,074] [UniVITrainer] [INFO] [Epoch 127] New best val loss: 766.6127\n",
      "2025-11-20 06:38:00 - INFO - [Epoch 127] New best val loss: 766.6127\n",
      "[2025-11-20 06:38:07,713] [UniVITrainer] [INFO] [Epoch 128] New best val loss: 766.5999\n",
      "2025-11-20 06:38:07 - INFO - [Epoch 128] New best val loss: 766.5999\n",
      "[2025-11-20 06:38:22,028] [UniVITrainer] [INFO] [Epoch 130] Train loss: 768.1352 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:38:22 - INFO - [Epoch 130] Train loss: 768.1352 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:38:22,862] [UniVITrainer] [INFO] [Epoch 130] Val loss: 766.5628 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:38:22 - INFO - [Epoch 130] Val loss: 766.5628 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:38:23,053] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 766.5628\n",
      "2025-11-20 06:38:23 - INFO - [Epoch 130] New best val loss: 766.5628\n",
      "[2025-11-20 06:38:45,448] [UniVITrainer] [INFO] [Epoch 133] New best val loss: 766.5605\n",
      "2025-11-20 06:38:45 - INFO - [Epoch 133] New best val loss: 766.5605\n",
      "[2025-11-20 06:39:36,445] [UniVITrainer] [INFO] [Epoch 140] Train loss: 768.9904 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:39:36 - INFO - [Epoch 140] Train loss: 768.9904 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:39:37,290] [UniVITrainer] [INFO] [Epoch 140] Val loss: 766.7527 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:39:37 - INFO - [Epoch 140] Val loss: 766.7527 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:39:59,013] [UniVITrainer] [INFO] [Epoch 143] New best val loss: 766.5116\n",
      "2025-11-20 06:39:59 - INFO - [Epoch 143] New best val loss: 766.5116\n",
      "[2025-11-20 06:40:49,151] [UniVITrainer] [INFO] [Epoch 150] Train loss: 769.3970 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:40:49 - INFO - [Epoch 150] Train loss: 769.3970 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:40:49,995] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.9266 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:40:49 - INFO - [Epoch 150] Val loss: 766.9266 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:42:02,678] [UniVITrainer] [INFO] [Epoch 160] Train loss: 768.4238 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:42:02 - INFO - [Epoch 160] Train loss: 768.4238 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:42:03,513] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.6235 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:42:03 - INFO - [Epoch 160] Val loss: 766.6235 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:42:26,293] [UniVITrainer] [INFO] [Epoch 163] New best val loss: 766.4868\n",
      "2025-11-20 06:42:26 - INFO - [Epoch 163] New best val loss: 766.4868\n",
      "[2025-11-20 06:42:56,616] [UniVITrainer] [INFO] [Epoch 167] New best val loss: 766.4319\n",
      "2025-11-20 06:42:56 - INFO - [Epoch 167] New best val loss: 766.4319\n",
      "[2025-11-20 06:43:18,271] [UniVITrainer] [INFO] [Epoch 170] Train loss: 767.6654 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:43:18 - INFO - [Epoch 170] Train loss: 767.6654 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:43:19,103] [UniVITrainer] [INFO] [Epoch 170] Val loss: 766.5517 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:43:19 - INFO - [Epoch 170] Val loss: 766.5517 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:44:28,597] [UniVITrainer] [INFO] [Epoch 180] Train loss: 768.4828 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:44:28 - INFO - [Epoch 180] Train loss: 768.4828 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:44:29,408] [UniVITrainer] [INFO] [Epoch 180] Val loss: 766.4474 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:44:29 - INFO - [Epoch 180] Val loss: 766.4474 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:44:49,115] [UniVITrainer] [INFO] [Epoch 183] New best val loss: 766.4220\n",
      "2025-11-20 06:44:49 - INFO - [Epoch 183] New best val loss: 766.4220\n",
      "[2025-11-20 06:45:04,416] [UniVITrainer] [INFO] [Epoch 185] New best val loss: 766.4142\n",
      "2025-11-20 06:45:04 - INFO - [Epoch 185] New best val loss: 766.4142\n",
      "[2025-11-20 06:45:37,947] [UniVITrainer] [INFO] [Epoch 190] Train loss: 766.1301 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:45:37 - INFO - [Epoch 190] Train loss: 766.1301 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:45:38,774] [UniVITrainer] [INFO] [Epoch 190] Val loss: 766.5185 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:45:38 - INFO - [Epoch 190] Val loss: 766.5185 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:45:53,863] [UniVITrainer] [INFO] [Epoch 192] New best val loss: 766.4064\n",
      "2025-11-20 06:45:53 - INFO - [Epoch 192] New best val loss: 766.4064\n",
      "[2025-11-20 06:46:44,951] [UniVITrainer] [INFO] [Epoch 199] New best val loss: 766.3898\n",
      "2025-11-20 06:46:44 - INFO - [Epoch 199] New best val loss: 766.3898\n",
      "[2025-11-20 06:46:51,479] [UniVITrainer] [INFO] [Epoch 200] Train loss: 767.7078 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:46:51 - INFO - [Epoch 200] Train loss: 767.7078 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:46:52,290] [UniVITrainer] [INFO] [Epoch 200] Val loss: 766.4165 (beta=180.000, gamma=240.000)\n",
      "2025-11-20 06:46:52 - INFO - [Epoch 200] Val loss: 766.4165 (beta=180.000, gamma=240.000)\n",
      "[2025-11-20 06:46:52,328] [UniVITrainer] [INFO] Restored best model from epoch 199 (val loss = 766.3898)\n",
      "2025-11-20 06:46:52 - INFO - Restored best model from epoch 199 (val loss = 766.3898)\n",
      "[2025-11-20 06:46:54,779] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 06:46:54 - INFO - TrainingConfig:\n",
      "[2025-11-20 06:46:54,781] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 06:46:54 - INFO -   n_epochs: 200\n",
      "[2025-11-20 06:46:54,788] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 06:46:54 - INFO -   batch_size: 256\n",
      "[2025-11-20 06:46:54,794] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 06:46:54 - INFO -   lr: 0.001\n",
      "[2025-11-20 06:46:54,800] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 06:46:54 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 06:46:54,801] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 06:46:54 - INFO -   device: cuda\n",
      "[2025-11-20 06:46:54,802] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 06:46:54 - INFO -   log_every: 10\n",
      "[2025-11-20 06:46:54,803] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 06:46:54 - INFO -   grad_clip: None\n",
      "[2025-11-20 06:46:54,813] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 06:46:54 - INFO -   num_workers: 0\n",
      "[2025-11-20 06:46:54,814] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 06:46:54 - INFO -   seed: 42\n",
      "[2025-11-20 06:46:54,820] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 06:46:54 - INFO -   early_stopping: True\n",
      "[2025-11-20 06:46:54,823] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 06:46:54 - INFO -   patience: 20\n",
      "[2025-11-20 06:46:54,825] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 06:46:54 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 22] Done in 24.6 min\n",
      "  best_val_loss              = 766.390\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4993\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4458\n",
      "[Config 22] FOSCTTM (ADT vs ATAC, val) = 0.4884\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4778\n",
      "  Modality mixing (k=20)     = 0.0000\n",
      "  Composite score            = 1132.63\n",
      "\n",
      "================================================================================\n",
      "[Config 23] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 40,\n",
      "  \"beta\": 240.0,\n",
      "  \"gamma\": 180.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_med2\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_wide2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39dfa5388e0242a9a6f13173f14f8ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 06:47:01,083] [UniVITrainer] [INFO] [Epoch 001] Train loss: 2632.2980 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:47:01 - INFO - [Epoch 001] Train loss: 2632.2980 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:47:01,862] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1078.4996 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:47:01 - INFO - [Epoch 001] Val loss: 1078.4996 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:47:02,061] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1078.4996\n",
      "2025-11-20 06:47:02 - INFO - [Epoch 001] New best val loss: 1078.4996\n",
      "[2025-11-20 06:47:09,565] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 875.6692\n",
      "2025-11-20 06:47:09 - INFO - [Epoch 002] New best val loss: 875.6692\n",
      "[2025-11-20 06:47:16,028] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 830.6809\n",
      "2025-11-20 06:47:16 - INFO - [Epoch 003] New best val loss: 830.6809\n",
      "[2025-11-20 06:47:23,627] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 812.2211\n",
      "2025-11-20 06:47:23 - INFO - [Epoch 004] New best val loss: 812.2211\n",
      "[2025-11-20 06:47:31,331] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 803.1232\n",
      "2025-11-20 06:47:31 - INFO - [Epoch 005] New best val loss: 803.1232\n",
      "[2025-11-20 06:47:39,045] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 800.1007\n",
      "2025-11-20 06:47:39 - INFO - [Epoch 006] New best val loss: 800.1007\n",
      "[2025-11-20 06:47:46,779] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 794.5474\n",
      "2025-11-20 06:47:46 - INFO - [Epoch 007] New best val loss: 794.5474\n",
      "[2025-11-20 06:47:54,348] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 789.4267\n",
      "2025-11-20 06:47:54 - INFO - [Epoch 008] New best val loss: 789.4267\n",
      "[2025-11-20 06:48:01,995] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 787.9252\n",
      "2025-11-20 06:48:01 - INFO - [Epoch 009] New best val loss: 787.9252\n",
      "[2025-11-20 06:48:08,543] [UniVITrainer] [INFO] [Epoch 010] Train loss: 827.0193 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:48:08 - INFO - [Epoch 010] Train loss: 827.0193 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:48:09,360] [UniVITrainer] [INFO] [Epoch 010] Val loss: 787.5482 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:48:09 - INFO - [Epoch 010] Val loss: 787.5482 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:48:09,539] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 787.5482\n",
      "2025-11-20 06:48:09 - INFO - [Epoch 010] New best val loss: 787.5482\n",
      "[2025-11-20 06:48:17,311] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 783.4584\n",
      "2025-11-20 06:48:17 - INFO - [Epoch 011] New best val loss: 783.4584\n",
      "[2025-11-20 06:48:25,019] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 782.7059\n",
      "2025-11-20 06:48:25 - INFO - [Epoch 012] New best val loss: 782.7059\n",
      "[2025-11-20 06:48:32,735] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 781.8450\n",
      "2025-11-20 06:48:32 - INFO - [Epoch 013] New best val loss: 781.8450\n",
      "[2025-11-20 06:48:40,467] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 780.1235\n",
      "2025-11-20 06:48:40 - INFO - [Epoch 014] New best val loss: 780.1235\n",
      "[2025-11-20 06:48:48,280] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 779.0144\n",
      "2025-11-20 06:48:48 - INFO - [Epoch 015] New best val loss: 779.0144\n",
      "[2025-11-20 06:48:55,730] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 777.7499\n",
      "2025-11-20 06:48:55 - INFO - [Epoch 016] New best val loss: 777.7499\n",
      "[2025-11-20 06:49:03,445] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 777.6664\n",
      "2025-11-20 06:49:03 - INFO - [Epoch 017] New best val loss: 777.6664\n",
      "[2025-11-20 06:49:11,255] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 777.0335\n",
      "2025-11-20 06:49:11 - INFO - [Epoch 018] New best val loss: 777.0335\n",
      "[2025-11-20 06:49:18,922] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 776.9024\n",
      "2025-11-20 06:49:18 - INFO - [Epoch 019] New best val loss: 776.9024\n",
      "[2025-11-20 06:49:25,716] [UniVITrainer] [INFO] [Epoch 020] Train loss: 788.8056 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:49:25 - INFO - [Epoch 020] Train loss: 788.8056 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:49:26,535] [UniVITrainer] [INFO] [Epoch 020] Val loss: 775.4357 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:49:26 - INFO - [Epoch 020] Val loss: 775.4357 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:49:26,701] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 775.4357\n",
      "2025-11-20 06:49:26 - INFO - [Epoch 020] New best val loss: 775.4357\n",
      "[2025-11-20 06:49:40,688] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 774.4578\n",
      "2025-11-20 06:49:40 - INFO - [Epoch 022] New best val loss: 774.4578\n",
      "[2025-11-20 06:49:56,130] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 774.3007\n",
      "2025-11-20 06:49:56 - INFO - [Epoch 024] New best val loss: 774.3007\n",
      "[2025-11-20 06:50:03,726] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 774.1748\n",
      "2025-11-20 06:50:03 - INFO - [Epoch 025] New best val loss: 774.1748\n",
      "[2025-11-20 06:50:19,114] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 773.0254\n",
      "2025-11-20 06:50:19 - INFO - [Epoch 027] New best val loss: 773.0254\n",
      "[2025-11-20 06:50:34,244] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 772.9882\n",
      "2025-11-20 06:50:34 - INFO - [Epoch 029] New best val loss: 772.9882\n",
      "[2025-11-20 06:50:41,008] [UniVITrainer] [INFO] [Epoch 030] Train loss: 778.6069 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:50:41 - INFO - [Epoch 030] Train loss: 778.6069 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:50:41,827] [UniVITrainer] [INFO] [Epoch 030] Val loss: 773.0961 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:50:41 - INFO - [Epoch 030] Val loss: 773.0961 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:51:11,330] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 772.4977\n",
      "2025-11-20 06:51:11 - INFO - [Epoch 034] New best val loss: 772.4977\n",
      "[2025-11-20 06:51:17,285] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 772.1372\n",
      "2025-11-20 06:51:17 - INFO - [Epoch 035] New best val loss: 772.1372\n",
      "[2025-11-20 06:51:24,697] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 771.9737\n",
      "2025-11-20 06:51:24 - INFO - [Epoch 036] New best val loss: 771.9737\n",
      "[2025-11-20 06:51:52,692] [UniVITrainer] [INFO] [Epoch 040] Train loss: 774.1094 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:51:52 - INFO - [Epoch 040] Train loss: 774.1094 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:51:53,510] [UniVITrainer] [INFO] [Epoch 040] Val loss: 772.2178 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:51:53 - INFO - [Epoch 040] Val loss: 772.2178 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:52:01,079] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 771.1881\n",
      "2025-11-20 06:52:01 - INFO - [Epoch 041] New best val loss: 771.1881\n",
      "[2025-11-20 06:52:13,075] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 770.6378\n",
      "2025-11-20 06:52:13 - INFO - [Epoch 043] New best val loss: 770.6378\n",
      "[2025-11-20 06:52:33,599] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 770.3370\n",
      "2025-11-20 06:52:33 - INFO - [Epoch 046] New best val loss: 770.3370\n",
      "[2025-11-20 06:52:41,203] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 770.0747\n",
      "2025-11-20 06:52:41 - INFO - [Epoch 047] New best val loss: 770.0747\n",
      "[2025-11-20 06:53:01,093] [UniVITrainer] [INFO] [Epoch 050] Train loss: 771.5145 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:53:01 - INFO - [Epoch 050] Train loss: 771.5145 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:53:01,909] [UniVITrainer] [INFO] [Epoch 050] Val loss: 771.1235 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:53:01 - INFO - [Epoch 050] Val loss: 771.1235 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:53:09,521] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 769.9035\n",
      "2025-11-20 06:53:09 - INFO - [Epoch 051] New best val loss: 769.9035\n",
      "[2025-11-20 06:53:23,990] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 769.7708\n",
      "2025-11-20 06:53:23 - INFO - [Epoch 053] New best val loss: 769.7708\n",
      "[2025-11-20 06:53:36,743] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 769.3519\n",
      "2025-11-20 06:53:36 - INFO - [Epoch 055] New best val loss: 769.3519\n",
      "[2025-11-20 06:53:56,618] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 769.0392\n",
      "2025-11-20 06:53:56 - INFO - [Epoch 058] New best val loss: 769.0392\n",
      "[2025-11-20 06:54:11,123] [UniVITrainer] [INFO] [Epoch 060] Train loss: 770.2081 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:54:11 - INFO - [Epoch 060] Train loss: 770.2081 (beta=240.000, gamma=180.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 06:54:11,940] [UniVITrainer] [INFO] [Epoch 060] Val loss: 769.2252 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:54:11 - INFO - [Epoch 060] Val loss: 769.2252 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:54:26,442] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 768.6997\n",
      "2025-11-20 06:54:26 - INFO - [Epoch 062] New best val loss: 768.6997\n",
      "[2025-11-20 06:54:55,630] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 768.3905\n",
      "2025-11-20 06:54:55 - INFO - [Epoch 066] New best val loss: 768.3905\n",
      "[2025-11-20 06:55:02,870] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 768.3362\n",
      "2025-11-20 06:55:02 - INFO - [Epoch 067] New best val loss: 768.3362\n",
      "[2025-11-20 06:55:15,317] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 768.1684\n",
      "2025-11-20 06:55:15 - INFO - [Epoch 069] New best val loss: 768.1684\n",
      "[2025-11-20 06:55:21,969] [UniVITrainer] [INFO] [Epoch 070] Train loss: 767.3963 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:55:21 - INFO - [Epoch 070] Train loss: 767.3963 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:55:22,126] [UniVITrainer] [INFO] [Epoch 070] Val loss: 768.4451 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:55:22 - INFO - [Epoch 070] Val loss: 768.4451 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:55:29,498] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 768.0882\n",
      "2025-11-20 06:55:29 - INFO - [Epoch 071] New best val loss: 768.0882\n",
      "[2025-11-20 06:55:37,034] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 768.0099\n",
      "2025-11-20 06:55:37 - INFO - [Epoch 072] New best val loss: 768.0099\n",
      "[2025-11-20 06:55:52,236] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 767.8951\n",
      "2025-11-20 06:55:52 - INFO - [Epoch 074] New best val loss: 767.8951\n",
      "[2025-11-20 06:55:59,391] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 767.8502\n",
      "2025-11-20 06:55:59 - INFO - [Epoch 075] New best val loss: 767.8502\n",
      "[2025-11-20 06:56:07,164] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 767.7495\n",
      "2025-11-20 06:56:07 - INFO - [Epoch 076] New best val loss: 767.7495\n",
      "[2025-11-20 06:56:14,765] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 767.6774\n",
      "2025-11-20 06:56:14 - INFO - [Epoch 077] New best val loss: 767.6774\n",
      "[2025-11-20 06:56:22,128] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 767.6358\n",
      "2025-11-20 06:56:22 - INFO - [Epoch 078] New best val loss: 767.6358\n",
      "[2025-11-20 06:56:29,547] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 767.5466\n",
      "2025-11-20 06:56:29 - INFO - [Epoch 079] New best val loss: 767.5466\n",
      "[2025-11-20 06:56:36,237] [UniVITrainer] [INFO] [Epoch 080] Train loss: 771.6283 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:56:36 - INFO - [Epoch 080] Train loss: 771.6283 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:56:36,647] [UniVITrainer] [INFO] [Epoch 080] Val loss: 767.6446 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:56:36 - INFO - [Epoch 080] Val loss: 767.6446 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:56:51,698] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 767.4987\n",
      "2025-11-20 06:56:51 - INFO - [Epoch 082] New best val loss: 767.4987\n",
      "[2025-11-20 06:56:59,496] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 767.3169\n",
      "2025-11-20 06:56:59 - INFO - [Epoch 083] New best val loss: 767.3169\n",
      "[2025-11-20 06:57:06,236] [UniVITrainer] [INFO] [Epoch 084] New best val loss: 767.3148\n",
      "2025-11-20 06:57:06 - INFO - [Epoch 084] New best val loss: 767.3148\n",
      "[2025-11-20 06:57:13,961] [UniVITrainer] [INFO] [Epoch 085] New best val loss: 767.2768\n",
      "2025-11-20 06:57:13 - INFO - [Epoch 085] New best val loss: 767.2768\n",
      "[2025-11-20 06:57:36,813] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 767.2047\n",
      "2025-11-20 06:57:36 - INFO - [Epoch 088] New best val loss: 767.2047\n",
      "[2025-11-20 06:57:43,835] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 767.0978\n",
      "2025-11-20 06:57:43 - INFO - [Epoch 089] New best val loss: 767.0978\n",
      "[2025-11-20 06:57:50,318] [UniVITrainer] [INFO] [Epoch 090] Train loss: 767.1782 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:57:50 - INFO - [Epoch 090] Train loss: 767.1782 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:57:51,146] [UniVITrainer] [INFO] [Epoch 090] Val loss: 767.1785 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:57:51 - INFO - [Epoch 090] Val loss: 767.1785 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:58:03,219] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 767.0790\n",
      "2025-11-20 06:58:03 - INFO - [Epoch 092] New best val loss: 767.0790\n",
      "[2025-11-20 06:58:17,557] [UniVITrainer] [INFO] [Epoch 094] New best val loss: 767.0456\n",
      "2025-11-20 06:58:17 - INFO - [Epoch 094] New best val loss: 767.0456\n",
      "[2025-11-20 06:58:25,210] [UniVITrainer] [INFO] [Epoch 095] New best val loss: 767.0394\n",
      "2025-11-20 06:58:25 - INFO - [Epoch 095] New best val loss: 767.0394\n",
      "[2025-11-20 06:58:31,386] [UniVITrainer] [INFO] [Epoch 096] New best val loss: 767.0298\n",
      "2025-11-20 06:58:31 - INFO - [Epoch 096] New best val loss: 767.0298\n",
      "[2025-11-20 06:58:37,671] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 767.0221\n",
      "2025-11-20 06:58:37 - INFO - [Epoch 097] New best val loss: 767.0221\n",
      "[2025-11-20 06:58:44,484] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 767.0025\n",
      "2025-11-20 06:58:44 - INFO - [Epoch 098] New best val loss: 767.0025\n",
      "[2025-11-20 06:58:51,967] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 766.9808\n",
      "2025-11-20 06:58:51 - INFO - [Epoch 099] New best val loss: 766.9808\n",
      "[2025-11-20 06:58:57,778] [UniVITrainer] [INFO] [Epoch 100] Train loss: 767.9708 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:58:57 - INFO - [Epoch 100] Train loss: 767.9708 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:58:58,606] [UniVITrainer] [INFO] [Epoch 100] Val loss: 766.9633 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 06:58:58 - INFO - [Epoch 100] Val loss: 766.9633 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 06:58:58,792] [UniVITrainer] [INFO] [Epoch 100] New best val loss: 766.9633\n",
      "2025-11-20 06:58:58 - INFO - [Epoch 100] New best val loss: 766.9633\n",
      "[2025-11-20 06:59:04,612] [UniVITrainer] [INFO] [Epoch 101] New best val loss: 766.9059\n",
      "2025-11-20 06:59:04 - INFO - [Epoch 101] New best val loss: 766.9059\n",
      "[2025-11-20 06:59:17,343] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 766.8884\n",
      "2025-11-20 06:59:17 - INFO - [Epoch 103] New best val loss: 766.8884\n",
      "[2025-11-20 06:59:31,974] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 766.8696\n",
      "2025-11-20 06:59:31 - INFO - [Epoch 105] New best val loss: 766.8696\n",
      "[2025-11-20 06:59:38,932] [UniVITrainer] [INFO] [Epoch 106] New best val loss: 766.8508\n",
      "2025-11-20 06:59:38 - INFO - [Epoch 106] New best val loss: 766.8508\n",
      "[2025-11-20 06:59:46,831] [UniVITrainer] [INFO] [Epoch 107] New best val loss: 766.8358\n",
      "2025-11-20 06:59:46 - INFO - [Epoch 107] New best val loss: 766.8358\n",
      "[2025-11-20 06:59:54,467] [UniVITrainer] [INFO] [Epoch 108] New best val loss: 766.8303\n",
      "2025-11-20 06:59:54 - INFO - [Epoch 108] New best val loss: 766.8303\n",
      "[2025-11-20 07:00:08,254] [UniVITrainer] [INFO] [Epoch 110] Train loss: 768.4912 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:00:08 - INFO - [Epoch 110] Train loss: 768.4912 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:00:09,078] [UniVITrainer] [INFO] [Epoch 110] Val loss: 766.8338 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:00:09 - INFO - [Epoch 110] Val loss: 766.8338 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:00:31,827] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 766.7874\n",
      "2025-11-20 07:00:31 - INFO - [Epoch 113] New best val loss: 766.7874\n",
      "[2025-11-20 07:00:39,456] [UniVITrainer] [INFO] [Epoch 114] New best val loss: 766.7327\n",
      "2025-11-20 07:00:39 - INFO - [Epoch 114] New best val loss: 766.7327\n",
      "[2025-11-20 07:01:23,383] [UniVITrainer] [INFO] [Epoch 120] Train loss: 767.3482 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:01:23 - INFO - [Epoch 120] Train loss: 767.3482 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:01:24,206] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.7127 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:01:24 - INFO - [Epoch 120] Val loss: 766.7127 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:01:24,420] [UniVITrainer] [INFO] [Epoch 120] New best val loss: 766.7127\n",
      "2025-11-20 07:01:24 - INFO - [Epoch 120] New best val loss: 766.7127\n",
      "[2025-11-20 07:01:54,765] [UniVITrainer] [INFO] [Epoch 124] New best val loss: 766.6983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 07:01:54 - INFO - [Epoch 124] New best val loss: 766.6983\n",
      "[2025-11-20 07:02:02,249] [UniVITrainer] [INFO] [Epoch 125] New best val loss: 766.6593\n",
      "2025-11-20 07:02:02 - INFO - [Epoch 125] New best val loss: 766.6593\n",
      "[2025-11-20 07:02:25,569] [UniVITrainer] [INFO] [Epoch 128] New best val loss: 766.6539\n",
      "2025-11-20 07:02:25 - INFO - [Epoch 128] New best val loss: 766.6539\n",
      "[2025-11-20 07:02:33,293] [UniVITrainer] [INFO] [Epoch 129] New best val loss: 766.6369\n",
      "2025-11-20 07:02:33 - INFO - [Epoch 129] New best val loss: 766.6369\n",
      "[2025-11-20 07:02:40,166] [UniVITrainer] [INFO] [Epoch 130] Train loss: 765.8719 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:02:40 - INFO - [Epoch 130] Train loss: 765.8719 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:02:40,990] [UniVITrainer] [INFO] [Epoch 130] Val loss: 766.6419 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:02:40 - INFO - [Epoch 130] Val loss: 766.6419 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:03:10,714] [UniVITrainer] [INFO] [Epoch 134] New best val loss: 766.6091\n",
      "2025-11-20 07:03:10 - INFO - [Epoch 134] New best val loss: 766.6091\n",
      "[2025-11-20 07:03:25,520] [UniVITrainer] [INFO] [Epoch 136] New best val loss: 766.5870\n",
      "2025-11-20 07:03:25 - INFO - [Epoch 136] New best val loss: 766.5870\n",
      "[2025-11-20 07:03:53,455] [UniVITrainer] [INFO] [Epoch 140] Train loss: 766.3646 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:03:53 - INFO - [Epoch 140] Train loss: 766.3646 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:03:54,272] [UniVITrainer] [INFO] [Epoch 140] Val loss: 766.5912 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:03:54 - INFO - [Epoch 140] Val loss: 766.5912 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:04:09,807] [UniVITrainer] [INFO] [Epoch 142] New best val loss: 766.5682\n",
      "2025-11-20 07:04:09 - INFO - [Epoch 142] New best val loss: 766.5682\n",
      "[2025-11-20 07:04:46,383] [UniVITrainer] [INFO] [Epoch 147] New best val loss: 766.5482\n",
      "2025-11-20 07:04:46 - INFO - [Epoch 147] New best val loss: 766.5482\n",
      "[2025-11-20 07:05:05,900] [UniVITrainer] [INFO] [Epoch 150] Train loss: 768.9970 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:05:05 - INFO - [Epoch 150] Train loss: 768.9970 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:05:06,542] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.5736 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:05:06 - INFO - [Epoch 150] Val loss: 766.5736 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:05:27,989] [UniVITrainer] [INFO] [Epoch 153] New best val loss: 766.5478\n",
      "2025-11-20 07:05:27 - INFO - [Epoch 153] New best val loss: 766.5478\n",
      "[2025-11-20 07:05:35,517] [UniVITrainer] [INFO] [Epoch 154] New best val loss: 766.5076\n",
      "2025-11-20 07:05:35 - INFO - [Epoch 154] New best val loss: 766.5076\n",
      "[2025-11-20 07:06:15,838] [UniVITrainer] [INFO] [Epoch 160] Train loss: 766.4934 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:06:15 - INFO - [Epoch 160] Train loss: 766.4934 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:06:16,646] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.5543 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:06:16 - INFO - [Epoch 160] Val loss: 766.5543 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:06:24,016] [UniVITrainer] [INFO] [Epoch 161] New best val loss: 766.5058\n",
      "2025-11-20 07:06:24 - INFO - [Epoch 161] New best val loss: 766.5058\n",
      "[2025-11-20 07:06:45,329] [UniVITrainer] [INFO] [Epoch 164] New best val loss: 766.4978\n",
      "2025-11-20 07:06:45 - INFO - [Epoch 164] New best val loss: 766.4978\n",
      "[2025-11-20 07:06:53,037] [UniVITrainer] [INFO] [Epoch 165] New best val loss: 766.4973\n",
      "2025-11-20 07:06:53 - INFO - [Epoch 165] New best val loss: 766.4973\n",
      "[2025-11-20 07:06:58,902] [UniVITrainer] [INFO] [Epoch 166] New best val loss: 766.4653\n",
      "2025-11-20 07:06:58 - INFO - [Epoch 166] New best val loss: 766.4653\n",
      "[2025-11-20 07:07:27,157] [UniVITrainer] [INFO] [Epoch 170] Train loss: 764.5436 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:07:27 - INFO - [Epoch 170] Train loss: 764.5436 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:07:27,963] [UniVITrainer] [INFO] [Epoch 170] Val loss: 766.4668 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:07:27 - INFO - [Epoch 170] Val loss: 766.4668 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:08:37,767] [UniVITrainer] [INFO] [Epoch 180] Train loss: 769.6905 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:08:37 - INFO - [Epoch 180] Train loss: 769.6905 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:08:38,576] [UniVITrainer] [INFO] [Epoch 180] Val loss: 766.4406 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:08:38 - INFO - [Epoch 180] Val loss: 766.4406 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:08:38,768] [UniVITrainer] [INFO] [Epoch 180] New best val loss: 766.4406\n",
      "2025-11-20 07:08:38 - INFO - [Epoch 180] New best val loss: 766.4406\n",
      "[2025-11-20 07:08:46,110] [UniVITrainer] [INFO] [Epoch 181] New best val loss: 766.4343\n",
      "2025-11-20 07:08:46 - INFO - [Epoch 181] New best val loss: 766.4343\n",
      "[2025-11-20 07:09:43,669] [UniVITrainer] [INFO] [Epoch 189] New best val loss: 766.4330\n",
      "2025-11-20 07:09:43 - INFO - [Epoch 189] New best val loss: 766.4330\n",
      "[2025-11-20 07:09:50,353] [UniVITrainer] [INFO] [Epoch 190] Train loss: 766.4686 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:09:50 - INFO - [Epoch 190] Train loss: 766.4686 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:09:51,118] [UniVITrainer] [INFO] [Epoch 190] Val loss: 766.4572 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:09:51 - INFO - [Epoch 190] Val loss: 766.4572 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:10:41,891] [UniVITrainer] [INFO] [Epoch 197] New best val loss: 766.4058\n",
      "2025-11-20 07:10:41 - INFO - [Epoch 197] New best val loss: 766.4058\n",
      "[2025-11-20 07:10:49,574] [UniVITrainer] [INFO] [Epoch 198] New best val loss: 766.3876\n",
      "2025-11-20 07:10:49 - INFO - [Epoch 198] New best val loss: 766.3876\n",
      "[2025-11-20 07:11:03,652] [UniVITrainer] [INFO] [Epoch 200] Train loss: 766.3881 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:11:03 - INFO - [Epoch 200] Train loss: 766.3881 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:11:04,444] [UniVITrainer] [INFO] [Epoch 200] Val loss: 766.4486 (beta=240.000, gamma=180.000)\n",
      "2025-11-20 07:11:04 - INFO - [Epoch 200] Val loss: 766.4486 (beta=240.000, gamma=180.000)\n",
      "[2025-11-20 07:11:04,474] [UniVITrainer] [INFO] Restored best model from epoch 198 (val loss = 766.3876)\n",
      "2025-11-20 07:11:04 - INFO - Restored best model from epoch 198 (val loss = 766.3876)\n",
      "[2025-11-20 07:11:06,918] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 07:11:06 - INFO - TrainingConfig:\n",
      "[2025-11-20 07:11:06,921] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 07:11:06 - INFO -   n_epochs: 200\n",
      "[2025-11-20 07:11:06,926] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 07:11:06 - INFO -   batch_size: 256\n",
      "[2025-11-20 07:11:06,930] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 07:11:06 - INFO -   lr: 0.0005\n",
      "[2025-11-20 07:11:06,935] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 07:11:06 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 07:11:06,937] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 07:11:06 - INFO -   device: cuda\n",
      "[2025-11-20 07:11:06,939] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 07:11:06 - INFO -   log_every: 10\n",
      "[2025-11-20 07:11:06,941] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 07:11:06 - INFO -   grad_clip: None\n",
      "[2025-11-20 07:11:06,944] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 07:11:06 - INFO -   num_workers: 0\n",
      "[2025-11-20 07:11:06,945] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 07:11:06 - INFO -   seed: 42\n",
      "[2025-11-20 07:11:06,947] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 07:11:06 - INFO -   early_stopping: True\n",
      "[2025-11-20 07:11:06,947] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 07:11:06 - INFO -   patience: 20\n",
      "[2025-11-20 07:11:06,948] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 07:11:06 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 23] Done in 24.2 min\n",
      "  best_val_loss              = 766.388\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5319\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.5082\n",
      "[Config 23] FOSCTTM (ADT vs ATAC, val) = 0.4989\n",
      "  Mean FOSCTTM (3 pairs)     = 0.5130\n",
      "  Modality mixing (k=20)     = 0.0004\n",
      "  Composite score            = 1160.00\n",
      "\n",
      "================================================================================\n",
      "[Config 24] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 32,\n",
      "  \"beta\": 180.0,\n",
      "  \"gamma\": 500.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.0,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_small2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cdc89003314caeb50f734cc1918926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 07:11:13,197] [UniVITrainer] [INFO] [Epoch 001] Train loss: 3624.9808 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:11:13 - INFO - [Epoch 001] Train loss: 3624.9808 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:11:13,935] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1740.6882 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:11:13 - INFO - [Epoch 001] Val loss: 1740.6882 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:11:14,096] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1740.6882\n",
      "2025-11-20 07:11:14 - INFO - [Epoch 001] New best val loss: 1740.6882\n",
      "[2025-11-20 07:11:21,598] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1191.5010\n",
      "2025-11-20 07:11:21 - INFO - [Epoch 002] New best val loss: 1191.5010\n",
      "[2025-11-20 07:11:29,143] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 1013.4858\n",
      "2025-11-20 07:11:29 - INFO - [Epoch 003] New best val loss: 1013.4858\n",
      "[2025-11-20 07:11:33,962] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 942.8653\n",
      "2025-11-20 07:11:33 - INFO - [Epoch 004] New best val loss: 942.8653\n",
      "[2025-11-20 07:11:41,697] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 897.9240\n",
      "2025-11-20 07:11:41 - INFO - [Epoch 005] New best val loss: 897.9240\n",
      "[2025-11-20 07:11:48,930] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 872.9932\n",
      "2025-11-20 07:11:48 - INFO - [Epoch 006] New best val loss: 872.9932\n",
      "[2025-11-20 07:11:55,537] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 861.0323\n",
      "2025-11-20 07:11:55 - INFO - [Epoch 007] New best val loss: 861.0323\n",
      "[2025-11-20 07:12:01,626] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 848.3893\n",
      "2025-11-20 07:12:01 - INFO - [Epoch 008] New best val loss: 848.3893\n",
      "[2025-11-20 07:12:08,995] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 841.9561\n",
      "2025-11-20 07:12:08 - INFO - [Epoch 009] New best val loss: 841.9561\n",
      "[2025-11-20 07:12:15,549] [UniVITrainer] [INFO] [Epoch 010] Train loss: 829.9682 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:12:15 - INFO - [Epoch 010] Train loss: 829.9682 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:12:16,368] [UniVITrainer] [INFO] [Epoch 010] Val loss: 835.7681 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:12:16 - INFO - [Epoch 010] Val loss: 835.7681 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:12:16,549] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 835.7681\n",
      "2025-11-20 07:12:16 - INFO - [Epoch 010] New best val loss: 835.7681\n",
      "[2025-11-20 07:12:23,696] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 826.9961\n",
      "2025-11-20 07:12:23 - INFO - [Epoch 011] New best val loss: 826.9961\n",
      "[2025-11-20 07:12:31,280] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 822.5763\n",
      "2025-11-20 07:12:31 - INFO - [Epoch 012] New best val loss: 822.5763\n",
      "[2025-11-20 07:12:38,894] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 819.2890\n",
      "2025-11-20 07:12:38 - INFO - [Epoch 013] New best val loss: 819.2890\n",
      "[2025-11-20 07:12:45,102] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 816.6204\n",
      "2025-11-20 07:12:45 - INFO - [Epoch 014] New best val loss: 816.6204\n",
      "[2025-11-20 07:12:52,888] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 811.9533\n",
      "2025-11-20 07:12:52 - INFO - [Epoch 015] New best val loss: 811.9533\n",
      "[2025-11-20 07:13:00,043] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 809.7232\n",
      "2025-11-20 07:13:00 - INFO - [Epoch 016] New best val loss: 809.7232\n",
      "[2025-11-20 07:13:07,840] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 806.3563\n",
      "2025-11-20 07:13:07 - INFO - [Epoch 017] New best val loss: 806.3563\n",
      "[2025-11-20 07:13:15,302] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 803.9009\n",
      "2025-11-20 07:13:15 - INFO - [Epoch 018] New best val loss: 803.9009\n",
      "[2025-11-20 07:13:22,483] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 802.2899\n",
      "2025-11-20 07:13:22 - INFO - [Epoch 019] New best val loss: 802.2899\n",
      "[2025-11-20 07:13:29,190] [UniVITrainer] [INFO] [Epoch 020] Train loss: 797.4490 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:13:29 - INFO - [Epoch 020] Train loss: 797.4490 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:13:29,817] [UniVITrainer] [INFO] [Epoch 020] Val loss: 799.2334 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:13:29 - INFO - [Epoch 020] Val loss: 799.2334 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:13:29,955] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 799.2334\n",
      "2025-11-20 07:13:29 - INFO - [Epoch 020] New best val loss: 799.2334\n",
      "[2025-11-20 07:13:36,921] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 798.0414\n",
      "2025-11-20 07:13:36 - INFO - [Epoch 021] New best val loss: 798.0414\n",
      "[2025-11-20 07:13:44,567] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 796.9425\n",
      "2025-11-20 07:13:44 - INFO - [Epoch 022] New best val loss: 796.9425\n",
      "[2025-11-20 07:13:51,723] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 796.3510\n",
      "2025-11-20 07:13:51 - INFO - [Epoch 023] New best val loss: 796.3510\n",
      "[2025-11-20 07:13:59,441] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 795.0842\n",
      "2025-11-20 07:13:59 - INFO - [Epoch 024] New best val loss: 795.0842\n",
      "[2025-11-20 07:14:06,743] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 792.6879\n",
      "2025-11-20 07:14:06 - INFO - [Epoch 025] New best val loss: 792.6879\n",
      "[2025-11-20 07:14:14,206] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 791.9202\n",
      "2025-11-20 07:14:14 - INFO - [Epoch 026] New best val loss: 791.9202\n",
      "[2025-11-20 07:14:21,901] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 790.9593\n",
      "2025-11-20 07:14:21 - INFO - [Epoch 027] New best val loss: 790.9593\n",
      "[2025-11-20 07:14:29,350] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 789.6597\n",
      "2025-11-20 07:14:29 - INFO - [Epoch 028] New best val loss: 789.6597\n",
      "[2025-11-20 07:14:36,968] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 788.7782\n",
      "2025-11-20 07:14:36 - INFO - [Epoch 029] New best val loss: 788.7782\n",
      "[2025-11-20 07:14:43,431] [UniVITrainer] [INFO] [Epoch 030] Train loss: 780.8157 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:14:43 - INFO - [Epoch 030] Train loss: 780.8157 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:14:44,246] [UniVITrainer] [INFO] [Epoch 030] Val loss: 788.3819 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:14:44 - INFO - [Epoch 030] Val loss: 788.3819 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:14:44,409] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 788.3819\n",
      "2025-11-20 07:14:44 - INFO - [Epoch 030] New best val loss: 788.3819\n",
      "[2025-11-20 07:14:50,506] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 786.6889\n",
      "2025-11-20 07:14:50 - INFO - [Epoch 031] New best val loss: 786.6889\n",
      "[2025-11-20 07:14:58,227] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 785.7331\n",
      "2025-11-20 07:14:58 - INFO - [Epoch 032] New best val loss: 785.7331\n",
      "[2025-11-20 07:15:05,994] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 785.3190\n",
      "2025-11-20 07:15:05 - INFO - [Epoch 033] New best val loss: 785.3190\n",
      "[2025-11-20 07:15:11,958] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 784.3460\n",
      "2025-11-20 07:15:11 - INFO - [Epoch 034] New best val loss: 784.3460\n",
      "[2025-11-20 07:15:26,877] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 782.9722\n",
      "2025-11-20 07:15:26 - INFO - [Epoch 036] New best val loss: 782.9722\n",
      "[2025-11-20 07:15:34,633] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 782.5313\n",
      "2025-11-20 07:15:34 - INFO - [Epoch 037] New best val loss: 782.5313\n",
      "[2025-11-20 07:15:42,414] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 781.8573\n",
      "2025-11-20 07:15:42 - INFO - [Epoch 038] New best val loss: 781.8573\n",
      "[2025-11-20 07:15:50,196] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 781.0571\n",
      "2025-11-20 07:15:50 - INFO - [Epoch 039] New best val loss: 781.0571\n",
      "[2025-11-20 07:15:56,586] [UniVITrainer] [INFO] [Epoch 040] Train loss: 776.8853 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:15:56 - INFO - [Epoch 040] Train loss: 776.8853 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:15:57,403] [UniVITrainer] [INFO] [Epoch 040] Val loss: 780.6536 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:15:57 - INFO - [Epoch 040] Val loss: 780.6536 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:15:57,569] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 780.6536\n",
      "2025-11-20 07:15:57 - INFO - [Epoch 040] New best val loss: 780.6536\n",
      "[2025-11-20 07:16:05,376] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 779.8676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 07:16:05 - INFO - [Epoch 041] New best val loss: 779.8676\n",
      "[2025-11-20 07:16:13,159] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 779.7656\n",
      "2025-11-20 07:16:13 - INFO - [Epoch 042] New best val loss: 779.7656\n",
      "[2025-11-20 07:16:20,877] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 779.3015\n",
      "2025-11-20 07:16:20 - INFO - [Epoch 043] New best val loss: 779.3015\n",
      "[2025-11-20 07:16:27,572] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 778.7939\n",
      "2025-11-20 07:16:27 - INFO - [Epoch 044] New best val loss: 778.7939\n",
      "[2025-11-20 07:16:50,237] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 777.9942\n",
      "2025-11-20 07:16:50 - INFO - [Epoch 047] New best val loss: 777.9942\n",
      "[2025-11-20 07:16:57,684] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 776.6966\n",
      "2025-11-20 07:16:57 - INFO - [Epoch 048] New best val loss: 776.6966\n",
      "[2025-11-20 07:17:12,102] [UniVITrainer] [INFO] [Epoch 050] Train loss: 776.3354 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:17:12 - INFO - [Epoch 050] Train loss: 776.3354 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:17:12,927] [UniVITrainer] [INFO] [Epoch 050] Val loss: 776.2698 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:17:12 - INFO - [Epoch 050] Val loss: 776.2698 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:17:13,104] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 776.2698\n",
      "2025-11-20 07:17:13 - INFO - [Epoch 050] New best val loss: 776.2698\n",
      "[2025-11-20 07:17:20,867] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 776.1964\n",
      "2025-11-20 07:17:20 - INFO - [Epoch 051] New best val loss: 776.1964\n",
      "[2025-11-20 07:17:28,663] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 776.0198\n",
      "2025-11-20 07:17:28 - INFO - [Epoch 052] New best val loss: 776.0198\n",
      "[2025-11-20 07:17:36,414] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 775.6954\n",
      "2025-11-20 07:17:36 - INFO - [Epoch 053] New best val loss: 775.6954\n",
      "[2025-11-20 07:17:44,117] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 775.4281\n",
      "2025-11-20 07:17:44 - INFO - [Epoch 054] New best val loss: 775.4281\n",
      "[2025-11-20 07:17:57,935] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 774.6429\n",
      "2025-11-20 07:17:57 - INFO - [Epoch 056] New best val loss: 774.6429\n",
      "[2025-11-20 07:18:12,653] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 774.3115\n",
      "2025-11-20 07:18:12 - INFO - [Epoch 058] New best val loss: 774.3115\n",
      "[2025-11-20 07:18:20,117] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 773.7094\n",
      "2025-11-20 07:18:20 - INFO - [Epoch 059] New best val loss: 773.7094\n",
      "[2025-11-20 07:18:26,244] [UniVITrainer] [INFO] [Epoch 060] Train loss: 776.7821 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:18:26 - INFO - [Epoch 060] Train loss: 776.7821 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:18:27,063] [UniVITrainer] [INFO] [Epoch 060] Val loss: 773.6815 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:18:27 - INFO - [Epoch 060] Val loss: 773.6815 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:18:27,232] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 773.6815\n",
      "2025-11-20 07:18:27 - INFO - [Epoch 060] New best val loss: 773.6815\n",
      "[2025-11-20 07:18:42,414] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 773.3314\n",
      "2025-11-20 07:18:42 - INFO - [Epoch 062] New best val loss: 773.3314\n",
      "[2025-11-20 07:18:49,784] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 773.2333\n",
      "2025-11-20 07:18:49 - INFO - [Epoch 063] New best val loss: 773.2333\n",
      "[2025-11-20 07:18:57,401] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 773.0422\n",
      "2025-11-20 07:18:57 - INFO - [Epoch 064] New best val loss: 773.0422\n",
      "[2025-11-20 07:19:11,107] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 772.5744\n",
      "2025-11-20 07:19:11 - INFO - [Epoch 066] New best val loss: 772.5744\n",
      "[2025-11-20 07:19:18,881] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 772.4849\n",
      "2025-11-20 07:19:18 - INFO - [Epoch 067] New best val loss: 772.4849\n",
      "[2025-11-20 07:19:33,682] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 772.3987\n",
      "2025-11-20 07:19:33 - INFO - [Epoch 069] New best val loss: 772.3987\n",
      "[2025-11-20 07:19:38,989] [UniVITrainer] [INFO] [Epoch 070] Train loss: 773.9535 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:19:38 - INFO - [Epoch 070] Train loss: 773.9535 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:19:39,064] [UniVITrainer] [INFO] [Epoch 070] Val loss: 771.8118 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:19:39 - INFO - [Epoch 070] Val loss: 771.8118 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:19:39,231] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 771.8118\n",
      "2025-11-20 07:19:39 - INFO - [Epoch 070] New best val loss: 771.8118\n",
      "[2025-11-20 07:19:54,402] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 771.7158\n",
      "2025-11-20 07:19:54 - INFO - [Epoch 072] New best val loss: 771.7158\n",
      "[2025-11-20 07:20:09,162] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 771.5966\n",
      "2025-11-20 07:20:09 - INFO - [Epoch 074] New best val loss: 771.5966\n",
      "[2025-11-20 07:20:16,881] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 771.5118\n",
      "2025-11-20 07:20:16 - INFO - [Epoch 075] New best val loss: 771.5118\n",
      "[2025-11-20 07:20:31,270] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 771.3599\n",
      "2025-11-20 07:20:31 - INFO - [Epoch 077] New best val loss: 771.3599\n",
      "[2025-11-20 07:20:38,959] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 771.0848\n",
      "2025-11-20 07:20:38 - INFO - [Epoch 078] New best val loss: 771.0848\n",
      "[2025-11-20 07:20:53,312] [UniVITrainer] [INFO] [Epoch 080] Train loss: 777.9264 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:20:53 - INFO - [Epoch 080] Train loss: 777.9264 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:20:54,132] [UniVITrainer] [INFO] [Epoch 080] Val loss: 771.0471 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:20:54 - INFO - [Epoch 080] Val loss: 771.0471 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:20:54,299] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 771.0471\n",
      "2025-11-20 07:20:54 - INFO - [Epoch 080] New best val loss: 771.0471\n",
      "[2025-11-20 07:21:08,990] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 770.8239\n",
      "2025-11-20 07:21:08 - INFO - [Epoch 082] New best val loss: 770.8239\n",
      "[2025-11-20 07:21:16,762] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 770.7856\n",
      "2025-11-20 07:21:16 - INFO - [Epoch 083] New best val loss: 770.7856\n",
      "[2025-11-20 07:21:24,064] [UniVITrainer] [INFO] [Epoch 084] New best val loss: 770.3743\n",
      "2025-11-20 07:21:24 - INFO - [Epoch 084] New best val loss: 770.3743\n",
      "[2025-11-20 07:21:39,053] [UniVITrainer] [INFO] [Epoch 086] New best val loss: 770.3004\n",
      "2025-11-20 07:21:39 - INFO - [Epoch 086] New best val loss: 770.3004\n",
      "[2025-11-20 07:21:46,818] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 770.2347\n",
      "2025-11-20 07:21:46 - INFO - [Epoch 087] New best val loss: 770.2347\n",
      "[2025-11-20 07:21:54,303] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 770.1131\n",
      "2025-11-20 07:21:54 - INFO - [Epoch 088] New best val loss: 770.1131\n",
      "[2025-11-20 07:22:08,722] [UniVITrainer] [INFO] [Epoch 090] Train loss: 772.6580 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:22:08 - INFO - [Epoch 090] Train loss: 772.6580 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:22:09,553] [UniVITrainer] [INFO] [Epoch 090] Val loss: 770.1579 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:22:09 - INFO - [Epoch 090] Val loss: 770.1579 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:22:17,309] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 769.8543\n",
      "2025-11-20 07:22:17 - INFO - [Epoch 091] New best val loss: 769.8543\n",
      "[2025-11-20 07:22:32,471] [UniVITrainer] [INFO] [Epoch 093] New best val loss: 769.7203\n",
      "2025-11-20 07:22:32 - INFO - [Epoch 093] New best val loss: 769.7203\n",
      "[2025-11-20 07:23:02,902] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 769.6531\n",
      "2025-11-20 07:23:02 - INFO - [Epoch 097] New best val loss: 769.6531\n",
      "[2025-11-20 07:23:18,179] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 769.4895\n",
      "2025-11-20 07:23:18 - INFO - [Epoch 099] New best val loss: 769.4895\n",
      "[2025-11-20 07:23:25,001] [UniVITrainer] [INFO] [Epoch 100] Train loss: 768.8597 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:23:25 - INFO - [Epoch 100] Train loss: 768.8597 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:23:25,818] [UniVITrainer] [INFO] [Epoch 100] Val loss: 769.6188 (beta=180.000, gamma=500.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 07:23:25 - INFO - [Epoch 100] Val loss: 769.6188 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:23:33,213] [UniVITrainer] [INFO] [Epoch 101] New best val loss: 769.4762\n",
      "2025-11-20 07:23:33 - INFO - [Epoch 101] New best val loss: 769.4762\n",
      "[2025-11-20 07:23:40,976] [UniVITrainer] [INFO] [Epoch 102] New best val loss: 769.3500\n",
      "2025-11-20 07:23:40 - INFO - [Epoch 102] New best val loss: 769.3500\n",
      "[2025-11-20 07:23:48,370] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 769.1810\n",
      "2025-11-20 07:23:48 - INFO - [Epoch 103] New best val loss: 769.1810\n",
      "[2025-11-20 07:24:03,759] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 769.0280\n",
      "2025-11-20 07:24:03 - INFO - [Epoch 105] New best val loss: 769.0280\n",
      "[2025-11-20 07:24:33,221] [UniVITrainer] [INFO] [Epoch 109] New best val loss: 768.9472\n",
      "2025-11-20 07:24:33 - INFO - [Epoch 109] New best val loss: 768.9472\n",
      "[2025-11-20 07:24:40,188] [UniVITrainer] [INFO] [Epoch 110] Train loss: 765.4574 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:24:40 - INFO - [Epoch 110] Train loss: 765.4574 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:24:41,031] [UniVITrainer] [INFO] [Epoch 110] Val loss: 768.9519 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:24:41 - INFO - [Epoch 110] Val loss: 768.9519 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:24:54,423] [UniVITrainer] [INFO] [Epoch 112] New best val loss: 768.7369\n",
      "2025-11-20 07:24:54 - INFO - [Epoch 112] New best val loss: 768.7369\n",
      "[2025-11-20 07:25:08,054] [UniVITrainer] [INFO] [Epoch 114] New best val loss: 768.6532\n",
      "2025-11-20 07:25:08 - INFO - [Epoch 114] New best val loss: 768.6532\n",
      "[2025-11-20 07:25:28,345] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 768.5691\n",
      "2025-11-20 07:25:28 - INFO - [Epoch 117] New best val loss: 768.5691\n",
      "[2025-11-20 07:25:48,868] [UniVITrainer] [INFO] [Epoch 120] Train loss: 770.5706 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:25:48 - INFO - [Epoch 120] Train loss: 770.5706 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:25:49,705] [UniVITrainer] [INFO] [Epoch 120] Val loss: 768.5738 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:25:49 - INFO - [Epoch 120] Val loss: 768.5738 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:26:18,840] [UniVITrainer] [INFO] [Epoch 124] New best val loss: 768.4849\n",
      "2025-11-20 07:26:18 - INFO - [Epoch 124] New best val loss: 768.4849\n",
      "[2025-11-20 07:26:49,834] [UniVITrainer] [INFO] [Epoch 128] New best val loss: 768.3568\n",
      "2025-11-20 07:26:49 - INFO - [Epoch 128] New best val loss: 768.3568\n",
      "[2025-11-20 07:27:04,169] [UniVITrainer] [INFO] [Epoch 130] Train loss: 771.9480 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:27:04 - INFO - [Epoch 130] Train loss: 771.9480 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:27:05,002] [UniVITrainer] [INFO] [Epoch 130] Val loss: 768.1983 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:27:05 - INFO - [Epoch 130] Val loss: 768.1983 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:27:05,143] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 768.1983\n",
      "2025-11-20 07:27:05 - INFO - [Epoch 130] New best val loss: 768.1983\n",
      "[2025-11-20 07:27:50,963] [UniVITrainer] [INFO] [Epoch 135] New best val loss: 768.1167\n",
      "2025-11-20 07:27:50 - INFO - [Epoch 135] New best val loss: 768.1167\n",
      "[2025-11-20 07:28:07,590] [UniVITrainer] [INFO] [Epoch 137] New best val loss: 768.0260\n",
      "2025-11-20 07:28:07 - INFO - [Epoch 137] New best val loss: 768.0260\n",
      "[2025-11-20 07:28:32,164] [UniVITrainer] [INFO] [Epoch 140] Train loss: 765.6543 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:28:32 - INFO - [Epoch 140] Train loss: 765.6543 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:28:33,269] [UniVITrainer] [INFO] [Epoch 140] Val loss: 768.0259 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:28:33 - INFO - [Epoch 140] Val loss: 768.0259 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:28:33,288] [UniVITrainer] [INFO] [Epoch 140] New best val loss: 768.0259\n",
      "2025-11-20 07:28:33 - INFO - [Epoch 140] New best val loss: 768.0259\n",
      "[2025-11-20 07:28:50,974] [UniVITrainer] [INFO] [Epoch 142] New best val loss: 767.8381\n",
      "2025-11-20 07:28:50 - INFO - [Epoch 142] New best val loss: 767.8381\n",
      "[2025-11-20 07:29:45,748] [UniVITrainer] [INFO] [Epoch 148] New best val loss: 767.8160\n",
      "2025-11-20 07:29:45 - INFO - [Epoch 148] New best val loss: 767.8160\n",
      "[2025-11-20 07:30:04,637] [UniVITrainer] [INFO] [Epoch 150] Train loss: 768.6861 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:30:04 - INFO - [Epoch 150] Train loss: 768.6861 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:30:05,750] [UniVITrainer] [INFO] [Epoch 150] Val loss: 767.8371 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:30:05 - INFO - [Epoch 150] Val loss: 767.8371 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:30:35,797] [UniVITrainer] [INFO] [Epoch 153] New best val loss: 767.7732\n",
      "2025-11-20 07:30:35 - INFO - [Epoch 153] New best val loss: 767.7732\n",
      "[2025-11-20 07:30:55,805] [UniVITrainer] [INFO] [Epoch 155] New best val loss: 767.7189\n",
      "2025-11-20 07:30:55 - INFO - [Epoch 155] New best val loss: 767.7189\n",
      "[2025-11-20 07:31:40,705] [UniVITrainer] [INFO] [Epoch 160] Train loss: 766.0943 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:31:40 - INFO - [Epoch 160] Train loss: 766.0943 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:31:41,778] [UniVITrainer] [INFO] [Epoch 160] Val loss: 767.7701 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:31:41 - INFO - [Epoch 160] Val loss: 767.7701 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:31:49,929] [UniVITrainer] [INFO] [Epoch 161] New best val loss: 767.7053\n",
      "2025-11-20 07:31:49 - INFO - [Epoch 161] New best val loss: 767.7053\n",
      "[2025-11-20 07:32:31,831] [UniVITrainer] [INFO] [Epoch 166] New best val loss: 767.7051\n",
      "2025-11-20 07:32:31 - INFO - [Epoch 166] New best val loss: 767.7051\n",
      "[2025-11-20 07:32:46,813] [UniVITrainer] [INFO] [Epoch 168] New best val loss: 767.6243\n",
      "2025-11-20 07:32:46 - INFO - [Epoch 168] New best val loss: 767.6243\n",
      "[2025-11-20 07:33:01,326] [UniVITrainer] [INFO] [Epoch 170] Train loss: 769.1829 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:33:01 - INFO - [Epoch 170] Train loss: 769.1829 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:33:02,399] [UniVITrainer] [INFO] [Epoch 170] Val loss: 767.5955 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:33:02 - INFO - [Epoch 170] Val loss: 767.5955 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:33:02,417] [UniVITrainer] [INFO] [Epoch 170] New best val loss: 767.5955\n",
      "2025-11-20 07:33:02 - INFO - [Epoch 170] New best val loss: 767.5955\n",
      "[2025-11-20 07:33:12,214] [UniVITrainer] [INFO] [Epoch 171] New best val loss: 767.4875\n",
      "2025-11-20 07:33:12 - INFO - [Epoch 171] New best val loss: 767.4875\n",
      "[2025-11-20 07:33:47,092] [UniVITrainer] [INFO] [Epoch 175] New best val loss: 767.4338\n",
      "2025-11-20 07:33:47 - INFO - [Epoch 175] New best val loss: 767.4338\n",
      "[2025-11-20 07:34:24,152] [UniVITrainer] [INFO] [Epoch 179] New best val loss: 767.4028\n",
      "2025-11-20 07:34:24 - INFO - [Epoch 179] New best val loss: 767.4028\n",
      "[2025-11-20 07:34:32,881] [UniVITrainer] [INFO] [Epoch 180] Train loss: 765.0154 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:34:32 - INFO - [Epoch 180] Train loss: 765.0154 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:34:33,953] [UniVITrainer] [INFO] [Epoch 180] Val loss: 767.4438 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:34:33 - INFO - [Epoch 180] Val loss: 767.4438 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:34:43,074] [UniVITrainer] [INFO] [Epoch 181] New best val loss: 767.3326\n",
      "2025-11-20 07:34:43 - INFO - [Epoch 181] New best val loss: 767.3326\n",
      "[2025-11-20 07:34:51,676] [UniVITrainer] [INFO] [Epoch 182] New best val loss: 767.3136\n",
      "2025-11-20 07:34:51 - INFO - [Epoch 182] New best val loss: 767.3136\n",
      "[2025-11-20 07:35:48,829] [UniVITrainer] [INFO] [Epoch 188] New best val loss: 767.2860\n",
      "2025-11-20 07:35:48 - INFO - [Epoch 188] New best val loss: 767.2860\n",
      "[2025-11-20 07:36:06,136] [UniVITrainer] [INFO] [Epoch 190] Train loss: 766.0542 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:36:06 - INFO - [Epoch 190] Train loss: 766.0542 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:36:07,209] [UniVITrainer] [INFO] [Epoch 190] Val loss: 767.2445 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:36:07 - INFO - [Epoch 190] Val loss: 767.2445 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:36:07,361] [UniVITrainer] [INFO] [Epoch 190] New best val loss: 767.2445\n",
      "2025-11-20 07:36:07 - INFO - [Epoch 190] New best val loss: 767.2445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 07:36:17,305] [UniVITrainer] [INFO] [Epoch 191] New best val loss: 767.2202\n",
      "2025-11-20 07:36:17 - INFO - [Epoch 191] New best val loss: 767.2202\n",
      "[2025-11-20 07:36:37,002] [UniVITrainer] [INFO] [Epoch 193] New best val loss: 767.1708\n",
      "2025-11-20 07:36:37 - INFO - [Epoch 193] New best val loss: 767.1708\n",
      "[2025-11-20 07:37:40,971] [UniVITrainer] [INFO] [Epoch 200] Train loss: 764.7915 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:37:40 - INFO - [Epoch 200] Train loss: 764.7915 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:37:42,039] [UniVITrainer] [INFO] [Epoch 200] Val loss: 767.1850 (beta=180.000, gamma=500.000)\n",
      "2025-11-20 07:37:42 - INFO - [Epoch 200] Val loss: 767.1850 (beta=180.000, gamma=500.000)\n",
      "[2025-11-20 07:37:42,086] [UniVITrainer] [INFO] Restored best model from epoch 193 (val loss = 767.1708)\n",
      "2025-11-20 07:37:42 - INFO - Restored best model from epoch 193 (val loss = 767.1708)\n",
      "[2025-11-20 07:37:44,657] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 07:37:44 - INFO - TrainingConfig:\n",
      "[2025-11-20 07:37:44,659] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 07:37:44 - INFO -   n_epochs: 200\n",
      "[2025-11-20 07:37:44,660] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 07:37:44 - INFO -   batch_size: 256\n",
      "[2025-11-20 07:37:44,661] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 07:37:44 - INFO -   lr: 0.001\n",
      "[2025-11-20 07:37:44,662] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 07:37:44 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 07:37:44,663] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 07:37:44 - INFO -   device: cuda\n",
      "[2025-11-20 07:37:44,664] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 07:37:44 - INFO -   log_every: 10\n",
      "[2025-11-20 07:37:44,665] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 07:37:44 - INFO -   grad_clip: None\n",
      "[2025-11-20 07:37:44,666] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 07:37:44 - INFO -   num_workers: 0\n",
      "[2025-11-20 07:37:44,667] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 07:37:44 - INFO -   seed: 42\n",
      "[2025-11-20 07:37:44,668] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 07:37:44 - INFO -   early_stopping: True\n",
      "[2025-11-20 07:37:44,669] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 07:37:44 - INFO -   patience: 20\n",
      "[2025-11-20 07:37:44,670] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 07:37:44 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 24] Done in 26.6 min\n",
      "  best_val_loss              = 767.171\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4204\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4901\n",
      "[Config 24] FOSCTTM (ADT vs ATAC, val) = 0.5023\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4709\n",
      "  Modality mixing (k=20)     = 0.1076\n",
      "  Composite score            = 1249.86\n",
      "\n",
      "================================================================================\n",
      "[Config 25] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 100,\n",
      "  \"beta\": 100.0,\n",
      "  \"gamma\": 60.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_small2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0d7845e8ee467ba2406fa5662d058f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 07:37:53,366] [UniVITrainer] [INFO] [Epoch 001] Train loss: 2503.7605 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:37:53 - INFO - [Epoch 001] Train loss: 2503.7605 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:37:54,440] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1097.0956 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:37:54 - INFO - [Epoch 001] Val loss: 1097.0956 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:37:54,589] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1097.0956\n",
      "2025-11-20 07:37:54 - INFO - [Epoch 001] New best val loss: 1097.0956\n",
      "[2025-11-20 07:38:04,614] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 879.2995\n",
      "2025-11-20 07:38:04 - INFO - [Epoch 002] New best val loss: 879.2995\n",
      "[2025-11-20 07:38:14,387] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 839.6522\n",
      "2025-11-20 07:38:14 - INFO - [Epoch 003] New best val loss: 839.6522\n",
      "[2025-11-20 07:38:24,361] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 823.5655\n",
      "2025-11-20 07:38:24 - INFO - [Epoch 004] New best val loss: 823.5655\n",
      "[2025-11-20 07:38:32,867] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 815.7738\n",
      "2025-11-20 07:38:32 - INFO - [Epoch 005] New best val loss: 815.7738\n",
      "[2025-11-20 07:38:41,612] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 804.7222\n",
      "2025-11-20 07:38:41 - INFO - [Epoch 006] New best val loss: 804.7222\n",
      "[2025-11-20 07:38:50,831] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 795.2988\n",
      "2025-11-20 07:38:50 - INFO - [Epoch 007] New best val loss: 795.2988\n",
      "[2025-11-20 07:39:00,753] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 790.9715\n",
      "2025-11-20 07:39:00 - INFO - [Epoch 008] New best val loss: 790.9715\n",
      "[2025-11-20 07:39:09,339] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 788.7275\n",
      "2025-11-20 07:39:09 - INFO - [Epoch 009] New best val loss: 788.7275\n",
      "[2025-11-20 07:39:18,096] [UniVITrainer] [INFO] [Epoch 010] Train loss: 819.1194 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:39:18 - INFO - [Epoch 010] Train loss: 819.1194 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:39:19,178] [UniVITrainer] [INFO] [Epoch 010] Val loss: 784.8810 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:39:19 - INFO - [Epoch 010] Val loss: 784.8810 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:39:19,329] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 784.8810\n",
      "2025-11-20 07:39:19 - INFO - [Epoch 010] New best val loss: 784.8810\n",
      "[2025-11-20 07:39:27,179] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 782.4989\n",
      "2025-11-20 07:39:27 - INFO - [Epoch 011] New best val loss: 782.4989\n",
      "[2025-11-20 07:39:37,059] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 781.1467\n",
      "2025-11-20 07:39:37 - INFO - [Epoch 012] New best val loss: 781.1467\n",
      "[2025-11-20 07:39:46,776] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 777.7619\n",
      "2025-11-20 07:39:46 - INFO - [Epoch 013] New best val loss: 777.7619\n",
      "[2025-11-20 07:39:55,145] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 776.6124\n",
      "2025-11-20 07:39:55 - INFO - [Epoch 014] New best val loss: 776.6124\n",
      "[2025-11-20 07:40:03,616] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 775.2490\n",
      "2025-11-20 07:40:03 - INFO - [Epoch 015] New best val loss: 775.2490\n",
      "[2025-11-20 07:40:10,878] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 774.1748\n",
      "2025-11-20 07:40:10 - INFO - [Epoch 016] New best val loss: 774.1748\n",
      "[2025-11-20 07:40:18,760] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 773.5866\n",
      "2025-11-20 07:40:18 - INFO - [Epoch 017] New best val loss: 773.5866\n",
      "[2025-11-20 07:40:26,702] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 773.2361\n",
      "2025-11-20 07:40:26 - INFO - [Epoch 018] New best val loss: 773.2361\n",
      "[2025-11-20 07:40:34,607] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 772.0440\n",
      "2025-11-20 07:40:34 - INFO - [Epoch 019] New best val loss: 772.0440\n",
      "[2025-11-20 07:40:42,454] [UniVITrainer] [INFO] [Epoch 020] Train loss: 783.9096 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:40:42 - INFO - [Epoch 020] Train loss: 783.9096 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:40:43,336] [UniVITrainer] [INFO] [Epoch 020] Val loss: 771.7242 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:40:43 - INFO - [Epoch 020] Val loss: 771.7242 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:40:43,487] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 771.7242\n",
      "2025-11-20 07:40:43 - INFO - [Epoch 020] New best val loss: 771.7242\n",
      "[2025-11-20 07:40:50,769] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 771.6254\n",
      "2025-11-20 07:40:50 - INFO - [Epoch 021] New best val loss: 771.6254\n",
      "[2025-11-20 07:40:58,807] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 770.5787\n",
      "2025-11-20 07:40:58 - INFO - [Epoch 022] New best val loss: 770.5787\n",
      "[2025-11-20 07:41:07,749] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 770.2526\n",
      "2025-11-20 07:41:07 - INFO - [Epoch 023] New best val loss: 770.2526\n",
      "[2025-11-20 07:41:15,438] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 769.9054\n",
      "2025-11-20 07:41:15 - INFO - [Epoch 024] New best val loss: 769.9054\n",
      "[2025-11-20 07:41:23,504] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 769.4703\n",
      "2025-11-20 07:41:23 - INFO - [Epoch 025] New best val loss: 769.4703\n",
      "[2025-11-20 07:41:33,420] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 769.2520\n",
      "2025-11-20 07:41:33 - INFO - [Epoch 026] New best val loss: 769.2520\n",
      "[2025-11-20 07:41:41,577] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 768.8652\n",
      "2025-11-20 07:41:41 - INFO - [Epoch 027] New best val loss: 768.8652\n",
      "[2025-11-20 07:41:58,383] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 768.6879\n",
      "2025-11-20 07:41:58 - INFO - [Epoch 029] New best val loss: 768.6879\n",
      "[2025-11-20 07:42:05,511] [UniVITrainer] [INFO] [Epoch 030] Train loss: 771.1208 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:42:05 - INFO - [Epoch 030] Train loss: 771.1208 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:42:06,558] [UniVITrainer] [INFO] [Epoch 030] Val loss: 768.6632 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:42:06 - INFO - [Epoch 030] Val loss: 768.6632 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:42:06,710] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 768.6632\n",
      "2025-11-20 07:42:06 - INFO - [Epoch 030] New best val loss: 768.6632\n",
      "[2025-11-20 07:42:16,234] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 768.1765\n",
      "2025-11-20 07:42:16 - INFO - [Epoch 031] New best val loss: 768.1765\n",
      "[2025-11-20 07:42:24,357] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 767.9260\n",
      "2025-11-20 07:42:24 - INFO - [Epoch 032] New best val loss: 767.9260\n",
      "[2025-11-20 07:42:32,621] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 767.9161\n",
      "2025-11-20 07:42:32 - INFO - [Epoch 033] New best val loss: 767.9161\n",
      "[2025-11-20 07:42:50,455] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 767.7430\n",
      "2025-11-20 07:42:50 - INFO - [Epoch 035] New best val loss: 767.7430\n",
      "[2025-11-20 07:43:05,980] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 767.6116\n",
      "2025-11-20 07:43:05 - INFO - [Epoch 037] New best val loss: 767.6116\n",
      "[2025-11-20 07:43:15,854] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 767.5102\n",
      "2025-11-20 07:43:15 - INFO - [Epoch 038] New best val loss: 767.5102\n",
      "[2025-11-20 07:43:24,401] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 767.4739\n",
      "2025-11-20 07:43:24 - INFO - [Epoch 039] New best val loss: 767.4739\n",
      "[2025-11-20 07:43:33,044] [UniVITrainer] [INFO] [Epoch 040] Train loss: 768.4425 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:43:33 - INFO - [Epoch 040] Train loss: 768.4425 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:43:34,113] [UniVITrainer] [INFO] [Epoch 040] Val loss: 767.4402 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:43:34 - INFO - [Epoch 040] Val loss: 767.4402 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:43:34,264] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 767.4402\n",
      "2025-11-20 07:43:34 - INFO - [Epoch 040] New best val loss: 767.4402\n",
      "[2025-11-20 07:43:42,456] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 767.3294\n",
      "2025-11-20 07:43:42 - INFO - [Epoch 041] New best val loss: 767.3294\n",
      "[2025-11-20 07:43:52,436] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 767.3272\n",
      "2025-11-20 07:43:52 - INFO - [Epoch 042] New best val loss: 767.3272\n",
      "[2025-11-20 07:44:00,885] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 767.1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 07:44:00 - INFO - [Epoch 043] New best val loss: 767.1606\n",
      "[2025-11-20 07:44:09,775] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 767.1515\n",
      "2025-11-20 07:44:09 - INFO - [Epoch 044] New best val loss: 767.1515\n",
      "[2025-11-20 07:44:26,669] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 767.1148\n",
      "2025-11-20 07:44:26 - INFO - [Epoch 046] New best val loss: 767.1148\n",
      "[2025-11-20 07:44:34,553] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 767.1140\n",
      "2025-11-20 07:44:34 - INFO - [Epoch 047] New best val loss: 767.1140\n",
      "[2025-11-20 07:44:42,978] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 767.1003\n",
      "2025-11-20 07:44:42 - INFO - [Epoch 048] New best val loss: 767.1003\n",
      "[2025-11-20 07:44:52,215] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 767.0043\n",
      "2025-11-20 07:44:52 - INFO - [Epoch 049] New best val loss: 767.0043\n",
      "[2025-11-20 07:45:00,580] [UniVITrainer] [INFO] [Epoch 050] Train loss: 771.4664 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:45:00 - INFO - [Epoch 050] Train loss: 771.4664 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:45:01,650] [UniVITrainer] [INFO] [Epoch 050] Val loss: 766.9535 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:45:01 - INFO - [Epoch 050] Val loss: 766.9535 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:45:01,805] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 766.9535\n",
      "2025-11-20 07:45:01 - INFO - [Epoch 050] New best val loss: 766.9535\n",
      "[2025-11-20 07:45:19,909] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 766.8840\n",
      "2025-11-20 07:45:19 - INFO - [Epoch 052] New best val loss: 766.8840\n",
      "[2025-11-20 07:45:38,294] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 766.8375\n",
      "2025-11-20 07:45:38 - INFO - [Epoch 054] New best val loss: 766.8375\n",
      "[2025-11-20 07:45:46,902] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 766.8177\n",
      "2025-11-20 07:45:46 - INFO - [Epoch 055] New best val loss: 766.8177\n",
      "[2025-11-20 07:45:55,164] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 766.7439\n",
      "2025-11-20 07:45:55 - INFO - [Epoch 056] New best val loss: 766.7439\n",
      "[2025-11-20 07:46:29,028] [UniVITrainer] [INFO] [Epoch 060] Train loss: 766.7982 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:46:29 - INFO - [Epoch 060] Train loss: 766.7982 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:46:30,095] [UniVITrainer] [INFO] [Epoch 060] Val loss: 766.7757 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:46:30 - INFO - [Epoch 060] Val loss: 766.7757 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:46:59,527] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 766.7211\n",
      "2025-11-20 07:46:59 - INFO - [Epoch 063] New best val loss: 766.7211\n",
      "[2025-11-20 07:47:09,492] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 766.6062\n",
      "2025-11-20 07:47:09 - INFO - [Epoch 064] New best val loss: 766.6062\n",
      "[2025-11-20 07:47:37,428] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 766.5921\n",
      "2025-11-20 07:47:37 - INFO - [Epoch 067] New best val loss: 766.5921\n",
      "[2025-11-20 07:47:45,524] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 766.5845\n",
      "2025-11-20 07:47:45 - INFO - [Epoch 068] New best val loss: 766.5845\n",
      "[2025-11-20 07:47:55,441] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 766.5312\n",
      "2025-11-20 07:47:55 - INFO - [Epoch 069] New best val loss: 766.5312\n",
      "[2025-11-20 07:48:02,703] [UniVITrainer] [INFO] [Epoch 070] Train loss: 767.4274 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:48:02 - INFO - [Epoch 070] Train loss: 767.4274 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:48:03,578] [UniVITrainer] [INFO] [Epoch 070] Val loss: 766.5428 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:48:03 - INFO - [Epoch 070] Val loss: 766.5428 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:48:28,709] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 766.5222\n",
      "2025-11-20 07:48:28 - INFO - [Epoch 073] New best val loss: 766.5222\n",
      "[2025-11-20 07:49:13,597] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 766.5003\n",
      "2025-11-20 07:49:13 - INFO - [Epoch 079] New best val loss: 766.5003\n",
      "[2025-11-20 07:49:20,177] [UniVITrainer] [INFO] [Epoch 080] Train loss: 764.6545 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:49:20 - INFO - [Epoch 080] Train loss: 764.6545 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:49:20,960] [UniVITrainer] [INFO] [Epoch 080] Val loss: 766.5345 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:49:20 - INFO - [Epoch 080] Val loss: 766.5345 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:49:28,507] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 766.4926\n",
      "2025-11-20 07:49:28 - INFO - [Epoch 081] New best val loss: 766.4926\n",
      "[2025-11-20 07:49:43,439] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 766.4819\n",
      "2025-11-20 07:49:43 - INFO - [Epoch 083] New best val loss: 766.4819\n",
      "[2025-11-20 07:50:26,981] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 766.4628\n",
      "2025-11-20 07:50:26 - INFO - [Epoch 089] New best val loss: 766.4628\n",
      "[2025-11-20 07:50:33,546] [UniVITrainer] [INFO] [Epoch 090] Train loss: 765.3246 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:50:33 - INFO - [Epoch 090] Train loss: 765.3246 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:50:34,336] [UniVITrainer] [INFO] [Epoch 090] Val loss: 766.5225 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:50:34 - INFO - [Epoch 090] Val loss: 766.5225 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:50:49,247] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 766.4307\n",
      "2025-11-20 07:50:49 - INFO - [Epoch 092] New best val loss: 766.4307\n",
      "[2025-11-20 07:51:25,164] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 766.4297\n",
      "2025-11-20 07:51:25 - INFO - [Epoch 097] New best val loss: 766.4297\n",
      "[2025-11-20 07:51:37,367] [UniVITrainer] [INFO] [Epoch 100] Train loss: 770.1590 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:51:37 - INFO - [Epoch 100] Train loss: 770.1590 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:51:37,865] [UniVITrainer] [INFO] [Epoch 100] Val loss: 775.4168 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:51:37 - INFO - [Epoch 100] Val loss: 775.4168 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:51:50,777] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 766.4130\n",
      "2025-11-20 07:51:50 - INFO - [Epoch 104] New best val loss: 766.4130\n",
      "[2025-11-20 07:52:14,439] [UniVITrainer] [INFO] [Epoch 109] New best val loss: 766.4064\n",
      "2025-11-20 07:52:14 - INFO - [Epoch 109] New best val loss: 766.4064\n",
      "[2025-11-20 07:52:18,764] [UniVITrainer] [INFO] [Epoch 110] Train loss: 769.5320 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:52:18 - INFO - [Epoch 110] Train loss: 769.5320 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:52:19,277] [UniVITrainer] [INFO] [Epoch 110] Val loss: 766.3841 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:52:19 - INFO - [Epoch 110] Val loss: 766.3841 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:52:19,326] [UniVITrainer] [INFO] [Epoch 110] New best val loss: 766.3841\n",
      "2025-11-20 07:52:19 - INFO - [Epoch 110] New best val loss: 766.3841\n",
      "[2025-11-20 07:52:57,643] [UniVITrainer] [INFO] [Epoch 118] New best val loss: 766.3596\n",
      "2025-11-20 07:52:57 - INFO - [Epoch 118] New best val loss: 766.3596\n",
      "[2025-11-20 07:53:06,527] [UniVITrainer] [INFO] [Epoch 120] Train loss: 770.5522 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:53:06 - INFO - [Epoch 120] Train loss: 770.5522 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:53:07,039] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.3561 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:53:07 - INFO - [Epoch 120] Val loss: 766.3561 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:53:07,078] [UniVITrainer] [INFO] [Epoch 120] New best val loss: 766.3561\n",
      "2025-11-20 07:53:07 - INFO - [Epoch 120] New best val loss: 766.3561\n",
      "[2025-11-20 07:53:11,892] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 766.3478\n",
      "2025-11-20 07:53:11 - INFO - [Epoch 121] New best val loss: 766.3478\n",
      "[2025-11-20 07:53:21,821] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 766.3418\n",
      "2025-11-20 07:53:21 - INFO - [Epoch 123] New best val loss: 766.3418\n",
      "[2025-11-20 07:53:53,543] [UniVITrainer] [INFO] [Epoch 130] Train loss: 765.7066 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:53:53 - INFO - [Epoch 130] Train loss: 765.7066 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:53:54,045] [UniVITrainer] [INFO] [Epoch 130] Val loss: 766.8311 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:53:54 - INFO - [Epoch 130] Val loss: 766.8311 (beta=100.000, gamma=60.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 07:54:37,824] [UniVITrainer] [INFO] [Epoch 140] Train loss: 764.8024 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:54:37 - INFO - [Epoch 140] Train loss: 764.8024 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:54:38,059] [UniVITrainer] [INFO] [Epoch 140] Val loss: 768.4365 (beta=100.000, gamma=60.000)\n",
      "2025-11-20 07:54:38 - INFO - [Epoch 140] Val loss: 768.4365 (beta=100.000, gamma=60.000)\n",
      "[2025-11-20 07:54:52,132] [UniVITrainer] [INFO] Early stopping at epoch 143 (best val loss = 766.3418)\n",
      "2025-11-20 07:54:52 - INFO - Early stopping at epoch 143 (best val loss = 766.3418)\n",
      "[2025-11-20 07:54:52,162] [UniVITrainer] [INFO] Restored best model from epoch 123 (val loss = 766.3418)\n",
      "2025-11-20 07:54:52 - INFO - Restored best model from epoch 123 (val loss = 766.3418)\n",
      "[2025-11-20 07:54:53,999] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 07:54:53 - INFO - TrainingConfig:\n",
      "[2025-11-20 07:54:54,002] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 07:54:54 - INFO -   n_epochs: 200\n",
      "[2025-11-20 07:54:54,003] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 07:54:54 - INFO -   batch_size: 256\n",
      "[2025-11-20 07:54:54,005] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 07:54:54 - INFO -   lr: 0.0005\n",
      "[2025-11-20 07:54:54,006] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 07:54:54 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 07:54:54,007] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 07:54:54 - INFO -   device: cuda\n",
      "[2025-11-20 07:54:54,009] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 07:54:54 - INFO -   log_every: 10\n",
      "[2025-11-20 07:54:54,010] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 07:54:54 - INFO -   grad_clip: None\n",
      "[2025-11-20 07:54:54,012] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 07:54:54 - INFO -   num_workers: 0\n",
      "[2025-11-20 07:54:54,014] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 07:54:54 - INFO -   seed: 42\n",
      "[2025-11-20 07:54:54,015] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 07:54:54 - INFO -   early_stopping: True\n",
      "[2025-11-20 07:54:54,016] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 07:54:54 - INFO -   patience: 20\n",
      "[2025-11-20 07:54:54,018] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 07:54:54 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 25] Done in 17.1 min\n",
      "  best_val_loss              = 766.342\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5206\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4177\n",
      "[Config 25] FOSCTTM (ADT vs ATAC, val) = 0.4753\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4712\n",
      "  Modality mixing (k=20)     = 0.0000\n",
      "  Composite score            = 1127.45\n",
      "\n",
      "================================================================================\n",
      "[Config 26] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 40,\n",
      "  \"beta\": 60.0,\n",
      "  \"gamma\": 60.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.0,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_med2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_small2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98c4ada09054def93e663bebdaded5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 07:54:58,248] [UniVITrainer] [INFO] [Epoch 001] Train loss: 1531.1146 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:54:58 - INFO - [Epoch 001] Train loss: 1531.1146 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:54:58,747] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1087.4734 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:54:58 - INFO - [Epoch 001] Val loss: 1087.4734 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:54:58,842] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1087.4734\n",
      "2025-11-20 07:54:58 - INFO - [Epoch 001] New best val loss: 1087.4734\n",
      "[2025-11-20 07:55:02,494] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 884.9745\n",
      "2025-11-20 07:55:02 - INFO - [Epoch 002] New best val loss: 884.9745\n",
      "[2025-11-20 07:55:07,327] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 825.0750\n",
      "2025-11-20 07:55:07 - INFO - [Epoch 003] New best val loss: 825.0750\n",
      "[2025-11-20 07:55:12,050] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 807.0419\n",
      "2025-11-20 07:55:12 - INFO - [Epoch 004] New best val loss: 807.0419\n",
      "[2025-11-20 07:55:16,817] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 797.2501\n",
      "2025-11-20 07:55:16 - INFO - [Epoch 005] New best val loss: 797.2501\n",
      "[2025-11-20 07:55:21,172] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 791.7149\n",
      "2025-11-20 07:55:21 - INFO - [Epoch 006] New best val loss: 791.7149\n",
      "[2025-11-20 07:55:25,876] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 787.0091\n",
      "2025-11-20 07:55:25 - INFO - [Epoch 007] New best val loss: 787.0091\n",
      "[2025-11-20 07:55:30,596] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 785.8871\n",
      "2025-11-20 07:55:30 - INFO - [Epoch 008] New best val loss: 785.8871\n",
      "[2025-11-20 07:55:35,340] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 781.9800\n",
      "2025-11-20 07:55:35 - INFO - [Epoch 009] New best val loss: 781.9800\n",
      "[2025-11-20 07:55:39,388] [UniVITrainer] [INFO] [Epoch 010] Train loss: 780.2739 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:55:39 - INFO - [Epoch 010] Train loss: 780.2739 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:55:39,897] [UniVITrainer] [INFO] [Epoch 010] Val loss: 781.6567 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:55:39 - INFO - [Epoch 010] Val loss: 781.6567 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:55:39,971] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 781.6567\n",
      "2025-11-20 07:55:39 - INFO - [Epoch 010] New best val loss: 781.6567\n",
      "[2025-11-20 07:55:44,733] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 780.0997\n",
      "2025-11-20 07:55:44 - INFO - [Epoch 011] New best val loss: 780.0997\n",
      "[2025-11-20 07:55:49,246] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 779.2480\n",
      "2025-11-20 07:55:49 - INFO - [Epoch 012] New best val loss: 779.2480\n",
      "[2025-11-20 07:55:54,111] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 778.0339\n",
      "2025-11-20 07:55:54 - INFO - [Epoch 013] New best val loss: 778.0339\n",
      "[2025-11-20 07:55:58,809] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 777.0586\n",
      "2025-11-20 07:55:58 - INFO - [Epoch 014] New best val loss: 777.0586\n",
      "[2025-11-20 07:56:03,674] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 776.3640\n",
      "2025-11-20 07:56:03 - INFO - [Epoch 015] New best val loss: 776.3640\n",
      "[2025-11-20 07:56:08,076] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 775.7488\n",
      "2025-11-20 07:56:08 - INFO - [Epoch 016] New best val loss: 775.7488\n",
      "[2025-11-20 07:56:12,871] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 773.8464\n",
      "2025-11-20 07:56:12 - INFO - [Epoch 017] New best val loss: 773.8464\n",
      "[2025-11-20 07:56:17,445] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 772.8281\n",
      "2025-11-20 07:56:17 - INFO - [Epoch 018] New best val loss: 772.8281\n",
      "[2025-11-20 07:56:22,096] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 768.4967\n",
      "2025-11-20 07:56:22 - INFO - [Epoch 019] New best val loss: 768.4967\n",
      "[2025-11-20 07:56:26,182] [UniVITrainer] [INFO] [Epoch 020] Train loss: 772.3942 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:56:26 - INFO - [Epoch 020] Train loss: 772.3942 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:56:26,676] [UniVITrainer] [INFO] [Epoch 020] Val loss: 772.1592 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:56:26 - INFO - [Epoch 020] Val loss: 772.1592 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:56:31,389] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 766.6290\n",
      "2025-11-20 07:56:31 - INFO - [Epoch 021] New best val loss: 766.6290\n",
      "[2025-11-20 07:56:45,077] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 766.4762\n",
      "2025-11-20 07:56:45 - INFO - [Epoch 024] New best val loss: 766.4762\n",
      "[2025-11-20 07:56:49,850] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 765.3690\n",
      "2025-11-20 07:56:49 - INFO - [Epoch 025] New best val loss: 765.3690\n",
      "[2025-11-20 07:57:10,209] [UniVITrainer] [INFO] [Epoch 030] Train loss: 770.8460 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:57:10 - INFO - [Epoch 030] Train loss: 770.8460 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:57:10,725] [UniVITrainer] [INFO] [Epoch 030] Val loss: 764.6446 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:57:10 - INFO - [Epoch 030] Val loss: 764.6446 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:57:10,739] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 764.6446\n",
      "2025-11-20 07:57:10 - INFO - [Epoch 030] New best val loss: 764.6446\n",
      "[2025-11-20 07:57:29,127] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 764.1170\n",
      "2025-11-20 07:57:29 - INFO - [Epoch 034] New best val loss: 764.1170\n",
      "[2025-11-20 07:57:56,345] [UniVITrainer] [INFO] [Epoch 040] Train loss: 762.5286 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:57:56 - INFO - [Epoch 040] Train loss: 762.5286 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:57:56,832] [UniVITrainer] [INFO] [Epoch 040] Val loss: 766.7287 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:57:56 - INFO - [Epoch 040] Val loss: 766.7287 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:58:10,817] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 763.7532\n",
      "2025-11-20 07:58:10 - INFO - [Epoch 043] New best val loss: 763.7532\n",
      "[2025-11-20 07:58:19,877] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 762.5158\n",
      "2025-11-20 07:58:19 - INFO - [Epoch 045] New best val loss: 762.5158\n",
      "[2025-11-20 07:58:46,442] [UniVITrainer] [INFO] [Epoch 050] Train loss: 762.5226 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:58:46 - INFO - [Epoch 050] Train loss: 762.5226 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:58:46,994] [UniVITrainer] [INFO] [Epoch 050] Val loss: 764.5185 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:58:46 - INFO - [Epoch 050] Val loss: 764.5185 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:59:57,501] [UniVITrainer] [INFO] [Epoch 060] Train loss: 763.2285 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:59:57 - INFO - [Epoch 060] Train loss: 763.2285 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 07:59:58,293] [UniVITrainer] [INFO] [Epoch 060] Val loss: 765.8524 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 07:59:58 - INFO - [Epoch 060] Val loss: 765.8524 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 08:00:12,573] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 762.3248\n",
      "2025-11-20 08:00:12 - INFO - [Epoch 062] New best val loss: 762.3248\n",
      "[2025-11-20 08:00:57,918] [UniVITrainer] [INFO] [Epoch 070] Train loss: 762.8501 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 08:00:57 - INFO - [Epoch 070] Train loss: 762.8501 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 08:00:58,655] [UniVITrainer] [INFO] [Epoch 070] Val loss: 763.4609 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 08:00:58 - INFO - [Epoch 070] Val loss: 763.4609 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 08:02:00,109] [UniVITrainer] [INFO] [Epoch 080] Train loss: 764.9626 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 08:02:00 - INFO - [Epoch 080] Train loss: 764.9626 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 08:02:00,903] [UniVITrainer] [INFO] [Epoch 080] Val loss: 762.6367 (beta=60.000, gamma=60.000)\n",
      "2025-11-20 08:02:00 - INFO - [Epoch 080] Val loss: 762.6367 (beta=60.000, gamma=60.000)\n",
      "[2025-11-20 08:02:15,437] [UniVITrainer] [INFO] Early stopping at epoch 82 (best val loss = 762.3248)\n",
      "2025-11-20 08:02:15 - INFO - Early stopping at epoch 82 (best val loss = 762.3248)\n",
      "[2025-11-20 08:02:15,470] [UniVITrainer] [INFO] Restored best model from epoch 62 (val loss = 762.3248)\n",
      "2025-11-20 08:02:15 - INFO - Restored best model from epoch 62 (val loss = 762.3248)\n",
      "[2025-11-20 08:02:17,943] [UniVITrainer] [INFO] TrainingConfig:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 08:02:17 - INFO - TrainingConfig:\n",
      "[2025-11-20 08:02:17,946] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 08:02:17 - INFO -   n_epochs: 200\n",
      "[2025-11-20 08:02:17,948] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 08:02:17 - INFO -   batch_size: 256\n",
      "[2025-11-20 08:02:17,949] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 08:02:17 - INFO -   lr: 0.0005\n",
      "[2025-11-20 08:02:17,950] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 08:02:17 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 08:02:17,951] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 08:02:17 - INFO -   device: cuda\n",
      "[2025-11-20 08:02:17,952] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 08:02:17 - INFO -   log_every: 10\n",
      "[2025-11-20 08:02:17,953] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 08:02:17 - INFO -   grad_clip: None\n",
      "[2025-11-20 08:02:17,954] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 08:02:17 - INFO -   num_workers: 0\n",
      "[2025-11-20 08:02:17,955] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 08:02:17 - INFO -   seed: 42\n",
      "[2025-11-20 08:02:17,956] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 08:02:17 - INFO -   early_stopping: True\n",
      "[2025-11-20 08:02:17,957] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 08:02:17 - INFO -   patience: 20\n",
      "[2025-11-20 08:02:17,958] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 08:02:17 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 26] Done in 7.4 min\n",
      "  best_val_loss              = 762.325\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.2086\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.2515\n",
      "[Config 26] FOSCTTM (ADT vs ATAC, val) = 0.2455\n",
      "  Mean FOSCTTM (3 pairs)     = 0.2352\n",
      "  Modality mixing (k=20)     = 0.3831\n",
      "  Composite score            = 1302.36\n",
      "\n",
      "================================================================================\n",
      "[Config 27] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 124,\n",
      "  \"beta\": 240.0,\n",
      "  \"gamma\": 500.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide2\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_small2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dd930d6d544fbdab665f8cf2c39659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 08:02:24,553] [UniVITrainer] [INFO] [Epoch 001] Train loss: 16786.9140 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:02:24 - INFO - [Epoch 001] Train loss: 16786.9140 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:02:25,345] [UniVITrainer] [INFO] [Epoch 001] Val loss: 5889.7700 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:02:25 - INFO - [Epoch 001] Val loss: 5889.7700 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:02:25,509] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 5889.7700\n",
      "2025-11-20 08:02:25 - INFO - [Epoch 001] New best val loss: 5889.7700\n",
      "[2025-11-20 08:02:32,482] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 3337.2332\n",
      "2025-11-20 08:02:32 - INFO - [Epoch 002] New best val loss: 3337.2332\n",
      "[2025-11-20 08:02:40,029] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 2120.0328\n",
      "2025-11-20 08:02:40 - INFO - [Epoch 003] New best val loss: 2120.0328\n",
      "[2025-11-20 08:02:46,815] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 1656.5616\n",
      "2025-11-20 08:02:46 - INFO - [Epoch 004] New best val loss: 1656.5616\n",
      "[2025-11-20 08:02:51,635] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 1428.3636\n",
      "2025-11-20 08:02:51 - INFO - [Epoch 005] New best val loss: 1428.3636\n",
      "[2025-11-20 08:02:56,459] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 1315.4346\n",
      "2025-11-20 08:02:56 - INFO - [Epoch 006] New best val loss: 1315.4346\n",
      "[2025-11-20 08:03:02,967] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 1218.4098\n",
      "2025-11-20 08:03:02 - INFO - [Epoch 007] New best val loss: 1218.4098\n",
      "[2025-11-20 08:03:10,167] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 1195.4934\n",
      "2025-11-20 08:03:10 - INFO - [Epoch 008] New best val loss: 1195.4934\n",
      "[2025-11-20 08:03:17,081] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 1120.6031\n",
      "2025-11-20 08:03:17 - INFO - [Epoch 009] New best val loss: 1120.6031\n",
      "[2025-11-20 08:03:22,728] [UniVITrainer] [INFO] [Epoch 010] Train loss: 1617.0986 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:03:22 - INFO - [Epoch 010] Train loss: 1617.0986 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:03:23,221] [UniVITrainer] [INFO] [Epoch 010] Val loss: 1077.4982 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:03:23 - INFO - [Epoch 010] Val loss: 1077.4982 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:03:23,262] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 1077.4982\n",
      "2025-11-20 08:03:23 - INFO - [Epoch 010] New best val loss: 1077.4982\n",
      "[2025-11-20 08:03:27,944] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 1063.4178\n",
      "2025-11-20 08:03:27 - INFO - [Epoch 011] New best val loss: 1063.4178\n",
      "[2025-11-20 08:03:33,486] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 1032.2791\n",
      "2025-11-20 08:03:33 - INFO - [Epoch 012] New best val loss: 1032.2791\n",
      "[2025-11-20 08:03:40,974] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 1017.8364\n",
      "2025-11-20 08:03:40 - INFO - [Epoch 013] New best val loss: 1017.8364\n",
      "[2025-11-20 08:03:47,719] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 997.1748\n",
      "2025-11-20 08:03:47 - INFO - [Epoch 014] New best val loss: 997.1748\n",
      "[2025-11-20 08:03:55,186] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 982.6117\n",
      "2025-11-20 08:03:55 - INFO - [Epoch 015] New best val loss: 982.6117\n",
      "[2025-11-20 08:04:02,508] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 957.9248\n",
      "2025-11-20 08:04:02 - INFO - [Epoch 016] New best val loss: 957.9248\n",
      "[2025-11-20 08:04:09,812] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 949.3002\n",
      "2025-11-20 08:04:09 - INFO - [Epoch 017] New best val loss: 949.3002\n",
      "[2025-11-20 08:04:24,097] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 927.1263\n",
      "2025-11-20 08:04:24 - INFO - [Epoch 019] New best val loss: 927.1263\n",
      "[2025-11-20 08:04:30,226] [UniVITrainer] [INFO] [Epoch 020] Train loss: 1145.4220 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:04:30 - INFO - [Epoch 020] Train loss: 1145.4220 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:04:31,021] [UniVITrainer] [INFO] [Epoch 020] Val loss: 909.6129 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:04:31 - INFO - [Epoch 020] Val loss: 909.6129 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:04:31,058] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 909.6129\n",
      "2025-11-20 08:04:31 - INFO - [Epoch 020] New best val loss: 909.6129\n",
      "[2025-11-20 08:04:38,509] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 904.3640\n",
      "2025-11-20 08:04:38 - INFO - [Epoch 021] New best val loss: 904.3640\n",
      "[2025-11-20 08:04:52,991] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 886.6104\n",
      "2025-11-20 08:04:52 - INFO - [Epoch 023] New best val loss: 886.6104\n",
      "[2025-11-20 08:04:59,784] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 879.1217\n",
      "2025-11-20 08:04:59 - INFO - [Epoch 024] New best val loss: 879.1217\n",
      "[2025-11-20 08:05:06,311] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 870.9714\n",
      "2025-11-20 08:05:06 - INFO - [Epoch 025] New best val loss: 870.9714\n",
      "[2025-11-20 08:05:13,681] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 861.3807\n",
      "2025-11-20 08:05:13 - INFO - [Epoch 026] New best val loss: 861.3807\n",
      "[2025-11-20 08:05:22,712] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 855.4529\n",
      "2025-11-20 08:05:22 - INFO - [Epoch 027] New best val loss: 855.4529\n",
      "[2025-11-20 08:05:32,352] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 851.4951\n",
      "2025-11-20 08:05:32 - INFO - [Epoch 028] New best val loss: 851.4951\n",
      "[2025-11-20 08:05:42,027] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 846.9241\n",
      "2025-11-20 08:05:42 - INFO - [Epoch 029] New best val loss: 846.9241\n",
      "[2025-11-20 08:05:50,467] [UniVITrainer] [INFO] [Epoch 030] Train loss: 962.4350 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:05:50 - INFO - [Epoch 030] Train loss: 962.4350 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:05:51,544] [UniVITrainer] [INFO] [Epoch 030] Val loss: 840.0087 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:05:51 - INFO - [Epoch 030] Val loss: 840.0087 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:05:51,698] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 840.0087\n",
      "2025-11-20 08:05:51 - INFO - [Epoch 030] New best val loss: 840.0087\n",
      "[2025-11-20 08:06:11,147] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 833.0647\n",
      "2025-11-20 08:06:11 - INFO - [Epoch 032] New best val loss: 833.0647\n",
      "[2025-11-20 08:06:30,147] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 825.7271\n",
      "2025-11-20 08:06:30 - INFO - [Epoch 034] New best val loss: 825.7271\n",
      "[2025-11-20 08:06:40,082] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 818.8366\n",
      "2025-11-20 08:06:40 - INFO - [Epoch 035] New best val loss: 818.8366\n",
      "[2025-11-20 08:06:49,810] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 816.5361\n",
      "2025-11-20 08:06:49 - INFO - [Epoch 036] New best val loss: 816.5361\n",
      "[2025-11-20 08:06:59,609] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 813.5799\n",
      "2025-11-20 08:06:59 - INFO - [Epoch 037] New best val loss: 813.5799\n",
      "[2025-11-20 08:07:09,243] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 811.0822\n",
      "2025-11-20 08:07:09 - INFO - [Epoch 038] New best val loss: 811.0822\n",
      "[2025-11-20 08:07:27,439] [UniVITrainer] [INFO] [Epoch 040] Train loss: 883.4184 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:07:27 - INFO - [Epoch 040] Train loss: 883.4184 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:07:28,494] [UniVITrainer] [INFO] [Epoch 040] Val loss: 803.6782 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:07:28 - INFO - [Epoch 040] Val loss: 803.6782 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:07:28,645] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 803.6782\n",
      "2025-11-20 08:07:28 - INFO - [Epoch 040] New best val loss: 803.6782\n",
      "[2025-11-20 08:07:48,301] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 803.1369\n",
      "2025-11-20 08:07:48 - INFO - [Epoch 042] New best val loss: 803.1369\n",
      "[2025-11-20 08:08:08,015] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 796.4958\n",
      "2025-11-20 08:08:08 - INFO - [Epoch 044] New best val loss: 796.4958\n",
      "[2025-11-20 08:08:17,929] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 795.4986\n",
      "2025-11-20 08:08:17 - INFO - [Epoch 045] New best val loss: 795.4986\n",
      "[2025-11-20 08:08:27,862] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 792.2665\n",
      "2025-11-20 08:08:27 - INFO - [Epoch 046] New best val loss: 792.2665\n",
      "[2025-11-20 08:08:37,583] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 791.5356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 08:08:37 - INFO - [Epoch 047] New best val loss: 791.5356\n",
      "[2025-11-20 08:08:56,949] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 790.3651\n",
      "2025-11-20 08:08:56 - INFO - [Epoch 049] New best val loss: 790.3651\n",
      "[2025-11-20 08:09:05,484] [UniVITrainer] [INFO] [Epoch 050] Train loss: 836.8710 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:09:05 - INFO - [Epoch 050] Train loss: 836.8710 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:09:06,545] [UniVITrainer] [INFO] [Epoch 050] Val loss: 789.0023 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:09:06 - INFO - [Epoch 050] Val loss: 789.0023 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:09:06,695] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 789.0023\n",
      "2025-11-20 08:09:06 - INFO - [Epoch 050] New best val loss: 789.0023\n",
      "[2025-11-20 08:09:16,586] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 787.4659\n",
      "2025-11-20 08:09:16 - INFO - [Epoch 051] New best val loss: 787.4659\n",
      "[2025-11-20 08:09:26,326] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 784.7887\n",
      "2025-11-20 08:09:26 - INFO - [Epoch 052] New best val loss: 784.7887\n",
      "[2025-11-20 08:09:36,335] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 784.2527\n",
      "2025-11-20 08:09:36 - INFO - [Epoch 053] New best val loss: 784.2527\n",
      "[2025-11-20 08:09:45,994] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 783.2703\n",
      "2025-11-20 08:09:45 - INFO - [Epoch 054] New best val loss: 783.2703\n",
      "[2025-11-20 08:09:55,556] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 782.3283\n",
      "2025-11-20 08:09:55 - INFO - [Epoch 055] New best val loss: 782.3283\n",
      "[2025-11-20 08:10:05,281] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 782.1974\n",
      "2025-11-20 08:10:05 - INFO - [Epoch 056] New best val loss: 782.1974\n",
      "[2025-11-20 08:10:15,240] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 781.9342\n",
      "2025-11-20 08:10:15 - INFO - [Epoch 057] New best val loss: 781.9342\n",
      "[2025-11-20 08:10:34,904] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 781.0972\n",
      "2025-11-20 08:10:34 - INFO - [Epoch 059] New best val loss: 781.0972\n",
      "[2025-11-20 08:10:43,330] [UniVITrainer] [INFO] [Epoch 060] Train loss: 810.3698 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:10:43 - INFO - [Epoch 060] Train loss: 810.3698 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:10:44,408] [UniVITrainer] [INFO] [Epoch 060] Val loss: 779.0255 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:10:44 - INFO - [Epoch 060] Val loss: 779.0255 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:10:44,559] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 779.0255\n",
      "2025-11-20 08:10:44 - INFO - [Epoch 060] New best val loss: 779.0255\n",
      "[2025-11-20 08:11:03,856] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 778.7833\n",
      "2025-11-20 08:11:03 - INFO - [Epoch 062] New best val loss: 778.7833\n",
      "[2025-11-20 08:11:13,503] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 777.4791\n",
      "2025-11-20 08:11:13 - INFO - [Epoch 063] New best val loss: 777.4791\n",
      "[2025-11-20 08:11:32,963] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 777.2615\n",
      "2025-11-20 08:11:32 - INFO - [Epoch 065] New best val loss: 777.2615\n",
      "[2025-11-20 08:11:42,876] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 777.1084\n",
      "2025-11-20 08:11:42 - INFO - [Epoch 066] New best val loss: 777.1084\n",
      "[2025-11-20 08:11:52,661] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 776.3180\n",
      "2025-11-20 08:11:52 - INFO - [Epoch 067] New best val loss: 776.3180\n",
      "[2025-11-20 08:12:12,382] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 776.0700\n",
      "2025-11-20 08:12:12 - INFO - [Epoch 069] New best val loss: 776.0700\n",
      "[2025-11-20 08:12:21,045] [UniVITrainer] [INFO] [Epoch 070] Train loss: 795.1204 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:12:21 - INFO - [Epoch 070] Train loss: 795.1204 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:12:22,116] [UniVITrainer] [INFO] [Epoch 070] Val loss: 774.7232 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:12:22 - INFO - [Epoch 070] Val loss: 774.7232 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:12:22,353] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 774.7232\n",
      "2025-11-20 08:12:22 - INFO - [Epoch 070] New best val loss: 774.7232\n",
      "[2025-11-20 08:12:42,030] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 774.1301\n",
      "2025-11-20 08:12:42 - INFO - [Epoch 072] New best val loss: 774.1301\n",
      "[2025-11-20 08:13:01,481] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 773.6793\n",
      "2025-11-20 08:13:01 - INFO - [Epoch 074] New best val loss: 773.6793\n",
      "[2025-11-20 08:13:21,115] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 773.3489\n",
      "2025-11-20 08:13:21 - INFO - [Epoch 076] New best val loss: 773.3489\n",
      "[2025-11-20 08:13:40,695] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 772.9747\n",
      "2025-11-20 08:13:40 - INFO - [Epoch 078] New best val loss: 772.9747\n",
      "[2025-11-20 08:13:58,987] [UniVITrainer] [INFO] [Epoch 080] Train loss: 788.7044 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:13:58 - INFO - [Epoch 080] Train loss: 788.7044 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:13:59,984] [UniVITrainer] [INFO] [Epoch 080] Val loss: 772.0657 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:13:59 - INFO - [Epoch 080] Val loss: 772.0657 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:14:00,203] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 772.0657\n",
      "2025-11-20 08:14:00 - INFO - [Epoch 080] New best val loss: 772.0657\n",
      "[2025-11-20 08:14:49,327] [UniVITrainer] [INFO] [Epoch 085] New best val loss: 771.3458\n",
      "2025-11-20 08:14:49 - INFO - [Epoch 085] New best val loss: 771.3458\n",
      "[2025-11-20 08:15:28,481] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 771.3136\n",
      "2025-11-20 08:15:28 - INFO - [Epoch 089] New best val loss: 771.3136\n",
      "[2025-11-20 08:15:37,012] [UniVITrainer] [INFO] [Epoch 090] Train loss: 779.3730 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:15:37 - INFO - [Epoch 090] Train loss: 779.3730 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:15:38,085] [UniVITrainer] [INFO] [Epoch 090] Val loss: 771.2908 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:15:38 - INFO - [Epoch 090] Val loss: 771.2908 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:15:38,304] [UniVITrainer] [INFO] [Epoch 090] New best val loss: 771.2908\n",
      "2025-11-20 08:15:38 - INFO - [Epoch 090] New best val loss: 771.2908\n",
      "[2025-11-20 08:15:48,297] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 771.1588\n",
      "2025-11-20 08:15:48 - INFO - [Epoch 091] New best val loss: 771.1588\n",
      "[2025-11-20 08:15:58,120] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 770.6687\n",
      "2025-11-20 08:15:58 - INFO - [Epoch 092] New best val loss: 770.6687\n",
      "[2025-11-20 08:16:37,283] [UniVITrainer] [INFO] [Epoch 096] New best val loss: 770.5278\n",
      "2025-11-20 08:16:37 - INFO - [Epoch 096] New best val loss: 770.5278\n",
      "[2025-11-20 08:17:14,886] [UniVITrainer] [INFO] [Epoch 100] Train loss: 775.9520 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:17:14 - INFO - [Epoch 100] Train loss: 775.9520 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:17:15,934] [UniVITrainer] [INFO] [Epoch 100] Val loss: 770.5083 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:17:15 - INFO - [Epoch 100] Val loss: 770.5083 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:17:16,173] [UniVITrainer] [INFO] [Epoch 100] New best val loss: 770.5083\n",
      "2025-11-20 08:17:16 - INFO - [Epoch 100] New best val loss: 770.5083\n",
      "[2025-11-20 08:17:26,143] [UniVITrainer] [INFO] [Epoch 101] New best val loss: 770.2360\n",
      "2025-11-20 08:17:26 - INFO - [Epoch 101] New best val loss: 770.2360\n",
      "[2025-11-20 08:18:05,478] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 769.8040\n",
      "2025-11-20 08:18:05 - INFO - [Epoch 105] New best val loss: 769.8040\n",
      "[2025-11-20 08:18:15,311] [UniVITrainer] [INFO] [Epoch 106] New best val loss: 769.7094\n",
      "2025-11-20 08:18:15 - INFO - [Epoch 106] New best val loss: 769.7094\n",
      "[2025-11-20 08:18:53,207] [UniVITrainer] [INFO] [Epoch 110] Train loss: 774.6456 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:18:53 - INFO - [Epoch 110] Train loss: 774.6456 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:18:54,276] [UniVITrainer] [INFO] [Epoch 110] Val loss: 769.7379 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:18:54 - INFO - [Epoch 110] Val loss: 769.7379 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:19:09,175] [UniVITrainer] [INFO] [Epoch 112] New best val loss: 769.6074\n",
      "2025-11-20 08:19:09 - INFO - [Epoch 112] New best val loss: 769.6074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 08:19:16,664] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 769.6005\n",
      "2025-11-20 08:19:16 - INFO - [Epoch 113] New best val loss: 769.6005\n",
      "[2025-11-20 08:19:22,111] [UniVITrainer] [INFO] [Epoch 114] New best val loss: 769.3230\n",
      "2025-11-20 08:19:22 - INFO - [Epoch 114] New best val loss: 769.3230\n",
      "[2025-11-20 08:19:26,796] [UniVITrainer] [INFO] [Epoch 115] New best val loss: 769.2602\n",
      "2025-11-20 08:19:26 - INFO - [Epoch 115] New best val loss: 769.2602\n",
      "[2025-11-20 08:20:01,146] [UniVITrainer] [INFO] [Epoch 120] Train loss: 774.9872 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:20:01 - INFO - [Epoch 120] Train loss: 774.9872 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:20:01,942] [UniVITrainer] [INFO] [Epoch 120] Val loss: 769.4606 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:20:01 - INFO - [Epoch 120] Val loss: 769.4606 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:20:31,404] [UniVITrainer] [INFO] [Epoch 124] New best val loss: 769.2380\n",
      "2025-11-20 08:20:31 - INFO - [Epoch 124] New best val loss: 769.2380\n",
      "[2025-11-20 08:20:38,854] [UniVITrainer] [INFO] [Epoch 125] New best val loss: 769.1827\n",
      "2025-11-20 08:20:38 - INFO - [Epoch 125] New best val loss: 769.1827\n",
      "[2025-11-20 08:20:53,377] [UniVITrainer] [INFO] [Epoch 127] New best val loss: 768.9038\n",
      "2025-11-20 08:20:53 - INFO - [Epoch 127] New best val loss: 768.9038\n",
      "[2025-11-20 08:21:14,620] [UniVITrainer] [INFO] [Epoch 130] Train loss: 772.1783 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:21:14 - INFO - [Epoch 130] Train loss: 772.1783 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:21:15,408] [UniVITrainer] [INFO] [Epoch 130] Val loss: 769.0810 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:21:15 - INFO - [Epoch 130] Val loss: 769.0810 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:21:22,805] [UniVITrainer] [INFO] [Epoch 131] New best val loss: 768.7162\n",
      "2025-11-20 08:21:22 - INFO - [Epoch 131] New best val loss: 768.7162\n",
      "[2025-11-20 08:21:30,296] [UniVITrainer] [INFO] [Epoch 132] New best val loss: 768.6354\n",
      "2025-11-20 08:21:30 - INFO - [Epoch 132] New best val loss: 768.6354\n",
      "[2025-11-20 08:21:52,267] [UniVITrainer] [INFO] [Epoch 135] New best val loss: 768.5143\n",
      "2025-11-20 08:21:52 - INFO - [Epoch 135] New best val loss: 768.5143\n",
      "[2025-11-20 08:22:27,674] [UniVITrainer] [INFO] [Epoch 140] Train loss: 773.9621 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:22:27 - INFO - [Epoch 140] Train loss: 773.9621 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:22:28,463] [UniVITrainer] [INFO] [Epoch 140] Val loss: 768.4837 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:22:28 - INFO - [Epoch 140] Val loss: 768.4837 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:22:28,605] [UniVITrainer] [INFO] [Epoch 140] New best val loss: 768.4837\n",
      "2025-11-20 08:22:28 - INFO - [Epoch 140] New best val loss: 768.4837\n",
      "[2025-11-20 08:22:50,168] [UniVITrainer] [INFO] [Epoch 143] New best val loss: 768.4835\n",
      "2025-11-20 08:22:50 - INFO - [Epoch 143] New best val loss: 768.4835\n",
      "[2025-11-20 08:22:57,687] [UniVITrainer] [INFO] [Epoch 144] New best val loss: 768.3430\n",
      "2025-11-20 08:22:57 - INFO - [Epoch 144] New best val loss: 768.3430\n",
      "[2025-11-20 08:23:19,524] [UniVITrainer] [INFO] [Epoch 147] New best val loss: 768.2626\n",
      "2025-11-20 08:23:19 - INFO - [Epoch 147] New best val loss: 768.2626\n",
      "[2025-11-20 08:23:40,612] [UniVITrainer] [INFO] [Epoch 150] Train loss: 768.9973 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:23:40 - INFO - [Epoch 150] Train loss: 768.9973 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:23:41,402] [UniVITrainer] [INFO] [Epoch 150] Val loss: 768.5025 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:23:41 - INFO - [Epoch 150] Val loss: 768.5025 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:23:48,853] [UniVITrainer] [INFO] [Epoch 151] New best val loss: 768.2062\n",
      "2025-11-20 08:23:48 - INFO - [Epoch 151] New best val loss: 768.2062\n",
      "[2025-11-20 08:24:11,090] [UniVITrainer] [INFO] [Epoch 154] New best val loss: 768.1105\n",
      "2025-11-20 08:24:11 - INFO - [Epoch 154] New best val loss: 768.1105\n",
      "[2025-11-20 08:24:39,951] [UniVITrainer] [INFO] [Epoch 158] New best val loss: 768.0323\n",
      "2025-11-20 08:24:39 - INFO - [Epoch 158] New best val loss: 768.0323\n",
      "[2025-11-20 08:24:53,884] [UniVITrainer] [INFO] [Epoch 160] Train loss: 769.7200 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:24:53 - INFO - [Epoch 160] Train loss: 769.7200 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:24:54,682] [UniVITrainer] [INFO] [Epoch 160] Val loss: 768.2868 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:24:54 - INFO - [Epoch 160] Val loss: 768.2868 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:25:09,574] [UniVITrainer] [INFO] [Epoch 162] New best val loss: 767.8784\n",
      "2025-11-20 08:25:09 - INFO - [Epoch 162] New best val loss: 767.8784\n",
      "[2025-11-20 08:25:24,301] [UniVITrainer] [INFO] [Epoch 164] New best val loss: 767.8456\n",
      "2025-11-20 08:25:24 - INFO - [Epoch 164] New best val loss: 767.8456\n",
      "[2025-11-20 08:25:46,100] [UniVITrainer] [INFO] [Epoch 167] New best val loss: 767.7845\n",
      "2025-11-20 08:25:46 - INFO - [Epoch 167] New best val loss: 767.7845\n",
      "[2025-11-20 08:25:53,635] [UniVITrainer] [INFO] [Epoch 168] New best val loss: 767.7291\n",
      "2025-11-20 08:25:53 - INFO - [Epoch 168] New best val loss: 767.7291\n",
      "[2025-11-20 08:26:07,616] [UniVITrainer] [INFO] [Epoch 170] Train loss: 769.7622 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:26:07 - INFO - [Epoch 170] Train loss: 769.7622 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:26:08,410] [UniVITrainer] [INFO] [Epoch 170] Val loss: 768.0604 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:26:08 - INFO - [Epoch 170] Val loss: 768.0604 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:27:20,242] [UniVITrainer] [INFO] [Epoch 180] Train loss: 769.4862 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:27:20 - INFO - [Epoch 180] Train loss: 769.4862 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:27:21,026] [UniVITrainer] [INFO] [Epoch 180] Val loss: 768.0980 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:27:21 - INFO - [Epoch 180] Val loss: 768.0980 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:27:43,211] [UniVITrainer] [INFO] [Epoch 183] New best val loss: 767.6161\n",
      "2025-11-20 08:27:43 - INFO - [Epoch 183] New best val loss: 767.6161\n",
      "[2025-11-20 08:28:33,497] [UniVITrainer] [INFO] [Epoch 190] Train loss: 770.3793 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:28:33 - INFO - [Epoch 190] Train loss: 770.3793 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:28:34,290] [UniVITrainer] [INFO] [Epoch 190] Val loss: 767.6190 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:28:34 - INFO - [Epoch 190] Val loss: 767.6190 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:29:03,463] [UniVITrainer] [INFO] [Epoch 194] New best val loss: 767.5673\n",
      "2025-11-20 08:29:03 - INFO - [Epoch 194] New best val loss: 767.5673\n",
      "[2025-11-20 08:29:46,132] [UniVITrainer] [INFO] [Epoch 200] Train loss: 767.9302 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:29:46 - INFO - [Epoch 200] Train loss: 767.9302 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:29:46,917] [UniVITrainer] [INFO] [Epoch 200] Val loss: 767.4323 (beta=240.000, gamma=500.000)\n",
      "2025-11-20 08:29:46 - INFO - [Epoch 200] Val loss: 767.4323 (beta=240.000, gamma=500.000)\n",
      "[2025-11-20 08:29:46,964] [UniVITrainer] [INFO] [Epoch 200] New best val loss: 767.4323\n",
      "2025-11-20 08:29:46 - INFO - [Epoch 200] New best val loss: 767.4323\n",
      "[2025-11-20 08:29:46,990] [UniVITrainer] [INFO] Restored best model from epoch 200 (val loss = 767.4323)\n",
      "2025-11-20 08:29:46 - INFO - Restored best model from epoch 200 (val loss = 767.4323)\n",
      "[2025-11-20 08:29:49,025] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 08:29:49 - INFO - TrainingConfig:\n",
      "[2025-11-20 08:29:49,027] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 08:29:49 - INFO -   n_epochs: 200\n",
      "[2025-11-20 08:29:49,034] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 08:29:49 - INFO -   batch_size: 256\n",
      "[2025-11-20 08:29:49,041] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 08:29:49 - INFO -   lr: 0.0005\n",
      "[2025-11-20 08:29:49,042] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 08:29:49 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 08:29:49,043] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 08:29:49 - INFO -   device: cuda\n",
      "[2025-11-20 08:29:49,052] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 08:29:49 - INFO -   log_every: 10\n",
      "[2025-11-20 08:29:49,053] [UniVITrainer] [INFO]   grad_clip: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 08:29:49 - INFO -   grad_clip: None\n",
      "[2025-11-20 08:29:49,054] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 08:29:49 - INFO -   num_workers: 0\n",
      "[2025-11-20 08:29:49,055] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 08:29:49 - INFO -   seed: 42\n",
      "[2025-11-20 08:29:49,056] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 08:29:49 - INFO -   early_stopping: True\n",
      "[2025-11-20 08:29:49,057] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 08:29:49 - INFO -   patience: 20\n",
      "[2025-11-20 08:29:49,059] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 08:29:49 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 27] Done in 27.5 min\n",
      "  best_val_loss              = 767.432\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.5288\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.3994\n",
      "[Config 27] FOSCTTM (ADT vs ATAC, val) = 0.3951\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4411\n",
      "  Modality mixing (k=20)     = 0.0006\n",
      "  Composite score            = 1106.65\n",
      "\n",
      "================================================================================\n",
      "[Config 28] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 64,\n",
      "  \"beta\": 100.0,\n",
      "  \"gamma\": 140.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e45bccde4b42efabf1ad765fb7f7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 08:29:55,706] [UniVITrainer] [INFO] [Epoch 001] Train loss: 3398.5123 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:29:55 - INFO - [Epoch 001] Train loss: 3398.5123 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:29:56,492] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1599.6244 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:29:56 - INFO - [Epoch 001] Val loss: 1599.6244 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:29:56,737] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1599.6244\n",
      "2025-11-20 08:29:56 - INFO - [Epoch 001] New best val loss: 1599.6244\n",
      "[2025-11-20 08:30:04,347] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1070.1698\n",
      "2025-11-20 08:30:04 - INFO - [Epoch 002] New best val loss: 1070.1698\n",
      "[2025-11-20 08:30:11,866] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 929.7274\n",
      "2025-11-20 08:30:11 - INFO - [Epoch 003] New best val loss: 929.7274\n",
      "[2025-11-20 08:30:19,466] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 879.9719\n",
      "2025-11-20 08:30:19 - INFO - [Epoch 004] New best val loss: 879.9719\n",
      "[2025-11-20 08:30:27,087] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 858.3778\n",
      "2025-11-20 08:30:27 - INFO - [Epoch 005] New best val loss: 858.3778\n",
      "[2025-11-20 08:30:34,564] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 838.5404\n",
      "2025-11-20 08:30:34 - INFO - [Epoch 006] New best val loss: 838.5404\n",
      "[2025-11-20 08:30:42,085] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 829.8144\n",
      "2025-11-20 08:30:42 - INFO - [Epoch 007] New best val loss: 829.8144\n",
      "[2025-11-20 08:30:49,668] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 819.2540\n",
      "2025-11-20 08:30:49 - INFO - [Epoch 008] New best val loss: 819.2540\n",
      "[2025-11-20 08:30:57,220] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 813.4461\n",
      "2025-11-20 08:30:57 - INFO - [Epoch 009] New best val loss: 813.4461\n",
      "[2025-11-20 08:31:03,899] [UniVITrainer] [INFO] [Epoch 010] Train loss: 890.6677 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:31:03 - INFO - [Epoch 010] Train loss: 890.6677 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:31:04,691] [UniVITrainer] [INFO] [Epoch 010] Val loss: 809.0328 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:31:04 - INFO - [Epoch 010] Val loss: 809.0328 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:31:04,841] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 809.0328\n",
      "2025-11-20 08:31:04 - INFO - [Epoch 010] New best val loss: 809.0328\n",
      "[2025-11-20 08:31:12,345] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 805.8822\n",
      "2025-11-20 08:31:12 - INFO - [Epoch 011] New best val loss: 805.8822\n",
      "[2025-11-20 08:31:19,894] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 802.4855\n",
      "2025-11-20 08:31:19 - INFO - [Epoch 012] New best val loss: 802.4855\n",
      "[2025-11-20 08:31:27,496] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 800.2658\n",
      "2025-11-20 08:31:27 - INFO - [Epoch 013] New best val loss: 800.2658\n",
      "[2025-11-20 08:31:35,101] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 799.3082\n",
      "2025-11-20 08:31:35 - INFO - [Epoch 014] New best val loss: 799.3082\n",
      "[2025-11-20 08:31:42,063] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 796.1622\n",
      "2025-11-20 08:31:42 - INFO - [Epoch 015] New best val loss: 796.1622\n",
      "[2025-11-20 08:31:49,553] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 794.3119\n",
      "2025-11-20 08:31:49 - INFO - [Epoch 016] New best val loss: 794.3119\n",
      "[2025-11-20 08:31:57,046] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 793.7532\n",
      "2025-11-20 08:31:57 - INFO - [Epoch 017] New best val loss: 793.7532\n",
      "[2025-11-20 08:32:04,542] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 792.4267\n",
      "2025-11-20 08:32:04 - INFO - [Epoch 018] New best val loss: 792.4267\n",
      "[2025-11-20 08:32:12,120] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 791.2898\n",
      "2025-11-20 08:32:12 - INFO - [Epoch 019] New best val loss: 791.2898\n",
      "[2025-11-20 08:32:18,779] [UniVITrainer] [INFO] [Epoch 020] Train loss: 825.2800 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:32:18 - INFO - [Epoch 020] Train loss: 825.2800 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:32:19,574] [UniVITrainer] [INFO] [Epoch 020] Val loss: 789.7453 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:32:19 - INFO - [Epoch 020] Val loss: 789.7453 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:32:19,727] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 789.7453\n",
      "2025-11-20 08:32:19 - INFO - [Epoch 020] New best val loss: 789.7453\n",
      "[2025-11-20 08:32:27,112] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 788.5241\n",
      "2025-11-20 08:32:27 - INFO - [Epoch 021] New best val loss: 788.5241\n",
      "[2025-11-20 08:32:49,361] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 788.2020\n",
      "2025-11-20 08:32:49 - INFO - [Epoch 024] New best val loss: 788.2020\n",
      "[2025-11-20 08:32:56,901] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 786.0787\n",
      "2025-11-20 08:32:56 - INFO - [Epoch 025] New best val loss: 786.0787\n",
      "[2025-11-20 08:33:04,333] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 785.7084\n",
      "2025-11-20 08:33:04 - INFO - [Epoch 026] New best val loss: 785.7084\n",
      "[2025-11-20 08:33:11,795] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 784.9065\n",
      "2025-11-20 08:33:11 - INFO - [Epoch 027] New best val loss: 784.9065\n",
      "[2025-11-20 08:33:19,355] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 783.5964\n",
      "2025-11-20 08:33:19 - INFO - [Epoch 028] New best val loss: 783.5964\n",
      "[2025-11-20 08:33:33,487] [UniVITrainer] [INFO] [Epoch 030] Train loss: 801.9689 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:33:33 - INFO - [Epoch 030] Train loss: 801.9689 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:33:34,286] [UniVITrainer] [INFO] [Epoch 030] Val loss: 783.8719 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:33:34 - INFO - [Epoch 030] Val loss: 783.8719 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:34:04,064] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 782.1501\n",
      "2025-11-20 08:34:04 - INFO - [Epoch 034] New best val loss: 782.1501\n",
      "[2025-11-20 08:34:11,634] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 782.0071\n",
      "2025-11-20 08:34:11 - INFO - [Epoch 035] New best val loss: 782.0071\n",
      "[2025-11-20 08:34:19,246] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 781.4382\n",
      "2025-11-20 08:34:19 - INFO - [Epoch 036] New best val loss: 781.4382\n",
      "[2025-11-20 08:34:25,874] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 780.2044\n",
      "2025-11-20 08:34:25 - INFO - [Epoch 037] New best val loss: 780.2044\n",
      "[2025-11-20 08:34:33,488] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 779.9238\n",
      "2025-11-20 08:34:33 - INFO - [Epoch 038] New best val loss: 779.9238\n",
      "[2025-11-20 08:34:47,438] [UniVITrainer] [INFO] [Epoch 040] Train loss: 789.8165 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:34:47 - INFO - [Epoch 040] Train loss: 789.8165 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:34:48,231] [UniVITrainer] [INFO] [Epoch 040] Val loss: 780.5227 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:34:48 - INFO - [Epoch 040] Val loss: 780.5227 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:35:10,284] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 778.3235\n",
      "2025-11-20 08:35:10 - INFO - [Epoch 043] New best val loss: 778.3235\n",
      "[2025-11-20 08:35:17,870] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 777.7564\n",
      "2025-11-20 08:35:17 - INFO - [Epoch 044] New best val loss: 777.7564\n",
      "[2025-11-20 08:35:24,346] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 777.5134\n",
      "2025-11-20 08:35:24 - INFO - [Epoch 045] New best val loss: 777.5134\n",
      "[2025-11-20 08:35:38,933] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 776.7750\n",
      "2025-11-20 08:35:38 - INFO - [Epoch 047] New best val loss: 776.7750\n",
      "[2025-11-20 08:36:00,206] [UniVITrainer] [INFO] [Epoch 050] Train loss: 785.1855 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:36:00 - INFO - [Epoch 050] Train loss: 785.1855 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:36:01,000] [UniVITrainer] [INFO] [Epoch 050] Val loss: 778.5868 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:36:01 - INFO - [Epoch 050] Val loss: 778.5868 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:36:15,670] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 776.3145\n",
      "2025-11-20 08:36:15 - INFO - [Epoch 052] New best val loss: 776.3145\n",
      "[2025-11-20 08:36:23,210] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 775.7097\n",
      "2025-11-20 08:36:23 - INFO - [Epoch 053] New best val loss: 775.7097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 08:36:37,894] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 774.6937\n",
      "2025-11-20 08:36:37 - INFO - [Epoch 055] New best val loss: 774.6937\n",
      "[2025-11-20 08:36:52,401] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 774.5969\n",
      "2025-11-20 08:36:52 - INFO - [Epoch 057] New best val loss: 774.5969\n",
      "[2025-11-20 08:36:57,875] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 774.1371\n",
      "2025-11-20 08:36:57 - INFO - [Epoch 058] New best val loss: 774.1371\n",
      "[2025-11-20 08:37:10,270] [UniVITrainer] [INFO] [Epoch 060] Train loss: 777.9722 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:37:10 - INFO - [Epoch 060] Train loss: 777.9722 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:37:11,074] [UniVITrainer] [INFO] [Epoch 060] Val loss: 774.1716 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:37:11 - INFO - [Epoch 060] Val loss: 774.1716 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:37:29,302] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 773.4042\n",
      "2025-11-20 08:37:29 - INFO - [Epoch 063] New best val loss: 773.4042\n",
      "[2025-11-20 08:37:36,697] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 773.2396\n",
      "2025-11-20 08:37:36 - INFO - [Epoch 064] New best val loss: 773.2396\n",
      "[2025-11-20 08:37:43,913] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 772.3846\n",
      "2025-11-20 08:37:43 - INFO - [Epoch 065] New best val loss: 772.3846\n",
      "[2025-11-20 08:38:05,560] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 771.7430\n",
      "2025-11-20 08:38:05 - INFO - [Epoch 068] New best val loss: 771.7430\n",
      "[2025-11-20 08:38:19,070] [UniVITrainer] [INFO] [Epoch 070] Train loss: 780.2128 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:38:19 - INFO - [Epoch 070] Train loss: 780.2128 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:38:19,868] [UniVITrainer] [INFO] [Epoch 070] Val loss: 772.4770 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:38:19 - INFO - [Epoch 070] Val loss: 772.4770 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:38:34,681] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 771.6131\n",
      "2025-11-20 08:38:34 - INFO - [Epoch 072] New best val loss: 771.6131\n",
      "[2025-11-20 08:38:49,223] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 771.2656\n",
      "2025-11-20 08:38:49 - INFO - [Epoch 074] New best val loss: 771.2656\n",
      "[2025-11-20 08:38:56,418] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 771.2238\n",
      "2025-11-20 08:38:56 - INFO - [Epoch 075] New best val loss: 771.2238\n",
      "[2025-11-20 08:39:03,757] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 771.2083\n",
      "2025-11-20 08:39:03 - INFO - [Epoch 076] New best val loss: 771.2083\n",
      "[2025-11-20 08:39:10,995] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 770.8241\n",
      "2025-11-20 08:39:10 - INFO - [Epoch 077] New best val loss: 770.8241\n",
      "[2025-11-20 08:39:18,245] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 770.2877\n",
      "2025-11-20 08:39:18 - INFO - [Epoch 078] New best val loss: 770.2877\n",
      "[2025-11-20 08:39:32,007] [UniVITrainer] [INFO] [Epoch 080] Train loss: 774.4827 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:39:32 - INFO - [Epoch 080] Train loss: 774.4827 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:39:32,790] [UniVITrainer] [INFO] [Epoch 080] Val loss: 770.5214 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:39:32 - INFO - [Epoch 080] Val loss: 770.5214 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:39:54,835] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 769.8905\n",
      "2025-11-20 08:39:54 - INFO - [Epoch 083] New best val loss: 769.8905\n",
      "[2025-11-20 08:40:14,981] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 769.8244\n",
      "2025-11-20 08:40:14 - INFO - [Epoch 087] New best val loss: 769.8244\n",
      "[2025-11-20 08:40:21,731] [UniVITrainer] [INFO] [Epoch 090] Train loss: 770.1678 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:40:21 - INFO - [Epoch 090] Train loss: 770.1678 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:40:22,235] [UniVITrainer] [INFO] [Epoch 090] Val loss: 769.6294 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:40:22 - INFO - [Epoch 090] Val loss: 769.6294 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:40:22,499] [UniVITrainer] [INFO] [Epoch 090] New best val loss: 769.6294\n",
      "2025-11-20 08:40:22 - INFO - [Epoch 090] New best val loss: 769.6294\n",
      "[2025-11-20 08:40:27,079] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 769.2166\n",
      "2025-11-20 08:40:27 - INFO - [Epoch 091] New best val loss: 769.2166\n",
      "[2025-11-20 08:40:28,807] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 769.0541\n",
      "2025-11-20 08:40:28 - INFO - [Epoch 092] New best val loss: 769.0541\n",
      "[2025-11-20 08:40:31,255] [UniVITrainer] [INFO] [Epoch 093] New best val loss: 768.9356\n",
      "2025-11-20 08:40:31 - INFO - [Epoch 093] New best val loss: 768.9356\n",
      "[2025-11-20 08:40:36,249] [UniVITrainer] [INFO] [Epoch 094] New best val loss: 768.9313\n",
      "2025-11-20 08:40:36 - INFO - [Epoch 094] New best val loss: 768.9313\n",
      "[2025-11-20 08:40:43,858] [UniVITrainer] [INFO] [Epoch 096] New best val loss: 768.6905\n",
      "2025-11-20 08:40:43 - INFO - [Epoch 096] New best val loss: 768.6905\n",
      "[2025-11-20 08:40:53,243] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 768.3769\n",
      "2025-11-20 08:40:53 - INFO - [Epoch 098] New best val loss: 768.3769\n",
      "[2025-11-20 08:41:02,322] [UniVITrainer] [INFO] [Epoch 100] Train loss: 772.7265 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:41:02 - INFO - [Epoch 100] Train loss: 772.7265 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:41:02,826] [UniVITrainer] [INFO] [Epoch 100] Val loss: 768.3490 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:41:02 - INFO - [Epoch 100] Val loss: 768.3490 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:41:02,852] [UniVITrainer] [INFO] [Epoch 100] New best val loss: 768.3490\n",
      "2025-11-20 08:41:02 - INFO - [Epoch 100] New best val loss: 768.3490\n",
      "[2025-11-20 08:41:12,216] [UniVITrainer] [INFO] [Epoch 102] New best val loss: 768.2937\n",
      "2025-11-20 08:41:12 - INFO - [Epoch 102] New best val loss: 768.2937\n",
      "[2025-11-20 08:41:17,105] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 768.0577\n",
      "2025-11-20 08:41:17 - INFO - [Epoch 103] New best val loss: 768.0577\n",
      "[2025-11-20 08:41:21,724] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 767.9535\n",
      "2025-11-20 08:41:21 - INFO - [Epoch 104] New best val loss: 767.9535\n",
      "[2025-11-20 08:41:25,573] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 767.9150\n",
      "2025-11-20 08:41:25 - INFO - [Epoch 105] New best val loss: 767.9150\n",
      "[2025-11-20 08:41:39,853] [UniVITrainer] [INFO] [Epoch 108] New best val loss: 767.8139\n",
      "2025-11-20 08:41:39 - INFO - [Epoch 108] New best val loss: 767.8139\n",
      "[2025-11-20 08:41:48,758] [UniVITrainer] [INFO] [Epoch 110] Train loss: 766.7149 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:41:48 - INFO - [Epoch 110] Train loss: 766.7149 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:41:49,251] [UniVITrainer] [INFO] [Epoch 110] Val loss: 767.9644 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:41:49 - INFO - [Epoch 110] Val loss: 767.9644 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:41:54,015] [UniVITrainer] [INFO] [Epoch 111] New best val loss: 767.8008\n",
      "2025-11-20 08:41:54 - INFO - [Epoch 111] New best val loss: 767.8008\n",
      "[2025-11-20 08:41:58,789] [UniVITrainer] [INFO] [Epoch 112] New best val loss: 767.5605\n",
      "2025-11-20 08:41:58 - INFO - [Epoch 112] New best val loss: 767.5605\n",
      "[2025-11-20 08:42:22,328] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 767.4066\n",
      "2025-11-20 08:42:22 - INFO - [Epoch 117] New best val loss: 767.4066\n",
      "[2025-11-20 08:42:27,199] [UniVITrainer] [INFO] [Epoch 118] New best val loss: 767.3814\n",
      "2025-11-20 08:42:27 - INFO - [Epoch 118] New best val loss: 767.3814\n",
      "[2025-11-20 08:42:36,373] [UniVITrainer] [INFO] [Epoch 120] Train loss: 765.7232 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:42:36 - INFO - [Epoch 120] Train loss: 765.7232 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:42:36,877] [UniVITrainer] [INFO] [Epoch 120] Val loss: 767.4359 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:42:36 - INFO - [Epoch 120] Val loss: 767.4359 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:42:41,421] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 767.3254\n",
      "2025-11-20 08:42:41 - INFO - [Epoch 121] New best val loss: 767.3254\n",
      "[2025-11-20 08:42:46,191] [UniVITrainer] [INFO] [Epoch 122] New best val loss: 767.2679\n",
      "2025-11-20 08:42:46 - INFO - [Epoch 122] New best val loss: 767.2679\n",
      "[2025-11-20 08:42:50,777] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 767.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 08:42:50 - INFO - [Epoch 123] New best val loss: 767.1243\n",
      "[2025-11-20 08:43:05,040] [UniVITrainer] [INFO] [Epoch 126] New best val loss: 766.9914\n",
      "2025-11-20 08:43:05 - INFO - [Epoch 126] New best val loss: 766.9914\n",
      "[2025-11-20 08:43:23,060] [UniVITrainer] [INFO] [Epoch 130] Train loss: 763.3913 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:43:23 - INFO - [Epoch 130] Train loss: 763.3913 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:43:23,540] [UniVITrainer] [INFO] [Epoch 130] Val loss: 767.0899 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:43:23 - INFO - [Epoch 130] Val loss: 767.0899 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:43:33,190] [UniVITrainer] [INFO] [Epoch 132] New best val loss: 766.9526\n",
      "2025-11-20 08:43:33 - INFO - [Epoch 132] New best val loss: 766.9526\n",
      "[2025-11-20 08:43:42,600] [UniVITrainer] [INFO] [Epoch 134] New best val loss: 766.9445\n",
      "2025-11-20 08:43:42 - INFO - [Epoch 134] New best val loss: 766.9445\n",
      "[2025-11-20 08:43:47,249] [UniVITrainer] [INFO] [Epoch 135] New best val loss: 766.9218\n",
      "2025-11-20 08:43:47 - INFO - [Epoch 135] New best val loss: 766.9218\n",
      "[2025-11-20 08:43:52,081] [UniVITrainer] [INFO] [Epoch 136] New best val loss: 766.8620\n",
      "2025-11-20 08:43:52 - INFO - [Epoch 136] New best val loss: 766.8620\n",
      "[2025-11-20 08:44:10,138] [UniVITrainer] [INFO] [Epoch 140] Train loss: 768.2520 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:44:10 - INFO - [Epoch 140] Train loss: 768.2520 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:44:10,635] [UniVITrainer] [INFO] [Epoch 140] Val loss: 766.8695 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:44:10 - INFO - [Epoch 140] Val loss: 766.8695 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:44:15,469] [UniVITrainer] [INFO] [Epoch 141] New best val loss: 766.7169\n",
      "2025-11-20 08:44:15 - INFO - [Epoch 141] New best val loss: 766.7169\n",
      "[2025-11-20 08:44:53,882] [UniVITrainer] [INFO] [Epoch 149] New best val loss: 766.7095\n",
      "2025-11-20 08:44:53 - INFO - [Epoch 149] New best val loss: 766.7095\n",
      "[2025-11-20 08:44:58,236] [UniVITrainer] [INFO] [Epoch 150] Train loss: 766.7845 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:44:58 - INFO - [Epoch 150] Train loss: 766.7845 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:44:58,745] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.6736 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:44:58 - INFO - [Epoch 150] Val loss: 766.6736 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:44:58,774] [UniVITrainer] [INFO] [Epoch 150] New best val loss: 766.6736\n",
      "2025-11-20 08:44:58 - INFO - [Epoch 150] New best val loss: 766.6736\n",
      "[2025-11-20 08:45:21,861] [UniVITrainer] [INFO] [Epoch 155] New best val loss: 766.6562\n",
      "2025-11-20 08:45:21 - INFO - [Epoch 155] New best val loss: 766.6562\n",
      "[2025-11-20 08:45:40,601] [UniVITrainer] [INFO] [Epoch 159] New best val loss: 766.6534\n",
      "2025-11-20 08:45:40 - INFO - [Epoch 159] New best val loss: 766.6534\n",
      "[2025-11-20 08:45:44,784] [UniVITrainer] [INFO] [Epoch 160] Train loss: 765.4317 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:45:44 - INFO - [Epoch 160] Train loss: 765.4317 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:45:45,270] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.6145 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:45:45 - INFO - [Epoch 160] Val loss: 766.6145 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:45:45,310] [UniVITrainer] [INFO] [Epoch 160] New best val loss: 766.6145\n",
      "2025-11-20 08:45:45 - INFO - [Epoch 160] New best val loss: 766.6145\n",
      "[2025-11-20 08:45:54,931] [UniVITrainer] [INFO] [Epoch 162] New best val loss: 766.4970\n",
      "2025-11-20 08:45:54 - INFO - [Epoch 162] New best val loss: 766.4970\n",
      "[2025-11-20 08:46:28,652] [UniVITrainer] [INFO] [Epoch 169] New best val loss: 766.4796\n",
      "2025-11-20 08:46:28 - INFO - [Epoch 169] New best val loss: 766.4796\n",
      "[2025-11-20 08:46:32,986] [UniVITrainer] [INFO] [Epoch 170] Train loss: 767.3160 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:46:32 - INFO - [Epoch 170] Train loss: 767.3160 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:46:33,494] [UniVITrainer] [INFO] [Epoch 170] Val loss: 766.5504 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:46:33 - INFO - [Epoch 170] Val loss: 766.5504 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:47:20,576] [UniVITrainer] [INFO] [Epoch 180] Train loss: 767.6842 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:47:20 - INFO - [Epoch 180] Train loss: 767.6842 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:47:21,064] [UniVITrainer] [INFO] [Epoch 180] Val loss: 766.4916 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:47:21 - INFO - [Epoch 180] Val loss: 766.4916 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:48:04,144] [UniVITrainer] [INFO] [Epoch 189] New best val loss: 766.4576\n",
      "2025-11-20 08:48:04 - INFO - [Epoch 189] New best val loss: 766.4576\n",
      "[2025-11-20 08:48:08,392] [UniVITrainer] [INFO] [Epoch 190] Train loss: 765.5316 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:48:08 - INFO - [Epoch 190] Train loss: 765.5316 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:48:08,902] [UniVITrainer] [INFO] [Epoch 190] Val loss: 766.4978 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:48:08 - INFO - [Epoch 190] Val loss: 766.4978 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:48:19,512] [UniVITrainer] [INFO] [Epoch 192] New best val loss: 766.4173\n",
      "2025-11-20 08:48:19 - INFO - [Epoch 192] New best val loss: 766.4173\n",
      "[2025-11-20 08:49:13,586] [UniVITrainer] [INFO] [Epoch 200] Train loss: 769.8989 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:49:13 - INFO - [Epoch 200] Train loss: 769.8989 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:49:14,385] [UniVITrainer] [INFO] [Epoch 200] Val loss: 766.4721 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 08:49:14 - INFO - [Epoch 200] Val loss: 766.4721 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 08:49:14,434] [UniVITrainer] [INFO] Restored best model from epoch 192 (val loss = 766.4173)\n",
      "2025-11-20 08:49:14 - INFO - Restored best model from epoch 192 (val loss = 766.4173)\n",
      "[2025-11-20 08:49:16,917] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 08:49:16 - INFO - TrainingConfig:\n",
      "[2025-11-20 08:49:16,919] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 08:49:16 - INFO -   n_epochs: 200\n",
      "[2025-11-20 08:49:16,926] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 08:49:16 - INFO -   batch_size: 256\n",
      "[2025-11-20 08:49:16,933] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 08:49:16 - INFO -   lr: 0.0005\n",
      "[2025-11-20 08:49:16,934] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 08:49:16 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 08:49:16,941] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 08:49:16 - INFO -   device: cuda\n",
      "[2025-11-20 08:49:16,943] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 08:49:16 - INFO -   log_every: 10\n",
      "[2025-11-20 08:49:16,945] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 08:49:16 - INFO -   grad_clip: None\n",
      "[2025-11-20 08:49:16,946] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 08:49:16 - INFO -   num_workers: 0\n",
      "[2025-11-20 08:49:16,947] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 08:49:16 - INFO -   seed: 42\n",
      "[2025-11-20 08:49:16,948] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 08:49:16 - INFO -   early_stopping: True\n",
      "[2025-11-20 08:49:16,949] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 08:49:16 - INFO -   patience: 20\n",
      "[2025-11-20 08:49:16,950] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 08:49:16 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 28] Done in 19.4 min\n",
      "  best_val_loss              = 766.417\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4267\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4172\n",
      "[Config 28] FOSCTTM (ADT vs ATAC, val) = 0.4374\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4271\n",
      "  Modality mixing (k=20)     = 0.0176\n",
      "  Composite score            = 1112.98\n",
      "\n",
      "================================================================================\n",
      "[Config 29] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 20,\n",
      "  \"beta\": 180.0,\n",
      "  \"gamma\": 60.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_med2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2bb2e225fe4d65a69fddd5c3538a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 08:49:22,694] [UniVITrainer] [INFO] [Epoch 001] Train loss: 1690.3035 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:49:22 - INFO - [Epoch 001] Train loss: 1690.3035 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:49:23,499] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1123.2552 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:49:23 - INFO - [Epoch 001] Val loss: 1123.2552 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:49:23,592] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1123.2552\n",
      "2025-11-20 08:49:23 - INFO - [Epoch 001] New best val loss: 1123.2552\n",
      "[2025-11-20 08:49:30,847] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 879.2043\n",
      "2025-11-20 08:49:30 - INFO - [Epoch 002] New best val loss: 879.2043\n",
      "[2025-11-20 08:49:38,239] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 836.9519\n",
      "2025-11-20 08:49:38 - INFO - [Epoch 003] New best val loss: 836.9519\n",
      "[2025-11-20 08:49:44,703] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 819.6089\n",
      "2025-11-20 08:49:44 - INFO - [Epoch 004] New best val loss: 819.6089\n",
      "[2025-11-20 08:49:51,914] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 810.0319\n",
      "2025-11-20 08:49:51 - INFO - [Epoch 005] New best val loss: 810.0319\n",
      "[2025-11-20 08:49:59,306] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 800.3485\n",
      "2025-11-20 08:49:59 - INFO - [Epoch 006] New best val loss: 800.3485\n",
      "[2025-11-20 08:50:06,872] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 796.6224\n",
      "2025-11-20 08:50:06 - INFO - [Epoch 007] New best val loss: 796.6224\n",
      "[2025-11-20 08:50:14,382] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 792.9404\n",
      "2025-11-20 08:50:14 - INFO - [Epoch 008] New best val loss: 792.9404\n",
      "[2025-11-20 08:50:21,867] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 790.9471\n",
      "2025-11-20 08:50:21 - INFO - [Epoch 009] New best val loss: 790.9471\n",
      "[2025-11-20 08:50:27,712] [UniVITrainer] [INFO] [Epoch 010] Train loss: 806.8581 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:50:27 - INFO - [Epoch 010] Train loss: 806.8581 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:50:28,507] [UniVITrainer] [INFO] [Epoch 010] Val loss: 786.8098 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:50:28 - INFO - [Epoch 010] Val loss: 786.8098 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:50:28,651] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 786.8098\n",
      "2025-11-20 08:50:28 - INFO - [Epoch 010] New best val loss: 786.8098\n",
      "[2025-11-20 08:50:35,299] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 785.8471\n",
      "2025-11-20 08:50:35 - INFO - [Epoch 011] New best val loss: 785.8471\n",
      "[2025-11-20 08:50:42,316] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 785.2659\n",
      "2025-11-20 08:50:42 - INFO - [Epoch 012] New best val loss: 785.2659\n",
      "[2025-11-20 08:50:49,711] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 782.5736\n",
      "2025-11-20 08:50:49 - INFO - [Epoch 013] New best val loss: 782.5736\n",
      "[2025-11-20 08:51:04,604] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 781.8267\n",
      "2025-11-20 08:51:04 - INFO - [Epoch 015] New best val loss: 781.8267\n",
      "[2025-11-20 08:51:11,966] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 780.3446\n",
      "2025-11-20 08:51:11 - INFO - [Epoch 016] New best val loss: 780.3446\n",
      "[2025-11-20 08:51:18,975] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 780.2467\n",
      "2025-11-20 08:51:18 - INFO - [Epoch 017] New best val loss: 780.2467\n",
      "[2025-11-20 08:51:25,052] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 778.6214\n",
      "2025-11-20 08:51:25 - INFO - [Epoch 018] New best val loss: 778.6214\n",
      "[2025-11-20 08:51:38,829] [UniVITrainer] [INFO] [Epoch 020] Train loss: 789.1992 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:51:38 - INFO - [Epoch 020] Train loss: 789.1992 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:51:39,635] [UniVITrainer] [INFO] [Epoch 020] Val loss: 778.3158 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:51:39 - INFO - [Epoch 020] Val loss: 778.3158 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:51:39,734] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 778.3158\n",
      "2025-11-20 08:51:39 - INFO - [Epoch 020] New best val loss: 778.3158\n",
      "[2025-11-20 08:51:47,358] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 777.8435\n",
      "2025-11-20 08:51:47 - INFO - [Epoch 021] New best val loss: 777.8435\n",
      "[2025-11-20 08:51:53,497] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 777.7741\n",
      "2025-11-20 08:51:53 - INFO - [Epoch 022] New best val loss: 777.7741\n",
      "[2025-11-20 08:51:58,984] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 776.8932\n",
      "2025-11-20 08:51:58 - INFO - [Epoch 023] New best val loss: 776.8932\n",
      "[2025-11-20 08:52:06,065] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 776.7595\n",
      "2025-11-20 08:52:06 - INFO - [Epoch 024] New best val loss: 776.7595\n",
      "[2025-11-20 08:52:13,591] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 776.7502\n",
      "2025-11-20 08:52:13 - INFO - [Epoch 025] New best val loss: 776.7502\n",
      "[2025-11-20 08:52:19,519] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 776.2025\n",
      "2025-11-20 08:52:19 - INFO - [Epoch 026] New best val loss: 776.2025\n",
      "[2025-11-20 08:52:27,071] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 775.7615\n",
      "2025-11-20 08:52:27 - INFO - [Epoch 027] New best val loss: 775.7615\n",
      "[2025-11-20 08:52:40,672] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 775.3981\n",
      "2025-11-20 08:52:40 - INFO - [Epoch 029] New best val loss: 775.3981\n",
      "[2025-11-20 08:52:47,108] [UniVITrainer] [INFO] [Epoch 030] Train loss: 780.7181 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:52:47 - INFO - [Epoch 030] Train loss: 780.7181 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:52:47,910] [UniVITrainer] [INFO] [Epoch 030] Val loss: 775.4451 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:52:47 - INFO - [Epoch 030] Val loss: 775.4451 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:52:55,484] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 775.0025\n",
      "2025-11-20 08:52:55 - INFO - [Epoch 031] New best val loss: 775.0025\n",
      "[2025-11-20 08:53:02,548] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 774.6764\n",
      "2025-11-20 08:53:02 - INFO - [Epoch 032] New best val loss: 774.6764\n",
      "[2025-11-20 08:53:15,970] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 774.6671\n",
      "2025-11-20 08:53:15 - INFO - [Epoch 034] New best val loss: 774.6671\n",
      "[2025-11-20 08:53:23,596] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 774.4664\n",
      "2025-11-20 08:53:23 - INFO - [Epoch 035] New best val loss: 774.4664\n",
      "[2025-11-20 08:53:29,843] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 774.0062\n",
      "2025-11-20 08:53:29 - INFO - [Epoch 036] New best val loss: 774.0062\n",
      "[2025-11-20 08:53:49,466] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 773.5688\n",
      "2025-11-20 08:53:49 - INFO - [Epoch 039] New best val loss: 773.5688\n",
      "[2025-11-20 08:53:56,074] [UniVITrainer] [INFO] [Epoch 040] Train loss: 776.0304 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:53:56 - INFO - [Epoch 040] Train loss: 776.0304 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:53:56,875] [UniVITrainer] [INFO] [Epoch 040] Val loss: 773.8206 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:53:56 - INFO - [Epoch 040] Val loss: 773.8206 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:54:11,128] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 772.8450\n",
      "2025-11-20 08:54:11 - INFO - [Epoch 042] New best val loss: 772.8450\n",
      "[2025-11-20 08:54:23,507] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 772.5579\n",
      "2025-11-20 08:54:23 - INFO - [Epoch 044] New best val loss: 772.5579\n",
      "[2025-11-20 08:54:44,054] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 772.3253\n",
      "2025-11-20 08:54:44 - INFO - [Epoch 047] New best val loss: 772.3253\n",
      "[2025-11-20 08:55:05,455] [UniVITrainer] [INFO] [Epoch 050] Train loss: 771.3665 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:55:05 - INFO - [Epoch 050] Train loss: 771.3665 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:55:06,236] [UniVITrainer] [INFO] [Epoch 050] Val loss: 772.6457 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:55:06 - INFO - [Epoch 050] Val loss: 772.6457 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:55:22,914] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 772.1717\n",
      "2025-11-20 08:55:22 - INFO - [Epoch 053] New best val loss: 772.1717\n",
      "[2025-11-20 08:55:38,855] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 771.8815\n",
      "2025-11-20 08:55:38 - INFO - [Epoch 056] New best val loss: 771.8815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 08:55:59,453] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 771.7233\n",
      "2025-11-20 08:55:59 - INFO - [Epoch 059] New best val loss: 771.7233\n",
      "[2025-11-20 08:56:06,114] [UniVITrainer] [INFO] [Epoch 060] Train loss: 775.8984 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:56:06 - INFO - [Epoch 060] Train loss: 775.8984 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:56:06,897] [UniVITrainer] [INFO] [Epoch 060] Val loss: 771.9242 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:56:06 - INFO - [Epoch 060] Val loss: 771.9242 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:56:39,439] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 771.5744\n",
      "2025-11-20 08:56:39 - INFO - [Epoch 065] New best val loss: 771.5744\n",
      "[2025-11-20 08:56:53,547] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 771.3670\n",
      "2025-11-20 08:56:53 - INFO - [Epoch 067] New best val loss: 771.3670\n",
      "[2025-11-20 08:57:08,238] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 771.0732\n",
      "2025-11-20 08:57:08 - INFO - [Epoch 069] New best val loss: 771.0732\n",
      "[2025-11-20 08:57:14,457] [UniVITrainer] [INFO] [Epoch 070] Train loss: 771.5138 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:57:14 - INFO - [Epoch 070] Train loss: 771.5138 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:57:15,260] [UniVITrainer] [INFO] [Epoch 070] Val loss: 771.2708 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:57:15 - INFO - [Epoch 070] Val loss: 771.2708 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:57:29,856] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 770.8878\n",
      "2025-11-20 08:57:29 - INFO - [Epoch 072] New best val loss: 770.8878\n",
      "[2025-11-20 08:58:06,037] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 770.6408\n",
      "2025-11-20 08:58:06 - INFO - [Epoch 077] New best val loss: 770.6408\n",
      "[2025-11-20 08:58:13,151] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 770.6065\n",
      "2025-11-20 08:58:13 - INFO - [Epoch 078] New best val loss: 770.6065\n",
      "[2025-11-20 08:58:20,168] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 770.5022\n",
      "2025-11-20 08:58:20 - INFO - [Epoch 079] New best val loss: 770.5022\n",
      "[2025-11-20 08:58:26,635] [UniVITrainer] [INFO] [Epoch 080] Train loss: 769.5681 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:58:26 - INFO - [Epoch 080] Train loss: 769.5681 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:58:27,267] [UniVITrainer] [INFO] [Epoch 080] Val loss: 770.9503 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:58:27 - INFO - [Epoch 080] Val loss: 770.9503 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:58:40,680] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 770.4688\n",
      "2025-11-20 08:58:40 - INFO - [Epoch 082] New best val loss: 770.4688\n",
      "[2025-11-20 08:58:47,711] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 770.3416\n",
      "2025-11-20 08:58:47 - INFO - [Epoch 083] New best val loss: 770.3416\n",
      "[2025-11-20 08:58:54,441] [UniVITrainer] [INFO] [Epoch 085] New best val loss: 770.3127\n",
      "2025-11-20 08:58:54 - INFO - [Epoch 085] New best val loss: 770.3127\n",
      "[2025-11-20 08:59:16,041] [UniVITrainer] [INFO] [Epoch 088] New best val loss: 770.1813\n",
      "2025-11-20 08:59:16 - INFO - [Epoch 088] New best val loss: 770.1813\n",
      "[2025-11-20 08:59:23,673] [UniVITrainer] [INFO] [Epoch 090] Train loss: 768.2837 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:59:23 - INFO - [Epoch 090] Train loss: 768.2837 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:59:24,294] [UniVITrainer] [INFO] [Epoch 090] Val loss: 770.2556 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 08:59:24 - INFO - [Epoch 090] Val loss: 770.2556 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 08:59:38,922] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 770.1570\n",
      "2025-11-20 08:59:38 - INFO - [Epoch 092] New best val loss: 770.1570\n",
      "[2025-11-20 08:59:45,168] [UniVITrainer] [INFO] [Epoch 093] New best val loss: 770.1288\n",
      "2025-11-20 08:59:45 - INFO - [Epoch 093] New best val loss: 770.1288\n",
      "[2025-11-20 09:00:17,348] [UniVITrainer] [INFO] [Epoch 098] New best val loss: 769.8211\n",
      "2025-11-20 09:00:17 - INFO - [Epoch 098] New best val loss: 769.8211\n",
      "[2025-11-20 09:00:32,549] [UniVITrainer] [INFO] [Epoch 100] Train loss: 768.9117 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:00:32 - INFO - [Epoch 100] Train loss: 768.9117 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:00:33,354] [UniVITrainer] [INFO] [Epoch 100] Val loss: 770.5161 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:00:33 - INFO - [Epoch 100] Val loss: 770.5161 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:00:45,995] [UniVITrainer] [INFO] [Epoch 102] New best val loss: 769.8064\n",
      "2025-11-20 09:00:45 - INFO - [Epoch 102] New best val loss: 769.8064\n",
      "[2025-11-20 09:01:13,071] [UniVITrainer] [INFO] [Epoch 106] New best val loss: 769.5536\n",
      "2025-11-20 09:01:13 - INFO - [Epoch 106] New best val loss: 769.5536\n",
      "[2025-11-20 09:01:40,620] [UniVITrainer] [INFO] [Epoch 110] Train loss: 769.5905 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:01:40 - INFO - [Epoch 110] Train loss: 769.5905 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:01:41,356] [UniVITrainer] [INFO] [Epoch 110] Val loss: 769.6909 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:01:41 - INFO - [Epoch 110] Val loss: 769.6909 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:01:52,950] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 769.4410\n",
      "2025-11-20 09:01:52 - INFO - [Epoch 113] New best val loss: 769.4410\n",
      "[2025-11-20 09:01:57,909] [UniVITrainer] [INFO] [Epoch 114] New best val loss: 769.3508\n",
      "2025-11-20 09:01:57 - INFO - [Epoch 114] New best val loss: 769.3508\n",
      "[2025-11-20 09:02:02,505] [UniVITrainer] [INFO] [Epoch 115] New best val loss: 769.2140\n",
      "2025-11-20 09:02:02 - INFO - [Epoch 115] New best val loss: 769.2140\n",
      "[2025-11-20 09:02:35,550] [UniVITrainer] [INFO] [Epoch 120] Train loss: 772.2987 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:02:35 - INFO - [Epoch 120] Train loss: 772.2987 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:02:36,355] [UniVITrainer] [INFO] [Epoch 120] Val loss: 769.4236 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:02:36 - INFO - [Epoch 120] Val loss: 769.4236 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:02:51,886] [UniVITrainer] [INFO] [Epoch 122] New best val loss: 769.1424\n",
      "2025-11-20 09:02:51 - INFO - [Epoch 122] New best val loss: 769.1424\n",
      "[2025-11-20 09:03:08,613] [UniVITrainer] [INFO] [Epoch 125] New best val loss: 769.0933\n",
      "2025-11-20 09:03:08 - INFO - [Epoch 125] New best val loss: 769.0933\n",
      "[2025-11-20 09:03:21,916] [UniVITrainer] [INFO] [Epoch 127] New best val loss: 768.9719\n",
      "2025-11-20 09:03:21 - INFO - [Epoch 127] New best val loss: 768.9719\n",
      "[2025-11-20 09:03:43,405] [UniVITrainer] [INFO] [Epoch 130] Train loss: 766.8065 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:03:43 - INFO - [Epoch 130] Train loss: 766.8065 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:03:44,206] [UniVITrainer] [INFO] [Epoch 130] Val loss: 769.0891 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:03:44 - INFO - [Epoch 130] Val loss: 769.0891 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:03:51,074] [UniVITrainer] [INFO] [Epoch 131] New best val loss: 768.9681\n",
      "2025-11-20 09:03:51 - INFO - [Epoch 131] New best val loss: 768.9681\n",
      "[2025-11-20 09:03:57,429] [UniVITrainer] [INFO] [Epoch 132] New best val loss: 768.8724\n",
      "2025-11-20 09:03:57 - INFO - [Epoch 132] New best val loss: 768.8724\n",
      "[2025-11-20 09:04:39,962] [UniVITrainer] [INFO] [Epoch 138] New best val loss: 768.7587\n",
      "2025-11-20 09:04:39 - INFO - [Epoch 138] New best val loss: 768.7587\n",
      "[2025-11-20 09:04:53,867] [UniVITrainer] [INFO] [Epoch 140] Train loss: 767.8233 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:04:53 - INFO - [Epoch 140] Train loss: 767.8233 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:04:54,666] [UniVITrainer] [INFO] [Epoch 140] Val loss: 768.9455 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:04:54 - INFO - [Epoch 140] Val loss: 768.9455 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:05:22,492] [UniVITrainer] [INFO] [Epoch 144] New best val loss: 768.6840\n",
      "2025-11-20 09:05:22 - INFO - [Epoch 144] New best val loss: 768.6840\n",
      "[2025-11-20 09:05:40,511] [UniVITrainer] [INFO] [Epoch 148] New best val loss: 768.6245\n",
      "2025-11-20 09:05:40 - INFO - [Epoch 148] New best val loss: 768.6245\n",
      "[2025-11-20 09:05:45,385] [UniVITrainer] [INFO] [Epoch 150] Train loss: 772.6406 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:05:45 - INFO - [Epoch 150] Train loss: 772.6406 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:05:45,770] [UniVITrainer] [INFO] [Epoch 150] Val loss: 768.8871 (beta=180.000, gamma=60.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 09:05:45 - INFO - [Epoch 150] Val loss: 768.8871 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:05:59,554] [UniVITrainer] [INFO] [Epoch 153] New best val loss: 768.6102\n",
      "2025-11-20 09:05:59 - INFO - [Epoch 153] New best val loss: 768.6102\n",
      "[2025-11-20 09:06:06,891] [UniVITrainer] [INFO] [Epoch 155] New best val loss: 768.4896\n",
      "2025-11-20 09:06:06 - INFO - [Epoch 155] New best val loss: 768.4896\n",
      "[2025-11-20 09:06:21,441] [UniVITrainer] [INFO] [Epoch 160] Train loss: 770.3677 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:06:21 - INFO - [Epoch 160] Train loss: 770.3677 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:06:21,941] [UniVITrainer] [INFO] [Epoch 160] Val loss: 768.5466 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:06:21 - INFO - [Epoch 160] Val loss: 768.5466 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:06:40,316] [UniVITrainer] [INFO] [Epoch 164] New best val loss: 768.3952\n",
      "2025-11-20 09:06:40 - INFO - [Epoch 164] New best val loss: 768.3952\n",
      "[2025-11-20 09:06:54,537] [UniVITrainer] [INFO] [Epoch 167] New best val loss: 768.3421\n",
      "2025-11-20 09:06:54 - INFO - [Epoch 167] New best val loss: 768.3421\n",
      "[2025-11-20 09:06:59,285] [UniVITrainer] [INFO] [Epoch 168] New best val loss: 768.2386\n",
      "2025-11-20 09:06:59 - INFO - [Epoch 168] New best val loss: 768.2386\n",
      "[2025-11-20 09:07:08,017] [UniVITrainer] [INFO] [Epoch 170] Train loss: 770.0315 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:07:08 - INFO - [Epoch 170] Train loss: 770.0315 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:07:08,514] [UniVITrainer] [INFO] [Epoch 170] Val loss: 768.1971 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:07:08 - INFO - [Epoch 170] Val loss: 768.1971 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:07:08,531] [UniVITrainer] [INFO] [Epoch 170] New best val loss: 768.1971\n",
      "2025-11-20 09:07:08 - INFO - [Epoch 170] New best val loss: 768.1971\n",
      "[2025-11-20 09:07:41,641] [UniVITrainer] [INFO] [Epoch 177] New best val loss: 768.1325\n",
      "2025-11-20 09:07:41 - INFO - [Epoch 177] New best val loss: 768.1325\n",
      "[2025-11-20 09:07:55,266] [UniVITrainer] [INFO] [Epoch 180] Train loss: 765.9693 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:07:55 - INFO - [Epoch 180] Train loss: 765.9693 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:07:55,784] [UniVITrainer] [INFO] [Epoch 180] Val loss: 768.2536 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:07:55 - INFO - [Epoch 180] Val loss: 768.2536 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:08:18,662] [UniVITrainer] [INFO] [Epoch 185] New best val loss: 768.0184\n",
      "2025-11-20 09:08:18 - INFO - [Epoch 185] New best val loss: 768.0184\n",
      "[2025-11-20 09:08:23,351] [UniVITrainer] [INFO] [Epoch 186] New best val loss: 767.9707\n",
      "2025-11-20 09:08:23 - INFO - [Epoch 186] New best val loss: 767.9707\n",
      "[2025-11-20 09:08:32,760] [UniVITrainer] [INFO] [Epoch 188] New best val loss: 767.9662\n",
      "2025-11-20 09:08:32 - INFO - [Epoch 188] New best val loss: 767.9662\n",
      "[2025-11-20 09:08:41,913] [UniVITrainer] [INFO] [Epoch 190] Train loss: 767.6189 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:08:41 - INFO - [Epoch 190] Train loss: 767.6189 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:08:42,393] [UniVITrainer] [INFO] [Epoch 190] Val loss: 768.0211 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:08:42 - INFO - [Epoch 190] Val loss: 768.0211 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:09:15,389] [UniVITrainer] [INFO] [Epoch 197] New best val loss: 767.8851\n",
      "2025-11-20 09:09:15 - INFO - [Epoch 197] New best val loss: 767.8851\n",
      "[2025-11-20 09:09:19,552] [UniVITrainer] [INFO] [Epoch 198] New best val loss: 767.8536\n",
      "2025-11-20 09:09:19 - INFO - [Epoch 198] New best val loss: 767.8536\n",
      "[2025-11-20 09:09:28,468] [UniVITrainer] [INFO] [Epoch 200] Train loss: 766.7279 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:09:28 - INFO - [Epoch 200] Train loss: 766.7279 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:09:28,544] [UniVITrainer] [INFO] [Epoch 200] Val loss: 767.8221 (beta=180.000, gamma=60.000)\n",
      "2025-11-20 09:09:28 - INFO - [Epoch 200] Val loss: 767.8221 (beta=180.000, gamma=60.000)\n",
      "[2025-11-20 09:09:28,563] [UniVITrainer] [INFO] [Epoch 200] New best val loss: 767.8221\n",
      "2025-11-20 09:09:28 - INFO - [Epoch 200] New best val loss: 767.8221\n",
      "[2025-11-20 09:09:28,571] [UniVITrainer] [INFO] Restored best model from epoch 200 (val loss = 767.8221)\n",
      "2025-11-20 09:09:28 - INFO - Restored best model from epoch 200 (val loss = 767.8221)\n",
      "[2025-11-20 09:09:30,384] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 09:09:30 - INFO - TrainingConfig:\n",
      "[2025-11-20 09:09:30,386] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 09:09:30 - INFO -   n_epochs: 200\n",
      "[2025-11-20 09:09:30,387] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 09:09:30 - INFO -   batch_size: 256\n",
      "[2025-11-20 09:09:30,389] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 09:09:30 - INFO -   lr: 0.001\n",
      "[2025-11-20 09:09:30,390] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 09:09:30 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 09:09:30,392] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 09:09:30 - INFO -   device: cuda\n",
      "[2025-11-20 09:09:30,393] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 09:09:30 - INFO -   log_every: 10\n",
      "[2025-11-20 09:09:30,394] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 09:09:30 - INFO -   grad_clip: None\n",
      "[2025-11-20 09:09:30,396] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 09:09:30 - INFO -   num_workers: 0\n",
      "[2025-11-20 09:09:30,397] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 09:09:30 - INFO -   seed: 42\n",
      "[2025-11-20 09:09:30,398] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 09:09:30 - INFO -   early_stopping: True\n",
      "[2025-11-20 09:09:30,400] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 09:09:30 - INFO -   patience: 20\n",
      "[2025-11-20 09:09:30,402] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 09:09:30 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 29] Done in 20.2 min\n",
      "  best_val_loss              = 767.822\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.1684\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.1758\n",
      "[Config 29] FOSCTTM (ADT vs ATAC, val) = 0.2053\n",
      "  Mean FOSCTTM (3 pairs)     = 0.1832\n",
      "  Modality mixing (k=20)     = 0.0232\n",
      "  Composite score            = 929.56\n",
      "\n",
      "================================================================================\n",
      "[Config 30] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 20,\n",
      "  \"beta\": 500.0,\n",
      "  \"gamma\": 1000.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_wide2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_wide2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae90a3f641a4e0891f0c146cb61a2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 09:09:34,798] [UniVITrainer] [INFO] [Epoch 001] Train loss: 4182.2584 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:09:34 - INFO - [Epoch 001] Train loss: 4182.2584 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:09:35,301] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1364.9265 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:09:35 - INFO - [Epoch 001] Val loss: 1364.9265 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:09:35,344] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1364.9265\n",
      "2025-11-20 09:09:35 - INFO - [Epoch 001] New best val loss: 1364.9265\n",
      "[2025-11-20 09:09:40,122] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1047.9574\n",
      "2025-11-20 09:09:40 - INFO - [Epoch 002] New best val loss: 1047.9574\n",
      "[2025-11-20 09:09:44,972] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 931.4203\n",
      "2025-11-20 09:09:44 - INFO - [Epoch 003] New best val loss: 931.4203\n",
      "[2025-11-20 09:09:49,631] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 883.5238\n",
      "2025-11-20 09:09:49 - INFO - [Epoch 004] New best val loss: 883.5238\n",
      "[2025-11-20 09:09:54,444] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 859.1027\n",
      "2025-11-20 09:09:54 - INFO - [Epoch 005] New best val loss: 859.1027\n",
      "[2025-11-20 09:09:59,196] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 849.9852\n",
      "2025-11-20 09:09:59 - INFO - [Epoch 006] New best val loss: 849.9852\n",
      "[2025-11-20 09:10:04,009] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 836.4890\n",
      "2025-11-20 09:10:04 - INFO - [Epoch 007] New best val loss: 836.4890\n",
      "[2025-11-20 09:10:08,857] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 822.4074\n",
      "2025-11-20 09:10:08 - INFO - [Epoch 008] New best val loss: 822.4074\n",
      "[2025-11-20 09:10:13,628] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 819.9795\n",
      "2025-11-20 09:10:13 - INFO - [Epoch 009] New best val loss: 819.9795\n",
      "[2025-11-20 09:10:17,593] [UniVITrainer] [INFO] [Epoch 010] Train loss: 914.4966 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:10:17 - INFO - [Epoch 010] Train loss: 914.4966 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:10:18,100] [UniVITrainer] [INFO] [Epoch 010] Val loss: 811.8591 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:10:18 - INFO - [Epoch 010] Val loss: 811.8591 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:10:18,118] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 811.8591\n",
      "2025-11-20 09:10:18 - INFO - [Epoch 010] New best val loss: 811.8591\n",
      "[2025-11-20 09:10:22,979] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 807.5295\n",
      "2025-11-20 09:10:22 - INFO - [Epoch 011] New best val loss: 807.5295\n",
      "[2025-11-20 09:10:27,630] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 802.7470\n",
      "2025-11-20 09:10:27 - INFO - [Epoch 012] New best val loss: 802.7470\n",
      "[2025-11-20 09:10:32,499] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 800.3043\n",
      "2025-11-20 09:10:32 - INFO - [Epoch 013] New best val loss: 800.3043\n",
      "[2025-11-20 09:10:36,932] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 796.3789\n",
      "2025-11-20 09:10:36 - INFO - [Epoch 014] New best val loss: 796.3789\n",
      "[2025-11-20 09:10:41,752] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 793.6957\n",
      "2025-11-20 09:10:41 - INFO - [Epoch 015] New best val loss: 793.6957\n",
      "[2025-11-20 09:10:46,476] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 791.8283\n",
      "2025-11-20 09:10:46 - INFO - [Epoch 016] New best val loss: 791.8283\n",
      "[2025-11-20 09:10:51,137] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 788.7444\n",
      "2025-11-20 09:10:51 - INFO - [Epoch 017] New best val loss: 788.7444\n",
      "[2025-11-20 09:10:55,837] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 787.1838\n",
      "2025-11-20 09:10:55 - INFO - [Epoch 018] New best val loss: 787.1838\n",
      "[2025-11-20 09:11:00,668] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 784.1050\n",
      "2025-11-20 09:11:00 - INFO - [Epoch 019] New best val loss: 784.1050\n",
      "[2025-11-20 09:11:04,573] [UniVITrainer] [INFO] [Epoch 020] Train loss: 813.7293 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:11:04 - INFO - [Epoch 020] Train loss: 813.7293 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:11:05,068] [UniVITrainer] [INFO] [Epoch 020] Val loss: 785.1593 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:11:05 - INFO - [Epoch 020] Val loss: 785.1593 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:11:09,932] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 783.3073\n",
      "2025-11-20 09:11:09 - INFO - [Epoch 021] New best val loss: 783.3073\n",
      "[2025-11-20 09:11:14,125] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 780.9893\n",
      "2025-11-20 09:11:14 - INFO - [Epoch 022] New best val loss: 780.9893\n",
      "[2025-11-20 09:11:23,898] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 780.7404\n",
      "2025-11-20 09:11:23 - INFO - [Epoch 024] New best val loss: 780.7404\n",
      "[2025-11-20 09:11:28,411] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 779.4364\n",
      "2025-11-20 09:11:28 - INFO - [Epoch 025] New best val loss: 779.4364\n",
      "[2025-11-20 09:11:33,118] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 778.1370\n",
      "2025-11-20 09:11:33 - INFO - [Epoch 026] New best val loss: 778.1370\n",
      "[2025-11-20 09:11:37,878] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 776.6291\n",
      "2025-11-20 09:11:37 - INFO - [Epoch 027] New best val loss: 776.6291\n",
      "[2025-11-20 09:11:42,667] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 776.5361\n",
      "2025-11-20 09:11:42 - INFO - [Epoch 028] New best val loss: 776.5361\n",
      "[2025-11-20 09:11:51,705] [UniVITrainer] [INFO] [Epoch 030] Train loss: 792.0317 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:11:51 - INFO - [Epoch 030] Train loss: 792.0317 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:11:52,211] [UniVITrainer] [INFO] [Epoch 030] Val loss: 776.4302 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:11:52 - INFO - [Epoch 030] Val loss: 776.4302 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:11:52,246] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 776.4302\n",
      "2025-11-20 09:11:52 - INFO - [Epoch 030] New best val loss: 776.4302\n",
      "[2025-11-20 09:11:57,029] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 776.1254\n",
      "2025-11-20 09:11:57 - INFO - [Epoch 031] New best val loss: 776.1254\n",
      "[2025-11-20 09:12:01,894] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 775.3229\n",
      "2025-11-20 09:12:01 - INFO - [Epoch 032] New best val loss: 775.3229\n",
      "[2025-11-20 09:12:06,673] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 774.0487\n",
      "2025-11-20 09:12:06 - INFO - [Epoch 033] New best val loss: 774.0487\n",
      "[2025-11-20 09:12:16,094] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 773.1908\n",
      "2025-11-20 09:12:16 - INFO - [Epoch 035] New best val loss: 773.1908\n",
      "[2025-11-20 09:12:20,892] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 772.7044\n",
      "2025-11-20 09:12:20 - INFO - [Epoch 036] New best val loss: 772.7044\n",
      "[2025-11-20 09:12:35,508] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 771.6939\n",
      "2025-11-20 09:12:35 - INFO - [Epoch 039] New best val loss: 771.6939\n",
      "[2025-11-20 09:12:39,188] [UniVITrainer] [INFO] [Epoch 040] Train loss: 781.0271 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:12:39 - INFO - [Epoch 040] Train loss: 781.0271 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:12:39,676] [UniVITrainer] [INFO] [Epoch 040] Val loss: 772.0033 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:12:39 - INFO - [Epoch 040] Val loss: 772.0033 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:12:44,668] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 770.7383\n",
      "2025-11-20 09:12:44 - INFO - [Epoch 041] New best val loss: 770.7383\n",
      "[2025-11-20 09:12:59,246] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 770.1968\n",
      "2025-11-20 09:12:59 - INFO - [Epoch 044] New best val loss: 770.1968\n",
      "[2025-11-20 09:13:13,786] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 769.3796\n",
      "2025-11-20 09:13:13 - INFO - [Epoch 047] New best val loss: 769.3796\n",
      "[2025-11-20 09:13:18,510] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 769.3164\n",
      "2025-11-20 09:13:18 - INFO - [Epoch 048] New best val loss: 769.3164\n",
      "[2025-11-20 09:13:27,588] [UniVITrainer] [INFO] [Epoch 050] Train loss: 773.3560 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:13:27 - INFO - [Epoch 050] Train loss: 773.3560 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:13:28,066] [UniVITrainer] [INFO] [Epoch 050] Val loss: 769.1137 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:13:28 - INFO - [Epoch 050] Val loss: 769.1137 (beta=500.000, gamma=1000.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 09:13:28,104] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 769.1137\n",
      "2025-11-20 09:13:28 - INFO - [Epoch 050] New best val loss: 769.1137\n",
      "[2025-11-20 09:13:37,541] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 769.0675\n",
      "2025-11-20 09:13:37 - INFO - [Epoch 052] New best val loss: 769.0675\n",
      "[2025-11-20 09:13:42,247] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 768.8837\n",
      "2025-11-20 09:13:42 - INFO - [Epoch 053] New best val loss: 768.8837\n",
      "[2025-11-20 09:13:51,777] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 768.4408\n",
      "2025-11-20 09:13:51 - INFO - [Epoch 055] New best val loss: 768.4408\n",
      "[2025-11-20 09:14:01,201] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 768.2605\n",
      "2025-11-20 09:14:01 - INFO - [Epoch 057] New best val loss: 768.2605\n",
      "[2025-11-20 09:14:06,064] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 768.0854\n",
      "2025-11-20 09:14:06 - INFO - [Epoch 058] New best val loss: 768.0854\n",
      "[2025-11-20 09:14:14,936] [UniVITrainer] [INFO] [Epoch 060] Train loss: 770.0778 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:14:14 - INFO - [Epoch 060] Train loss: 770.0778 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:14:15,455] [UniVITrainer] [INFO] [Epoch 060] Val loss: 768.1662 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:14:15 - INFO - [Epoch 060] Val loss: 768.1662 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:14:34,444] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 767.9828\n",
      "2025-11-20 09:14:34 - INFO - [Epoch 064] New best val loss: 767.9828\n",
      "[2025-11-20 09:14:39,107] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 767.6348\n",
      "2025-11-20 09:14:39 - INFO - [Epoch 065] New best val loss: 767.6348\n",
      "[2025-11-20 09:14:57,415] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 767.5876\n",
      "2025-11-20 09:14:57 - INFO - [Epoch 069] New best val loss: 767.5876\n",
      "[2025-11-20 09:15:01,716] [UniVITrainer] [INFO] [Epoch 070] Train loss: 774.0382 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:15:01 - INFO - [Epoch 070] Train loss: 774.0382 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:15:02,232] [UniVITrainer] [INFO] [Epoch 070] Val loss: 767.3335 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:15:02 - INFO - [Epoch 070] Val loss: 767.3335 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:15:02,427] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 767.3335\n",
      "2025-11-20 09:15:02 - INFO - [Epoch 070] New best val loss: 767.3335\n",
      "[2025-11-20 09:15:20,936] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 767.1825\n",
      "2025-11-20 09:15:20 - INFO - [Epoch 074] New best val loss: 767.1825\n",
      "[2025-11-20 09:15:30,496] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 767.1366\n",
      "2025-11-20 09:15:30 - INFO - [Epoch 076] New best val loss: 767.1366\n",
      "[2025-11-20 09:15:48,892] [UniVITrainer] [INFO] [Epoch 080] Train loss: 766.6773 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:15:48 - INFO - [Epoch 080] Train loss: 766.6773 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:15:49,401] [UniVITrainer] [INFO] [Epoch 080] Val loss: 766.9675 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:15:49 - INFO - [Epoch 080] Val loss: 766.9675 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:15:49,425] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 766.9675\n",
      "2025-11-20 09:15:49 - INFO - [Epoch 080] New best val loss: 766.9675\n",
      "[2025-11-20 09:16:31,854] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 766.8783\n",
      "2025-11-20 09:16:31 - INFO - [Epoch 089] New best val loss: 766.8783\n",
      "[2025-11-20 09:16:36,168] [UniVITrainer] [INFO] [Epoch 090] Train loss: 771.6170 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:16:36 - INFO - [Epoch 090] Train loss: 771.6170 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:16:36,652] [UniVITrainer] [INFO] [Epoch 090] Val loss: 766.9710 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:16:36 - INFO - [Epoch 090] Val loss: 766.9710 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:16:41,581] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 766.8455\n",
      "2025-11-20 09:16:41 - INFO - [Epoch 091] New best val loss: 766.8455\n",
      "[2025-11-20 09:16:46,377] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 766.7612\n",
      "2025-11-20 09:16:46 - INFO - [Epoch 092] New best val loss: 766.7612\n",
      "[2025-11-20 09:17:23,812] [UniVITrainer] [INFO] [Epoch 100] Train loss: 765.7562 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:17:23 - INFO - [Epoch 100] Train loss: 765.7562 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:17:24,318] [UniVITrainer] [INFO] [Epoch 100] Val loss: 766.8805 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:17:24 - INFO - [Epoch 100] Val loss: 766.8805 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:17:38,583] [UniVITrainer] [INFO] [Epoch 103] New best val loss: 766.7157\n",
      "2025-11-20 09:17:38 - INFO - [Epoch 103] New best val loss: 766.7157\n",
      "[2025-11-20 09:17:49,967] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 766.5532\n",
      "2025-11-20 09:17:49 - INFO - [Epoch 105] New best val loss: 766.5532\n",
      "[2025-11-20 09:18:23,350] [UniVITrainer] [INFO] [Epoch 110] Train loss: 769.4895 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:18:23 - INFO - [Epoch 110] Train loss: 769.4895 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:18:24,158] [UniVITrainer] [INFO] [Epoch 110] Val loss: 766.6242 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:18:24 - INFO - [Epoch 110] Val loss: 766.6242 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:19:04,935] [UniVITrainer] [INFO] [Epoch 116] New best val loss: 766.5432\n",
      "2025-11-20 09:19:04 - INFO - [Epoch 116] New best val loss: 766.5432\n",
      "[2025-11-20 09:19:30,492] [UniVITrainer] [INFO] [Epoch 120] Train loss: 770.7773 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:19:30 - INFO - [Epoch 120] Train loss: 770.7773 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:19:31,284] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.6990 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:19:31 - INFO - [Epoch 120] Val loss: 766.6990 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:19:36,904] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 766.4575\n",
      "2025-11-20 09:19:36 - INFO - [Epoch 121] New best val loss: 766.4575\n",
      "[2025-11-20 09:20:41,486] [UniVITrainer] [INFO] [Epoch 130] Train loss: 770.2778 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:20:41 - INFO - [Epoch 130] Train loss: 770.2778 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:20:42,282] [UniVITrainer] [INFO] [Epoch 130] Val loss: 768.6450 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:20:42 - INFO - [Epoch 130] Val loss: 768.6450 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:21:38,837] [UniVITrainer] [INFO] [Epoch 138] New best val loss: 766.4293\n",
      "2025-11-20 09:21:38 - INFO - [Epoch 138] New best val loss: 766.4293\n",
      "[2025-11-20 09:21:52,682] [UniVITrainer] [INFO] [Epoch 140] Train loss: 764.4486 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:21:52 - INFO - [Epoch 140] Train loss: 764.4486 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:21:53,485] [UniVITrainer] [INFO] [Epoch 140] Val loss: 767.9311 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:21:53 - INFO - [Epoch 140] Val loss: 767.9311 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:23:02,360] [UniVITrainer] [INFO] [Epoch 150] Train loss: 767.4718 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:23:02 - INFO - [Epoch 150] Train loss: 767.4718 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:23:03,161] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.3970 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:23:03 - INFO - [Epoch 150] Val loss: 766.3970 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:23:03,353] [UniVITrainer] [INFO] [Epoch 150] New best val loss: 766.3970\n",
      "2025-11-20 09:23:03 - INFO - [Epoch 150] New best val loss: 766.3970\n",
      "[2025-11-20 09:24:21,701] [UniVITrainer] [INFO] [Epoch 160] Train loss: 764.5242 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:24:21 - INFO - [Epoch 160] Train loss: 764.5242 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:24:22,788] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.5376 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:24:22 - INFO - [Epoch 160] Val loss: 766.5376 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:25:52,369] [UniVITrainer] [INFO] [Epoch 170] Train loss: 764.2785 (beta=500.000, gamma=1000.000)\n",
      "2025-11-20 09:25:52 - INFO - [Epoch 170] Train loss: 764.2785 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:25:53,428] [UniVITrainer] [INFO] [Epoch 170] Val loss: 766.5153 (beta=500.000, gamma=1000.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 09:25:53 - INFO - [Epoch 170] Val loss: 766.5153 (beta=500.000, gamma=1000.000)\n",
      "[2025-11-20 09:25:53,433] [UniVITrainer] [INFO] Early stopping at epoch 170 (best val loss = 766.3970)\n",
      "2025-11-20 09:25:53 - INFO - Early stopping at epoch 170 (best val loss = 766.3970)\n",
      "[2025-11-20 09:25:53,491] [UniVITrainer] [INFO] Restored best model from epoch 150 (val loss = 766.3970)\n",
      "2025-11-20 09:25:53 - INFO - Restored best model from epoch 150 (val loss = 766.3970)\n",
      "[2025-11-20 09:25:55,907] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 09:25:55 - INFO - TrainingConfig:\n",
      "[2025-11-20 09:25:55,908] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 09:25:55 - INFO -   n_epochs: 200\n",
      "[2025-11-20 09:25:55,909] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 09:25:55 - INFO -   batch_size: 256\n",
      "[2025-11-20 09:25:55,910] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 09:25:55 - INFO -   lr: 0.001\n",
      "[2025-11-20 09:25:55,911] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 09:25:55 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 09:25:55,912] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 09:25:55 - INFO -   device: cuda\n",
      "[2025-11-20 09:25:55,913] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 09:25:55 - INFO -   log_every: 10\n",
      "[2025-11-20 09:25:55,914] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 09:25:55 - INFO -   grad_clip: None\n",
      "[2025-11-20 09:25:55,915] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 09:25:55 - INFO -   num_workers: 0\n",
      "[2025-11-20 09:25:55,916] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 09:25:55 - INFO -   seed: 42\n",
      "[2025-11-20 09:25:55,917] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 09:25:55 - INFO -   early_stopping: True\n",
      "[2025-11-20 09:25:55,918] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 09:25:55 - INFO -   patience: 20\n",
      "[2025-11-20 09:25:55,919] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 09:25:55 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 30] Done in 16.4 min\n",
      "  best_val_loss              = 766.397\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4953\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.4842\n",
      "[Config 30] FOSCTTM (ADT vs ATAC, val) = 0.4983\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4926\n",
      "  Modality mixing (k=20)     = 0.0071\n",
      "  Composite score            = 1152.09\n",
      "\n",
      "================================================================================\n",
      "[Config 31] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 32,\n",
      "  \"beta\": 0.0,\n",
      "  \"gamma\": 40.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.0,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide2\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_small2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096be0606dcb46a5a6fa0e7317db0a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 09:26:04,488] [UniVITrainer] [INFO] [Epoch 001] Train loss: 891.4039 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:26:04 - INFO - [Epoch 001] Train loss: 891.4039 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:26:05,675] [UniVITrainer] [INFO] [Epoch 001] Val loss: 764.7662 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:26:05 - INFO - [Epoch 001] Val loss: 764.7662 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:26:05,792] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 764.7662\n",
      "2025-11-20 09:26:05 - INFO - [Epoch 001] New best val loss: 764.7662\n",
      "[2025-11-20 09:26:14,209] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 711.1315\n",
      "2025-11-20 09:26:14 - INFO - [Epoch 002] New best val loss: 711.1315\n",
      "[2025-11-20 09:26:24,085] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 667.6153\n",
      "2025-11-20 09:26:24 - INFO - [Epoch 003] New best val loss: 667.6153\n",
      "[2025-11-20 09:26:31,668] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 657.8009\n",
      "2025-11-20 09:26:31 - INFO - [Epoch 004] New best val loss: 657.8009\n",
      "[2025-11-20 09:26:40,446] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 654.4217\n",
      "2025-11-20 09:26:40 - INFO - [Epoch 005] New best val loss: 654.4217\n",
      "[2025-11-20 09:26:48,281] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 649.8450\n",
      "2025-11-20 09:26:48 - INFO - [Epoch 006] New best val loss: 649.8450\n",
      "[2025-11-20 09:26:58,153] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 648.4767\n",
      "2025-11-20 09:26:58 - INFO - [Epoch 007] New best val loss: 648.4767\n",
      "[2025-11-20 09:27:15,764] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 644.4173\n",
      "2025-11-20 09:27:15 - INFO - [Epoch 009] New best val loss: 644.4173\n",
      "[2025-11-20 09:27:22,232] [UniVITrainer] [INFO] [Epoch 010] Train loss: 641.4055 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:27:22 - INFO - [Epoch 010] Train loss: 641.4055 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:27:23,014] [UniVITrainer] [INFO] [Epoch 010] Val loss: 644.8786 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:27:23 - INFO - [Epoch 010] Val loss: 644.8786 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:27:30,376] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 643.0734\n",
      "2025-11-20 09:27:30 - INFO - [Epoch 011] New best val loss: 643.0734\n",
      "[2025-11-20 09:27:44,001] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 639.9759\n",
      "2025-11-20 09:27:44 - INFO - [Epoch 013] New best val loss: 639.9759\n",
      "[2025-11-20 09:27:58,551] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 638.3766\n",
      "2025-11-20 09:27:58 - INFO - [Epoch 015] New best val loss: 638.3766\n",
      "[2025-11-20 09:28:13,101] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 637.3508\n",
      "2025-11-20 09:28:13 - INFO - [Epoch 017] New best val loss: 637.3508\n",
      "[2025-11-20 09:28:20,243] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 635.7624\n",
      "2025-11-20 09:28:20 - INFO - [Epoch 018] New best val loss: 635.7624\n",
      "[2025-11-20 09:28:34,054] [UniVITrainer] [INFO] [Epoch 020] Train loss: 625.9538 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:28:34 - INFO - [Epoch 020] Train loss: 625.9538 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:28:34,713] [UniVITrainer] [INFO] [Epoch 020] Val loss: 634.0298 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:28:34 - INFO - [Epoch 020] Val loss: 634.0298 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:28:34,809] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 634.0298\n",
      "2025-11-20 09:28:34 - INFO - [Epoch 020] New best val loss: 634.0298\n",
      "[2025-11-20 09:28:49,244] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 631.3345\n",
      "2025-11-20 09:28:49 - INFO - [Epoch 022] New best val loss: 631.3345\n",
      "[2025-11-20 09:29:03,843] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 630.9311\n",
      "2025-11-20 09:29:03 - INFO - [Epoch 024] New best val loss: 630.9311\n",
      "[2025-11-20 09:29:10,502] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 630.6509\n",
      "2025-11-20 09:29:10 - INFO - [Epoch 025] New best val loss: 630.6509\n",
      "[2025-11-20 09:29:39,404] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 629.4008\n",
      "2025-11-20 09:29:39 - INFO - [Epoch 029] New best val loss: 629.4008\n",
      "[2025-11-20 09:29:45,846] [UniVITrainer] [INFO] [Epoch 030] Train loss: 615.5287 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:29:45 - INFO - [Epoch 030] Train loss: 615.5287 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:29:46,623] [UniVITrainer] [INFO] [Epoch 030] Val loss: 627.0402 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:29:46 - INFO - [Epoch 030] Val loss: 627.0402 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:29:46,755] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 627.0402\n",
      "2025-11-20 09:29:46 - INFO - [Epoch 030] New best val loss: 627.0402\n",
      "[2025-11-20 09:30:14,424] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 626.7500\n",
      "2025-11-20 09:30:14 - INFO - [Epoch 034] New best val loss: 626.7500\n",
      "[2025-11-20 09:30:21,351] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 625.8917\n",
      "2025-11-20 09:30:21 - INFO - [Epoch 035] New best val loss: 625.8917\n",
      "[2025-11-20 09:30:35,995] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 625.4258\n",
      "2025-11-20 09:30:35 - INFO - [Epoch 037] New best val loss: 625.4258\n",
      "[2025-11-20 09:30:56,834] [UniVITrainer] [INFO] [Epoch 040] Train loss: 598.0291 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:30:56 - INFO - [Epoch 040] Train loss: 598.0291 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:30:57,615] [UniVITrainer] [INFO] [Epoch 040] Val loss: 624.0798 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:30:57 - INFO - [Epoch 040] Val loss: 624.0798 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:30:57,666] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 624.0798\n",
      "2025-11-20 09:30:57 - INFO - [Epoch 040] New best val loss: 624.0798\n",
      "[2025-11-20 09:31:18,363] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 623.4046\n",
      "2025-11-20 09:31:18 - INFO - [Epoch 043] New best val loss: 623.4046\n",
      "[2025-11-20 09:31:54,280] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 622.7625\n",
      "2025-11-20 09:31:54 - INFO - [Epoch 048] New best val loss: 622.7625\n",
      "[2025-11-20 09:32:01,311] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 620.6809\n",
      "2025-11-20 09:32:01 - INFO - [Epoch 049] New best val loss: 620.6809\n",
      "[2025-11-20 09:32:07,822] [UniVITrainer] [INFO] [Epoch 050] Train loss: 583.4200 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:32:07 - INFO - [Epoch 050] Train loss: 583.4200 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:32:08,603] [UniVITrainer] [INFO] [Epoch 050] Val loss: 621.3522 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:32:08 - INFO - [Epoch 050] Val loss: 621.3522 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:32:15,964] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 618.2607\n",
      "2025-11-20 09:32:15 - INFO - [Epoch 051] New best val loss: 618.2607\n",
      "[2025-11-20 09:33:19,540] [UniVITrainer] [INFO] [Epoch 060] Train loss: 574.1679 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:33:19 - INFO - [Epoch 060] Train loss: 574.1679 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:33:20,321] [UniVITrainer] [INFO] [Epoch 060] Val loss: 618.7753 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:33:20 - INFO - [Epoch 060] Val loss: 618.7753 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:33:27,581] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 616.5742\n",
      "2025-11-20 09:33:27 - INFO - [Epoch 061] New best val loss: 616.5742\n",
      "[2025-11-20 09:33:49,182] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 616.3593\n",
      "2025-11-20 09:33:49 - INFO - [Epoch 064] New best val loss: 616.3593\n",
      "[2025-11-20 09:33:56,511] [UniVITrainer] [INFO] [Epoch 065] New best val loss: 615.8933\n",
      "2025-11-20 09:33:56 - INFO - [Epoch 065] New best val loss: 615.8933\n",
      "[2025-11-20 09:34:25,378] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 615.0704\n",
      "2025-11-20 09:34:25 - INFO - [Epoch 069] New best val loss: 615.0704\n",
      "[2025-11-20 09:34:31,885] [UniVITrainer] [INFO] [Epoch 070] Train loss: 562.3812 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:34:31 - INFO - [Epoch 070] Train loss: 562.3812 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:34:32,668] [UniVITrainer] [INFO] [Epoch 070] Val loss: 615.6818 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:34:32 - INFO - [Epoch 070] Val loss: 615.6818 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:34:54,633] [UniVITrainer] [INFO] [Epoch 073] New best val loss: 614.7904\n",
      "2025-11-20 09:34:54 - INFO - [Epoch 073] New best val loss: 614.7904\n",
      "[2025-11-20 09:35:09,228] [UniVITrainer] [INFO] [Epoch 075] New best val loss: 614.1552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 09:35:09 - INFO - [Epoch 075] New best val loss: 614.1552\n",
      "[2025-11-20 09:35:44,274] [UniVITrainer] [INFO] [Epoch 080] Train loss: 549.7147 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:35:44 - INFO - [Epoch 080] Train loss: 549.7147 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:35:45,056] [UniVITrainer] [INFO] [Epoch 080] Val loss: 615.0278 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:35:45 - INFO - [Epoch 080] Val loss: 615.0278 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:35:52,385] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 612.2406\n",
      "2025-11-20 09:35:52 - INFO - [Epoch 081] New best val loss: 612.2406\n",
      "[2025-11-20 09:36:35,541] [UniVITrainer] [INFO] [Epoch 087] New best val loss: 612.1973\n",
      "2025-11-20 09:36:35 - INFO - [Epoch 087] New best val loss: 612.1973\n",
      "[2025-11-20 09:36:58,153] [UniVITrainer] [INFO] [Epoch 090] Train loss: 539.5264 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:36:58 - INFO - [Epoch 090] Train loss: 539.5264 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:36:59,213] [UniVITrainer] [INFO] [Epoch 090] Val loss: 614.4636 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:36:59 - INFO - [Epoch 090] Val loss: 614.4636 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:37:22,748] [UniVITrainer] [INFO] [Epoch 093] New best val loss: 611.7595\n",
      "2025-11-20 09:37:22 - INFO - [Epoch 093] New best val loss: 611.7595\n",
      "[2025-11-20 09:37:31,007] [UniVITrainer] [INFO] [Epoch 094] New best val loss: 610.9630\n",
      "2025-11-20 09:37:31 - INFO - [Epoch 094] New best val loss: 610.9630\n",
      "[2025-11-20 09:38:20,261] [UniVITrainer] [INFO] [Epoch 100] Train loss: 530.4714 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:38:20 - INFO - [Epoch 100] Train loss: 530.4714 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:38:20,445] [UniVITrainer] [INFO] [Epoch 100] Val loss: 616.0455 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:38:20 - INFO - [Epoch 100] Val loss: 616.0455 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:39:40,630] [UniVITrainer] [INFO] [Epoch 110] Train loss: 523.2834 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:39:40 - INFO - [Epoch 110] Train loss: 523.2834 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:39:41,681] [UniVITrainer] [INFO] [Epoch 110] Val loss: 614.5686 (beta=0.000, gamma=40.000)\n",
      "2025-11-20 09:39:41 - INFO - [Epoch 110] Val loss: 614.5686 (beta=0.000, gamma=40.000)\n",
      "[2025-11-20 09:40:14,437] [UniVITrainer] [INFO] Early stopping at epoch 114 (best val loss = 610.9630)\n",
      "2025-11-20 09:40:14 - INFO - Early stopping at epoch 114 (best val loss = 610.9630)\n",
      "[2025-11-20 09:40:14,478] [UniVITrainer] [INFO] Restored best model from epoch 94 (val loss = 610.9630)\n",
      "2025-11-20 09:40:14 - INFO - Restored best model from epoch 94 (val loss = 610.9630)\n",
      "[2025-11-20 09:40:17,984] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 09:40:17 - INFO - TrainingConfig:\n",
      "[2025-11-20 09:40:17,985] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 09:40:17 - INFO -   n_epochs: 200\n",
      "[2025-11-20 09:40:17,986] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 09:40:17 - INFO -   batch_size: 256\n",
      "[2025-11-20 09:40:17,987] [UniVITrainer] [INFO]   lr: 0.0005\n",
      "2025-11-20 09:40:17 - INFO -   lr: 0.0005\n",
      "[2025-11-20 09:40:17,988] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 09:40:17 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 09:40:17,989] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 09:40:17 - INFO -   device: cuda\n",
      "[2025-11-20 09:40:17,990] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 09:40:17 - INFO -   log_every: 10\n",
      "[2025-11-20 09:40:17,991] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 09:40:17 - INFO -   grad_clip: None\n",
      "[2025-11-20 09:40:17,992] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 09:40:17 - INFO -   num_workers: 0\n",
      "[2025-11-20 09:40:17,993] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 09:40:17 - INFO -   seed: 42\n",
      "[2025-11-20 09:40:17,994] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 09:40:17 - INFO -   early_stopping: True\n",
      "[2025-11-20 09:40:17,995] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 09:40:17 - INFO -   patience: 20\n",
      "[2025-11-20 09:40:17,996] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 09:40:17 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 31] Done in 14.3 min\n",
      "  best_val_loss              = 610.963\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.0729\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.0906\n",
      "[Config 31] FOSCTTM (ADT vs ATAC, val) = 0.1012\n",
      "  Mean FOSCTTM (3 pairs)     = 0.0882\n",
      "  Modality mixing (k=20)     = 0.4295\n",
      "  Composite score            = 950.42\n",
      "\n",
      "================================================================================\n",
      "[Config 32] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 200,\n",
      "  \"beta\": 300.0,\n",
      "  \"gamma\": 240.0,\n",
      "  \"lr\": 0.0005,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.0,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_small2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb86a0438f55454bb7b5801da905bb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 09:40:25,101] [UniVITrainer] [INFO] [Epoch 001] Train loss: 19342.2047 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:40:25 - INFO - [Epoch 001] Train loss: 19342.2047 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:40:26,161] [UniVITrainer] [INFO] [Epoch 001] Val loss: 9768.4284 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:40:26 - INFO - [Epoch 001] Val loss: 9768.4284 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:40:26,363] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 9768.4284\n",
      "2025-11-20 09:40:26 - INFO - [Epoch 001] New best val loss: 9768.4284\n",
      "[2025-11-20 09:40:34,657] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 4843.1672\n",
      "2025-11-20 09:40:34 - INFO - [Epoch 002] New best val loss: 4843.1672\n",
      "[2025-11-20 09:40:41,343] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 2534.2644\n",
      "2025-11-20 09:40:41 - INFO - [Epoch 003] New best val loss: 2534.2644\n",
      "[2025-11-20 09:40:49,380] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 1803.0614\n",
      "2025-11-20 09:40:49 - INFO - [Epoch 004] New best val loss: 1803.0614\n",
      "[2025-11-20 09:40:57,913] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 1526.8843\n",
      "2025-11-20 09:40:57 - INFO - [Epoch 005] New best val loss: 1526.8843\n",
      "[2025-11-20 09:41:06,191] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 1364.1636\n",
      "2025-11-20 09:41:06 - INFO - [Epoch 006] New best val loss: 1364.1636\n",
      "[2025-11-20 09:41:14,704] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 1270.3400\n",
      "2025-11-20 09:41:14 - INFO - [Epoch 007] New best val loss: 1270.3400\n",
      "[2025-11-20 09:41:23,104] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 1196.5654\n",
      "2025-11-20 09:41:23 - INFO - [Epoch 008] New best val loss: 1196.5654\n",
      "[2025-11-20 09:41:31,558] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 1152.6665\n",
      "2025-11-20 09:41:31 - INFO - [Epoch 009] New best val loss: 1152.6665\n",
      "[2025-11-20 09:41:40,222] [UniVITrainer] [INFO] [Epoch 010] Train loss: 1114.9239 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:41:40 - INFO - [Epoch 010] Train loss: 1114.9239 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:41:41,292] [UniVITrainer] [INFO] [Epoch 010] Val loss: 1101.3511 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:41:41 - INFO - [Epoch 010] Val loss: 1101.3511 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:41:41,311] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 1101.3511\n",
      "2025-11-20 09:41:41 - INFO - [Epoch 010] New best val loss: 1101.3511\n",
      "[2025-11-20 09:41:49,465] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 1074.0672\n",
      "2025-11-20 09:41:49 - INFO - [Epoch 011] New best val loss: 1074.0672\n",
      "[2025-11-20 09:41:57,195] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 1042.0802\n",
      "2025-11-20 09:41:57 - INFO - [Epoch 012] New best val loss: 1042.0802\n",
      "[2025-11-20 09:42:05,261] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 1026.2815\n",
      "2025-11-20 09:42:05 - INFO - [Epoch 013] New best val loss: 1026.2815\n",
      "[2025-11-20 09:42:13,393] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 1010.8437\n",
      "2025-11-20 09:42:13 - INFO - [Epoch 014] New best val loss: 1010.8437\n",
      "[2025-11-20 09:42:22,027] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 988.8705\n",
      "2025-11-20 09:42:22 - INFO - [Epoch 015] New best val loss: 988.8705\n",
      "[2025-11-20 09:42:31,806] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 977.5875\n",
      "2025-11-20 09:42:31 - INFO - [Epoch 016] New best val loss: 977.5875\n",
      "[2025-11-20 09:42:40,330] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 962.7161\n",
      "2025-11-20 09:42:40 - INFO - [Epoch 017] New best val loss: 962.7161\n",
      "[2025-11-20 09:42:50,242] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 957.2415\n",
      "2025-11-20 09:42:50 - INFO - [Epoch 018] New best val loss: 957.2415\n",
      "[2025-11-20 09:42:58,478] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 944.5796\n",
      "2025-11-20 09:42:58 - INFO - [Epoch 019] New best val loss: 944.5796\n",
      "[2025-11-20 09:43:05,687] [UniVITrainer] [INFO] [Epoch 020] Train loss: 904.8444 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:43:05 - INFO - [Epoch 020] Train loss: 904.8444 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:43:06,750] [UniVITrainer] [INFO] [Epoch 020] Val loss: 949.9430 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:43:06 - INFO - [Epoch 020] Val loss: 949.9430 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:43:16,374] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 928.8995\n",
      "2025-11-20 09:43:16 - INFO - [Epoch 021] New best val loss: 928.8995\n",
      "[2025-11-20 09:43:24,568] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 919.7205\n",
      "2025-11-20 09:43:24 - INFO - [Epoch 022] New best val loss: 919.7205\n",
      "[2025-11-20 09:43:32,940] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 917.5916\n",
      "2025-11-20 09:43:32 - INFO - [Epoch 023] New best val loss: 917.5916\n",
      "[2025-11-20 09:43:41,257] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 907.7569\n",
      "2025-11-20 09:43:41 - INFO - [Epoch 024] New best val loss: 907.7569\n",
      "[2025-11-20 09:43:49,654] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 904.1449\n",
      "2025-11-20 09:43:49 - INFO - [Epoch 025] New best val loss: 904.1449\n",
      "[2025-11-20 09:43:57,884] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 895.9032\n",
      "2025-11-20 09:43:57 - INFO - [Epoch 026] New best val loss: 895.9032\n",
      "[2025-11-20 09:44:06,425] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 892.7691\n",
      "2025-11-20 09:44:06 - INFO - [Epoch 027] New best val loss: 892.7691\n",
      "[2025-11-20 09:44:14,848] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 890.0363\n",
      "2025-11-20 09:44:14 - INFO - [Epoch 028] New best val loss: 890.0363\n",
      "[2025-11-20 09:44:23,525] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 883.9033\n",
      "2025-11-20 09:44:23 - INFO - [Epoch 029] New best val loss: 883.9033\n",
      "[2025-11-20 09:44:31,866] [UniVITrainer] [INFO] [Epoch 030] Train loss: 837.9472 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:44:31 - INFO - [Epoch 030] Train loss: 837.9472 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:44:32,017] [UniVITrainer] [INFO] [Epoch 030] Val loss: 881.8075 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:44:32 - INFO - [Epoch 030] Val loss: 881.8075 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:44:32,233] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 881.8075\n",
      "2025-11-20 09:44:32 - INFO - [Epoch 030] New best val loss: 881.8075\n",
      "[2025-11-20 09:44:41,021] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 878.4521\n",
      "2025-11-20 09:44:41 - INFO - [Epoch 031] New best val loss: 878.4521\n",
      "[2025-11-20 09:44:59,833] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 873.9629\n",
      "2025-11-20 09:44:59 - INFO - [Epoch 033] New best val loss: 873.9629\n",
      "[2025-11-20 09:45:09,826] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 865.1319\n",
      "2025-11-20 09:45:09 - INFO - [Epoch 034] New best val loss: 865.1319\n",
      "[2025-11-20 09:45:28,904] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 859.7276\n",
      "2025-11-20 09:45:28 - INFO - [Epoch 036] New best val loss: 859.7276\n",
      "[2025-11-20 09:45:47,854] [UniVITrainer] [INFO] [Epoch 038] New best val loss: 859.6161\n",
      "2025-11-20 09:45:47 - INFO - [Epoch 038] New best val loss: 859.6161\n",
      "[2025-11-20 09:45:57,536] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 853.2841\n",
      "2025-11-20 09:45:57 - INFO - [Epoch 039] New best val loss: 853.2841\n",
      "[2025-11-20 09:46:06,130] [UniVITrainer] [INFO] [Epoch 040] Train loss: 806.0613 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:46:06 - INFO - [Epoch 040] Train loss: 806.0613 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:46:06,911] [UniVITrainer] [INFO] [Epoch 040] Val loss: 854.8391 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:46:06 - INFO - [Epoch 040] Val loss: 854.8391 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:46:16,319] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 850.8265\n",
      "2025-11-20 09:46:16 - INFO - [Epoch 041] New best val loss: 850.8265\n",
      "[2025-11-20 09:46:45,209] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 850.3861\n",
      "2025-11-20 09:46:45 - INFO - [Epoch 044] New best val loss: 850.3861\n",
      "[2025-11-20 09:46:54,782] [UniVITrainer] [INFO] [Epoch 045] New best val loss: 849.3335\n",
      "2025-11-20 09:46:54 - INFO - [Epoch 045] New best val loss: 849.3335\n",
      "[2025-11-20 09:47:04,713] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 846.5071\n",
      "2025-11-20 09:47:04 - INFO - [Epoch 046] New best val loss: 846.5071\n",
      "[2025-11-20 09:47:14,411] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 845.8028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 09:47:14 - INFO - [Epoch 047] New best val loss: 845.8028\n",
      "[2025-11-20 09:47:24,082] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 843.9423\n",
      "2025-11-20 09:47:24 - INFO - [Epoch 048] New best val loss: 843.9423\n",
      "[2025-11-20 09:47:33,466] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 841.1292\n",
      "2025-11-20 09:47:33 - INFO - [Epoch 049] New best val loss: 841.1292\n",
      "[2025-11-20 09:47:42,107] [UniVITrainer] [INFO] [Epoch 050] Train loss: 797.8342 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:47:42 - INFO - [Epoch 050] Train loss: 797.8342 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:47:43,170] [UniVITrainer] [INFO] [Epoch 050] Val loss: 840.3665 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:47:43 - INFO - [Epoch 050] Val loss: 840.3665 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:47:43,389] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 840.3665\n",
      "2025-11-20 09:47:43 - INFO - [Epoch 050] New best val loss: 840.3665\n",
      "[2025-11-20 09:47:53,265] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 839.1854\n",
      "2025-11-20 09:47:53 - INFO - [Epoch 051] New best val loss: 839.1854\n",
      "[2025-11-20 09:48:12,642] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 838.1598\n",
      "2025-11-20 09:48:12 - INFO - [Epoch 053] New best val loss: 838.1598\n",
      "[2025-11-20 09:48:31,880] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 836.1819\n",
      "2025-11-20 09:48:31 - INFO - [Epoch 055] New best val loss: 836.1819\n",
      "[2025-11-20 09:48:51,785] [UniVITrainer] [INFO] [Epoch 057] New best val loss: 834.4942\n",
      "2025-11-20 09:48:51 - INFO - [Epoch 057] New best val loss: 834.4942\n",
      "[2025-11-20 09:49:01,764] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 832.9143\n",
      "2025-11-20 09:49:01 - INFO - [Epoch 058] New best val loss: 832.9143\n",
      "[2025-11-20 09:49:20,638] [UniVITrainer] [INFO] [Epoch 060] Train loss: 790.0057 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:49:20 - INFO - [Epoch 060] Train loss: 790.0057 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:49:21,731] [UniVITrainer] [INFO] [Epoch 060] Val loss: 830.2204 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:49:21 - INFO - [Epoch 060] Val loss: 830.2204 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:49:21,939] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 830.2204\n",
      "2025-11-20 09:49:21 - INFO - [Epoch 060] New best val loss: 830.2204\n",
      "[2025-11-20 09:49:32,068] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 828.7660\n",
      "2025-11-20 09:49:32 - INFO - [Epoch 061] New best val loss: 828.7660\n",
      "[2025-11-20 09:49:52,036] [UniVITrainer] [INFO] [Epoch 063] New best val loss: 827.9801\n",
      "2025-11-20 09:49:52 - INFO - [Epoch 063] New best val loss: 827.9801\n",
      "[2025-11-20 09:50:01,857] [UniVITrainer] [INFO] [Epoch 064] New best val loss: 827.6985\n",
      "2025-11-20 09:50:01 - INFO - [Epoch 064] New best val loss: 827.6985\n",
      "[2025-11-20 09:50:31,037] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 826.5447\n",
      "2025-11-20 09:50:31 - INFO - [Epoch 067] New best val loss: 826.5447\n",
      "[2025-11-20 09:50:50,547] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 825.6312\n",
      "2025-11-20 09:50:50 - INFO - [Epoch 069] New best val loss: 825.6312\n",
      "[2025-11-20 09:50:59,071] [UniVITrainer] [INFO] [Epoch 070] Train loss: 784.3778 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:50:59 - INFO - [Epoch 070] Train loss: 784.3778 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:51:00,168] [UniVITrainer] [INFO] [Epoch 070] Val loss: 822.9054 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:51:00 - INFO - [Epoch 070] Val loss: 822.9054 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:51:00,470] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 822.9054\n",
      "2025-11-20 09:51:00 - INFO - [Epoch 070] New best val loss: 822.9054\n",
      "[2025-11-20 09:52:10,162] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 822.8617\n",
      "2025-11-20 09:52:10 - INFO - [Epoch 078] New best val loss: 822.8617\n",
      "[2025-11-20 09:52:17,080] [UniVITrainer] [INFO] [Epoch 079] New best val loss: 821.5124\n",
      "2025-11-20 09:52:17 - INFO - [Epoch 079] New best val loss: 821.5124\n",
      "[2025-11-20 09:52:21,650] [UniVITrainer] [INFO] [Epoch 080] Train loss: 782.6002 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:52:21 - INFO - [Epoch 080] Train loss: 782.6002 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:52:22,395] [UniVITrainer] [INFO] [Epoch 080] Val loss: 822.4011 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:52:22 - INFO - [Epoch 080] Val loss: 822.4011 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:52:36,900] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 820.5880\n",
      "2025-11-20 09:52:36 - INFO - [Epoch 083] New best val loss: 820.5880\n",
      "[2025-11-20 09:52:43,993] [UniVITrainer] [INFO] [Epoch 084] New best val loss: 819.4585\n",
      "2025-11-20 09:52:43 - INFO - [Epoch 084] New best val loss: 819.4585\n",
      "[2025-11-20 09:53:17,441] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 817.3547\n",
      "2025-11-20 09:53:17 - INFO - [Epoch 089] New best val loss: 817.3547\n",
      "[2025-11-20 09:53:23,647] [UniVITrainer] [INFO] [Epoch 090] Train loss: 778.1134 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:53:23 - INFO - [Epoch 090] Train loss: 778.1134 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:53:24,433] [UniVITrainer] [INFO] [Epoch 090] Val loss: 816.2014 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:53:24 - INFO - [Epoch 090] Val loss: 816.2014 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:53:24,638] [UniVITrainer] [INFO] [Epoch 090] New best val loss: 816.2014\n",
      "2025-11-20 09:53:24 - INFO - [Epoch 090] New best val loss: 816.2014\n",
      "[2025-11-20 09:53:31,904] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 815.7486\n",
      "2025-11-20 09:53:31 - INFO - [Epoch 091] New best val loss: 815.7486\n",
      "[2025-11-20 09:54:36,145] [UniVITrainer] [INFO] [Epoch 100] Train loss: 778.7028 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:54:36 - INFO - [Epoch 100] Train loss: 778.7028 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:54:36,734] [UniVITrainer] [INFO] [Epoch 100] Val loss: 814.5637 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:54:36 - INFO - [Epoch 100] Val loss: 814.5637 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:54:36,815] [UniVITrainer] [INFO] [Epoch 100] New best val loss: 814.5637\n",
      "2025-11-20 09:54:36 - INFO - [Epoch 100] New best val loss: 814.5637\n",
      "[2025-11-20 09:55:12,759] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 812.9995\n",
      "2025-11-20 09:55:12 - INFO - [Epoch 105] New best val loss: 812.9995\n",
      "[2025-11-20 09:55:42,175] [UniVITrainer] [INFO] [Epoch 109] New best val loss: 812.6991\n",
      "2025-11-20 09:55:42 - INFO - [Epoch 109] New best val loss: 812.6991\n",
      "[2025-11-20 09:55:48,569] [UniVITrainer] [INFO] [Epoch 110] Train loss: 776.9239 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:55:48 - INFO - [Epoch 110] Train loss: 776.9239 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:55:49,402] [UniVITrainer] [INFO] [Epoch 110] Val loss: 814.4674 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:55:49 - INFO - [Epoch 110] Val loss: 814.4674 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:55:57,091] [UniVITrainer] [INFO] [Epoch 111] New best val loss: 811.9268\n",
      "2025-11-20 09:55:57 - INFO - [Epoch 111] New best val loss: 811.9268\n",
      "[2025-11-20 09:56:11,215] [UniVITrainer] [INFO] [Epoch 113] New best val loss: 811.6889\n",
      "2025-11-20 09:56:11 - INFO - [Epoch 113] New best val loss: 811.6889\n",
      "[2025-11-20 09:56:38,486] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 811.6828\n",
      "2025-11-20 09:56:38 - INFO - [Epoch 117] New best val loss: 811.6828\n",
      "[2025-11-20 09:56:59,266] [UniVITrainer] [INFO] [Epoch 120] Train loss: 776.8780 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:56:59 - INFO - [Epoch 120] Train loss: 776.8780 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:57:00,091] [UniVITrainer] [INFO] [Epoch 120] Val loss: 810.7387 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:57:00 - INFO - [Epoch 120] Val loss: 810.7387 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:57:00,280] [UniVITrainer] [INFO] [Epoch 120] New best val loss: 810.7387\n",
      "2025-11-20 09:57:00 - INFO - [Epoch 120] New best val loss: 810.7387\n",
      "[2025-11-20 09:57:15,392] [UniVITrainer] [INFO] [Epoch 122] New best val loss: 807.8480\n",
      "2025-11-20 09:57:15 - INFO - [Epoch 122] New best val loss: 807.8480\n",
      "[2025-11-20 09:58:09,697] [UniVITrainer] [INFO] [Epoch 130] Train loss: 775.5274 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:58:09 - INFO - [Epoch 130] Train loss: 775.5274 (beta=300.000, gamma=240.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 09:58:10,506] [UniVITrainer] [INFO] [Epoch 130] Val loss: 806.8873 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:58:10 - INFO - [Epoch 130] Val loss: 806.8873 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:58:10,687] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 806.8873\n",
      "2025-11-20 09:58:10 - INFO - [Epoch 130] New best val loss: 806.8873\n",
      "[2025-11-20 09:58:46,513] [UniVITrainer] [INFO] [Epoch 135] New best val loss: 806.5604\n",
      "2025-11-20 09:58:46 - INFO - [Epoch 135] New best val loss: 806.5604\n",
      "[2025-11-20 09:58:54,037] [UniVITrainer] [INFO] [Epoch 136] New best val loss: 806.3702\n",
      "2025-11-20 09:58:54 - INFO - [Epoch 136] New best val loss: 806.3702\n",
      "[2025-11-20 09:59:22,843] [UniVITrainer] [INFO] [Epoch 140] Train loss: 774.6080 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:59:22 - INFO - [Epoch 140] Train loss: 774.6080 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:59:23,299] [UniVITrainer] [INFO] [Epoch 140] Val loss: 806.5336 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 09:59:23 - INFO - [Epoch 140] Val loss: 806.5336 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 09:59:30,471] [UniVITrainer] [INFO] [Epoch 141] New best val loss: 806.1107\n",
      "2025-11-20 09:59:30 - INFO - [Epoch 141] New best val loss: 806.1107\n",
      "[2025-11-20 09:59:43,634] [UniVITrainer] [INFO] [Epoch 143] New best val loss: 805.7761\n",
      "2025-11-20 09:59:43 - INFO - [Epoch 143] New best val loss: 805.7761\n",
      "[2025-11-20 10:00:05,735] [UniVITrainer] [INFO] [Epoch 146] New best val loss: 803.1119\n",
      "2025-11-20 10:00:05 - INFO - [Epoch 146] New best val loss: 803.1119\n",
      "[2025-11-20 10:00:34,302] [UniVITrainer] [INFO] [Epoch 150] Train loss: 775.4438 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:00:34 - INFO - [Epoch 150] Train loss: 775.4438 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:00:35,103] [UniVITrainer] [INFO] [Epoch 150] Val loss: 805.7992 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:00:35 - INFO - [Epoch 150] Val loss: 805.7992 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:00:42,413] [UniVITrainer] [INFO] [Epoch 151] New best val loss: 801.5028\n",
      "2025-11-20 10:00:42 - INFO - [Epoch 151] New best val loss: 801.5028\n",
      "[2025-11-20 10:01:40,787] [UniVITrainer] [INFO] [Epoch 159] New best val loss: 801.4549\n",
      "2025-11-20 10:01:40 - INFO - [Epoch 159] New best val loss: 801.4549\n",
      "[2025-11-20 10:01:47,401] [UniVITrainer] [INFO] [Epoch 160] Train loss: 770.3170 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:01:47 - INFO - [Epoch 160] Train loss: 770.3170 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:01:48,213] [UniVITrainer] [INFO] [Epoch 160] Val loss: 802.3903 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:01:48 - INFO - [Epoch 160] Val loss: 802.3903 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:02:52,979] [UniVITrainer] [INFO] [Epoch 169] New best val loss: 800.3389\n",
      "2025-11-20 10:02:52 - INFO - [Epoch 169] New best val loss: 800.3389\n",
      "[2025-11-20 10:02:59,591] [UniVITrainer] [INFO] [Epoch 170] Train loss: 772.9316 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:02:59 - INFO - [Epoch 170] Train loss: 772.9316 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:03:00,404] [UniVITrainer] [INFO] [Epoch 170] Val loss: 801.6207 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:03:00 - INFO - [Epoch 170] Val loss: 801.6207 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:03:40,493] [UniVITrainer] [INFO] [Epoch 176] New best val loss: 797.9358\n",
      "2025-11-20 10:03:40 - INFO - [Epoch 176] New best val loss: 797.9358\n",
      "[2025-11-20 10:04:08,221] [UniVITrainer] [INFO] [Epoch 180] Train loss: 772.5419 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:04:08 - INFO - [Epoch 180] Train loss: 772.5419 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:04:09,026] [UniVITrainer] [INFO] [Epoch 180] Val loss: 799.2290 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:04:09 - INFO - [Epoch 180] Val loss: 799.2290 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:04:40,914] [UniVITrainer] [INFO] [Epoch 184] New best val loss: 797.6594\n",
      "2025-11-20 10:04:40 - INFO - [Epoch 184] New best val loss: 797.6594\n",
      "[2025-11-20 10:05:37,618] [UniVITrainer] [INFO] [Epoch 190] Train loss: 770.1512 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:05:37 - INFO - [Epoch 190] Train loss: 770.1512 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:05:38,710] [UniVITrainer] [INFO] [Epoch 190] Val loss: 796.9716 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:05:38 - INFO - [Epoch 190] Val loss: 796.9716 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:05:38,909] [UniVITrainer] [INFO] [Epoch 190] New best val loss: 796.9716\n",
      "2025-11-20 10:05:38 - INFO - [Epoch 190] New best val loss: 796.9716\n",
      "[2025-11-20 10:06:20,110] [UniVITrainer] [INFO] [Epoch 194] New best val loss: 796.8540\n",
      "2025-11-20 10:06:20 - INFO - [Epoch 194] New best val loss: 796.8540\n",
      "[2025-11-20 10:07:05,931] [UniVITrainer] [INFO] [Epoch 199] New best val loss: 796.3243\n",
      "2025-11-20 10:07:05 - INFO - [Epoch 199] New best val loss: 796.3243\n",
      "[2025-11-20 10:07:14,765] [UniVITrainer] [INFO] [Epoch 200] Train loss: 773.6441 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:07:14 - INFO - [Epoch 200] Train loss: 773.6441 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:07:15,868] [UniVITrainer] [INFO] [Epoch 200] Val loss: 795.9623 (beta=300.000, gamma=240.000)\n",
      "2025-11-20 10:07:15 - INFO - [Epoch 200] Val loss: 795.9623 (beta=300.000, gamma=240.000)\n",
      "[2025-11-20 10:07:16,112] [UniVITrainer] [INFO] [Epoch 200] New best val loss: 795.9623\n",
      "2025-11-20 10:07:16 - INFO - [Epoch 200] New best val loss: 795.9623\n",
      "[2025-11-20 10:07:16,168] [UniVITrainer] [INFO] Restored best model from epoch 200 (val loss = 795.9623)\n",
      "2025-11-20 10:07:16 - INFO - Restored best model from epoch 200 (val loss = 795.9623)\n",
      "[2025-11-20 10:07:18,849] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 10:07:18 - INFO - TrainingConfig:\n",
      "[2025-11-20 10:07:18,852] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 10:07:18 - INFO -   n_epochs: 200\n",
      "[2025-11-20 10:07:18,855] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 10:07:18 - INFO -   batch_size: 256\n",
      "[2025-11-20 10:07:18,858] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 10:07:18 - INFO -   lr: 0.001\n",
      "[2025-11-20 10:07:18,860] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-20 10:07:18 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-20 10:07:18,867] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 10:07:18 - INFO -   device: cuda\n",
      "[2025-11-20 10:07:18,870] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 10:07:18 - INFO -   log_every: 10\n",
      "[2025-11-20 10:07:18,872] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 10:07:18 - INFO -   grad_clip: None\n",
      "[2025-11-20 10:07:18,873] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 10:07:18 - INFO -   num_workers: 0\n",
      "[2025-11-20 10:07:18,876] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 10:07:18 - INFO -   seed: 42\n",
      "[2025-11-20 10:07:18,877] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 10:07:18 - INFO -   early_stopping: True\n",
      "[2025-11-20 10:07:18,878] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 10:07:18 - INFO -   patience: 20\n",
      "[2025-11-20 10:07:18,879] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 10:07:18 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 32] Done in 27.0 min\n",
      "  best_val_loss              = 795.962\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4856\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.5037\n",
      "[Config 32] FOSCTTM (ADT vs ATAC, val) = 0.4956\n",
      "  Mean FOSCTTM (3 pairs)     = 0.4950\n",
      "  Modality mixing (k=20)     = 0.0141\n",
      "  Composite score            = 1206.70\n",
      "\n",
      "================================================================================\n",
      "[Config 33] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 72,\n",
      "  \"beta\": 100.0,\n",
      "  \"gamma\": 140.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"encoder_dropout\": 0.0,\n",
      "  \"decoder_batchnorm\": false,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_med2\",\n",
      "  \"atac_arch\": \"atac_wide2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8971ef43da841f295da865c16bf212d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 10:07:27,187] [UniVITrainer] [INFO] [Epoch 001] Train loss: 2060.1318 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:07:27 - INFO - [Epoch 001] Train loss: 2060.1318 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:07:28,282] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1003.6471 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:07:28 - INFO - [Epoch 001] Val loss: 1003.6471 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:07:28,586] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1003.6471\n",
      "2025-11-20 10:07:28 - INFO - [Epoch 001] New best val loss: 1003.6471\n",
      "[2025-11-20 10:07:38,587] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 858.8225\n",
      "2025-11-20 10:07:38 - INFO - [Epoch 002] New best val loss: 858.8225\n",
      "[2025-11-20 10:07:47,937] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 823.2824\n",
      "2025-11-20 10:07:47 - INFO - [Epoch 003] New best val loss: 823.2824\n",
      "[2025-11-20 10:07:58,194] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 808.4771\n",
      "2025-11-20 10:07:58 - INFO - [Epoch 004] New best val loss: 808.4771\n",
      "[2025-11-20 10:08:08,277] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 801.8109\n",
      "2025-11-20 10:08:08 - INFO - [Epoch 005] New best val loss: 801.8109\n",
      "[2025-11-20 10:08:17,902] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 796.2922\n",
      "2025-11-20 10:08:17 - INFO - [Epoch 006] New best val loss: 796.2922\n",
      "[2025-11-20 10:08:27,299] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 793.7028\n",
      "2025-11-20 10:08:27 - INFO - [Epoch 007] New best val loss: 793.7028\n",
      "[2025-11-20 10:08:37,015] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 790.4730\n",
      "2025-11-20 10:08:37 - INFO - [Epoch 008] New best val loss: 790.4730\n",
      "[2025-11-20 10:08:47,136] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 787.0834\n",
      "2025-11-20 10:08:47 - INFO - [Epoch 009] New best val loss: 787.0834\n",
      "[2025-11-20 10:08:55,771] [UniVITrainer] [INFO] [Epoch 010] Train loss: 782.8013 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:08:55 - INFO - [Epoch 010] Train loss: 782.8013 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:08:56,882] [UniVITrainer] [INFO] [Epoch 010] Val loss: 785.3235 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:08:56 - INFO - [Epoch 010] Val loss: 785.3235 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:08:57,421] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 785.3235\n",
      "2025-11-20 10:08:57 - INFO - [Epoch 010] New best val loss: 785.3235\n",
      "[2025-11-20 10:09:07,986] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 783.8341\n",
      "2025-11-20 10:09:07 - INFO - [Epoch 011] New best val loss: 783.8341\n",
      "[2025-11-20 10:09:18,476] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 782.7271\n",
      "2025-11-20 10:09:18 - INFO - [Epoch 012] New best val loss: 782.7271\n",
      "[2025-11-20 10:09:28,000] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 782.7045\n",
      "2025-11-20 10:09:28 - INFO - [Epoch 013] New best val loss: 782.7045\n",
      "[2025-11-20 10:09:37,847] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 781.4476\n",
      "2025-11-20 10:09:37 - INFO - [Epoch 014] New best val loss: 781.4476\n",
      "[2025-11-20 10:09:46,365] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 780.5879\n",
      "2025-11-20 10:09:46 - INFO - [Epoch 015] New best val loss: 780.5879\n",
      "[2025-11-20 10:10:04,590] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 779.3534\n",
      "2025-11-20 10:10:04 - INFO - [Epoch 017] New best val loss: 779.3534\n",
      "[2025-11-20 10:10:22,434] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 778.7451\n",
      "2025-11-20 10:10:22 - INFO - [Epoch 019] New best val loss: 778.7451\n",
      "[2025-11-20 10:10:31,068] [UniVITrainer] [INFO] [Epoch 020] Train loss: 774.3351 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:10:31 - INFO - [Epoch 020] Train loss: 774.3351 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:10:32,051] [UniVITrainer] [INFO] [Epoch 020] Val loss: 778.0919 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:10:32 - INFO - [Epoch 020] Val loss: 778.0919 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:10:32,578] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 778.0919\n",
      "2025-11-20 10:10:32 - INFO - [Epoch 020] New best val loss: 778.0919\n",
      "[2025-11-20 10:10:40,339] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 777.4835\n",
      "2025-11-20 10:10:40 - INFO - [Epoch 021] New best val loss: 777.4835\n",
      "[2025-11-20 10:11:08,376] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 776.7424\n",
      "2025-11-20 10:11:08 - INFO - [Epoch 024] New best val loss: 776.7424\n",
      "[2025-11-20 10:11:27,210] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 776.1232\n",
      "2025-11-20 10:11:27 - INFO - [Epoch 026] New best val loss: 776.1232\n",
      "[2025-11-20 10:11:53,530] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 775.6831\n",
      "2025-11-20 10:11:53 - INFO - [Epoch 029] New best val loss: 775.6831\n",
      "[2025-11-20 10:12:02,375] [UniVITrainer] [INFO] [Epoch 030] Train loss: 772.7336 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:12:02 - INFO - [Epoch 030] Train loss: 772.7336 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:12:03,457] [UniVITrainer] [INFO] [Epoch 030] Val loss: 775.8377 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:12:03 - INFO - [Epoch 030] Val loss: 775.8377 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:12:22,267] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 775.3824\n",
      "2025-11-20 10:12:22 - INFO - [Epoch 032] New best val loss: 775.3824\n",
      "[2025-11-20 10:12:40,158] [UniVITrainer] [INFO] [Epoch 034] New best val loss: 775.1790\n",
      "2025-11-20 10:12:40 - INFO - [Epoch 034] New best val loss: 775.1790\n",
      "[2025-11-20 10:12:57,999] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 774.9179\n",
      "2025-11-20 10:12:57 - INFO - [Epoch 036] New best val loss: 774.9179\n",
      "[2025-11-20 10:13:08,200] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 774.7539\n",
      "2025-11-20 10:13:08 - INFO - [Epoch 037] New best val loss: 774.7539\n",
      "[2025-11-20 10:13:27,957] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 774.6022\n",
      "2025-11-20 10:13:27 - INFO - [Epoch 039] New best val loss: 774.6022\n",
      "[2025-11-20 10:13:36,159] [UniVITrainer] [INFO] [Epoch 040] Train loss: 768.6538 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:13:36 - INFO - [Epoch 040] Train loss: 768.6538 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:13:37,142] [UniVITrainer] [INFO] [Epoch 040] Val loss: 774.4471 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:13:37 - INFO - [Epoch 040] Val loss: 774.4471 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:13:37,663] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 774.4471\n",
      "2025-11-20 10:13:37 - INFO - [Epoch 040] New best val loss: 774.4471\n",
      "[2025-11-20 10:13:57,639] [UniVITrainer] [INFO] [Epoch 042] New best val loss: 774.1387\n",
      "2025-11-20 10:13:57 - INFO - [Epoch 042] New best val loss: 774.1387\n",
      "[2025-11-20 10:14:17,504] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 773.6442\n",
      "2025-11-20 10:14:17 - INFO - [Epoch 044] New best val loss: 773.6442\n",
      "[2025-11-20 10:14:50,159] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 773.5024\n",
      "2025-11-20 10:14:50 - INFO - [Epoch 046] New best val loss: 773.5024\n",
      "[2025-11-20 10:15:25,597] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 773.3929\n",
      "2025-11-20 10:15:25 - INFO - [Epoch 049] New best val loss: 773.3929\n",
      "[2025-11-20 10:15:42,795] [UniVITrainer] [INFO] [Epoch 050] Train loss: 771.9467 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:15:42 - INFO - [Epoch 050] Train loss: 771.9467 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:15:44,901] [UniVITrainer] [INFO] [Epoch 050] Val loss: 773.3052 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:15:44 - INFO - [Epoch 050] Val loss: 773.3052 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:15:45,337] [UniVITrainer] [INFO] [Epoch 050] New best val loss: 773.3052\n",
      "2025-11-20 10:15:45 - INFO - [Epoch 050] New best val loss: 773.3052\n",
      "[2025-11-20 10:16:42,833] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 773.1336\n",
      "2025-11-20 10:16:42 - INFO - [Epoch 053] New best val loss: 773.1336\n",
      "[2025-11-20 10:17:02,786] [UniVITrainer] [INFO] [Epoch 054] New best val loss: 773.1177\n",
      "2025-11-20 10:17:02 - INFO - [Epoch 054] New best val loss: 773.1177\n",
      "[2025-11-20 10:17:29,242] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 773.0318\n",
      "2025-11-20 10:17:29 - INFO - [Epoch 056] New best val loss: 773.0318\n",
      "[2025-11-20 10:17:52,547] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 772.7132\n",
      "2025-11-20 10:17:52 - INFO - [Epoch 058] New best val loss: 772.7132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 10:18:08,771] [UniVITrainer] [INFO] [Epoch 059] New best val loss: 772.4293\n",
      "2025-11-20 10:18:08 - INFO - [Epoch 059] New best val loss: 772.4293\n",
      "[2025-11-20 10:18:17,580] [UniVITrainer] [INFO] [Epoch 060] Train loss: 770.8941 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:18:17 - INFO - [Epoch 060] Train loss: 770.8941 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:18:18,675] [UniVITrainer] [INFO] [Epoch 060] Val loss: 772.6317 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:18:18 - INFO - [Epoch 060] Val loss: 772.6317 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:18:33,962] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 772.4088\n",
      "2025-11-20 10:18:33 - INFO - [Epoch 061] New best val loss: 772.4088\n",
      "[2025-11-20 10:19:53,698] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 772.0888\n",
      "2025-11-20 10:19:53 - INFO - [Epoch 066] New best val loss: 772.0888\n",
      "[2025-11-20 10:20:43,813] [UniVITrainer] [INFO] [Epoch 069] New best val loss: 772.0533\n",
      "2025-11-20 10:20:43 - INFO - [Epoch 069] New best val loss: 772.0533\n",
      "[2025-11-20 10:20:51,955] [UniVITrainer] [INFO] [Epoch 070] Train loss: 767.9527 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:20:51 - INFO - [Epoch 070] Train loss: 767.9527 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:20:53,081] [UniVITrainer] [INFO] [Epoch 070] Val loss: 772.1319 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:20:53 - INFO - [Epoch 070] Val loss: 772.1319 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:21:02,719] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 771.9096\n",
      "2025-11-20 10:21:02 - INFO - [Epoch 071] New best val loss: 771.9096\n",
      "[2025-11-20 10:21:11,562] [UniVITrainer] [INFO] [Epoch 072] New best val loss: 771.8369\n",
      "2025-11-20 10:21:11 - INFO - [Epoch 072] New best val loss: 771.8369\n",
      "[2025-11-20 10:21:28,592] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 771.7641\n",
      "2025-11-20 10:21:28 - INFO - [Epoch 074] New best val loss: 771.7641\n",
      "[2025-11-20 10:22:05,990] [UniVITrainer] [INFO] [Epoch 078] New best val loss: 771.6485\n",
      "2025-11-20 10:22:05 - INFO - [Epoch 078] New best val loss: 771.6485\n",
      "[2025-11-20 10:22:23,787] [UniVITrainer] [INFO] [Epoch 080] Train loss: 768.5237 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:22:23 - INFO - [Epoch 080] Train loss: 768.5237 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:22:24,504] [UniVITrainer] [INFO] [Epoch 080] Val loss: 771.6436 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:22:24 - INFO - [Epoch 080] Val loss: 771.6436 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:22:24,993] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 771.6436\n",
      "2025-11-20 10:22:24 - INFO - [Epoch 080] New best val loss: 771.6436\n",
      "[2025-11-20 10:22:34,734] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 771.4806\n",
      "2025-11-20 10:22:34 - INFO - [Epoch 081] New best val loss: 771.4806\n",
      "[2025-11-20 10:22:44,529] [UniVITrainer] [INFO] [Epoch 082] New best val loss: 771.3607\n",
      "2025-11-20 10:22:44 - INFO - [Epoch 082] New best val loss: 771.3607\n",
      "[2025-11-20 10:23:02,885] [UniVITrainer] [INFO] [Epoch 084] New best val loss: 771.1380\n",
      "2025-11-20 10:23:02 - INFO - [Epoch 084] New best val loss: 771.1380\n",
      "[2025-11-20 10:23:55,490] [UniVITrainer] [INFO] [Epoch 090] Train loss: 769.0277 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:23:55 - INFO - [Epoch 090] Train loss: 769.0277 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:23:56,255] [UniVITrainer] [INFO] [Epoch 090] Val loss: 771.3516 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:23:56 - INFO - [Epoch 090] Val loss: 771.3516 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:24:16,493] [UniVITrainer] [INFO] [Epoch 092] New best val loss: 770.8803\n",
      "2025-11-20 10:24:16 - INFO - [Epoch 092] New best val loss: 770.8803\n",
      "[2025-11-20 10:24:43,175] [UniVITrainer] [INFO] [Epoch 095] New best val loss: 770.7955\n",
      "2025-11-20 10:24:43 - INFO - [Epoch 095] New best val loss: 770.7955\n",
      "[2025-11-20 10:25:19,936] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 770.6505\n",
      "2025-11-20 10:25:19 - INFO - [Epoch 099] New best val loss: 770.6505\n",
      "[2025-11-20 10:25:28,320] [UniVITrainer] [INFO] [Epoch 100] Train loss: 768.4973 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:25:28 - INFO - [Epoch 100] Train loss: 768.4973 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:25:29,415] [UniVITrainer] [INFO] [Epoch 100] Val loss: 770.7733 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:25:29 - INFO - [Epoch 100] Val loss: 770.7733 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:25:39,699] [UniVITrainer] [INFO] [Epoch 101] New best val loss: 770.5919\n",
      "2025-11-20 10:25:39 - INFO - [Epoch 101] New best val loss: 770.5919\n",
      "[2025-11-20 10:26:05,995] [UniVITrainer] [INFO] [Epoch 104] New best val loss: 770.2868\n",
      "2025-11-20 10:26:05 - INFO - [Epoch 104] New best val loss: 770.2868\n",
      "[2025-11-20 10:26:15,960] [UniVITrainer] [INFO] [Epoch 105] New best val loss: 770.2711\n",
      "2025-11-20 10:26:15 - INFO - [Epoch 105] New best val loss: 770.2711\n",
      "[2025-11-20 10:26:53,975] [UniVITrainer] [INFO] [Epoch 109] New best val loss: 770.1431\n",
      "2025-11-20 10:26:53 - INFO - [Epoch 109] New best val loss: 770.1431\n",
      "[2025-11-20 10:27:02,165] [UniVITrainer] [INFO] [Epoch 110] Train loss: 764.0950 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:27:02 - INFO - [Epoch 110] Train loss: 764.0950 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:27:03,272] [UniVITrainer] [INFO] [Epoch 110] Val loss: 769.9886 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:27:03 - INFO - [Epoch 110] Val loss: 769.9886 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:27:03,696] [UniVITrainer] [INFO] [Epoch 110] New best val loss: 769.9886\n",
      "2025-11-20 10:27:03 - INFO - [Epoch 110] New best val loss: 769.9886\n",
      "[2025-11-20 10:27:59,564] [UniVITrainer] [INFO] [Epoch 116] New best val loss: 769.9231\n",
      "2025-11-20 10:27:59 - INFO - [Epoch 116] New best val loss: 769.9231\n",
      "[2025-11-20 10:28:09,127] [UniVITrainer] [INFO] [Epoch 117] New best val loss: 769.8732\n",
      "2025-11-20 10:28:09 - INFO - [Epoch 117] New best val loss: 769.8732\n",
      "[2025-11-20 10:28:36,455] [UniVITrainer] [INFO] [Epoch 120] Train loss: 766.4348 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:28:36 - INFO - [Epoch 120] Train loss: 766.4348 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:28:37,498] [UniVITrainer] [INFO] [Epoch 120] Val loss: 770.2129 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:28:37 - INFO - [Epoch 120] Val loss: 770.2129 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:28:46,712] [UniVITrainer] [INFO] [Epoch 121] New best val loss: 769.8128\n",
      "2025-11-20 10:28:46 - INFO - [Epoch 121] New best val loss: 769.8128\n",
      "[2025-11-20 10:29:04,912] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 769.7046\n",
      "2025-11-20 10:29:04 - INFO - [Epoch 123] New best val loss: 769.7046\n",
      "[2025-11-20 10:29:14,749] [UniVITrainer] [INFO] [Epoch 124] New best val loss: 769.6618\n",
      "2025-11-20 10:29:14 - INFO - [Epoch 124] New best val loss: 769.6618\n",
      "[2025-11-20 10:29:24,813] [UniVITrainer] [INFO] [Epoch 125] New best val loss: 769.6601\n",
      "2025-11-20 10:29:24 - INFO - [Epoch 125] New best val loss: 769.6601\n",
      "[2025-11-20 10:29:44,262] [UniVITrainer] [INFO] [Epoch 127] New best val loss: 769.5294\n",
      "2025-11-20 10:29:44 - INFO - [Epoch 127] New best val loss: 769.5294\n",
      "[2025-11-20 10:30:08,807] [UniVITrainer] [INFO] [Epoch 130] Train loss: 766.5307 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:30:08 - INFO - [Epoch 130] Train loss: 766.5307 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:30:09,914] [UniVITrainer] [INFO] [Epoch 130] Val loss: 769.5076 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:30:09 - INFO - [Epoch 130] Val loss: 769.5076 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:30:10,365] [UniVITrainer] [INFO] [Epoch 130] New best val loss: 769.5076\n",
      "2025-11-20 10:30:10 - INFO - [Epoch 130] New best val loss: 769.5076\n",
      "[2025-11-20 10:30:25,972] [UniVITrainer] [INFO] [Epoch 132] New best val loss: 769.3963\n",
      "2025-11-20 10:30:25 - INFO - [Epoch 132] New best val loss: 769.3963\n",
      "[2025-11-20 10:30:34,084] [UniVITrainer] [INFO] [Epoch 133] New best val loss: 769.2879\n",
      "2025-11-20 10:30:34 - INFO - [Epoch 133] New best val loss: 769.2879\n",
      "[2025-11-20 10:30:42,158] [UniVITrainer] [INFO] [Epoch 134] New best val loss: 769.1249\n",
      "2025-11-20 10:30:42 - INFO - [Epoch 134] New best val loss: 769.1249\n",
      "[2025-11-20 10:31:20,521] [UniVITrainer] [INFO] [Epoch 139] New best val loss: 769.1159\n",
      "2025-11-20 10:31:20 - INFO - [Epoch 139] New best val loss: 769.1159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 10:31:26,814] [UniVITrainer] [INFO] [Epoch 140] Train loss: 765.0983 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:31:26 - INFO - [Epoch 140] Train loss: 765.0983 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:31:27,530] [UniVITrainer] [INFO] [Epoch 140] Val loss: 769.2179 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:31:27 - INFO - [Epoch 140] Val loss: 769.2179 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:31:52,507] [UniVITrainer] [INFO] [Epoch 143] New best val loss: 769.0420\n",
      "2025-11-20 10:31:52 - INFO - [Epoch 143] New best val loss: 769.0420\n",
      "[2025-11-20 10:32:32,061] [UniVITrainer] [INFO] [Epoch 148] New best val loss: 768.9637\n",
      "2025-11-20 10:32:32 - INFO - [Epoch 148] New best val loss: 768.9637\n",
      "[2025-11-20 10:32:40,167] [UniVITrainer] [INFO] [Epoch 149] New best val loss: 768.8677\n",
      "2025-11-20 10:32:40 - INFO - [Epoch 149] New best val loss: 768.8677\n",
      "[2025-11-20 10:32:47,252] [UniVITrainer] [INFO] [Epoch 150] Train loss: 769.4236 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:32:47 - INFO - [Epoch 150] Train loss: 769.4236 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:32:47,391] [UniVITrainer] [INFO] [Epoch 150] Val loss: 768.8586 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:32:47 - INFO - [Epoch 150] Val loss: 768.8586 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:32:47,896] [UniVITrainer] [INFO] [Epoch 150] New best val loss: 768.8586\n",
      "2025-11-20 10:32:47 - INFO - [Epoch 150] New best val loss: 768.8586\n",
      "[2025-11-20 10:33:05,625] [UniVITrainer] [INFO] [Epoch 152] New best val loss: 768.8097\n",
      "2025-11-20 10:33:05 - INFO - [Epoch 152] New best val loss: 768.8097\n",
      "[2025-11-20 10:33:14,838] [UniVITrainer] [INFO] [Epoch 153] New best val loss: 768.7302\n",
      "2025-11-20 10:33:14 - INFO - [Epoch 153] New best val loss: 768.7302\n",
      "[2025-11-20 10:33:24,010] [UniVITrainer] [INFO] [Epoch 154] New best val loss: 768.6494\n",
      "2025-11-20 10:33:24 - INFO - [Epoch 154] New best val loss: 768.6494\n",
      "[2025-11-20 10:33:32,972] [UniVITrainer] [INFO] [Epoch 155] New best val loss: 768.6443\n",
      "2025-11-20 10:33:32 - INFO - [Epoch 155] New best val loss: 768.6443\n",
      "[2025-11-20 10:33:41,905] [UniVITrainer] [INFO] [Epoch 156] New best val loss: 768.6394\n",
      "2025-11-20 10:33:41 - INFO - [Epoch 156] New best val loss: 768.6394\n",
      "[2025-11-20 10:33:50,795] [UniVITrainer] [INFO] [Epoch 157] New best val loss: 768.5412\n",
      "2025-11-20 10:33:50 - INFO - [Epoch 157] New best val loss: 768.5412\n",
      "[2025-11-20 10:34:15,658] [UniVITrainer] [INFO] [Epoch 160] Train loss: 766.5294 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:34:15 - INFO - [Epoch 160] Train loss: 766.5294 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:34:16,731] [UniVITrainer] [INFO] [Epoch 160] Val loss: 768.8444 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:34:16 - INFO - [Epoch 160] Val loss: 768.8444 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:34:32,175] [UniVITrainer] [INFO] [Epoch 162] New best val loss: 768.4755\n",
      "2025-11-20 10:34:32 - INFO - [Epoch 162] New best val loss: 768.4755\n",
      "[2025-11-20 10:35:11,496] [UniVITrainer] [INFO] [Epoch 167] New best val loss: 768.3886\n",
      "2025-11-20 10:35:11 - INFO - [Epoch 167] New best val loss: 768.3886\n",
      "[2025-11-20 10:35:28,701] [UniVITrainer] [INFO] [Epoch 169] New best val loss: 768.3603\n",
      "2025-11-20 10:35:28 - INFO - [Epoch 169] New best val loss: 768.3603\n",
      "[2025-11-20 10:35:36,648] [UniVITrainer] [INFO] [Epoch 170] Train loss: 767.8077 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:35:36 - INFO - [Epoch 170] Train loss: 767.8077 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:35:37,701] [UniVITrainer] [INFO] [Epoch 170] Val loss: 768.6032 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:35:37 - INFO - [Epoch 170] Val loss: 768.6032 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:35:46,543] [UniVITrainer] [INFO] [Epoch 171] New best val loss: 768.3087\n",
      "2025-11-20 10:35:46 - INFO - [Epoch 171] New best val loss: 768.3087\n",
      "[2025-11-20 10:36:25,738] [UniVITrainer] [INFO] [Epoch 175] New best val loss: 768.2592\n",
      "2025-11-20 10:36:25 - INFO - [Epoch 175] New best val loss: 768.2592\n",
      "[2025-11-20 10:36:35,737] [UniVITrainer] [INFO] [Epoch 176] New best val loss: 768.1653\n",
      "2025-11-20 10:36:35 - INFO - [Epoch 176] New best val loss: 768.1653\n",
      "[2025-11-20 10:37:13,549] [UniVITrainer] [INFO] [Epoch 180] Train loss: 767.4478 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:37:13 - INFO - [Epoch 180] Train loss: 767.4478 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:37:14,621] [UniVITrainer] [INFO] [Epoch 180] Val loss: 768.1410 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:37:14 - INFO - [Epoch 180] Val loss: 768.1410 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:37:14,926] [UniVITrainer] [INFO] [Epoch 180] New best val loss: 768.1410\n",
      "2025-11-20 10:37:14 - INFO - [Epoch 180] New best val loss: 768.1410\n",
      "[2025-11-20 10:37:24,939] [UniVITrainer] [INFO] [Epoch 181] New best val loss: 768.0067\n",
      "2025-11-20 10:37:24 - INFO - [Epoch 181] New best val loss: 768.0067\n",
      "[2025-11-20 10:38:23,770] [UniVITrainer] [INFO] [Epoch 187] New best val loss: 768.0002\n",
      "2025-11-20 10:38:23 - INFO - [Epoch 187] New best val loss: 768.0002\n",
      "[2025-11-20 10:38:43,467] [UniVITrainer] [INFO] [Epoch 189] New best val loss: 767.9159\n",
      "2025-11-20 10:38:43 - INFO - [Epoch 189] New best val loss: 767.9159\n",
      "[2025-11-20 10:38:52,024] [UniVITrainer] [INFO] [Epoch 190] Train loss: 770.0735 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:38:52 - INFO - [Epoch 190] Train loss: 770.0735 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:38:53,094] [UniVITrainer] [INFO] [Epoch 190] Val loss: 767.9063 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:38:53 - INFO - [Epoch 190] Val loss: 767.9063 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:38:53,365] [UniVITrainer] [INFO] [Epoch 190] New best val loss: 767.9063\n",
      "2025-11-20 10:38:53 - INFO - [Epoch 190] New best val loss: 767.9063\n",
      "[2025-11-20 10:39:03,387] [UniVITrainer] [INFO] [Epoch 191] New best val loss: 767.8647\n",
      "2025-11-20 10:39:03 - INFO - [Epoch 191] New best val loss: 767.8647\n",
      "[2025-11-20 10:39:23,195] [UniVITrainer] [INFO] [Epoch 193] New best val loss: 767.8099\n",
      "2025-11-20 10:39:23 - INFO - [Epoch 193] New best val loss: 767.8099\n",
      "[2025-11-20 10:40:30,137] [UniVITrainer] [INFO] [Epoch 200] Train loss: 768.0974 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:40:30 - INFO - [Epoch 200] Train loss: 768.0974 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:40:31,176] [UniVITrainer] [INFO] [Epoch 200] Val loss: 767.9774 (beta=100.000, gamma=140.000)\n",
      "2025-11-20 10:40:31 - INFO - [Epoch 200] Val loss: 767.9774 (beta=100.000, gamma=140.000)\n",
      "[2025-11-20 10:40:31,221] [UniVITrainer] [INFO] Restored best model from epoch 193 (val loss = 767.8099)\n",
      "2025-11-20 10:40:31 - INFO - Restored best model from epoch 193 (val loss = 767.8099)\n",
      "[2025-11-20 10:40:33,731] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-20 10:40:33 - INFO - TrainingConfig:\n",
      "[2025-11-20 10:40:33,734] [UniVITrainer] [INFO]   n_epochs: 200\n",
      "2025-11-20 10:40:33 - INFO -   n_epochs: 200\n",
      "[2025-11-20 10:40:33,735] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-20 10:40:33 - INFO -   batch_size: 256\n",
      "[2025-11-20 10:40:33,738] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-20 10:40:33 - INFO -   lr: 0.001\n",
      "[2025-11-20 10:40:33,740] [UniVITrainer] [INFO]   weight_decay: 1e-05\n",
      "2025-11-20 10:40:33 - INFO -   weight_decay: 1e-05\n",
      "[2025-11-20 10:40:33,742] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-20 10:40:33 - INFO -   device: cuda\n",
      "[2025-11-20 10:40:33,744] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-20 10:40:33 - INFO -   log_every: 10\n",
      "[2025-11-20 10:40:33,748] [UniVITrainer] [INFO]   grad_clip: None\n",
      "2025-11-20 10:40:33 - INFO -   grad_clip: None\n",
      "[2025-11-20 10:40:33,749] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-20 10:40:33 - INFO -   num_workers: 0\n",
      "[2025-11-20 10:40:33,752] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-20 10:40:33 - INFO -   seed: 42\n",
      "[2025-11-20 10:40:33,754] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-20 10:40:33 - INFO -   early_stopping: True\n",
      "[2025-11-20 10:40:33,756] [UniVITrainer] [INFO]   patience: 20\n",
      "2025-11-20 10:40:33 - INFO -   patience: 20\n",
      "[2025-11-20 10:40:33,758] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-20 10:40:33 - INFO -   min_delta: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config 33] Done in 33.2 min\n",
      "  best_val_loss              = 767.810\n",
      "  FOSCTTM (RNA vs ADT, val)  = 0.4914\n",
      "  FOSCTTM (RNA vs ATAC, val) = 0.5564\n",
      "[Config 33] FOSCTTM (ADT vs ATAC, val) = 0.5110\n",
      "  Mean FOSCTTM (3 pairs)     = 0.5196\n",
      "  Modality mixing (k=20)     = 0.0093\n",
      "  Composite score            = 1177.59\n",
      "\n",
      "================================================================================\n",
      "[Config 34] Hyperparameters:\n",
      "{\n",
      "  \"latent_dim\": 20,\n",
      "  \"beta\": 80.0,\n",
      "  \"gamma\": 1000.0,\n",
      "  \"lr\": 0.001,\n",
      "  \"weight_decay\": 1e-05,\n",
      "  \"encoder_dropout\": 0.1,\n",
      "  \"decoder_batchnorm\": true,\n",
      "  \"rna_arch\": \"rna_wide3\",\n",
      "  \"adt_arch\": \"adt_small2\",\n",
      "  \"atac_arch\": \"atac_med2\"\n",
      "}\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87092037d66c4d89bf13a34c68441044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 10:40:42,499] [UniVITrainer] [INFO] [Epoch 001] Train loss: 3617.7135 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:40:42 - INFO - [Epoch 001] Train loss: 3617.7135 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:40:43,217] [UniVITrainer] [INFO] [Epoch 001] Val loss: 1278.2282 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:40:43 - INFO - [Epoch 001] Val loss: 1278.2282 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:40:43,428] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 1278.2282\n",
      "2025-11-20 10:40:43 - INFO - [Epoch 001] New best val loss: 1278.2282\n",
      "[2025-11-20 10:40:49,913] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 1000.9229\n",
      "2025-11-20 10:40:49 - INFO - [Epoch 002] New best val loss: 1000.9229\n",
      "[2025-11-20 10:40:52,521] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 885.9991\n",
      "2025-11-20 10:40:52 - INFO - [Epoch 003] New best val loss: 885.9991\n",
      "[2025-11-20 10:40:56,473] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 849.4610\n",
      "2025-11-20 10:40:56 - INFO - [Epoch 004] New best val loss: 849.4610\n",
      "[2025-11-20 10:41:04,231] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 831.0209\n",
      "2025-11-20 10:41:04 - INFO - [Epoch 005] New best val loss: 831.0209\n",
      "[2025-11-20 10:41:11,714] [UniVITrainer] [INFO] [Epoch 006] New best val loss: 814.0396\n",
      "2025-11-20 10:41:11 - INFO - [Epoch 006] New best val loss: 814.0396\n",
      "[2025-11-20 10:41:19,527] [UniVITrainer] [INFO] [Epoch 007] New best val loss: 806.0628\n",
      "2025-11-20 10:41:19 - INFO - [Epoch 007] New best val loss: 806.0628\n",
      "[2025-11-20 10:41:25,516] [UniVITrainer] [INFO] [Epoch 008] New best val loss: 800.6760\n",
      "2025-11-20 10:41:25 - INFO - [Epoch 008] New best val loss: 800.6760\n",
      "[2025-11-20 10:41:30,530] [UniVITrainer] [INFO] [Epoch 009] New best val loss: 796.3905\n",
      "2025-11-20 10:41:30 - INFO - [Epoch 009] New best val loss: 796.3905\n",
      "[2025-11-20 10:41:36,872] [UniVITrainer] [INFO] [Epoch 010] Train loss: 877.7847 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:41:36 - INFO - [Epoch 010] Train loss: 877.7847 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:41:37,681] [UniVITrainer] [INFO] [Epoch 010] Val loss: 793.0917 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:41:37 - INFO - [Epoch 010] Val loss: 793.0917 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:41:37,840] [UniVITrainer] [INFO] [Epoch 010] New best val loss: 793.0917\n",
      "2025-11-20 10:41:37 - INFO - [Epoch 010] New best val loss: 793.0917\n",
      "[2025-11-20 10:41:45,379] [UniVITrainer] [INFO] [Epoch 011] New best val loss: 788.1559\n",
      "2025-11-20 10:41:45 - INFO - [Epoch 011] New best val loss: 788.1559\n",
      "[2025-11-20 10:41:52,856] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 787.4674\n",
      "2025-11-20 10:41:52 - INFO - [Epoch 012] New best val loss: 787.4674\n",
      "[2025-11-20 10:42:00,206] [UniVITrainer] [INFO] [Epoch 013] New best val loss: 785.0819\n",
      "2025-11-20 10:42:00 - INFO - [Epoch 013] New best val loss: 785.0819\n",
      "[2025-11-20 10:42:07,632] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 782.8456\n",
      "2025-11-20 10:42:07 - INFO - [Epoch 014] New best val loss: 782.8456\n",
      "[2025-11-20 10:42:15,403] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 781.7308\n",
      "2025-11-20 10:42:15 - INFO - [Epoch 015] New best val loss: 781.7308\n",
      "[2025-11-20 10:42:23,101] [UniVITrainer] [INFO] [Epoch 016] New best val loss: 780.5671\n",
      "2025-11-20 10:42:23 - INFO - [Epoch 016] New best val loss: 780.5671\n",
      "[2025-11-20 10:42:30,708] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 778.4582\n",
      "2025-11-20 10:42:30 - INFO - [Epoch 017] New best val loss: 778.4582\n",
      "[2025-11-20 10:42:37,658] [UniVITrainer] [INFO] [Epoch 018] New best val loss: 778.2537\n",
      "2025-11-20 10:42:37 - INFO - [Epoch 018] New best val loss: 778.2537\n",
      "[2025-11-20 10:42:45,197] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 776.2886\n",
      "2025-11-20 10:42:45 - INFO - [Epoch 019] New best val loss: 776.2886\n",
      "[2025-11-20 10:42:51,936] [UniVITrainer] [INFO] [Epoch 020] Train loss: 803.7108 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:42:51 - INFO - [Epoch 020] Train loss: 803.7108 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:42:52,744] [UniVITrainer] [INFO] [Epoch 020] Val loss: 775.8550 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:42:52 - INFO - [Epoch 020] Val loss: 775.8550 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:42:52,879] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 775.8550\n",
      "2025-11-20 10:42:52 - INFO - [Epoch 020] New best val loss: 775.8550\n",
      "[2025-11-20 10:43:00,219] [UniVITrainer] [INFO] [Epoch 021] New best val loss: 774.9184\n",
      "2025-11-20 10:43:00 - INFO - [Epoch 021] New best val loss: 774.9184\n",
      "[2025-11-20 10:43:15,072] [UniVITrainer] [INFO] [Epoch 023] New best val loss: 773.7775\n",
      "2025-11-20 10:43:15 - INFO - [Epoch 023] New best val loss: 773.7775\n",
      "[2025-11-20 10:43:22,557] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 773.3388\n",
      "2025-11-20 10:43:22 - INFO - [Epoch 024] New best val loss: 773.3388\n",
      "[2025-11-20 10:43:37,341] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 772.4271\n",
      "2025-11-20 10:43:37 - INFO - [Epoch 026] New best val loss: 772.4271\n",
      "[2025-11-20 10:43:45,034] [UniVITrainer] [INFO] [Epoch 027] New best val loss: 772.2463\n",
      "2025-11-20 10:43:45 - INFO - [Epoch 027] New best val loss: 772.2463\n",
      "[2025-11-20 10:43:52,695] [UniVITrainer] [INFO] [Epoch 028] New best val loss: 772.0935\n",
      "2025-11-20 10:43:52 - INFO - [Epoch 028] New best val loss: 772.0935\n",
      "[2025-11-20 10:44:00,089] [UniVITrainer] [INFO] [Epoch 029] New best val loss: 771.5946\n",
      "2025-11-20 10:44:00 - INFO - [Epoch 029] New best val loss: 771.5946\n",
      "[2025-11-20 10:44:06,872] [UniVITrainer] [INFO] [Epoch 030] Train loss: 780.1948 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:44:06 - INFO - [Epoch 030] Train loss: 780.1948 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:44:07,684] [UniVITrainer] [INFO] [Epoch 030] Val loss: 771.1430 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:44:07 - INFO - [Epoch 030] Val loss: 771.1430 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:44:07,854] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 771.1430\n",
      "2025-11-20 10:44:07 - INFO - [Epoch 030] New best val loss: 771.1430\n",
      "[2025-11-20 10:44:14,036] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 771.0634\n",
      "2025-11-20 10:44:14 - INFO - [Epoch 031] New best val loss: 771.0634\n",
      "[2025-11-20 10:44:21,652] [UniVITrainer] [INFO] [Epoch 032] New best val loss: 770.0108\n",
      "2025-11-20 10:44:21 - INFO - [Epoch 032] New best val loss: 770.0108\n",
      "[2025-11-20 10:44:48,581] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 769.6182\n",
      "2025-11-20 10:44:48 - INFO - [Epoch 035] New best val loss: 769.6182\n",
      "[2025-11-20 10:44:58,316] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 769.1446\n",
      "2025-11-20 10:44:58 - INFO - [Epoch 036] New best val loss: 769.1446\n",
      "[2025-11-20 10:45:08,071] [UniVITrainer] [INFO] [Epoch 037] New best val loss: 769.0117\n",
      "2025-11-20 10:45:08 - INFO - [Epoch 037] New best val loss: 769.0117\n",
      "[2025-11-20 10:45:27,255] [UniVITrainer] [INFO] [Epoch 039] New best val loss: 768.7065\n",
      "2025-11-20 10:45:27 - INFO - [Epoch 039] New best val loss: 768.7065\n",
      "[2025-11-20 10:45:35,827] [UniVITrainer] [INFO] [Epoch 040] Train loss: 773.4344 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:45:35 - INFO - [Epoch 040] Train loss: 773.4344 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:45:36,893] [UniVITrainer] [INFO] [Epoch 040] Val loss: 768.7314 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:45:36 - INFO - [Epoch 040] Val loss: 768.7314 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:45:46,735] [UniVITrainer] [INFO] [Epoch 041] New best val loss: 768.3236\n",
      "2025-11-20 10:45:46 - INFO - [Epoch 041] New best val loss: 768.3236\n",
      "[2025-11-20 10:46:14,870] [UniVITrainer] [INFO] [Epoch 044] New best val loss: 768.1086\n",
      "2025-11-20 10:46:14 - INFO - [Epoch 044] New best val loss: 768.1086\n",
      "[2025-11-20 10:46:34,165] [UniVITrainer] [INFO] [Epoch 046] New best val loss: 767.8893\n",
      "2025-11-20 10:46:34 - INFO - [Epoch 046] New best val loss: 767.8893\n",
      "[2025-11-20 10:46:44,308] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 767.7066\n",
      "2025-11-20 10:46:44 - INFO - [Epoch 047] New best val loss: 767.7066\n",
      "[2025-11-20 10:47:02,253] [UniVITrainer] [INFO] [Epoch 049] New best val loss: 767.6137\n",
      "2025-11-20 10:47:02 - INFO - [Epoch 049] New best val loss: 767.6137\n",
      "[2025-11-20 10:47:10,579] [UniVITrainer] [INFO] [Epoch 050] Train loss: 771.5643 (beta=80.000, gamma=1000.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 10:47:10 - INFO - [Epoch 050] Train loss: 771.5643 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:47:11,682] [UniVITrainer] [INFO] [Epoch 050] Val loss: 767.6783 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:47:11 - INFO - [Epoch 050] Val loss: 767.6783 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:47:30,998] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 767.5096\n",
      "2025-11-20 10:47:30 - INFO - [Epoch 052] New best val loss: 767.5096\n",
      "[2025-11-20 10:47:40,834] [UniVITrainer] [INFO] [Epoch 053] New best val loss: 767.4125\n",
      "2025-11-20 10:47:40 - INFO - [Epoch 053] New best val loss: 767.4125\n",
      "[2025-11-20 10:48:09,882] [UniVITrainer] [INFO] [Epoch 056] New best val loss: 767.3844\n",
      "2025-11-20 10:48:09 - INFO - [Epoch 056] New best val loss: 767.3844\n",
      "[2025-11-20 10:48:29,491] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 767.2456\n",
      "2025-11-20 10:48:29 - INFO - [Epoch 058] New best val loss: 767.2456\n",
      "[2025-11-20 10:48:47,489] [UniVITrainer] [INFO] [Epoch 060] Train loss: 769.8746 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:48:47 - INFO - [Epoch 060] Train loss: 769.8746 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:48:48,592] [UniVITrainer] [INFO] [Epoch 060] Val loss: 767.2402 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:48:48 - INFO - [Epoch 060] Val loss: 767.2402 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:48:48,869] [UniVITrainer] [INFO] [Epoch 060] New best val loss: 767.2402\n",
      "2025-11-20 10:48:48 - INFO - [Epoch 060] New best val loss: 767.2402\n",
      "[2025-11-20 10:48:58,840] [UniVITrainer] [INFO] [Epoch 061] New best val loss: 767.2053\n",
      "2025-11-20 10:48:58 - INFO - [Epoch 061] New best val loss: 767.2053\n",
      "[2025-11-20 10:49:08,504] [UniVITrainer] [INFO] [Epoch 062] New best val loss: 767.0769\n",
      "2025-11-20 10:49:08 - INFO - [Epoch 062] New best val loss: 767.0769\n",
      "[2025-11-20 10:49:46,798] [UniVITrainer] [INFO] [Epoch 066] New best val loss: 767.0503\n",
      "2025-11-20 10:49:46 - INFO - [Epoch 066] New best val loss: 767.0503\n",
      "[2025-11-20 10:50:06,207] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 766.9199\n",
      "2025-11-20 10:50:06 - INFO - [Epoch 068] New best val loss: 766.9199\n",
      "[2025-11-20 10:50:24,098] [UniVITrainer] [INFO] [Epoch 070] Train loss: 766.1331 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:50:24 - INFO - [Epoch 070] Train loss: 766.1331 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:50:25,191] [UniVITrainer] [INFO] [Epoch 070] Val loss: 766.8512 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:50:25 - INFO - [Epoch 070] Val loss: 766.8512 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:50:25,466] [UniVITrainer] [INFO] [Epoch 070] New best val loss: 766.8512\n",
      "2025-11-20 10:50:25 - INFO - [Epoch 070] New best val loss: 766.8512\n",
      "[2025-11-20 10:51:02,377] [UniVITrainer] [INFO] [Epoch 074] New best val loss: 766.7720\n",
      "2025-11-20 10:51:02 - INFO - [Epoch 074] New best val loss: 766.7720\n",
      "[2025-11-20 10:51:57,805] [UniVITrainer] [INFO] [Epoch 080] Train loss: 768.2647 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:51:57 - INFO - [Epoch 080] Train loss: 768.2647 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:51:58,783] [UniVITrainer] [INFO] [Epoch 080] Val loss: 766.7125 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:51:58 - INFO - [Epoch 080] Val loss: 766.7125 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:51:59,082] [UniVITrainer] [INFO] [Epoch 080] New best val loss: 766.7125\n",
      "2025-11-20 10:51:59 - INFO - [Epoch 080] New best val loss: 766.7125\n",
      "[2025-11-20 10:52:08,812] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 766.6901\n",
      "2025-11-20 10:52:08 - INFO - [Epoch 081] New best val loss: 766.6901\n",
      "[2025-11-20 10:52:55,493] [UniVITrainer] [INFO] [Epoch 086] New best val loss: 766.6256\n",
      "2025-11-20 10:52:55 - INFO - [Epoch 086] New best val loss: 766.6256\n",
      "[2025-11-20 10:53:24,290] [UniVITrainer] [INFO] [Epoch 089] New best val loss: 766.5861\n",
      "2025-11-20 10:53:24 - INFO - [Epoch 089] New best val loss: 766.5861\n",
      "[2025-11-20 10:53:32,717] [UniVITrainer] [INFO] [Epoch 090] Train loss: 767.7752 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:53:32 - INFO - [Epoch 090] Train loss: 767.7752 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:53:33,798] [UniVITrainer] [INFO] [Epoch 090] Val loss: 766.6676 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:53:33 - INFO - [Epoch 090] Val loss: 766.6676 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:53:43,591] [UniVITrainer] [INFO] [Epoch 091] New best val loss: 766.5112\n",
      "2025-11-20 10:53:43 - INFO - [Epoch 091] New best val loss: 766.5112\n",
      "[2025-11-20 10:54:39,128] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 766.5019\n",
      "2025-11-20 10:54:39 - INFO - [Epoch 097] New best val loss: 766.5019\n",
      "[2025-11-20 10:55:06,390] [UniVITrainer] [INFO] [Epoch 100] Train loss: 767.6579 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:55:06 - INFO - [Epoch 100] Train loss: 767.6579 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:55:07,210] [UniVITrainer] [INFO] [Epoch 100] Val loss: 766.5620 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:55:07 - INFO - [Epoch 100] Val loss: 766.5620 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:56:25,358] [UniVITrainer] [INFO] [Epoch 108] New best val loss: 766.4540\n",
      "2025-11-20 10:56:25 - INFO - [Epoch 108] New best val loss: 766.4540\n",
      "[2025-11-20 10:56:34,968] [UniVITrainer] [INFO] [Epoch 109] New best val loss: 766.3755\n",
      "2025-11-20 10:56:34 - INFO - [Epoch 109] New best val loss: 766.3755\n",
      "[2025-11-20 10:56:43,597] [UniVITrainer] [INFO] [Epoch 110] Train loss: 767.5949 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:56:43 - INFO - [Epoch 110] Train loss: 767.5949 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:56:44,704] [UniVITrainer] [INFO] [Epoch 110] Val loss: 766.5591 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:56:44 - INFO - [Epoch 110] Val loss: 766.5591 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:58:20,020] [UniVITrainer] [INFO] [Epoch 120] Train loss: 766.8477 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:58:20 - INFO - [Epoch 120] Train loss: 766.8477 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:58:21,117] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.4738 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:58:21 - INFO - [Epoch 120] Val loss: 766.4738 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:58:50,726] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 766.3742\n",
      "2025-11-20 10:58:50 - INFO - [Epoch 123] New best val loss: 766.3742\n",
      "[2025-11-20 10:59:54,462] [UniVITrainer] [INFO] [Epoch 130] Train loss: 767.4310 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:59:54 - INFO - [Epoch 130] Train loss: 767.4310 (beta=80.000, gamma=1000.000)\n",
      "[2025-11-20 10:59:55,259] [UniVITrainer] [INFO] [Epoch 130] Val loss: 766.4492 (beta=80.000, gamma=1000.000)\n",
      "2025-11-20 10:59:55 - INFO - [Epoch 130] Val loss: 766.4492 (beta=80.000, gamma=1000.000)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# 6. Run the search\n",
    "# ------------------------------------------------------\n",
    "\n",
    "all_results = []\n",
    "best_score = None\n",
    "best_result = None\n",
    "\n",
    "for i, hp in enumerate(iter_hparam_configs(search_space), start=1):\n",
    "    res = evaluate_config(hp, config_id=i)\n",
    "    s = res[\"score\"]\n",
    "    all_results.append(res)\n",
    "\n",
    "    if best_score is None or s < best_score:\n",
    "        best_score = s\n",
    "        best_result = res\n",
    "        print(f\"--> New best config (id={i}) with score={s:.3f}\")\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(\"TEA-seq Hyperparameter search finished.\")\n",
    "print(\"========================================\")\n",
    "\n",
    "# Sort configs by score\n",
    "all_results_sorted = sorted(all_results, key=lambda r: r[\"score\"])\n",
    "for r in all_results_sorted:\n",
    "    hp = r[\"hp\"]\n",
    "    print(\n",
    "        f\"Config {r['config_id']:02d} | \"\n",
    "        f\"latent={hp['latent_dim']:>2d}, \"\n",
    "        f\"beta={hp['beta']:>5.1f}, \"\n",
    "        f\"gamma={hp['gamma']:>5.1f}, \"\n",
    "        f\"lr={hp['lr']:.0e}, \"\n",
    "        f\"wd={hp['weight_decay']:.0e}, \"\n",
    "        f\"enc_drop={hp['encoder_dropout']:.2f}, \"\n",
    "        f\"dec_bn={hp['decoder_batchnorm']} | \"\n",
    "        f\"rna_arch={hp['rna_arch']['name']}, \"\n",
    "        f\"adt_arch={hp['adt_arch']['name']}, \"\n",
    "        f\"atac_arch={hp['atac_arch']['name']} | \"\n",
    "        f\"val_loss={r['best_val_loss']:.2f}, \"\n",
    "        f\"FOS_RNA-ADT={r['fos_rna_adt_val']:.4f}, \"\n",
    "        f\"FOS_RNA-ATAC={r['fos_rna_atac_val']:.4f}, \"\n",
    "        f\"FOS_ADT-ATAC={r['fos_adt_atac_val']:.4f}, \"\n",
    "        f\"mixing={r['mixing_score_val']:.4f}, \"\n",
    "        f\"score={r['score']:.2f}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nBest configuration hyperparameters:\")\n",
    "pretty_best = {\n",
    "    **{k: v for k, v in best_result[\"hp\"].items() if k not in (\"rna_arch\", \"adt_arch\", \"atac_arch\")},\n",
    "    \"rna_arch\": best_result[\"hp\"][\"rna_arch\"][\"name\"],\n",
    "    \"adt_arch\": best_result[\"hp\"][\"adt_arch\"][\"name\"],\n",
    "    \"atac_arch\": best_result[\"hp\"][\"atac_arch\"][\"name\"],\n",
    "}\n",
    "print(json.dumps(pretty_best, indent=2))\n",
    "print(\n",
    "    f\"Best val_loss={best_result['best_val_loss']:.3f}, \"\n",
    "    f\"FOS_mean={best_result['fos_mean_val']:.4f}, \"\n",
    "    f\"mixing={best_result['mixing_score_val']:.4f}, \"\n",
    "    f\"score={best_result['score']:.2f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 7. Hyperparameter search diagnostics & plots (TEA-seq)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "rows = []\n",
    "for r in all_results:\n",
    "    hp = r[\"hp\"]\n",
    "    rows.append(\n",
    "        {\n",
    "            \"config_id\": r[\"config_id\"],\n",
    "            \"latent_dim\": hp[\"latent_dim\"],\n",
    "            \"beta\": hp[\"beta\"],\n",
    "            \"gamma\": hp[\"gamma\"],\n",
    "            \"lr\": hp[\"lr\"],\n",
    "            \"weight_decay\": hp[\"weight_decay\"],\n",
    "            \"encoder_dropout\": hp[\"encoder_dropout\"],\n",
    "            \"decoder_batchnorm\": hp[\"decoder_batchnorm\"],\n",
    "            \"rna_arch\": hp[\"rna_arch\"][\"name\"],\n",
    "            \"adt_arch\": hp[\"adt_arch\"][\"name\"],\n",
    "            \"atac_arch\": hp[\"atac_arch\"][\"name\"],\n",
    "            \"val_loss\": r[\"best_val_loss\"],\n",
    "            \"fos_rna_adt\": r[\"fos_rna_adt_val\"],\n",
    "            \"fos_rna_atac\": r[\"fos_rna_atac_val\"],\n",
    "            \"fos_adt_atac\": r[\"fos_adt_atac_val\"],\n",
    "            \"fos_mean\": r[\"fos_mean_val\"],\n",
    "            \"mixing_score\": r[\"mixing_score_val\"],\n",
    "            \"score\": r[\"score\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"TEA-seq hyperparameter search results (head):\")\n",
    "print(df.head())\n",
    "\n",
    "# 7.1 Metric relationships: pairplot\n",
    "metrics = [\"val_loss\", \"fos_mean\", \"mixing_score\", \"score\"]\n",
    "g = sns.pairplot(df[metrics], diag_kind=\"kde\")\n",
    "g.fig.suptitle(\"Metric relationships across TEA-seq configs\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# 7.2 FOS_mean vs mixing, colored by score\n",
    "plt.figure(figsize=(6, 5))\n",
    "scat = plt.scatter(\n",
    "    df[\"fos_mean\"],\n",
    "    df[\"mixing_score\"],\n",
    "    c=df[\"score\"],\n",
    "    s=70,\n",
    "    cmap=\"viridis\",\n",
    "    edgecolor=\"k\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.colorbar(scat, label=\"Composite score (lower = better)\")\n",
    "plt.xlabel(\"Mean FOSCTTM across pairs (lower = better)\")\n",
    "plt.ylabel(\"Modality mixing score (lower = better)\")\n",
    "plt.title(\"TEA-seq: FOS_mean vs mixing, colored by score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7.3 Score vs individual numeric hyperparameters\n",
    "num_hps = [\"latent_dim\", \"beta\", \"gamma\", \"lr\", \"weight_decay\", \"encoder_dropout\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for ax, hp_name in zip(axes, num_hps):\n",
    "    ax.scatter(df[hp_name], df[\"score\"], s=60, alpha=0.8)\n",
    "    ax.set_xlabel(hp_name)\n",
    "    ax.set_ylabel(\"score\")\n",
    "    ax.set_title(f\"Score vs {hp_name}\")\n",
    "    if hp_name in [\"lr\", \"weight_decay\"]:\n",
    "        ax.set_xscale(\"log\")\n",
    "\n",
    "plt.suptitle(\"TEA-seq: Score vs numeric hyperparameters\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7.4 Categorical hyperparams vs score (boxplots)\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(data=df, x=\"decoder_batchnorm\", y=\"score\")\n",
    "plt.xlabel(\"decoder_batchnorm\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.title(\"TEA-seq: effect of decoder_batchnorm on score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(data=df, x=\"rna_arch\", y=\"score\")\n",
    "plt.xlabel(\"rna_arch\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.title(\"TEA-seq: score distribution by RNA architecture\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(data=df, x=\"adt_arch\", y=\"score\")\n",
    "plt.xlabel(\"adt_arch\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.title(\"TEA-seq: score distribution by ADT architecture\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(data=df, x=\"atac_arch\", y=\"score\")\n",
    "plt.xlabel(\"atac_arch\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.title(\"TEA-seq: score distribution by ATAC architecture\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7.5 Beta vs gamma with score as color (2D hyperparam landscape)\n",
    "plt.figure(figsize=(6, 5))\n",
    "scat = plt.scatter(\n",
    "    df[\"beta\"],\n",
    "    df[\"gamma\"],\n",
    "    c=df[\"score\"],\n",
    "    s=80,\n",
    "    cmap=\"viridis\",\n",
    "    edgecolor=\"k\",\n",
    "    alpha=0.9,\n",
    ")\n",
    "plt.colorbar(scat, label=\"Composite score (lower = better)\")\n",
    "plt.xlabel(\"beta\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.title(\"TEA-seq: beta vs gamma hyperparameter landscape\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7.6 Correlation heatmap: hyperparams & metrics\n",
    "corr_cols = [\n",
    "    \"latent_dim\",\n",
    "    \"beta\",\n",
    "    \"gamma\",\n",
    "    \"lr\",\n",
    "    \"weight_decay\",\n",
    "    \"encoder_dropout\",\n",
    "    \"val_loss\",\n",
    "    \"fos_mean\",\n",
    "    \"mixing_score\",\n",
    "    \"score\",\n",
    "]\n",
    "corr = df[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"vlag\",\n",
    "    center=0.0,\n",
    "    square=True,\n",
    ")\n",
    "plt.title(\"TEA-seq: correlation between hyperparameters and metrics\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7.7 Training curves for top K configs (by score)\n",
    "top_k = 3  # tweak as desired\n",
    "top_ids = df.nsmallest(top_k, \"score\")[\"config_id\"].tolist()\n",
    "print(f\"Top {top_k} TEA-seq configs by score:\", top_ids)\n",
    "\n",
    "for cid in top_ids:\n",
    "    res_c = next(r for r in all_results if r[\"config_id\"] == cid)\n",
    "    hist_c = res_c[\"history\"]\n",
    "    epochs_c = np.arange(1, len(hist_c[\"train_loss\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs_c, hist_c[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(epochs_c, hist_c[\"val_loss\"], label=\"val\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"TEA-seq training curves – Config {cid} (score={res_c['score']:.2f})\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 7.8 Overlay val-loss curves for all configs\n",
    "plt.figure(figsize=(7, 5))\n",
    "for r in all_results:\n",
    "    hist_r = r[\"history\"]\n",
    "    epochs_r = np.arange(1, len(hist_r[\"train_loss\"]) + 1)\n",
    "    plt.plot(\n",
    "        epochs_r,\n",
    "        hist_r[\"val_loss\"],\n",
    "        alpha=0.3,\n",
    "        linewidth=1.0,\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Val loss\")\n",
    "plt.title(\"TEA-seq: val loss curves for all configs (overlay)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7.9 Training curve for best config\n",
    "hist = best_result[\"history\"]\n",
    "epochs = np.arange(1, len(hist[\"train_loss\"]) + 1)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(epochs, hist[\"train_loss\"], label=\"train\")\n",
    "plt.plot(epochs, hist[\"val_loss\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Best UniVI TEA-seq config training curves (search)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214cfa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b81a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da5743",
   "metadata": {},
   "source": [
    "#### Initialize model and data via dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cdc6665",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_dict = {\n",
    "    \"rna\": rna,\n",
    "    \"adt\": adt,\n",
    "    \"atac\": atac,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63888c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# ---------- UniVI config (Gaussian for all 3) ----------\\nunivi_cfg = UniVIConfig(\\n    latent_dim=60,\\n    beta=100.0,\\n    gamma=120.0,\\n    encoder_dropout=0.0,\\n    decoder_dropout=0.0,\\n    encoder_batchnorm=True,\\n    decoder_batchnorm=False,\\n    kl_anneal_start=0,\\n    kl_anneal_end=0,\\n    align_anneal_start=0,\\n    align_anneal_end=0,\\n    modalities=[\\n        ModalityConfig(\\n            name=\"rna\",\\n            input_dim=rna.n_vars,\\n            encoder_hidden=[512, 256],\\n            decoder_hidden=[256, 512],\\n            likelihood=\"gaussian\",\\n        ),\\n        ModalityConfig(\\n            name=\"adt\",\\n            input_dim=adt.n_vars,\\n            encoder_hidden=[128, 64],\\n            decoder_hidden=[64, 128],\\n            likelihood=\"gaussian\",\\n        ),\\n        ModalityConfig(\\n            name=\"atac\",\\n            input_dim=atac.n_vars,  # n_lsi (e.g. 50)\\n            encoder_hidden=[128, 64],\\n            decoder_hidden=[64, 128],\\n            likelihood=\"gaussian\",\\n        ),\\n    ],\\n)\\n\\ntrain_cfg = TrainingConfig(\\n    n_epochs=200,\\n    batch_size=256,\\n    lr=1e-3,\\n    weight_decay=1e-4,\\n    #device=\"cuda\",   # or \"cpu\"\\n    device=device,\\n    log_every=10,\\n    grad_clip=5.0,\\n    num_workers=0,\\n    seed=42,\\n    early_stopping=True,\\n    patience=20,\\n    min_delta=0.0,\\n)\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from univi.data import MultiModalDataset\n",
    "from univi.config import UniVIConfig, ModalityConfig, TrainingConfig\n",
    "from univi.models.univi import UniVIMultiModalVAE\n",
    "from univi.trainer import UniVITrainer\n",
    "'''\n",
    "# ---------- UniVI config (Gaussian for all 3) ----------\n",
    "univi_cfg = UniVIConfig(\n",
    "    latent_dim=60,\n",
    "    beta=100.0,\n",
    "    gamma=120.0,\n",
    "    encoder_dropout=0.0,\n",
    "    decoder_dropout=0.0,\n",
    "    encoder_batchnorm=True,\n",
    "    decoder_batchnorm=False,\n",
    "    kl_anneal_start=0,\n",
    "    kl_anneal_end=0,\n",
    "    align_anneal_start=0,\n",
    "    align_anneal_end=0,\n",
    "    modalities=[\n",
    "        ModalityConfig(\n",
    "            name=\"rna\",\n",
    "            input_dim=rna.n_vars,\n",
    "            encoder_hidden=[512, 256],\n",
    "            decoder_hidden=[256, 512],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "        ModalityConfig(\n",
    "            name=\"adt\",\n",
    "            input_dim=adt.n_vars,\n",
    "            encoder_hidden=[128, 64],\n",
    "            decoder_hidden=[64, 128],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "        ModalityConfig(\n",
    "            name=\"atac\",\n",
    "            input_dim=atac.n_vars,  # n_lsi (e.g. 50)\n",
    "            encoder_hidden=[128, 64],\n",
    "            decoder_hidden=[64, 128],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "train_cfg = TrainingConfig(\n",
    "    n_epochs=200,\n",
    "    batch_size=256,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    #device=\"cuda\",   # or \"cpu\"\n",
    "    device=device,\n",
    "    log_every=10,\n",
    "    grad_clip=5.0,\n",
    "    num_workers=0,\n",
    "    seed=42,\n",
    "    early_stopping=True,\n",
    "    patience=20,\n",
    "    min_delta=0.0,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f89e6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from univi.config import UniVIConfig, ModalityConfig, TrainingConfig\n",
    "\n",
    "univi_cfg = UniVIConfig(\n",
    "    latent_dim=32,\n",
    "    beta=40.0,          # softer\n",
    "    gamma=60.0,         # moderate alignment\n",
    "    encoder_dropout=0.0,\n",
    "    decoder_dropout=0.0,\n",
    "    encoder_batchnorm=True,\n",
    "    decoder_batchnorm=False,\n",
    "    kl_anneal_start=0,\n",
    "    kl_anneal_end=0,   # ramp KL up over first 50 epochs\n",
    "    align_anneal_start=5,  # let reconstructions stabilize a bit first\n",
    "    align_anneal_end=15,\n",
    "    modalities=[\n",
    "        ModalityConfig(\n",
    "            name=\"rna\",\n",
    "            input_dim=rna.n_vars,\n",
    "            encoder_hidden=[512, 256],\n",
    "            decoder_hidden=[256, 512],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "        ModalityConfig(\n",
    "            name=\"adt\",\n",
    "            input_dim=adt.n_vars,\n",
    "            encoder_hidden=[128, 64],\n",
    "            decoder_hidden=[64, 128],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "        ModalityConfig(\n",
    "            name=\"atac\",\n",
    "            input_dim=atac.n_vars,  # n_lsi\n",
    "            encoder_hidden=[128, 64],\n",
    "            decoder_hidden=[64, 128],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "train_cfg = TrainingConfig(\n",
    "    n_epochs=300,\n",
    "    batch_size=256,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    device=device,      # \"cuda\"\n",
    "    log_every=10,\n",
    "    grad_clip=5.0,\n",
    "    num_workers=0,\n",
    "    seed=42,\n",
    "    early_stopping=True,\n",
    "    patience=35,\n",
    "    min_delta=0.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97960e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 21:49:07,215] [UniVITrainer] [INFO] TrainingConfig:\n",
      "2025-11-19 21:49:07 - INFO - TrainingConfig:\n",
      "[2025-11-19 21:49:07,217] [UniVITrainer] [INFO]   n_epochs: 300\n",
      "2025-11-19 21:49:07 - INFO -   n_epochs: 300\n",
      "[2025-11-19 21:49:07,252] [UniVITrainer] [INFO]   batch_size: 256\n",
      "2025-11-19 21:49:07 - INFO -   batch_size: 256\n",
      "[2025-11-19 21:49:07,259] [UniVITrainer] [INFO]   lr: 0.001\n",
      "2025-11-19 21:49:07 - INFO -   lr: 0.001\n",
      "[2025-11-19 21:49:07,260] [UniVITrainer] [INFO]   weight_decay: 0.0001\n",
      "2025-11-19 21:49:07 - INFO -   weight_decay: 0.0001\n",
      "[2025-11-19 21:49:07,260] [UniVITrainer] [INFO]   device: cuda\n",
      "2025-11-19 21:49:07 - INFO -   device: cuda\n",
      "[2025-11-19 21:49:07,263] [UniVITrainer] [INFO]   log_every: 10\n",
      "2025-11-19 21:49:07 - INFO -   log_every: 10\n",
      "[2025-11-19 21:49:07,268] [UniVITrainer] [INFO]   grad_clip: 5.0\n",
      "2025-11-19 21:49:07 - INFO -   grad_clip: 5.0\n",
      "[2025-11-19 21:49:07,268] [UniVITrainer] [INFO]   num_workers: 0\n",
      "2025-11-19 21:49:07 - INFO -   num_workers: 0\n",
      "[2025-11-19 21:49:07,269] [UniVITrainer] [INFO]   seed: 42\n",
      "2025-11-19 21:49:07 - INFO -   seed: 42\n",
      "[2025-11-19 21:49:07,270] [UniVITrainer] [INFO]   early_stopping: True\n",
      "2025-11-19 21:49:07 - INFO -   early_stopping: True\n",
      "[2025-11-19 21:49:07,272] [UniVITrainer] [INFO]   patience: 35\n",
      "2025-11-19 21:49:07 - INFO -   patience: 35\n",
      "[2025-11-19 21:49:07,273] [UniVITrainer] [INFO]   min_delta: 0.0\n",
      "2025-11-19 21:49:07 - INFO -   min_delta: 0.0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "dataset = MultiModalDataset(\n",
    "    adata_dict=adata_dict,\n",
    "    X_key=\"X\",\n",
    "    device=train_cfg.device,\n",
    ")\n",
    "\n",
    "n_cells = dataset.n_cells\n",
    "indices = np.arange(n_cells)\n",
    "rng = np.random.default_rng(42)\n",
    "rng.shuffle(indices)\n",
    "\n",
    "frac_train = 0.8\n",
    "frac_val   = 0.1\n",
    "n_train = int(frac_train * n_cells)\n",
    "n_val   = int(frac_val * n_cells)\n",
    "\n",
    "train_idx = indices[:n_train]\n",
    "val_idx   = indices[n_train:n_train + n_val]\n",
    "test_idx  = indices[n_train + n_val:]\n",
    "\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds   = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=train_cfg.num_workers,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=train_cfg.num_workers,\n",
    ")\n",
    "\n",
    "model = UniVIMultiModalVAE(univi_cfg).to(train_cfg.device)\n",
    "trainer = UniVITrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    train_cfg=train_cfg,\n",
    "    device=train_cfg.device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c6ed2",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f789498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85e004349bd44fa994731489fd755ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training UniVI:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-19 21:49:16,390] [UniVITrainer] [INFO] [Epoch 001] Train loss: 917.2002 (beta=40.000, gamma=0.000)\n",
      "2025-11-19 21:49:16 - INFO - [Epoch 001] Train loss: 917.2002 (beta=40.000, gamma=0.000)\n",
      "[2025-11-19 21:49:17,040] [UniVITrainer] [INFO] [Epoch 001] Val loss: 800.3322 (beta=40.000, gamma=0.000)\n",
      "2025-11-19 21:49:17 - INFO - [Epoch 001] Val loss: 800.3322 (beta=40.000, gamma=0.000)\n",
      "[2025-11-19 21:49:17,081] [UniVITrainer] [INFO] [Epoch 001] New best val loss: 800.3322\n",
      "2025-11-19 21:49:17 - INFO - [Epoch 001] New best val loss: 800.3322\n",
      "[2025-11-19 21:49:24,745] [UniVITrainer] [INFO] [Epoch 002] New best val loss: 771.9595\n",
      "2025-11-19 21:49:24 - INFO - [Epoch 002] New best val loss: 771.9595\n",
      "[2025-11-19 21:49:31,834] [UniVITrainer] [INFO] [Epoch 003] New best val loss: 768.6938\n",
      "2025-11-19 21:49:31 - INFO - [Epoch 003] New best val loss: 768.6938\n",
      "[2025-11-19 21:49:39,265] [UniVITrainer] [INFO] [Epoch 004] New best val loss: 767.7239\n",
      "2025-11-19 21:49:39 - INFO - [Epoch 004] New best val loss: 767.7239\n",
      "[2025-11-19 21:49:46,985] [UniVITrainer] [INFO] [Epoch 005] New best val loss: 767.4692\n",
      "2025-11-19 21:49:46 - INFO - [Epoch 005] New best val loss: 767.4692\n",
      "[2025-11-19 21:50:20,710] [UniVITrainer] [INFO] [Epoch 010] Train loss: 767.1698 (beta=40.000, gamma=30.000)\n",
      "2025-11-19 21:50:20 - INFO - [Epoch 010] Train loss: 767.1698 (beta=40.000, gamma=30.000)\n",
      "[2025-11-19 21:50:21,526] [UniVITrainer] [INFO] [Epoch 010] Val loss: 767.4879 (beta=40.000, gamma=30.000)\n",
      "2025-11-19 21:50:21 - INFO - [Epoch 010] Val loss: 767.4879 (beta=40.000, gamma=30.000)\n",
      "[2025-11-19 21:50:36,008] [UniVITrainer] [INFO] [Epoch 012] New best val loss: 767.3792\n",
      "2025-11-19 21:50:36 - INFO - [Epoch 012] New best val loss: 767.3792\n",
      "[2025-11-19 21:50:50,972] [UniVITrainer] [INFO] [Epoch 014] New best val loss: 767.3384\n",
      "2025-11-19 21:50:50 - INFO - [Epoch 014] New best val loss: 767.3384\n",
      "[2025-11-19 21:50:58,549] [UniVITrainer] [INFO] [Epoch 015] New best val loss: 767.3188\n",
      "2025-11-19 21:50:58 - INFO - [Epoch 015] New best val loss: 767.3188\n",
      "[2025-11-19 21:51:12,061] [UniVITrainer] [INFO] [Epoch 017] New best val loss: 767.3035\n",
      "2025-11-19 21:51:12 - INFO - [Epoch 017] New best val loss: 767.3035\n",
      "[2025-11-19 21:51:26,831] [UniVITrainer] [INFO] [Epoch 019] New best val loss: 767.2465\n",
      "2025-11-19 21:51:26 - INFO - [Epoch 019] New best val loss: 767.2465\n",
      "[2025-11-19 21:51:33,624] [UniVITrainer] [INFO] [Epoch 020] Train loss: 764.7346 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:51:33 - INFO - [Epoch 020] Train loss: 764.7346 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:51:34,433] [UniVITrainer] [INFO] [Epoch 020] Val loss: 767.1637 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:51:34 - INFO - [Epoch 020] Val loss: 767.1637 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:51:34,536] [UniVITrainer] [INFO] [Epoch 020] New best val loss: 767.1637\n",
      "2025-11-19 21:51:34 - INFO - [Epoch 020] New best val loss: 767.1637\n",
      "[2025-11-19 21:51:49,863] [UniVITrainer] [INFO] [Epoch 022] New best val loss: 767.0959\n",
      "2025-11-19 21:51:49 - INFO - [Epoch 022] New best val loss: 767.0959\n",
      "[2025-11-19 21:52:04,925] [UniVITrainer] [INFO] [Epoch 024] New best val loss: 767.0881\n",
      "2025-11-19 21:52:04 - INFO - [Epoch 024] New best val loss: 767.0881\n",
      "[2025-11-19 21:52:12,604] [UniVITrainer] [INFO] [Epoch 025] New best val loss: 767.0213\n",
      "2025-11-19 21:52:12 - INFO - [Epoch 025] New best val loss: 767.0213\n",
      "[2025-11-19 21:52:19,601] [UniVITrainer] [INFO] [Epoch 026] New best val loss: 766.9856\n",
      "2025-11-19 21:52:19 - INFO - [Epoch 026] New best val loss: 766.9856\n",
      "[2025-11-19 21:52:48,168] [UniVITrainer] [INFO] [Epoch 030] Train loss: 764.2964 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:52:48 - INFO - [Epoch 030] Train loss: 764.2964 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:52:48,987] [UniVITrainer] [INFO] [Epoch 030] Val loss: 766.9231 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:52:48 - INFO - [Epoch 030] Val loss: 766.9231 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:52:49,089] [UniVITrainer] [INFO] [Epoch 030] New best val loss: 766.9231\n",
      "2025-11-19 21:52:49 - INFO - [Epoch 030] New best val loss: 766.9231\n",
      "[2025-11-19 21:52:56,796] [UniVITrainer] [INFO] [Epoch 031] New best val loss: 766.8659\n",
      "2025-11-19 21:52:56 - INFO - [Epoch 031] New best val loss: 766.8659\n",
      "[2025-11-19 21:53:12,095] [UniVITrainer] [INFO] [Epoch 033] New best val loss: 766.8553\n",
      "2025-11-19 21:53:12 - INFO - [Epoch 033] New best val loss: 766.8553\n",
      "[2025-11-19 21:53:27,420] [UniVITrainer] [INFO] [Epoch 035] New best val loss: 766.8390\n",
      "2025-11-19 21:53:27 - INFO - [Epoch 035] New best val loss: 766.8390\n",
      "[2025-11-19 21:53:35,101] [UniVITrainer] [INFO] [Epoch 036] New best val loss: 766.8282\n",
      "2025-11-19 21:53:35 - INFO - [Epoch 036] New best val loss: 766.8282\n",
      "[2025-11-19 21:54:03,536] [UniVITrainer] [INFO] [Epoch 040] Train loss: 766.2821 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:54:03 - INFO - [Epoch 040] Train loss: 766.2821 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:54:04,356] [UniVITrainer] [INFO] [Epoch 040] Val loss: 766.7841 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:54:04 - INFO - [Epoch 040] Val loss: 766.7841 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:54:04,467] [UniVITrainer] [INFO] [Epoch 040] New best val loss: 766.7841\n",
      "2025-11-19 21:54:04 - INFO - [Epoch 040] New best val loss: 766.7841\n",
      "[2025-11-19 21:54:26,615] [UniVITrainer] [INFO] [Epoch 043] New best val loss: 766.7785\n",
      "2025-11-19 21:54:26 - INFO - [Epoch 043] New best val loss: 766.7785\n",
      "[2025-11-19 21:54:54,416] [UniVITrainer] [INFO] [Epoch 047] New best val loss: 766.6893\n",
      "2025-11-19 21:54:54 - INFO - [Epoch 047] New best val loss: 766.6893\n",
      "[2025-11-19 21:55:01,746] [UniVITrainer] [INFO] [Epoch 048] New best val loss: 766.6798\n",
      "2025-11-19 21:55:01 - INFO - [Epoch 048] New best val loss: 766.6798\n",
      "[2025-11-19 21:55:15,838] [UniVITrainer] [INFO] [Epoch 050] Train loss: 767.4165 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:55:15 - INFO - [Epoch 050] Train loss: 767.4165 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:55:16,654] [UniVITrainer] [INFO] [Epoch 050] Val loss: 766.6968 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:55:16 - INFO - [Epoch 050] Val loss: 766.6968 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:55:23,974] [UniVITrainer] [INFO] [Epoch 051] New best val loss: 766.6636\n",
      "2025-11-19 21:55:23 - INFO - [Epoch 051] New best val loss: 766.6636\n",
      "[2025-11-19 21:55:31,474] [UniVITrainer] [INFO] [Epoch 052] New best val loss: 766.6260\n",
      "2025-11-19 21:55:31 - INFO - [Epoch 052] New best val loss: 766.6260\n",
      "[2025-11-19 21:55:53,311] [UniVITrainer] [INFO] [Epoch 055] New best val loss: 766.5986\n",
      "2025-11-19 21:55:53 - INFO - [Epoch 055] New best val loss: 766.5986\n",
      "[2025-11-19 21:56:14,650] [UniVITrainer] [INFO] [Epoch 058] New best val loss: 766.5838\n",
      "2025-11-19 21:56:14 - INFO - [Epoch 058] New best val loss: 766.5838\n",
      "[2025-11-19 21:56:28,400] [UniVITrainer] [INFO] [Epoch 060] Train loss: 767.2171 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:56:28 - INFO - [Epoch 060] Train loss: 767.2171 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:56:29,212] [UniVITrainer] [INFO] [Epoch 060] Val loss: 766.6606 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:56:29 - INFO - [Epoch 060] Val loss: 766.6606 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:57:20,310] [UniVITrainer] [INFO] [Epoch 067] New best val loss: 766.5601\n",
      "2025-11-19 21:57:20 - INFO - [Epoch 067] New best val loss: 766.5601\n",
      "[2025-11-19 21:57:27,981] [UniVITrainer] [INFO] [Epoch 068] New best val loss: 766.5385\n",
      "2025-11-19 21:57:27 - INFO - [Epoch 068] New best val loss: 766.5385\n",
      "[2025-11-19 21:57:39,920] [UniVITrainer] [INFO] [Epoch 070] Train loss: 764.3335 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:57:39 - INFO - [Epoch 070] Train loss: 764.3335 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:57:40,732] [UniVITrainer] [INFO] [Epoch 070] Val loss: 766.5643 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:57:40 - INFO - [Epoch 070] Val loss: 766.5643 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:57:48,179] [UniVITrainer] [INFO] [Epoch 071] New best val loss: 766.5373\n",
      "2025-11-19 21:57:48 - INFO - [Epoch 071] New best val loss: 766.5373\n",
      "[2025-11-19 21:58:24,053] [UniVITrainer] [INFO] [Epoch 076] New best val loss: 766.5264\n",
      "2025-11-19 21:58:24 - INFO - [Epoch 076] New best val loss: 766.5264\n",
      "[2025-11-19 21:58:31,733] [UniVITrainer] [INFO] [Epoch 077] New best val loss: 766.5197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 21:58:31 - INFO - [Epoch 077] New best val loss: 766.5197\n",
      "[2025-11-19 21:58:53,502] [UniVITrainer] [INFO] [Epoch 080] Train loss: 767.9334 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:58:53 - INFO - [Epoch 080] Train loss: 767.9334 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:58:54,313] [UniVITrainer] [INFO] [Epoch 080] Val loss: 766.5602 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 21:58:54 - INFO - [Epoch 080] Val loss: 766.5602 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 21:59:01,973] [UniVITrainer] [INFO] [Epoch 081] New best val loss: 766.5141\n",
      "2025-11-19 21:59:01 - INFO - [Epoch 081] New best val loss: 766.5141\n",
      "[2025-11-19 21:59:16,139] [UniVITrainer] [INFO] [Epoch 083] New best val loss: 766.4804\n",
      "2025-11-19 21:59:16 - INFO - [Epoch 083] New best val loss: 766.4804\n",
      "[2025-11-19 21:59:38,931] [UniVITrainer] [INFO] [Epoch 086] New best val loss: 766.4589\n",
      "2025-11-19 21:59:38 - INFO - [Epoch 086] New best val loss: 766.4589\n",
      "[2025-11-19 22:00:08,377] [UniVITrainer] [INFO] [Epoch 090] Train loss: 770.7166 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:00:08 - INFO - [Epoch 090] Train loss: 770.7166 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:00:09,194] [UniVITrainer] [INFO] [Epoch 090] Val loss: 766.4942 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:00:09 - INFO - [Epoch 090] Val loss: 766.4942 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:00:38,801] [UniVITrainer] [INFO] [Epoch 094] New best val loss: 766.4546\n",
      "2025-11-19 22:00:38 - INFO - [Epoch 094] New best val loss: 766.4546\n",
      "[2025-11-19 22:01:01,567] [UniVITrainer] [INFO] [Epoch 097] New best val loss: 766.4330\n",
      "2025-11-19 22:01:01 - INFO - [Epoch 097] New best val loss: 766.4330\n",
      "[2025-11-19 22:01:16,638] [UniVITrainer] [INFO] [Epoch 099] New best val loss: 766.4268\n",
      "2025-11-19 22:01:16 - INFO - [Epoch 099] New best val loss: 766.4268\n",
      "[2025-11-19 22:01:23,392] [UniVITrainer] [INFO] [Epoch 100] Train loss: 768.3955 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:01:23 - INFO - [Epoch 100] Train loss: 768.3955 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:01:24,209] [UniVITrainer] [INFO] [Epoch 100] Val loss: 766.4343 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:01:24 - INFO - [Epoch 100] Val loss: 766.4343 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:02:31,778] [UniVITrainer] [INFO] [Epoch 110] Train loss: 766.2043 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:02:31 - INFO - [Epoch 110] Train loss: 766.2043 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:02:32,586] [UniVITrainer] [INFO] [Epoch 110] Val loss: 766.4165 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:02:32 - INFO - [Epoch 110] Val loss: 766.4165 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:02:32,664] [UniVITrainer] [INFO] [Epoch 110] New best val loss: 766.4165\n",
      "2025-11-19 22:02:32 - INFO - [Epoch 110] New best val loss: 766.4165\n",
      "[2025-11-19 22:02:40,197] [UniVITrainer] [INFO] [Epoch 111] New best val loss: 766.3888\n",
      "2025-11-19 22:02:40 - INFO - [Epoch 111] New best val loss: 766.3888\n",
      "[2025-11-19 22:03:43,724] [UniVITrainer] [INFO] [Epoch 120] Train loss: 764.0600 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:03:43 - INFO - [Epoch 120] Train loss: 764.0600 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:03:44,519] [UniVITrainer] [INFO] [Epoch 120] Val loss: 766.3959 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:03:44 - INFO - [Epoch 120] Val loss: 766.3959 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:04:05,180] [UniVITrainer] [INFO] [Epoch 123] New best val loss: 766.3882\n",
      "2025-11-19 22:04:05 - INFO - [Epoch 123] New best val loss: 766.3882\n",
      "[2025-11-19 22:04:54,729] [UniVITrainer] [INFO] [Epoch 130] Train loss: 768.2448 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:04:54 - INFO - [Epoch 130] Train loss: 768.2448 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:04:55,378] [UniVITrainer] [INFO] [Epoch 130] Val loss: 766.4612 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:04:55 - INFO - [Epoch 130] Val loss: 766.4612 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:05:09,646] [UniVITrainer] [INFO] [Epoch 132] New best val loss: 766.3656\n",
      "2025-11-19 22:05:09 - INFO - [Epoch 132] New best val loss: 766.3656\n",
      "[2025-11-19 22:06:06,232] [UniVITrainer] [INFO] [Epoch 140] Train loss: 768.1588 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:06:06 - INFO - [Epoch 140] Train loss: 768.1588 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:06:07,037] [UniVITrainer] [INFO] [Epoch 140] Val loss: 766.4064 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:06:07 - INFO - [Epoch 140] Val loss: 766.4064 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:07:18,390] [UniVITrainer] [INFO] [Epoch 150] Train loss: 763.9716 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:07:18 - INFO - [Epoch 150] Train loss: 763.9716 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:07:19,202] [UniVITrainer] [INFO] [Epoch 150] Val loss: 766.4248 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:07:19 - INFO - [Epoch 150] Val loss: 766.4248 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:07:49,380] [UniVITrainer] [INFO] [Epoch 154] New best val loss: 766.3622\n",
      "2025-11-19 22:07:49 - INFO - [Epoch 154] New best val loss: 766.3622\n",
      "[2025-11-19 22:08:03,976] [UniVITrainer] [INFO] [Epoch 156] New best val loss: 766.3464\n",
      "2025-11-19 22:08:03 - INFO - [Epoch 156] New best val loss: 766.3464\n",
      "[2025-11-19 22:08:29,719] [UniVITrainer] [INFO] [Epoch 160] Train loss: 765.1613 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:08:29 - INFO - [Epoch 160] Train loss: 765.1613 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:08:30,562] [UniVITrainer] [INFO] [Epoch 160] Val loss: 766.3716 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:08:30 - INFO - [Epoch 160] Val loss: 766.3716 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:09:39,876] [UniVITrainer] [INFO] [Epoch 170] Train loss: 770.2865 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:09:39 - INFO - [Epoch 170] Train loss: 770.2865 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:09:40,722] [UniVITrainer] [INFO] [Epoch 170] Val loss: 766.3924 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:09:40 - INFO - [Epoch 170] Val loss: 766.3924 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:09:52,152] [UniVITrainer] [INFO] [Epoch 172] New best val loss: 766.3362\n",
      "2025-11-19 22:09:52 - INFO - [Epoch 172] New best val loss: 766.3362\n",
      "[2025-11-19 22:10:45,327] [UniVITrainer] [INFO] [Epoch 180] Train loss: 767.9299 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:10:45 - INFO - [Epoch 180] Train loss: 767.9299 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:10:45,972] [UniVITrainer] [INFO] [Epoch 180] Val loss: 766.4152 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:10:45 - INFO - [Epoch 180] Val loss: 766.4152 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:11:58,378] [UniVITrainer] [INFO] [Epoch 190] Train loss: 766.6280 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:11:58 - INFO - [Epoch 190] Train loss: 766.6280 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:11:59,180] [UniVITrainer] [INFO] [Epoch 190] Val loss: 766.3586 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:11:59 - INFO - [Epoch 190] Val loss: 766.3586 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:12:06,991] [UniVITrainer] [INFO] [Epoch 191] New best val loss: 766.3072\n",
      "2025-11-19 22:12:06 - INFO - [Epoch 191] New best val loss: 766.3072\n",
      "[2025-11-19 22:13:07,996] [UniVITrainer] [INFO] [Epoch 199] New best val loss: 766.2976\n",
      "2025-11-19 22:13:07 - INFO - [Epoch 199] New best val loss: 766.2976\n",
      "[2025-11-19 22:13:14,076] [UniVITrainer] [INFO] [Epoch 200] Train loss: 766.2951 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:13:14 - INFO - [Epoch 200] Train loss: 766.2951 (beta=40.000, gamma=60.000)\n",
      "[2025-11-19 22:13:14,887] [UniVITrainer] [INFO] [Epoch 200] Val loss: 766.3576 (beta=40.000, gamma=60.000)\n",
      "2025-11-19 22:13:14 - INFO - [Epoch 200] Val loss: 766.3576 (beta=40.000, gamma=60.000)\n"
     ]
    }
   ],
   "source": [
    "# ---------- train ----------\n",
    "history = trainer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Quick training curves\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(history[\"train_loss\"], label=\"train\")\n",
    "ax.plot(history[\"val_loss\"], label=\"val\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"UniVI Multiome training curves\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(history[\"beta\"], label=\"beta\")\n",
    "ax.plot(history[\"gamma\"], label=\"gamma\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Weight\")\n",
    "ax.set_title(\"KL / alignment annealing\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ffc3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "import torch\n",
    "\n",
    "os.makedirs(\"../saved_models\", exist_ok=True)\n",
    "\n",
    "# trainer.model already has the best weights (because we restored best_state_dict)\n",
    "ckpt_path = \"../saved_models/univi_tea_seq_beta_40_gamma_60_32_latent_dims.pt\"\n",
    "torch.save(\n",
    "    {\n",
    "        \"state_dict\": trainer.model.state_dict(),\n",
    "        \"univi_cfg\": asdict(univi_cfg),\n",
    "        \"best_epoch\": trainer.best_epoch,\n",
    "        \"best_val_loss\": trainer.best_val_loss,\n",
    "    },\n",
    "    ckpt_path,\n",
    ")\n",
    "print(\"Saved best model to:\", ckpt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bca0ca",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ccf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from univi.config import UniVIConfig, ModalityConfig\n",
    "from univi.models.univi import UniVIMultiModalVAE\n",
    "\n",
    "device = \"cpu\"  # or \"cuda\" if available\n",
    "\n",
    "ckpt = torch.load(\n",
    "    \"../saved_models/univi_tea_seq_beta_40_gamma_60_32_latent_dims.pt\",\n",
    "    map_location=device,\n",
    ")\n",
    "\n",
    "# ---- Rebuild UniVIConfig, making sure modalities are ModalityConfig objects ----\n",
    "cfg_dict = ckpt[\"univi_cfg\"]\n",
    "\n",
    "# If this is an OmegaConf object or similar, make sure it's a plain dict\n",
    "try:\n",
    "    from omegaconf import DictConfig, OmegaConf\n",
    "    if isinstance(cfg_dict, DictConfig):\n",
    "        cfg_dict = OmegaConf.to_container(cfg_dict, resolve=True)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Now rehydrate each modality\n",
    "modalities = [ModalityConfig(**m) for m in cfg_dict[\"modalities\"]]\n",
    "cfg_dict = {**cfg_dict, \"modalities\": modalities}\n",
    "\n",
    "univi_cfg_loaded = UniVIConfig(**cfg_dict)\n",
    "\n",
    "# ---- Rebuild model + load weights ----\n",
    "model_loaded = UniVIMultiModalVAE(univi_cfg_loaded).to(device)\n",
    "model_loaded.load_state_dict(ckpt[\"state_dict\"])\n",
    "\n",
    "print(\"Best epoch was:\", ckpt.get(\"best_epoch\"), \"val loss =\", ckpt.get(\"best_val_loss\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11047dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_rna  = trainer.encode_modality(rna,  modality=\"rna\")\n",
    "z_adt  = trainer.encode_modality(adt,  modality=\"adt\")\n",
    "z_atac = trainer.encode_modality(atac, modality=\"atac\")\n",
    "\n",
    "rna.obsm[\"X_univi\"]  = z_rna\n",
    "adt.obsm[\"X_univi\"]  = z_adt\n",
    "atac.obsm[\"X_univi\"] = z_atac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52de1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should be the *same* cells across modalities\n",
    "assert np.array_equal(rna.obs_names, adt.obs_names)\n",
    "assert np.array_equal(rna.obs_names, atac.obs_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Build train / val / test adatas\n",
    "# ------------------------------\n",
    "\n",
    "rna_train_adata  = rna[train_idx].copy()\n",
    "rna_val_adata    = rna[val_idx].copy()\n",
    "rna_test_adata   = rna[test_idx].copy()\n",
    "\n",
    "adt_train_adata  = adt[train_idx].copy()\n",
    "adt_val_adata    = adt[val_idx].copy()\n",
    "adt_test_adata   = adt[test_idx].copy()\n",
    "\n",
    "atac_train_adata = atac[train_idx].copy()\n",
    "atac_val_adata   = atac[val_idx].copy()\n",
    "atac_test_adata  = atac[test_idx].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rna_test_adata)\n",
    "print(adt_test_adata)\n",
    "print(atac_test_adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0d78c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# UniVI TEA-seq evaluation (RNA / ADT / ATAC) – label-free, tri-modal\n",
    "# ============================\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from univi import evaluation as univi_eval\n",
    "from univi import plotting as univi_plot  # not strictly needed, but left for convenience\n",
    "\n",
    "# -----------------------------------------\n",
    "# CONFIG\n",
    "# -----------------------------------------\n",
    "FIGDIR = \"../figures/teaseq_univi_tri_modal_eval\"\n",
    "os.makedirs(FIGDIR, exist_ok=True)\n",
    "\n",
    "device = train_cfg.device  # e.g. \"cuda\" or \"cpu\"\n",
    "\n",
    "# -----------------------------------------\n",
    "# 0. Sanity checks\n",
    "# -----------------------------------------\n",
    "assert (\n",
    "    rna_test_adata.n_obs == adt_test_adata.n_obs == atac_test_adata.n_obs\n",
    "), \"RNA / ADT / ATAC TEST sets must have same #cells\"\n",
    "assert np.array_equal(rna_test_adata.obs_names, adt_test_adata.obs_names), (\n",
    "    \"RNA and ADT obs_names must match 1:1 for pairwise metrics.\"\n",
    ")\n",
    "assert np.array_equal(rna_test_adata.obs_names, atac_test_adata.obs_names), (\n",
    "    \"RNA and ATAC obs_names must match 1:1 for pairwise metrics.\"\n",
    ")\n",
    "\n",
    "print(f\"Test cells: {rna_test_adata.n_obs}\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1. Encode latent embeddings for test sets\n",
    "# -----------------------------------------\n",
    "print(\"\\nEncoding test sets into UniVI latent space...\")\n",
    "\n",
    "z_rna  = univi_eval.encode_adata(model, rna_test_adata,  modality=\"rna\",  device=device)\n",
    "z_adt  = univi_eval.encode_adata(model, adt_test_adata,  modality=\"adt\",  device=device)\n",
    "z_atac = univi_eval.encode_adata(model, atac_test_adata, modality=\"atac\", device=device)\n",
    "\n",
    "rna_test_adata.obsm[\"X_univi\"]  = z_rna\n",
    "adt_test_adata.obsm[\"X_univi\"]  = z_adt\n",
    "atac_test_adata.obsm[\"X_univi\"] = z_atac\n",
    "\n",
    "print(\"Latent shapes (test):\")\n",
    "print(\"  RNA :\", z_rna.shape)\n",
    "print(\"  ADT :\", z_adt.shape)\n",
    "print(\"  ATAC:\", z_atac.shape)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2. FOSCTTM (pairwise alignment)\n",
    "# -----------------------------------------\n",
    "print(\"\\nComputing FOSCTTM for each modality pair (lower = better)...\")\n",
    "fos_rna_adt  = univi_eval.compute_foscttm(z_rna,  z_adt)\n",
    "fos_rna_atac = univi_eval.compute_foscttm(z_rna,  z_atac)\n",
    "fos_adt_atac = univi_eval.compute_foscttm(z_adt,  z_atac)\n",
    "\n",
    "print(f\"  RNA  vs ADT : {fos_rna_adt:.4f}\")\n",
    "print(f\"  RNA  vs ATAC: {fos_rna_atac:.4f}\")\n",
    "print(f\"  ADT  vs ATAC: {fos_adt_atac:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "pairs = [\"RNA–ADT\", \"RNA–ATAC\", \"ADT–ATAC\"]\n",
    "vals = [fos_rna_adt, fos_rna_atac, fos_adt_atac]\n",
    "sns.barplot(x=pairs, y=vals)\n",
    "plt.ylabel(\"FOSCTTM (mean)\")\n",
    "plt.title(\"Tri-modal FOSCTTM (lower = better)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"foscttm_barplot.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3. Modality mixing (all three modalities)\n",
    "# -----------------------------------------\n",
    "Z_joint = np.concatenate([z_rna, z_adt, z_atac], axis=0)\n",
    "modality_labels = np.array(\n",
    "    [\"rna\"]  * z_rna.shape[0]\n",
    "    + [\"adt\"]  * z_adt.shape[0]\n",
    "    + [\"atac\"] * z_atac.shape[0]\n",
    ")\n",
    "\n",
    "mixing_score = univi_eval.compute_modality_mixing(\n",
    "    Z_joint,\n",
    "    modality_labels,\n",
    "    k=20,\n",
    ")\n",
    "print(f\"\\nGlobal modality mixing score (RNA/ADT/ATAC, k=20): {mixing_score:.3f}\")\n",
    "\n",
    "# kNN modality composition heatmap\n",
    "print(\"Computing kNN modality composition...\")\n",
    "k = 20\n",
    "nn = NearestNeighbors(n_neighbors=k + 1)\n",
    "nn.fit(Z_joint)\n",
    "_, idx = nn.kneighbors(Z_joint)\n",
    "\n",
    "idx_neighbors = idx[:, 1:]  # drop self\n",
    "neighbor_mods = modality_labels[idx_neighbors]\n",
    "\n",
    "modalities = np.array([\"rna\", \"adt\", \"atac\"])\n",
    "comp_matrix = np.zeros((len(modalities), len(modalities)))  # row = center, col = neighbor\n",
    "\n",
    "for i, m_center in enumerate(modalities):\n",
    "    mask_center = modality_labels == m_center\n",
    "    neigh_for_center = neighbor_mods[mask_center].reshape(-1)\n",
    "    for j, m_neigh in enumerate(modalities):\n",
    "        comp_matrix[i, j] = (neigh_for_center == m_neigh).mean()\n",
    "\n",
    "same_mod_frac = (neighbor_mods == modality_labels[:, None]).mean()\n",
    "print(f\"  Fraction of neighbors with same modality (k={k}): {same_mod_frac:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(\n",
    "    comp_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    xticklabels=modalities,\n",
    "    yticklabels=modalities,\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "plt.xlabel(\"Neighbor modality\")\n",
    "plt.ylabel(\"Center modality\")\n",
    "plt.title(f\"kNN modality composition (k={k})\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"knn_modality_composition.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4. UMAP on UniVI latent (tri-modal)\n",
    "# -----------------------------------------\n",
    "print(\"\\nBuilding tri-modal UMAP on UniVI latent...\")\n",
    "\n",
    "# Tag each test set with modality\n",
    "rna_tmp  = rna_test_adata.copy()\n",
    "adt_tmp  = adt_test_adata.copy()\n",
    "atac_tmp = atac_test_adata.copy()\n",
    "\n",
    "rna_tmp.obs[\"univi_source\"]  = \"rna\"\n",
    "adt_tmp.obs[\"univi_source\"]  = \"adt\"\n",
    "atac_tmp.obs[\"univi_source\"] = \"atac\"\n",
    "\n",
    "combined = rna_tmp.concatenate(\n",
    "    adt_tmp,\n",
    "    atac_tmp,\n",
    "    join=\"outer\",\n",
    "    batch_key=\"univi_batch\",\n",
    "    batch_categories=[\"rna\", \"adt\", \"atac\"],\n",
    "    index_unique=None,\n",
    ")\n",
    "\n",
    "# ensure latent is correctly stacked\n",
    "combined.obsm[\"X_univi\"] = np.vstack([\n",
    "    rna_test_adata.obsm[\"X_univi\"],\n",
    "    adt_test_adata.obsm[\"X_univi\"],\n",
    "    atac_test_adata.obsm[\"X_univi\"],\n",
    "])\n",
    "\n",
    "# neighbors / UMAP / Leiden\n",
    "sc.pp.neighbors(combined, use_rep=\"X_univi\", n_neighbors=20)\n",
    "sc.tl.umap(combined)\n",
    "sc.tl.leiden(combined, key_added=\"univi_leiden\", resolution=0.5)\n",
    "\n",
    "# UMAP colored by modality\n",
    "sc.pl.umap(\n",
    "    combined,\n",
    "    color=\"univi_source\",\n",
    "    size=8,\n",
    "    alpha=0.7,\n",
    "    show=False,\n",
    ")\n",
    "plt.savefig(os.path.join(FIGDIR, \"umap_tri_modal_modality.png\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# UMAP colored by Leiden clusters (pseudo-clusters)\n",
    "sc.pl.umap(\n",
    "    combined,\n",
    "    color=\"univi_leiden\",\n",
    "    size=8,\n",
    "    alpha=0.7,\n",
    "    show=False,\n",
    ")\n",
    "plt.savefig(os.path.join(FIGDIR, \"umap_tri_modal_leiden.png\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Per-modality UMAPs, colored by Leiden\n",
    "for mod in [\"rna\", \"adt\", \"atac\"]:\n",
    "    sub = combined[combined.obs[\"univi_source\"] == mod].copy()\n",
    "    sc.pl.umap(\n",
    "        sub,\n",
    "        color=\"univi_leiden\",\n",
    "        size=8,\n",
    "        alpha=0.7,\n",
    "        show=False,\n",
    "    )\n",
    "    plt.savefig(\n",
    "        os.path.join(FIGDIR, f\"umap_{mod}_only_leiden.png\"),\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------------------------\n",
    "# 5. Latent geometry diagnostics\n",
    "# -----------------------------------------\n",
    "print(\"\\nLatent geometry diagnostics...\")\n",
    "\n",
    "def latent_norms(z, label):\n",
    "    norms = np.linalg.norm(z, axis=1)\n",
    "    return norms, np.repeat(label, len(norms))\n",
    "\n",
    "norm_rna,  lab_rna  = latent_norms(z_rna,  \"RNA\")\n",
    "norm_adt,  lab_adt  = latent_norms(z_adt,  \"ADT\")\n",
    "norm_atac, lab_atac = latent_norms(z_atac, \"ATAC\")\n",
    "\n",
    "norms_all = np.concatenate([norm_rna, norm_adt, norm_atac])\n",
    "labs_all  = np.concatenate([lab_rna, lab_adt, lab_atac])\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.violinplot(x=labs_all, y=norms_all, inner=\"box\")\n",
    "plt.ylabel(\"‖z‖ (L2 norm)\")\n",
    "plt.xlabel(\"Modality\")\n",
    "plt.title(\"Latent L2-norm distribution by modality\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"latent_norms_by_modality.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Latent correlation heatmap of RNA latent dims\n",
    "corr_latent = np.corrcoef(z_rna, rowvar=False)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(corr_latent, cmap=\"vlag\", center=0)\n",
    "plt.title(\"RNA latent dimension correlation (test set)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"latent_corr_heatmap_rna.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Silhouette score on modality (lower = better mixing)\n",
    "if len(np.unique(modality_labels)) > 1:\n",
    "    sil_mod = silhouette_score(Z_joint, modality_labels)\n",
    "else:\n",
    "    sil_mod = np.nan\n",
    "print(f\"Silhouette (modality) on UniVI latent: {sil_mod:.3f}\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 6. Local modality entropy (kNN) + UMAP\n",
    "# -----------------------------------------\n",
    "print(\"\\nComputing local modality entropy...\")\n",
    "\n",
    "n_neighbors_local = 20\n",
    "nn_local = NearestNeighbors(n_neighbors=n_neighbors_local, metric=\"euclidean\")\n",
    "nn_local.fit(Z_joint)\n",
    "_, idx_local = nn_local.kneighbors(Z_joint)\n",
    "\n",
    "mods = modality_labels\n",
    "local_modality_entropy = []\n",
    "\n",
    "for i in range(Z_joint.shape[0]):\n",
    "    neigh = idx_local[i, 1:]  # drop self\n",
    "    neigh_mod = mods[neigh]\n",
    "\n",
    "    # empirical distribution over modalities\n",
    "    ent = 0.0\n",
    "    for m in modalities:\n",
    "        p = (neigh_mod == m).mean()\n",
    "        if p > 0:\n",
    "            ent -= p * np.log2(p)\n",
    "    local_modality_entropy.append(ent)\n",
    "\n",
    "local_modality_entropy = np.asarray(local_modality_entropy)\n",
    "combined.obs[\"local_modality_entropy\"] = local_modality_entropy\n",
    "\n",
    "print(f\"Mean local modality entropy (k={n_neighbors_local}): {local_modality_entropy.mean():.3f}\")\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(local_modality_entropy, bins=30)\n",
    "plt.xlabel(\"Local modality entropy (bits)\")\n",
    "plt.ylabel(\"Cells\")\n",
    "plt.title(\"kNN modality entropy\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"local_modality_entropy_hist.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# UMAP colored by local modality entropy\n",
    "sc.pl.umap(\n",
    "    combined,\n",
    "    color=\"local_modality_entropy\",\n",
    "    size=8,\n",
    "    alpha=0.7,\n",
    "    show=False,\n",
    ")\n",
    "plt.savefig(os.path.join(FIGDIR, \"umap_local_modality_entropy.png\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# -----------------------------------------\n",
    "# 7. Pairwise matching metrics (top-k) for all modality pairs\n",
    "# -----------------------------------------\n",
    "print(\"\\nPairwise matching metrics (top-1 / top-5 / top-10)...\")\n",
    "\n",
    "def topk_matching(z_src, z_tgt, pair_name: str, k_match: int = 10):\n",
    "    nn = NearestNeighbors(n_neighbors=k_match, metric=\"euclidean\")\n",
    "    nn.fit(z_tgt)\n",
    "    _, idx_knn = nn.kneighbors(z_src)\n",
    "\n",
    "    true_idx = np.arange(z_src.shape[0])\n",
    "    top1_hits  = (idx_knn[:, 0] == true_idx)\n",
    "    top5_hits  = (idx_knn[:, :5] == true_idx[:, None]).any(axis=1)\n",
    "    top10_hits = (idx_knn[:, :10] == true_idx[:, None]).any(axis=1)\n",
    "\n",
    "    print(f\"  {pair_name}:\")\n",
    "    print(f\"    Top-1 accuracy:  {top1_hits.mean():.3f}\")\n",
    "    print(f\"    Top-5 accuracy:  {top5_hits.mean():.3f}\")\n",
    "    print(f\"    Top-10 accuracy: {top10_hits.mean():.3f}\")\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.bar(\n",
    "        [\"Top-1\", \"Top-5\", \"Top-10\"],\n",
    "        [top1_hits.mean(), top5_hits.mean(), top10_hits.mean()],\n",
    "    )\n",
    "    plt.ylabel(\"Fraction of correctly matched pairs\")\n",
    "    plt.title(f\"Cross-modal matching accuracy ({pair_name})\")\n",
    "    plt.tight_layout()\n",
    "    fname = f\"matching_{pair_name.replace(' ', '_').replace('→','to')}.png\"\n",
    "    plt.savefig(os.path.join(FIGDIR, fname))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "topk_matching(z_rna,  z_adt,  \"RNA→ADT\")\n",
    "topk_matching(z_adt,  z_rna,  \"ADT→RNA\")\n",
    "topk_matching(z_rna,  z_atac, \"RNA→ATAC\")\n",
    "topk_matching(z_atac, z_rna,  \"ATAC→RNA\")\n",
    "topk_matching(z_adt,  z_atac, \"ADT→ATAC\")\n",
    "topk_matching(z_atac, z_adt,  \"ATAC→ADT\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 8. Cross-modal reconstruction metrics\n",
    "# -----------------------------------------\n",
    "def _to_dense(X):\n",
    "    return X.toarray() if sp.issparse(X) else np.asarray(X)\n",
    "\n",
    "def cross_modal_metrics(\n",
    "    model,\n",
    "    src_adata,\n",
    "    tgt_adata,\n",
    "    src_mod: str,\n",
    "    tgt_mod: str,\n",
    "    name_prefix: str,\n",
    "    device: str,\n",
    "):\n",
    "    Xhat_tgt = univi_eval.cross_modal_predict(\n",
    "        model,\n",
    "        adata_src=src_adata,\n",
    "        src_mod=src_mod,\n",
    "        tgt_mod=tgt_mod,\n",
    "        device=device,\n",
    "        batch_size=512,\n",
    "    )\n",
    "\n",
    "    X_tgt = _to_dense(tgt_adata.X)\n",
    "\n",
    "    mse_feat  = univi_eval.mse_per_feature(X_tgt, Xhat_tgt)\n",
    "    corr_feat = univi_eval.pearson_corr_per_feature(X_tgt, Xhat_tgt)\n",
    "\n",
    "    print(f\"\\nCross-modal reconstruction: {src_mod} → {tgt_mod}\")\n",
    "    print(f\"  Mean feature MSE: {mse_feat.mean():.4f}\")\n",
    "    print(f\"  Mean feature Pearson r: {corr_feat.mean():.3f}\")\n",
    "\n",
    "    # Histogram of per-feature correlation\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.histplot(corr_feat, bins=40, kde=False)\n",
    "    plt.xlabel(\"Per-feature Pearson r\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"{src_mod} → {tgt_mod}: feature-wise correlation\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGDIR, f\"{name_prefix}_corr_hist.png\"))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Histogram of per-feature MSE\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.histplot(mse_feat, bins=40, kde=False)\n",
    "    plt.xlabel(\"Per-feature MSE\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"{src_mod} → {tgt_mod}: feature-wise MSE\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGDIR, f\"{name_prefix}_mse_hist.png\"))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return mse_feat, corr_feat\n",
    "\n",
    "# Evaluate key directions on TEST set\n",
    "_ = cross_modal_metrics(model, rna_test_adata, adt_test_adata,\n",
    "                        src_mod=\"rna\", tgt_mod=\"adt\",\n",
    "                        name_prefix=\"RNA_to_ADT_test\", device=device)\n",
    "\n",
    "_ = cross_modal_metrics(model, rna_test_adata, atac_test_adata,\n",
    "                        src_mod=\"rna\", tgt_mod=\"atac\",\n",
    "                        name_prefix=\"RNA_to_ATAC_test\", device=device)\n",
    "\n",
    "_ = cross_modal_metrics(model, adt_test_adata, rna_test_adata,\n",
    "                        src_mod=\"adt\", tgt_mod=\"rna\",\n",
    "                        name_prefix=\"ADT_to_RNA_test\", device=device)\n",
    "\n",
    "_ = cross_modal_metrics(model, atac_test_adata, rna_test_adata,\n",
    "                        src_mod=\"atac\", tgt_mod=\"rna\",\n",
    "                        name_prefix=\"ATAC_to_RNA_test\", device=device)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 9. Denoising with decoders (on \"unused\" cells)\n",
    "# -----------------------------------------\n",
    "print(\"\\nDenoising on *_unused sets (if present)...\")\n",
    "\n",
    "for adata, mod, tag in [\n",
    "    (locals().get(\"rna_unused\",  None), \"rna\",  \"rna_unused\"),\n",
    "    (locals().get(\"adt_unused\",  None), \"adt\",  \"adt_unused\"),\n",
    "    (locals().get(\"atac_unused\", None), \"atac\", \"atac_unused\"),\n",
    "]:\n",
    "    if adata is None or adata.n_obs == 0:\n",
    "        print(f\"  Skipping {tag} ({mod}) – no cells.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  Denoising {tag} ({mod})...\")\n",
    "    univi_eval.denoise_adata(\n",
    "        model, adata, modality=mod,\n",
    "        device=device, batch_size=512,\n",
    "        out_layer=\"univi_denoised\",\n",
    "    )\n",
    "    X_raw = _to_dense(adata.X)\n",
    "    X_den = _to_dense(adata.layers[\"univi_denoised\"])\n",
    "    per_cell_mse = ((X_raw - X_den) ** 2).mean(axis=1)\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.histplot(per_cell_mse, bins=40)\n",
    "    plt.xlabel(\"Per-cell MSE (raw vs denoised)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Denoising quality: {tag} ({mod})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGDIR, f\"denoise_{tag}_{mod}.png\"))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nNo curated celltypes; all metrics are label-free (modality-based only).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 10. Summarize TEA-seq metrics & save as JSON\n",
    "# ============================\n",
    "import json\n",
    "\n",
    "teaseq_metrics = {\n",
    "    # Pairwise FOSCTTM\n",
    "    \"foscttm_rna_adt\": float(fos_rna_adt),\n",
    "    \"foscttm_rna_atac\": float(fos_rna_atac),\n",
    "    \"foscttm_adt_atac\": float(fos_adt_atac),\n",
    "\n",
    "    # Global mixing\n",
    "    \"modality_mixing_k20\": float(mixing_score),\n",
    "    \"same_modality_neighbor_frac_k20\": float(same_mod_frac),\n",
    "\n",
    "    # Latent geometry\n",
    "    \"silhouette_modality\": float(sil_mod) if not np.isnan(sil_mod) else None,\n",
    "    \"mean_local_modality_entropy_k20\": float(local_modality_entropy.mean()),\n",
    "    \"median_local_modality_entropy_k20\": float(np.median(local_modality_entropy)),\n",
    "\n",
    "    # Dataset sizes\n",
    "    \"n_cells_test\": int(rna_test_adata.n_obs),\n",
    "    \"n_genes_rna\": int(rna_test_adata.n_vars),\n",
    "    \"n_features_adt\": int(adt_test_adata.n_vars),\n",
    "    \"n_features_atac\": int(atac_test_adata.n_vars),\n",
    "}\n",
    "\n",
    "'''\n",
    "metrics_path = os.path.join(FIGDIR, \"teaseq_univi_metrics.json\")\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(teaseq_metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\n[TEA-seq] Saved benchmark metrics to: {metrics_path}\")\n",
    "'''\n",
    "\n",
    "# ============================\n",
    "# 11. kNN distance diagnostics: same vs cross-modality neighbors\n",
    "# ============================\n",
    "print(\"\\nComputing kNN distance distributions (same vs cross-modality)...\")\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "k_dist = 20\n",
    "nn_dist = NearestNeighbors(n_neighbors=k_dist + 1, metric=\"euclidean\")\n",
    "dists_all, idx_all = nn_dist.kneighbors(Z_joint)\n",
    "\n",
    "# drop self\n",
    "dists_neighbors = dists_all[:, 1:]              # (n_cells, k_dist)\n",
    "idx_neighbors_dist = idx_all[:, 1:]             # already had neighbor_mods from earlier\n",
    "flat_dists = dists_neighbors.reshape(-1)\n",
    "\n",
    "# Center & neighbor modalities (flattened to per-edge view)\n",
    "center_mods_flat = np.repeat(modality_labels, k_dist)\n",
    "neighbor_mods_flat = neighbor_mods.reshape(-1)\n",
    "\n",
    "same_mod_edge = neighbor_mods_flat == center_mods_flat\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.kdeplot(flat_dists[same_mod_edge], label=\"same modality\", fill=True, alpha=0.6)\n",
    "sns.kdeplot(flat_dists[~same_mod_edge], label=\"different modality\", fill=True, alpha=0.6)\n",
    "plt.xlabel(\"Euclidean distance in UniVI latent\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(f\"kNN distance distribution (k={k_dist})\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"knn_distance_same_vs_cross_modality.png\"), dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 12. Cross-modal neighbor fraction per cell (and UMAP)\n",
    "# ============================\n",
    "print(\"\\nComputing per-cell cross-modal neighbor fraction...\")\n",
    "\n",
    "# fraction of neighbors NOT sharing the cell's modality\n",
    "cross_mod_neighbor_frac = 1.0 - (neighbor_mods == modality_labels[:, None]).mean(axis=1)\n",
    "combined.obs[\"cross_mod_neighbor_frac\"] = cross_mod_neighbor_frac\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.histplot(cross_mod_neighbor_frac, bins=30)\n",
    "plt.xlabel(\"Fraction of neighbors with different modality\")\n",
    "plt.ylabel(\"Cells\")\n",
    "plt.title(f\"Cross-modal neighbor fraction (k={k})\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGDIR, \"cross_mod_neighbor_fraction_hist.png\"), dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# UMAP colored by cross-modal neighbor fraction\n",
    "sc.pl.umap(\n",
    "    combined,\n",
    "    color=\"cross_mod_neighbor_frac\",\n",
    "    size=8,\n",
    "    alpha=0.7,\n",
    "    cmap=\"viridis\",\n",
    "    show=False,\n",
    ")\n",
    "plt.title(\"UMAP – cross-modal neighbor fraction\")\n",
    "plt.savefig(os.path.join(FIGDIR, \"umap_cross_mod_neighbor_fraction.png\"),\n",
    "            bbox_inches=\"tight\", dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 13. Per-cluster modality composition (Leiden clusters)\n",
    "# ============================\n",
    "print(\"\\nComputing modality composition per Leiden cluster...\")\n",
    "\n",
    "if \"univi_leiden\" in combined.obs.columns:\n",
    "    comp_ct = pd.crosstab(combined.obs[\"univi_leiden\"], combined.obs[\"univi_source\"])\n",
    "    comp_prop = comp_ct.div(comp_ct.sum(axis=1), axis=0)  # row-normalize\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    comp_prop.sort_index().plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        width=0.9,\n",
    "        colormap=\"tab10\",\n",
    "    )\n",
    "    plt.xlabel(\"UniVI Leiden cluster\")\n",
    "    plt.ylabel(\"Fraction of cells\")\n",
    "    plt.title(\"Modality composition per UniVI Leiden cluster\")\n",
    "    plt.legend(title=\"Modality\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGDIR, \"cluster_modality_composition_stacked_bar.png\"),\n",
    "                dpi=200)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"  WARNING: 'univi_leiden' not found in combined.obs; skipping cluster composition plot.\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 14. Feature-level cross-modal scatter plots (RNA → ADT / ATAC)\n",
    "# ============================\n",
    "print(\"\\nFeature-level scatter plots for cross-modal prediction (RNA→ADT / RNA→ATAC)...\")\n",
    "\n",
    "# Example: RNA → ADT for a small subset of cells & selected markers\n",
    "# (adjust marker names to what you actually have in adt_test_adata.var_names)\n",
    "\n",
    "n_scatter_cells = min(5000, adt_test_adata.n_obs)  # subsample if huge\n",
    "cell_idx = np.random.default_rng(42).choice(adt_test_adata.n_obs, n_scatter_cells, replace=False)\n",
    "\n",
    "# recompute predictions just for this subset to avoid reusing big arrays\n",
    "Xhat_adt_sub = univi_eval.cross_modal_predict(\n",
    "    model,\n",
    "    adata_src=rna_test_adata[cell_idx],\n",
    "    src_mod=\"rna\",\n",
    "    tgt_mod=\"adt\",\n",
    "    device=device,\n",
    "    batch_size=512,\n",
    ")\n",
    "X_adt_sub = _to_dense(adt_test_adata[cell_idx].X)\n",
    "\n",
    "adt_markers_to_plot = [\n",
    "    # put your favorite ADT markers here\n",
    "    # e.g. \"CD3\", \"CD4\", \"CD8A\", \"CD56\", ...\n",
    "]\n",
    "\n",
    "for marker in adt_markers_to_plot:\n",
    "    if marker not in adt_test_adata.var_names:\n",
    "        print(f\"  [RNA→ADT] Marker '{marker}' not found in adt_test_adata.var_names; skipping.\")\n",
    "        continue\n",
    "\n",
    "    j = np.where(adt_test_adata.var_names == marker)[0][0]\n",
    "    y_true = X_adt_sub[:, j]\n",
    "    y_pred = Xhat_adt_sub[:, j]\n",
    "\n",
    "    plt.figure(figsize=(4.5, 4))\n",
    "    plt.hexbin(y_true, y_pred, gridsize=50, mincnt=1)\n",
    "    plt.xlabel(f\"True ADT ({marker})\")\n",
    "    plt.ylabel(f\"Predicted ADT ({marker})\")\n",
    "    plt.title(f\"RNA→ADT prediction for {marker}\")\n",
    "    plt.tight_layout()\n",
    "    fname = f\"scatter_RNA_to_ADT_{marker}.png\".replace(\" \", \"_\")\n",
    "    plt.savefig(os.path.join(FIGDIR, fname), dpi=200)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Example: RNA → ATAC for a few peaks / gene-body features (if named)\n",
    "# (This is more exploratory since ATAC features are often peaks; choose a few named ones if available.)\n",
    "\n",
    "n_scatter_cells_atac = min(5000, atac_test_adata.n_obs)\n",
    "cell_idx_atac = np.random.default_rng(123).choice(atac_test_adata.n_obs, n_scatter_cells_atac, replace=False)\n",
    "\n",
    "Xhat_atac_sub = univi_eval.cross_modal_predict(\n",
    "    model,\n",
    "    adata_src=rna_test_adata[cell_idx_atac],\n",
    "    src_mod=\"rna\",\n",
    "    tgt_mod=\"atac\",\n",
    "    device=device,\n",
    "    batch_size=512,\n",
    ")\n",
    "X_atac_sub = _to_dense(atac_test_adata[cell_idx_atac].X)\n",
    "\n",
    "# If you have named ATAC features (e.g. gene body aggregates), you can list them here.\n",
    "atac_features_to_plot = [\n",
    "    # e.g. \"TNFRSF4_body\", \"IFNG_enh\", ...\n",
    "]\n",
    "\n",
    "for feat in atac_features_to_plot:\n",
    "    if feat not in atac_test_adata.var_names:\n",
    "        print(f\"  [RNA→ATAC] Feature '{feat}' not found in atac_test_adata.var_names; skipping.\")\n",
    "        continue\n",
    "\n",
    "    j = np.where(atac_test_adata.var_names == feat)[0][0]\n",
    "    y_true = X_atac_sub[:, j]\n",
    "    y_pred = Xhat_atac_sub[:, j]\n",
    "\n",
    "    plt.figure(figsize=(4.5, 4))\n",
    "    plt.hexbin(y_true, y_pred, gridsize=50, mincnt=1)\n",
    "    plt.xlabel(f\"True ATAC ({feat})\")\n",
    "    plt.ylabel(f\"Predicted ATAC ({feat})\")\n",
    "    plt.title(f\"RNA→ATAC prediction for {feat}\")\n",
    "    plt.tight_layout()\n",
    "    fname = f\"scatter_RNA_to_ATAC_{feat}.png\".replace(\" \", \"_\")\n",
    "    plt.savefig(os.path.join(FIGDIR, fname), dpi=200)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faee3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de93dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a9f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c951523",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8748831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2061bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc76fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniVI_TEA-seq_working_environment",
   "language": "python",
   "name": "univi_tea-seq_working_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
