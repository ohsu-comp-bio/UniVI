{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83ac317",
   "metadata": {},
   "source": [
    "# UniVI manuscript - Figure 4 generation reproducible workflow\n",
    "### Multiome RNA + ATAC latent embedding by cell type and modality; examples of predicted accessibility programs from RNA; predicted gene programs from aTAC; alignment and reconstruction metrics\n",
    "\n",
    "Andrew Ashford, Pathways + Omics Group, Oregon Health & Science University, Portland, OR - 12/7/2025\n",
    "\n",
    "This Jupyter Notebook will house the end-to-end workflow to generate the panels in Figure 4 of our manuscript, \"Unifying multimodal single-cell data with a mixture-of-experts β-variational autoencoder framework\" which is currently being revised for Genome Research and is available currently on bioRxiv at the following link: https://www.biorxiv.org/content/10.1101/2025.02.28.640429v1.full\n",
    "\n",
    "GitHub for the project - including a Quickstart guide - can be found at: https://github.com/Ashford-A/UniVI\n",
    "\n",
    "Package is pip installable via the command: \n",
    "```bash\n",
    "pip install univi\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad73266",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import non-UniVI modules\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d2f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ee212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required UniVI modules\n",
    "from univi import (\n",
    "    ModalityConfig,\n",
    "    UniVIConfig,\n",
    "    TrainingConfig,\n",
    "    UniVIMultiModalVAE,\n",
    "    matching,\n",
    "    UniVITrainer,\n",
    "    write_univi_latent,\n",
    "    MultiModalDataset,\n",
    ")\n",
    "\n",
    "import univi as uv\n",
    "import univi.evaluation as ue\n",
    "import univi.plotting as up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485fc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check UniVI module version\n",
    "print(\"Installed version is univi v\" + str(uv.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c551d6",
   "metadata": {},
   "source": [
    "### Specify device to use for model\n",
    "\n",
    "Set \"device\" - preferably device should be \"cuda\" for speedier model implementation/training. Requires GPU and the correct packages/versions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c37f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f017fa37",
   "metadata": {},
   "source": [
    "### Specify file paths\n",
    "\n",
    "Where data lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1593188",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/home/groups/precepts/ashforda/UniVI_v2/UniVI_older-non_git/data/PBMC_10x_Multiome_data/10x_Genomics_Multiome_data\")\n",
    "\n",
    "RNA_PATH = DATA_ROOT / \"10x-Multiome-Pbmc10k-RNA.h5ad\"\n",
    "ATAC_PATH = DATA_ROOT / \"10x-Multiome-Pbmc10k-ATAC.h5ad\"\n",
    "\n",
    "print(\"RNA file:\", RNA_PATH)\n",
    "print(\"ATAC file:\", ATAC_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f717b4",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "Read data into AnnData objects using the paths in the code chunk above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36dbdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = sc.read_h5ad(RNA_PATH)\n",
    "atac = sc.read_h5ad(ATAC_PATH)\n",
    "\n",
    "print(rna)\n",
    "print(atac)\n",
    "\n",
    "print(\"RNA obs names head:\", rna.obs_names[:5].tolist())\n",
    "print(\"ATAC obs names head:\", atac.obs_names[:5].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e02781",
   "metadata": {},
   "source": [
    "### Align cells between RNA and ATAC\n",
    "\n",
    "Make sure the cell indices are aligned so UniVI knows which samples are paired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e65aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersect barcodes\n",
    "common_cells = rna.obs_names.intersection(atac.obs_names)\n",
    "print(\"Common cells:\", len(common_cells))\n",
    "\n",
    "rna = rna[common_cells].copy()\n",
    "atac = atac[common_cells].copy()\n",
    "\n",
    "# Make sure order matches\n",
    "atac = atac[rna.obs_names].copy()\n",
    "\n",
    "assert np.array_equal(rna.obs_names.values, atac.obs_names.values)\n",
    "print(\"obs_names aligned between RNA and ATAC.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75458aab",
   "metadata": {},
   "source": [
    "### Stratify the data by celltype so that we train a balanced/generalizeable model\n",
    "\n",
    "Also specifying all the data preprocessing functions below, will be used in their own respective sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Stratified split with cap\n",
    "# -----------------------------\n",
    "def stratified_split(\n",
    "    idx,\n",
    "    labels,\n",
    "    frac_train=0.8,\n",
    "    frac_val=0.1,\n",
    "    seed=0,\n",
    "    max_per_label=None,\n",
    "    unused_to_test=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each label:\n",
    "      - shuffle its indices\n",
    "      - keep up to max_per_label as \"used\"\n",
    "      - split used -> train/val/test by fractions\n",
    "      - leftover beyond max_per_label -> unused\n",
    "    If unused_to_test=True, unused is appended into test and not returned separately.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.asarray(idx)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    train_idx, val_idx, test_idx, unused_idx = [], [], [], []\n",
    "\n",
    "    # stable label order (preserves category order if categorical, else sorted unique)\n",
    "    uniq = pd.unique(labels)\n",
    "\n",
    "    for lab in uniq:\n",
    "        m = idx[labels == lab]\n",
    "        rng.shuffle(m)\n",
    "\n",
    "        if max_per_label is not None:\n",
    "            used = m[:max_per_label]\n",
    "            leftover = m[max_per_label:]\n",
    "            if leftover.size:\n",
    "                unused_idx.append(leftover)\n",
    "        else:\n",
    "            used = m\n",
    "\n",
    "        n = used.size\n",
    "        if n == 0:\n",
    "            continue\n",
    "\n",
    "        n_train = int(frac_train * n)\n",
    "        n_val   = int(frac_val * n)\n",
    "        # remainder -> test\n",
    "        train_idx.append(used[:n_train])\n",
    "        val_idx.append(used[n_train:n_train + n_val])\n",
    "        test_idx.append(used[n_train + n_val:])\n",
    "\n",
    "    train_idx = np.concatenate(train_idx) if train_idx else np.array([], dtype=int)\n",
    "    val_idx   = np.concatenate(val_idx)   if val_idx   else np.array([], dtype=int)\n",
    "    test_idx  = np.concatenate(test_idx)  if test_idx  else np.array([], dtype=int)\n",
    "    unused_idx = np.concatenate(unused_idx) if unused_idx else np.array([], dtype=int)\n",
    "\n",
    "    if unused_to_test and unused_idx.size:\n",
    "        test_idx = np.concatenate([test_idx, unused_idx])\n",
    "        unused_idx = np.array([], dtype=int)\n",
    "\n",
    "    return train_idx, val_idx, test_idx, unused_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Small helper functions\n",
    "# -----------------------------\n",
    "def _ensure_counts_layer(adata, layer_name=\"counts\"):\n",
    "    if layer_name in adata.layers:\n",
    "        return\n",
    "    # Fall back to X as counts if needed (only if X is actually raw counts!)\n",
    "    adata.layers[layer_name] = adata.X.copy()\n",
    "\n",
    "def _subset_by_idx_pair(rna, adt, idx):\n",
    "    # Assumes rna/adt are already paired in the same order\n",
    "    return rna[idx].copy(), adt[idx].copy()\n",
    "\n",
    "def preprocess_multiome_splits(\n",
    "    rna_train, atac_train,\n",
    "    rna_val,   atac_val,\n",
    "    rna_test,  atac_test,\n",
    "    *,\n",
    "    rna_counts_layer=\"counts\",\n",
    "    atac_counts_layer=\"counts\",\n",
    "    n_hvg=2000,\n",
    "    target_sum=1e4,\n",
    "    n_lsi=50,\n",
    "    seed=0,\n",
    "):\n",
    "    # --- ensure counts layers ---\n",
    "    for a in (rna_train, rna_val, rna_test):\n",
    "        if rna_counts_layer not in a.layers:\n",
    "            a.layers[rna_counts_layer] = a.X.copy()\n",
    "    for a in (atac_train, atac_val, atac_test):\n",
    "        if atac_counts_layer not in a.layers:\n",
    "            a.layers[atac_counts_layer] = a.X.copy()\n",
    "\n",
    "    # =========================\n",
    "    # RNA: HVG on TRAIN only\n",
    "    # =========================\n",
    "    rna_train_tmp = rna_train.copy()\n",
    "    rna_train_tmp.X = rna_train_tmp.layers[rna_counts_layer]\n",
    "    try:\n",
    "        sc.pp.highly_variable_genes(rna_train_tmp, n_top_genes=int(n_hvg), flavor=\"seurat_v3\")\n",
    "    except Exception:\n",
    "        sc.pp.highly_variable_genes(rna_train_tmp, n_top_genes=int(n_hvg), flavor=\"seurat\")\n",
    "\n",
    "    hvg = rna_train_tmp.var_names[rna_train_tmp.var[\"highly_variable\"].to_numpy()].tolist()\n",
    "\n",
    "    def _rna_transform(a):\n",
    "        ad = a[:, hvg].copy()\n",
    "        X = ad.layers[rna_counts_layer]\n",
    "        sc.pp.normalize_total(ad, target_sum=float(target_sum), layer=rna_counts_layer)\n",
    "        sc.pp.log1p(ad, layer=rna_counts_layer)\n",
    "        ad.X = ad.layers[rna_counts_layer].copy()\n",
    "        return ad\n",
    "\n",
    "    rna_train_pp = _rna_transform(rna_train)\n",
    "    rna_val_pp   = _rna_transform(rna_val)\n",
    "    rna_test_pp  = _rna_transform(rna_test)\n",
    "\n",
    "    # =========================\n",
    "    # ATAC: TFIDF + SVD (LSI) fit on TRAIN only\n",
    "    # =========================\n",
    "    Xtr = atac_train.layers[atac_counts_layer]\n",
    "    Xva = atac_val.layers[atac_counts_layer]\n",
    "    Xte = atac_test.layers[atac_counts_layer]\n",
    "\n",
    "    if not sp.issparse(Xtr):\n",
    "        Xtr = sp.csr_matrix(Xtr)\n",
    "    if not sp.issparse(Xva):\n",
    "        Xva = sp.csr_matrix(Xva)\n",
    "    if not sp.issparse(Xte):\n",
    "        Xte = sp.csr_matrix(Xte)\n",
    "\n",
    "    tfidf = TfidfTransformer(norm=\"l2\", use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "    Xtr_t = tfidf.fit_transform(Xtr)\n",
    "    Xva_t = tfidf.transform(Xva)\n",
    "    Xte_t = tfidf.transform(Xte)\n",
    "\n",
    "    svd = TruncatedSVD(n_components=int(n_lsi), random_state=int(seed))\n",
    "    Ztr = svd.fit_transform(Xtr_t)\n",
    "    Zva = svd.transform(Xva_t)\n",
    "    Zte = svd.transform(Xte_t)\n",
    "\n",
    "    # scale using TRAIN only (good for Gaussian decoder stability)\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    Ztr = scaler.fit_transform(Ztr).astype(np.float32, copy=False)\n",
    "    Zva = scaler.transform(Zva).astype(np.float32, copy=False)\n",
    "    Zte = scaler.transform(Zte).astype(np.float32, copy=False)\n",
    "\n",
    "    # Build ATAC-LSI AnnDatas (keeps pairing/obs; var are \"LSI_0..\")\n",
    "    atac_train_lsi = ad.AnnData(X=Ztr, obs=atac_train.obs.copy(),\n",
    "                               var=pd.DataFrame(index=[f\"LSI_{i}\" for i in range(Ztr.shape[1])]))\n",
    "    atac_val_lsi   = ad.AnnData(X=Zva, obs=atac_val.obs.copy(),\n",
    "                               var=pd.DataFrame(index=[f\"LSI_{i}\" for i in range(Zva.shape[1])]))\n",
    "    atac_test_lsi  = ad.AnnData(X=Zte, obs=atac_test.obs.copy(),\n",
    "                               var=pd.DataFrame(index=[f\"LSI_{i}\" for i in range(Zte.shape[1])]))\n",
    "\n",
    "    # keep raw peaks around for biology (optional; you already have atac_* originals)\n",
    "    return (rna_train_pp, atac_train_lsi,\n",
    "            rna_val_pp,   atac_val_lsi,\n",
    "            rna_test_pp,  atac_test_lsi,\n",
    "            hvg, tfidf, svd, scaler)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def transform_rna_with_hvg(rna, *, hvg, counts_layer=\"counts\", target_sum=1e4):\n",
    "    a = rna[:, hvg].copy()\n",
    "\n",
    "    # make sure counts exist\n",
    "    if counts_layer not in a.layers:\n",
    "        a.layers[counts_layer] = a.X.copy()\n",
    "\n",
    "    # IMPORTANT: don't overwrite your raw counts layer; work in a fresh layer\n",
    "    a.layers[\"log1p\"] = a.layers[counts_layer].copy()\n",
    "    sc.pp.normalize_total(a, target_sum=float(target_sum), layer=\"log1p\")\n",
    "    sc.pp.log1p(a, layer=\"log1p\")\n",
    "    a.X = a.layers[\"log1p\"]\n",
    "    return a\n",
    "\n",
    "def transform_atac_with_lsi(atac, *, counts_layer=\"counts\", tfidf=None, svd=None, scaler=None):\n",
    "    if tfidf is None or svd is None or scaler is None:\n",
    "        raise ValueError(\"Need tfidf, svd, scaler objects from preprocess_multiome_splits().\")\n",
    "\n",
    "    a = atac.copy()\n",
    "    if counts_layer not in a.layers:\n",
    "        a.layers[counts_layer] = a.X.copy()\n",
    "\n",
    "    X = a.layers[counts_layer]\n",
    "    if not sp.issparse(X):\n",
    "        X = sp.csr_matrix(X)\n",
    "\n",
    "    Xt = tfidf.transform(X)\n",
    "    Z  = svd.transform(Xt)\n",
    "    Z  = scaler.transform(Z).astype(np.float32, copy=False)\n",
    "\n",
    "    atac_lsi = ad.AnnData(\n",
    "        X=Z,\n",
    "        obs=a.obs.copy(),\n",
    "        var=pd.DataFrame(index=[f\"LSI_{i}\" for i in range(Z.shape[1])]),\n",
    "    )\n",
    "    return atac_lsi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf9b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the counts of each celltype.l1 in the data\n",
    "print(rna.obs[\"cell_type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Use it on 10k PBMC 10x Genomic Multiome RNA + ATAC\n",
    "# --------------------------------------------------\n",
    "labels = rna.obs[\"cell_type\"].astype(str).to_numpy()\n",
    "idx = np.arange(rna.n_obs)\n",
    "\n",
    "train_idx, val_idx, test_idx, unused_idx = stratified_split(\n",
    "    idx, labels,\n",
    "    frac_train=0.8, frac_val=0.1, seed=0,\n",
    "    max_per_label=5000,\n",
    "    unused_to_test=True,      # set True if you want unused merged into test\n",
    ")\n",
    "\n",
    "# paired splits\n",
    "rna_train, atac_train = _subset_by_idx_pair(rna, atac, train_idx)\n",
    "rna_val,   atac_val   = _subset_by_idx_pair(rna, atac, val_idx)\n",
    "rna_test,  atac_test  = _subset_by_idx_pair(rna, atac, test_idx)\n",
    "\n",
    "if unused_idx.size:\n",
    "    rna_unused, atac_unused = _subset_by_idx_pair(rna, atac, unused_idx)\n",
    "else:\n",
    "    rna_unused, atac_unused = None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523bbfee-a3df-40ee-b00b-4ec37003b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rna_train.obs['cell_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a42b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_train_to_target(train_idx, labels, target_per_label=1000, seed=0, shuffle=True):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    train_idx = np.asarray(train_idx, dtype=int)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    y = labels[train_idx]\n",
    "    out = []\n",
    "\n",
    "    # stable-ish label order\n",
    "    for lab in pd.unique(y):\n",
    "        m = train_idx[y == lab]\n",
    "        if m.size == 0:\n",
    "            continue\n",
    "\n",
    "        replace = (m.size < int(target_per_label))\n",
    "        out.append(rng.choice(m, size=int(target_per_label), replace=replace))\n",
    "\n",
    "    out = np.concatenate(out).astype(int, copy=False)\n",
    "\n",
    "    if shuffle:\n",
    "        rng.shuffle(out)\n",
    "    return out\n",
    "\n",
    "# ---- usage (paired adatas) ----\n",
    "# make sure rna/atac aligned first\n",
    "'''\n",
    "assert (rna.obs_names == atac.obs_names).all()\n",
    "\n",
    "labels = rna.obs[\"cell_type\"].astype(str).to_numpy()\n",
    "\n",
    "train_idx_bal = upsample_train_to_target(\n",
    "    train_idx,\n",
    "    labels,\n",
    "    target_per_label=1500,\n",
    "    seed=0,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "rna_train_bal  = rna[train_idx_bal].copy()\n",
    "atac_train_bal = atac[train_idx_bal].copy()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb505d7d",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "* RNA preprocessing (log1p + HVG + scale → Gaussian decoder)\n",
    "\n",
    "* ATAC preprocessing (TF-IDF + LSI + scale → Gaussian decoder)\n",
    "\n",
    "Running the preprocessing functions specified above. Of note, we're performing the preprocessing per-train/val/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "# preprocessing (fit on train, apply to val/test)\n",
    "(rna_train_pp, atac_train_lsi,\n",
    " rna_val_pp,   atac_val_lsi,\n",
    " rna_test_pp,  atac_test_lsi,\n",
    " hvg_genes, tfidf, svd, scaler) = preprocess_multiome_splits(\n",
    "    rna_train, atac_train,\n",
    "    rna_val,   atac_val,\n",
    "    rna_test,  atac_test,\n",
    "    n_hvg=2000, n_lsi=100, seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 1) Fit preprocessing on UNIQUE train (your existing call)\n",
    "(rna_train_pp_u, atac_train_lsi_u,\n",
    " rna_val_pp,     atac_val_lsi,\n",
    " rna_test_pp,    atac_test_lsi,\n",
    " hvg, tfidf, svd, scaler) = preprocess_multiome_splits(\n",
    "    rna_train, atac_train,\n",
    "    rna_val,   atac_val,\n",
    "    rna_test,  atac_test,\n",
    "    n_hvg=5000, n_lsi=200, seed=42\n",
    ")\n",
    "\n",
    "# 2) Upsample indices INSIDE the train split\n",
    "train_idx_u = np.arange(rna_train.n_obs)\n",
    "train_idx_bal = upsample_train_to_target(\n",
    "    train_idx_u,\n",
    "    rna_train.obs[\"cell_type\"].to_numpy(),\n",
    "    target_per_label=1500,\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "# 3) Build upsampled paired train adatas\n",
    "rna_train_bal  = rna_train[train_idx_bal].copy()\n",
    "atac_train_bal = atac_train[train_idx_bal].copy()\n",
    "\n",
    "# (optional) if duplicates annoy scanpy later:\n",
    "# rna_train_bal.obs_names_make_unique()\n",
    "# atac_train_bal.obs_names_make_unique()\n",
    "\n",
    "# 4) Transform upsampled train using the FIT objects\n",
    "rna_train_pp  = transform_rna_with_hvg(rna_train_bal, hvg=hvg, counts_layer=\"counts\", target_sum=1e4)\n",
    "atac_train_lsi = transform_atac_with_lsi(atac_train_bal, counts_layer=\"counts\", tfidf=tfidf, svd=svd, scaler=scaler)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5609d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check above preprocessed data objects - start with RNA\n",
    "print(rna_train_pp)\n",
    "print(rna_val_pp)\n",
    "print(rna_test_pp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bd801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now sanity check ATAC LSI data objects\n",
    "print(atac_train_lsi)\n",
    "print(atac_val_lsi)\n",
    "print(atac_test_lsi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464bf1d9",
   "metadata": {},
   "source": [
    "### Wrap into MultiModalDataset & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d509d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from univi.data import align_paired_obs_names\n",
    "\n",
    "pin_memory = (device == \"cuda\")\n",
    "\n",
    "# Make sure each split is paired and ordered the same across modalities\n",
    "# This was erroring out due to a function bug, fixed it and should be fixed by manuscript publication\n",
    "#train_dict = align_paired_obs_names({\"rna\": rna_train_pp, \"adt\": atac_train_lsi})\n",
    "#val_dict   = align_paired_obs_names({\"rna\": rna_val_pp,   \"adt\": atac_val_lsi})\n",
    "#test_dict  = align_paired_obs_names({\"rna\": rna_test_pp,  \"adt\": atac_test_lsi})\n",
    "\n",
    "# Using this instead for now since we know the data are already paired from above code\n",
    "assert (rna_train_pp.obs_names == atac_train_lsi.obs_names).all()\n",
    "assert (rna_val_pp.obs_names   == atac_val_lsi.obs_names).all()\n",
    "assert (rna_test_pp.obs_names  == atac_test_lsi.obs_names).all()\n",
    "\n",
    "train_dict = {\"rna\": rna_train_pp, \"atac\": atac_train_lsi}\n",
    "val_dict   = {\"rna\": rna_val_pp,   \"atac\": atac_val_lsi}\n",
    "test_dict  = {\"rna\": rna_test_pp,  \"atac\": atac_test_lsi}\n",
    "\n",
    "# Build datasets (CPU tensors; trainer/model moves to GPU)\n",
    "train_ds = MultiModalDataset(adata_dict=train_dict, X_key=\"X\", device=None)\n",
    "val_ds   = MultiModalDataset(adata_dict=val_dict,   X_key=\"X\", device=None)\n",
    "test_ds  = MultiModalDataset(adata_dict=test_dict,  X_key=\"X\", device=None)\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 0\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "'''\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# labels for the TRAIN split (same order as train_ds cells)\n",
    "y = rna_train_pp.obs[\"cell_type\"].astype(str).to_numpy()\n",
    "\n",
    "# inverse frequency weights\n",
    "vals, counts = np.unique(y, return_counts=True)\n",
    "freq = dict(zip(vals, counts))\n",
    "w = np.array([1.0 / freq[c] for c in y], dtype=np.float64)\n",
    "w = w / w.sum()\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=torch.as_tensor(w, dtype=torch.double),\n",
    "    num_samples=len(w),   # one \"epoch\" worth of draws\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler,      # <-- instead of shuffle=True\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    ")\n",
    "'''\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "print(\"n_train / n_val / n_test:\", train_ds.n_cells, val_ds.n_cells, test_ds.n_cells)\n",
    "print(\"batches:\", len(train_loader), len(val_loader), len(test_loader))\n",
    "\n",
    "# sanity check one batch\n",
    "x = next(iter(train_loader))\n",
    "print({k: v.shape for k, v in x.items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440bef8a",
   "metadata": {},
   "source": [
    "### UniVI configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9849b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_codes = rna.obs[\"cell_type\"].astype(\"category\").cat.codes.to_numpy()\n",
    "n_classes = int(y_codes.max() + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8436ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "univi_cfg = UniVIConfig(\n",
    "    latent_dim=30,\n",
    "    beta=1.25,\n",
    "    gamma=4.35,\n",
    "    encoder_dropout=0.1,\n",
    "    decoder_dropout=0.05,\n",
    "    encoder_batchnorm=True,\n",
    "    decoder_batchnorm=False,\n",
    "    kl_anneal_start=50,\n",
    "    kl_anneal_end=85,\n",
    "    align_anneal_start=75,\n",
    "    align_anneal_end=110,\n",
    "    modalities=[\n",
    "        ModalityConfig(\n",
    "            name=\"rna\",\n",
    "            input_dim=rna_train_pp.n_vars,\n",
    "            encoder_hidden=[512, 256, 128],\n",
    "            decoder_hidden=[128, 256, 512],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "        ModalityConfig(\n",
    "            name=\"atac\",\n",
    "            input_dim=atac_train_lsi.n_vars,\n",
    "            encoder_hidden=[128, 64],\n",
    "            decoder_hidden=[64, 128],\n",
    "            likelihood=\"gaussian\",\n",
    "        ),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f3b73",
   "metadata": {},
   "source": [
    "If you want raw-count NB/ZINB instead, you’d:\n",
    "* Put raw counts in .layers[\"counts\"]\n",
    "* Set X_key=\"counts\" in the dataset\n",
    "* Use likelihood=\"nb\" or \"zinb\" above\n",
    "\n",
    "But for this \"Figure 4\" notebook, the scaled Gaussian setup is nicely stable and good for the best-integrated latent space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467656e6",
   "metadata": {},
   "source": [
    "### Instantiate model and model objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdceded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = UniVIMultiModalVAE(\n",
    "    univi_cfg,\n",
    "    loss_mode=\"v1\",      # cross-recon + cross-posterior alignment\n",
    "    #loss_mode=\"lite\"\n",
    "    #v1_recon=\"cross\",   # full k→j cross-recon\n",
    "    v1_recon=\"avg\",\n",
    "    #v1_recon_mix=0.5,\n",
    "    normalize_v1_terms=True,\n",
    ").to(device)\n",
    "\n",
    "'''\n",
    "model = UniVIMultiModalVAE(\n",
    "    univi_cfg,\n",
    "    loss_mode=\"v1\",      # cross-recon + cross-posterior alignment\n",
    "    #loss_mode=\"lite\"\n",
    "    #v1_recon=\"cross\",   # full k→j cross-recon\n",
    "    v1_recon=\"avg\",\n",
    "    #v1_recon_mix=0.5,\n",
    "    normalize_v1_terms=True,\n",
    "    n_label_classes=n_classes,\n",
    "    label_loss_weight=5.0,\n",
    "    label_ignore_index=-1,\n",
    "    classify_from_mu=True,\n",
    ").to(device)\n",
    "'''\n",
    "'''\n",
    "model = UniVIMultiModalVAE(\n",
    "    univi_cfg,\n",
    "    loss_mode=\"lite\",\n",
    "\n",
    "    # Optional: keep the decoder-side classification head too\n",
    "    n_label_classes=n_classes,\n",
    "    label_loss_weight=2.0,\n",
    "\n",
    "    # Encoder-side label expert injected into fusion\n",
    "    use_label_encoder=True,\n",
    "    label_moe_weight=3.5,      # >1 => labels influence fusion more\n",
    "    unlabeled_logvar=20.0,     # very high => tiny precision => ignored in fusion\n",
    "    label_encoder_warmup=5,    # wait N epochs before injecting labels into fusion\n",
    "    label_ignore_index=-1,\n",
    ").to(\"cuda\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7700f937",
   "metadata": {},
   "source": [
    "### Instantiate TrainingConfig & trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2debd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg = TrainingConfig(\n",
    "    n_epochs=5000,\n",
    "    batch_size=batch_size,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    device=device,\n",
    "    log_every=100,\n",
    "    grad_clip=5.0,\n",
    "    num_workers=0,\n",
    "    seed=42,\n",
    "    early_stopping=True,\n",
    "    patience=300,         # Setting kind of high patience since training takes ~1s/iteration because of small-ish dataset\n",
    "    min_delta=0.0,\n",
    ")\n",
    "\n",
    "print(train_cfg)\n",
    "print(univi_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80cf3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = UniVITrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    train_cfg=train_cfg,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(trainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c7e3b",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f710c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.fit()\n",
    "\n",
    "# history is a dict with keys like \"train_loss\", \"val_loss\", \"beta\", \"gamma\"\n",
    "print(\"Training finished.\")\n",
    "print(\"Best val loss:\", np.min(history[\"val_loss\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"train_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_loss\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"UniVI training (Multiome)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9965c64",
   "metadata": {},
   "source": [
    "### Write latent z back to AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test batches:\", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e944299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure adata_dict has the *same ordering* as during training\n",
    "adata_dict = {\n",
    "    \"rna\": rna_test_pp,\n",
    "    \"atac\": atac_test_lsi,\n",
    "}\n",
    "\n",
    "Z = write_univi_latent(\n",
    "    model,\n",
    "    adata_dict,\n",
    "    obsm_key=\"X_univi\",   # will be added to each AnnData in adata_dict\n",
    "    batch_size=512,\n",
    "    device=device,\n",
    "    use_mean=True,       # deterministic: use encoder means instead of noisy samples\n",
    "    #use_mean=False,       # Stochastic\n",
    ")\n",
    "\n",
    "print(\"UniVI latent shape:\",  Z.shape)\n",
    "print(\"rna.obsm keys:\",       rna_test_pp.obsm.keys())\n",
    "print(\"adt.obsm keys:\",       atac_test_lsi.obsm.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b0b35",
   "metadata": {},
   "source": [
    "Now both rna and atac have a shared latent:\n",
    "\n",
    "* rna_test_pp.obsm[\"X_univi\"]\n",
    "\n",
    "* atac_test_pp.obsm[\"X_univi\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb770958",
   "metadata": {},
   "source": [
    "### Code to save/load modal if so inclined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3917f-3d07-4e32-be54-ba2cad9f372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_used = \"1.25\"\n",
    "gamma_used = \"4.35\"\n",
    "latent_dims_used = \"30\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e351bfb7-77d7-4f1d-bd62-80204bc7d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'./results/univi_TEA-seq_Figure_4_Multiome_beta-{beta_used}_gamma-{gamma_used}_latent_dims-{latent_dims_used}_gaussian_all_reproducibility/'\n",
    "out_file = f\"trained_model_beta-{beta_used}_gamma-{gamma_used}_latent_dims-{latent_dims_used}_gaussian_both_reproducibility.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740bae1-628c-4cf3-a47a-70cd27c80b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "ckpt_path = output_dir + out_file\n",
    "\n",
    "\n",
    "rna = rna_test_pp.copy()\n",
    "atac = atac_test_lsi.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f2b19-310d-407b-a4c6-d16671f718d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hvg = len(rna.var_names)\n",
    "target_sum = 1e4\n",
    "n_lsi = len(atac.var_names)\n",
    "rna_hvg_names = rna.var_names\n",
    "\n",
    "\n",
    "# after training\n",
    "#history = trainer.fit()\n",
    "\n",
    "import sys, platform, hashlib, numpy as np, torch\n",
    "\n",
    "def _hash_list(x):\n",
    "    h = hashlib.sha256()\n",
    "    for s in x:\n",
    "        h.update(str(s).encode())\n",
    "        h.update(b\"\\n\")\n",
    "    return h.hexdigest()\n",
    "\n",
    "ckpt = {\n",
    "    # core\n",
    "    \"state_dict\": trainer.model.state_dict(),\n",
    "    \"univi_cfg\": asdict(univi_cfg),\n",
    "\n",
    "    # best model info\n",
    "    \"best_epoch\": trainer.best_epoch,\n",
    "    \"best_val_loss\": float(trainer.best_val_loss),\n",
    "\n",
    "    # splits (STORE THESE!)\n",
    "    \"splits\": {\n",
    "        \"train\": np.asarray(train_idx, dtype=np.int64),\n",
    "        \"val\":   np.asarray(val_idx, dtype=np.int64),\n",
    "        \"test\":  np.asarray(test_idx, dtype=np.int64),\n",
    "    },\n",
    "\n",
    "    # preprocessing + feature sets (examples; include what you actually use)\n",
    "    \"preproc\": {\n",
    "        \"rna\":  {\"layer\": \"counts\", \"n_hvg\": n_hvg, \"target_sum\": target_sum, \"log1p\": True, \"zscore\": True},\n",
    "        \"adt\":  {\"layer\": \"counts\", \"clr\": True, \"zscore\": True},\n",
    "        \"atac\": {\"layer\": \"counts\", \"tfidf\": True, \"n_lsi\": n_lsi, \"lsi_drop_first\": True, \"zscore\": True},\n",
    "    },\n",
    "    \"features\": {\n",
    "        \"rna_hvgs\": list(rna_hvg_names),          # list[str]\n",
    "        \"atac_peaks\": list(atac.var_names),       # list[str] (or whatever LSI used)\n",
    "    },\n",
    "\n",
    "    # provenance checks\n",
    "    \"data_fingerprint\": {\n",
    "        \"rna_obs_hash\": _hash_list(rna.obs_names),\n",
    "        \"rna_var_hash\": _hash_list(rna.var_names),\n",
    "        \"atac_obs_hash\": _hash_list(atac.obs_names),\n",
    "        \"atac_var_hash\": _hash_list(atac.var_names),\n",
    "    },\n",
    "\n",
    "    # environment versions\n",
    "    \"versions\": {\n",
    "        \"python\": sys.version,\n",
    "        \"platform\": platform.platform(),\n",
    "        \"torch\": torch.__version__,\n",
    "        \"numpy\": np.__version__,\n",
    "        \"univi\": uv.__version__,\n",
    "        \"anndata\": ad.__version__,\n",
    "        \"scanpy\": sc.__version__,\n",
    "    },\n",
    "\n",
    "    # history (optional)\n",
    "    \"history\": history,\n",
    "}\n",
    "\n",
    "torch.save(ckpt, ckpt_path)\n",
    "print(\"Saved best model to:\", ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2eb7e-8a9c-421c-8aa0-c79a6706d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later to reload model\n",
    "import torch\n",
    "from univi.config import UniVIConfig, ModalityConfig\n",
    "from univi.models.univi import UniVIMultiModalVAE\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "#device = \"cuda\"  # or \"cuda\" if available\n",
    "\n",
    "\n",
    "ckpt = torch.load(\n",
    "    #output_dir + out_file,\n",
    "    ckpt_path,\n",
    "    map_location=device,\n",
    "    weights_only=False,\n",
    ")\n",
    "\n",
    "\n",
    "# ---- Rebuild UniVIConfig, making sure modalities are ModalityConfig objects ----\n",
    "cfg_dict = ckpt[\"univi_cfg\"]\n",
    "\n",
    "# If this is an OmegaConf object or similar, make sure it's a plain dict\n",
    "try:\n",
    "    from omegaconf import DictConfig, OmegaConf\n",
    "    if isinstance(cfg_dict, DictConfig):\n",
    "        cfg_dict = OmegaConf.to_container(cfg_dict, resolve=True)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Now rehydrate each modality\n",
    "modalities = [ModalityConfig(**m) for m in cfg_dict[\"modalities\"]]\n",
    "cfg_dict = {**cfg_dict, \"modalities\": modalities}\n",
    "\n",
    "univi_cfg_loaded = UniVIConfig(**cfg_dict)\n",
    "\n",
    "# ---- Rebuild model + load weights ----\n",
    "model_loaded = UniVIMultiModalVAE(univi_cfg_loaded).to(device)\n",
    "model_loaded.load_state_dict(ckpt[\"state_dict\"])\n",
    "\n",
    "print(\"Best epoch was:\", ckpt.get(\"best_epoch\"), \"val loss =\", ckpt.get(\"best_val_loss\"))\n",
    "\n",
    "\n",
    "print(sorted(ckpt.keys()))\n",
    "#print(ckpt['splits'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad0f25",
   "metadata": {},
   "source": [
    "### Figure 4A–D: UMAP (modality + celltype levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from univi.evaluation import encode_adata\n",
    "\n",
    "Z_rna = encode_adata(model, rna_test_pp, modality=\"rna\",\n",
    "                     latent=\"modality_mean\", device=device, batch_size=1024)\n",
    "Z_atac = encode_adata(model, atac_test_lsi, modality=\"atac\",\n",
    "                     latent=\"modality_mean\", device=device, batch_size=1024)\n",
    "\n",
    "key_rna = \"encode_adata(modality_mean)\"\n",
    "key_atac = \"encode_adata(modality_mean)\"\n",
    "\n",
    "rna_test_pp.obsm[\"X_univi_rna\"] = Z_rna\n",
    "atac_test_lsi.obsm[\"X_univi_atac\"] = Z_atac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_u = rna_test_pp.copy()\n",
    "atac_u = atac_test_lsi.copy()\n",
    "\n",
    "rna_u.obs[\"modality\"] = \"rna\"\n",
    "atac_u.obs[\"modality\"] = \"atac\"\n",
    "\n",
    "combo = ad.concat([rna_u, atac_u], join=\"outer\", label=\"modality\", keys=[\"rna\",\"atac\"], index_unique=\"-\")\n",
    "\n",
    "# IMPORTANT: put the correct latent for each half\n",
    "combo.obsm[\"X_univi_sep\"] = np.vstack([Z_rna, Z_atac]).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbors/umap on the *separate* stacked latent\n",
    "sc.pp.neighbors(combo, use_rep=\"X_univi_sep\", n_neighbors=30)\n",
    "sc.tl.umap(combo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f70c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Scanpy defaults (affects sc.pl.*)\n",
    "sc.set_figure_params(\n",
    "    figsize=(14, 12),   # bigger canvas\n",
    "    dpi=200,            # on-screen sharpness\n",
    "    dpi_save=600,       # saved file sharpness\n",
    "    fontsize=14,\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "# Matplotlib defaults (affects plt.*)\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (14, 12),\n",
    "    \"figure.dpi\": 200,\n",
    "    \"savefig.dpi\": 600,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"savefig.pad_inches\": 0.1,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"legend.fontsize\": 12,\n",
    "})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf20f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_key = 'cell_type'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot UMAPs\n",
    "#sc.pl.umap(combo, color=[\"modality\"], frameon=False, size=25.0)\n",
    "#sc.pl.umap(combo, color=[celltype_key], frameon=False, size=25.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out many of each cell type are in the test set for level 2 cell annotations\n",
    "print(rna_test_pp.obs[\"cell_type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18caa9",
   "metadata": {},
   "source": [
    "### Figure 4E–F: alignment metrics (FOSCTTM + label transfer + mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0eb681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# If plots ever don't show in classic notebook, run once:\n",
    "# %matplotlib inline\n",
    "\n",
    "# -------------------------\n",
    "# show-or-save helper\n",
    "# -------------------------\n",
    "def _finish(fig=None, outpath=None, dpi=100, show=True, close=True):\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath, dpi=dpi, bbox_inches=\"tight\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if close:\n",
    "        plt.close(fig if fig is not None else plt.gcf())\n",
    "\n",
    "# -------------------------\n",
    "# plots\n",
    "# -------------------------\n",
    "def plot_metrics_bar(\n",
    "    metrics,\n",
    "    keys,\n",
    "    title=\"Figure 4 summary metrics\",\n",
    "    outpath=None,\n",
    "    err_keys=None,          # dict: metric_key -> error_metric_key\n",
    "    default_err=np.nan,     # np.nan = no error bar drawn; 0.0 = zero-length\n",
    "    capsize=4,\n",
    "):\n",
    "    vals = np.array([float(metrics[k]) for k in keys], dtype=float)\n",
    "\n",
    "    if err_keys is None:\n",
    "        yerr = np.full_like(vals, default_err, dtype=float)\n",
    "    else:\n",
    "        yerr = np.array(\n",
    "            [float(metrics[err_keys[k]]) if k in err_keys and err_keys[k] in metrics else default_err\n",
    "             for k in keys],\n",
    "            dtype=float\n",
    "        )\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.bar(keys, vals, yerr=yerr, capsize=capsize)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # inline “finish” behavior\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_confusion(cm, classes, title, normalize=\"true\", outpath=None, cmap=\"viridis\"):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    cm = np.asarray(cm, dtype=float)\n",
    "    if normalize == \"true\":\n",
    "        cm = cm / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
    "        subtitle = \"Row-normalized\"\n",
    "    elif normalize == \"pred\":\n",
    "        cm = cm / (cm.sum(axis=0, keepdims=True) + 1e-12)\n",
    "        subtitle = \"Col-normalized\"\n",
    "    elif normalize == \"all\":\n",
    "        cm = cm / (cm.sum() + 1e-12)\n",
    "        subtitle = \"Global-normalized\"\n",
    "    else:\n",
    "        subtitle = \"Counts\"\n",
    "\n",
    "    classes = np.asarray(classes, dtype=str)\n",
    "    n = len(classes)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 13))\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\", cmap=cmap, aspect=\"auto\")\n",
    "\n",
    "    # kill any gridlines (including ones from styles)\n",
    "    ax.grid(False)\n",
    "    ax.minorticks_off()\n",
    "\n",
    "    ax.set_title(f\"{title}\\n({subtitle})\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "\n",
    "    ax.set_xticks(np.arange(n))\n",
    "    ax.set_yticks(np.arange(n))\n",
    "    ax.set_xticklabels(classes, rotation=90)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label(\"value\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if outpath is not None:\n",
    "        fig.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_per_class_f1(y_true, y_pred, title=\"Per-class F1\", outpath=None, top_n=None):\n",
    "    y_true = np.asarray(y_true).astype(str)\n",
    "    y_pred = np.asarray(y_pred).astype(str)\n",
    "    classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "\n",
    "    _, _, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=classes, zero_division=0\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame({\"class\": classes, \"f1\": f1, \"support\": support})\n",
    "    df = df.sort_values([\"f1\", \"support\"], ascending=[True, False])\n",
    "\n",
    "    if top_n is not None:\n",
    "        df = df.head(int(top_n))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 0.35 * len(df) + 2.0))\n",
    "    plt.barh(df[\"class\"], df[\"f1\"])\n",
    "    plt.xlabel(\"F1\")\n",
    "    plt.title(title)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n",
    "    return df\n",
    "\n",
    "def plot_modality_mixing_hist(Z, mods, k=20, metric=\"euclidean\", title=\"Modality mixing\", outpath=None):\n",
    "    Z = np.asarray(Z, dtype=np.float32)\n",
    "    mods = np.asarray(mods)\n",
    "\n",
    "    n = Z.shape[0]\n",
    "    k_eff = int(min(max(int(k), 1), n - 1))\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff + 1, metric=metric)\n",
    "    nn.fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]\n",
    "    frac_other = (mods[nbrs] != mods[:, None]).mean(axis=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(7, 4.5))\n",
    "    plt.hist(frac_other, bins=60)\n",
    "    plt.xlabel(\"Fraction of kNN from other modality\")\n",
    "    plt.ylabel(\"# cells\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n",
    "    return frac_other\n",
    "\n",
    "def plot_foscttm_sanity(Z1, Z2, idx, title=\"FOSCTTM sanity\", outpath=None):\n",
    "    Z1s = np.asarray(Z1[idx], dtype=np.float32)\n",
    "    Z2s = np.asarray(Z2[idx], dtype=np.float32)\n",
    "\n",
    "    d_true = np.sum((Z1s - Z2s) ** 2, axis=1)\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=51, metric=\"euclidean\")\n",
    "    nn.fit(np.asarray(Z2, dtype=np.float32))\n",
    "    dist, _ = nn.kneighbors(Z1s)\n",
    "    d_min = dist[:, 0] ** 2\n",
    "\n",
    "    fig = plt.figure(figsize=(5.5, 5.5))\n",
    "    plt.scatter(d_true, d_min, s=8, alpha=0.4)\n",
    "    mx = np.percentile(np.concatenate([d_true, d_min]), 99)\n",
    "    plt.plot([0, mx], [0, mx], linewidth=1)\n",
    "    plt.xlim(0, mx); plt.ylim(0, mx)\n",
    "    plt.xlabel(\"d(true match)^2\")\n",
    "    plt.ylabel(\"d(nearest neighbor)^2\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n",
    "\n",
    "def plot_paired_distance_hist(Z_rna, Z_adt, idx, title=\"Paired latent distance (subset)\", outpath=None):\n",
    "    d_pair = np.sqrt(np.sum((Z_rna[idx] - Z_adt[idx]) ** 2, axis=1))\n",
    "    fig = plt.figure(figsize=(7, 4.5))\n",
    "    plt.hist(d_pair, bins=80)\n",
    "    plt.xlabel(\"||z_rna - z_adt||\")\n",
    "    plt.ylabel(\"# cells\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    _finish(fig, outpath=outpath, show=True, close=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdee34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# ----------------------------\n",
    "# Metrics helpers\n",
    "# ----------------------------\n",
    "def foscttm_chunked(Z1, Z2, block=512):\n",
    "    \"\"\"\n",
    "    Exact FOSCTTM computed in blocks to avoid NxN memory blowups.\n",
    "    Assumes 1:1 pairing between rows i in Z1 and Z2.\n",
    "    \"\"\"\n",
    "    Z1 = np.asarray(Z1, dtype=np.float32)\n",
    "    Z2 = np.asarray(Z2, dtype=np.float32)\n",
    "    assert Z1.shape == Z2.shape\n",
    "    n = Z1.shape[0]\n",
    "\n",
    "    Z2_T = Z2.T\n",
    "    n2 = np.sum(Z2 * Z2, axis=1)  # (n,)\n",
    "\n",
    "    fos = np.empty(n, dtype=np.float32)\n",
    "\n",
    "    for i0 in range(0, n, block):\n",
    "        i1 = min(i0 + block, n)\n",
    "        A = Z1[i0:i1]  # (b, d)\n",
    "        n1 = np.sum(A * A, axis=1)[:, None]  # (b,1)\n",
    "\n",
    "        d2 = n1 + n2[None, :] - 2.0 * (A @ Z2_T)  # (b,n)\n",
    "\n",
    "        true = d2[np.arange(i1 - i0), np.arange(i0, i1)]\n",
    "        fos[i0:i1] = (d2 < true[:, None]).sum(axis=1) / (n - 1)\n",
    "\n",
    "    return float(fos.mean()), float(fos.std(ddof=1) / np.sqrt(n))\n",
    "\n",
    "\n",
    "def modality_mixing_score(Z, modality_labels, k=20, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Vanilla modality mixing:\n",
    "    Mean fraction of kNN neighbors that differ in modality.\n",
    "    Use this for *non-duplicated* sets (e.g., concatenated modality-specific embeddings).\n",
    "    \"\"\"\n",
    "    Z = np.asarray(Z, dtype=np.float32)\n",
    "    modality_labels = np.asarray(modality_labels)\n",
    "\n",
    "    n = Z.shape[0]\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    k_eff = int(min(max(int(k), 1), n - 1))\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff + 1, metric=metric)\n",
    "    nn.fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]  # drop self\n",
    "\n",
    "    same = (modality_labels[nbrs] == modality_labels[:, None])\n",
    "    return float((~same).mean())\n",
    "\n",
    "\n",
    "def modality_mixing_score_excluding_pairs(Z, modality_labels, cell_ids, k=20, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Pair-aware modality mixing for 'combo' style stacked data (same cell appears twice: RNA + ADT),\n",
    "    where the fused embedding may be identical (or extremely close) for the paired duplicates.\n",
    "\n",
    "    Computes: for each row, the fraction of neighbors from the other modality,\n",
    "    AFTER removing the paired duplicate (same cell_id) from its neighbor list.\n",
    "\n",
    "    cell_ids must map each row to a shared cell identifier (same for RNA+ADT copy).\n",
    "    \"\"\"\n",
    "    Z = np.asarray(Z, dtype=np.float32)\n",
    "    modality_labels = np.asarray(modality_labels)\n",
    "    cell_ids = np.asarray(cell_ids).astype(str)\n",
    "\n",
    "    n = Z.shape[0]\n",
    "    if n <= 2:\n",
    "        return 0.0\n",
    "\n",
    "    # Need enough neighbors so we can drop self + paired duplicate and still have k\n",
    "    k_eff = int(min(max(int(k), 1), n - 2))\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff + 2, metric=metric)\n",
    "    nn.fit(Z)\n",
    "    nbrs = nn.kneighbors(Z, return_distance=False)[:, 1:]  # drop self\n",
    "\n",
    "    # Build \"pair index\": for each row i, pair[i] is the index of the other modality copy\n",
    "    first = {}\n",
    "    pair = np.full(n, -1, dtype=np.int64)\n",
    "    for i, cid in enumerate(cell_ids):\n",
    "        if cid in first:\n",
    "            j = first[cid]\n",
    "            pair[i] = j\n",
    "            pair[j] = i\n",
    "        else:\n",
    "            first[cid] = i\n",
    "\n",
    "    frac_other = np.empty(n, dtype=np.float32)\n",
    "    for i in range(n):\n",
    "        neigh = nbrs[i]\n",
    "\n",
    "        # remove paired duplicate if present\n",
    "        pj = pair[i]\n",
    "        if pj != -1:\n",
    "            neigh = neigh[neigh != pj]\n",
    "\n",
    "        neigh = neigh[:k_eff]\n",
    "        frac_other[i] = (modality_labels[neigh] != modality_labels[i]).mean()\n",
    "\n",
    "    return float(frac_other.mean())\n",
    "\n",
    "\n",
    "def knn_label_transfer(Z_source, y_source, Z_target, y_target, k=15, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    kNN label transfer: predict y_target from neighbors in Z_source.\n",
    "    Returns predictions, accuracy, macro-F1, confusion matrix.\n",
    "    \"\"\"\n",
    "    Z_source = np.asarray(Z_source, dtype=np.float32)\n",
    "    Z_target = np.asarray(Z_target, dtype=np.float32)\n",
    "    y_source = np.asarray(y_source, dtype=str)\n",
    "    y_target = np.asarray(y_target, dtype=str)\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=k, metric=metric)\n",
    "    nn.fit(Z_source)\n",
    "    nbrs = nn.kneighbors(Z_target, return_distance=False)\n",
    "\n",
    "    preds = []\n",
    "    for inds in nbrs:\n",
    "        votes = y_source[inds]\n",
    "        vals, cnts = np.unique(votes, return_counts=True)\n",
    "        preds.append(vals[np.argmax(cnts)])\n",
    "    preds = np.asarray(preds, dtype=str)\n",
    "\n",
    "    acc = float(accuracy_score(y_target, preds))\n",
    "    macro_f1 = float(f1_score(y_target, preds, average=\"macro\"))\n",
    "    classes = np.unique(np.concatenate([y_source, y_target]))\n",
    "    cm = confusion_matrix(y_target, preds, labels=classes)\n",
    "    return preds, acc, macro_f1, cm, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66cc608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from univi.evaluation import encode_adata\n",
    "\n",
    "Z_rna  = encode_adata(model, rna_test_pp,      modality=\"rna\",  latent=\"modality_mean\", device=device, batch_size=1024)\n",
    "Z_atac = encode_adata(model, atac_test_lsi,    modality=\"atac\", latent=\"modality_mean\", device=device, batch_size=1024)\n",
    "\n",
    "labels_rna  = rna_test_pp.obs[\"cell_type\"].astype(str).to_numpy()\n",
    "labels_atac = atac_test_lsi.obs[\"cell_type\"].astype(str).to_numpy()\n",
    "assert Z_rna.shape[0] == labels_rna.shape[0]\n",
    "assert Z_atac.shape[0] == labels_atac.shape[0]\n",
    "\n",
    "# FOSCTTM (subsample)\n",
    "n_total = rna_test_pp.n_obs\n",
    "sub = np.random.default_rng(42).choice(n_total, size=min(20000, n_total), replace=False)\n",
    "fos_mean, fos_sem = foscttm_chunked(Z_rna[sub], Z_atac[sub], block=512)\n",
    "\n",
    "# modality mixing on stacked embeddings (NOT fused duplicates)\n",
    "Z_concat = np.vstack([Z_rna, Z_atac])\n",
    "mods = np.array([\"rna\"]*Z_rna.shape[0] + [\"atac\"]*Z_atac.shape[0], dtype=object)\n",
    "mix = modality_mixing_score(Z_concat, mods, k=30)\n",
    "\n",
    "# label transfer\n",
    "pred_atac, acc_r2a, f1_r2a, cm_r2a, classes = knn_label_transfer(Z_rna,  labels_rna,  Z_atac, labels_atac, k=3)\n",
    "pred_rna,  acc_a2r, f1_a2r, cm_a2r, _       = knn_label_transfer(Z_atac, labels_atac, Z_rna,  labels_rna,  k=3)\n",
    "\n",
    "print(\"FOSCTTM:\", fos_mean, \"±\", fos_sem)\n",
    "print(\"mixing:\", mix)\n",
    "print(\"RNA→ATAC acc/F1:\", acc_r2a, f1_r2a)\n",
    "print(\"ATAC→RNA acc/F1:\", acc_a2r, f1_a2r)\n",
    "\n",
    "plot_confusion(cm_r2a, classes, title=\"Label transfer (RNA→ATAC)\", normalize=\"true\")\n",
    "plot_confusion(cm_a2r, classes, title=\"Label transfer (ATAC→RNA)\", normalize=\"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8124ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(atac_train_lsi.obs['cell_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f30517",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(atac_val_lsi.obs['cell_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188dd32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(atac_test_lsi.obs['cell_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rna_u = rna_test_pp.copy()\n",
    "#atac_u = atac_test_lsi.copy()\n",
    "\n",
    "#rna_u.obs[\"modality\"] = \"rna\"\n",
    "#atac_u.obs[\"modality\"] = \"atac\"\n",
    "\n",
    "#combo = ad.concat([rna_u, atac_u], join=\"outer\", label=\"modality\", keys=[\"rna\",\"atac\"], index_unique=\"-\")\n",
    "\n",
    "# IMPORTANT: put the correct latent for each half\n",
    "#combo.obsm[\"X_univi_sep\"] = np.vstack([Z_rna, Z_atac]).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df585d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbors/umap on the *separate* stacked latent\n",
    "#sc.pp.neighbors(combo, use_rep=\"X_univi_sep\", n_neighbors=15)\n",
    "#sc.tl.umap(combo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7086fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) UMAPs\n",
    "#sc.pl.umap(combo, color=[\"modality\"], frameon=False, size=25.0)\n",
    "#sc.pl.umap(combo, color=[celltype_key], frameon=False, size=25.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5fc74",
   "metadata": {},
   "source": [
    "### Figure 4G–H: cross-modal prediction panels (interpretable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc4cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Predict ATAC-LSI from RNA, and RNA from ATAC-LSI\n",
    "# If ue.cross_modal_predict exists in your version, use it; otherwise use your helper.\n",
    "try:\n",
    "    X_atac_hat = ue.cross_modal_predict(model, rna_test_pp, \"rna\", \"atac\", device=device, batch_size=1024)\n",
    "    X_rna_hat  = ue.cross_modal_predict(model, atac_test_lsi, \"atac\", \"rna\", device=device, batch_size=1024)\n",
    "except Exception:\n",
    "    # fallback: use your cross_modal_predict_subset and request all features\n",
    "    X_atac_hat = cross_modal_predict_subset(model, rna_test_pp, \"rna\", \"atac\",\n",
    "                                           feat_idx=np.arange(atac_test_lsi.n_vars),\n",
    "                                           device=device, batch_size=1024)\n",
    "    X_rna_hat  = cross_modal_predict_subset(model, atac_test_lsi, \"atac\", \"rna\",\n",
    "                                           feat_idx=np.arange(rna_test_pp.n_vars),\n",
    "                                           device=device, batch_size=1024)\n",
    "\n",
    "X_atac_obs = np.asarray(atac_test_lsi.X, dtype=np.float32)\n",
    "X_rna_obs  = np.asarray(rna_test_pp.X.toarray() if sp.issparse(rna_test_pp.X) else rna_test_pp.X, dtype=np.float32)\n",
    "\n",
    "# 2) Pick a few LSI dims to show as \"accessibility programs\"\n",
    "lsi_dims = [0, 1, 2, 3]  # choose ones that look biological; you can rank by variance too\n",
    "\n",
    "for d in lsi_dims:\n",
    "    rna_test_pp.obs[f\"ATAC_LSI{d}_obs\"] = X_atac_obs[:, d]\n",
    "    rna_test_pp.obs[f\"ATAC_LSI{d}_hat\"] = X_atac_hat[:, d]\n",
    "\n",
    "# ensure you have a UMAP basis to plot on (use the shared latent UMAP for consistency)\n",
    "if \"X_umap\" not in rna_test_pp.obsm:\n",
    "    tmp = rna_test_pp.copy()\n",
    "    sc.pp.neighbors(tmp, use_rep=\"X_univi\", n_neighbors=15)\n",
    "    sc.tl.umap(tmp)\n",
    "    rna_test_pp.obsm[\"X_umap\"] = tmp.obsm[\"X_umap\"].copy()\n",
    "\n",
    "# plot obs vs predicted for LSI programs (nice 2×4 grid)\n",
    "keys = []\n",
    "for d in lsi_dims:\n",
    "    keys += [f\"ATAC_LSI{d}_obs\", f\"ATAC_LSI{d}_hat\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e5368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scanpy defaults (affects sc.pl.*)\n",
    "sc.set_figure_params(\n",
    "    figsize=(10, 8),    # bigger canvas\n",
    "    dpi=100,            # on-screen sharpness\n",
    "    dpi_save=300,       # saved file sharpness\n",
    "    fontsize=10,\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "# Matplotlib defaults (affects plt.*)\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (10, 8),\n",
    "    \"figure.dpi\": 100,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"savefig.pad_inches\": 0.1,\n",
    "    \"axes.titlesize\": 12,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"legend.fontsize\": 10,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1cb024",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "rna_u = rna_test_pp.copy()\n",
    "atac_u = atac_test_lsi.copy()\n",
    "\n",
    "rna_u.obs[\"modality\"] = \"rna\"\n",
    "atac_u.obs[\"modality\"] = \"atac\"\n",
    "\n",
    "combo = ad.concat([rna_u, atac_u], join=\"outer\", label=\"modality\", keys=[\"rna\",\"atac\"], index_unique=\"-\")\n",
    "\n",
    "# IMPORTANT: put the correct latent for each half\n",
    "combo.obsm[\"X_univi_sep\"] = np.vstack([Z_rna, Z_atac]).astype(np.float32)\n",
    "\n",
    "# neighbors/umap on the *separate* stacked latent\n",
    "sc.pp.neighbors(combo, use_rep=\"X_univi_sep\", n_neighbors=15)\n",
    "sc.tl.umap(combo)\n",
    "\n",
    "# plot UMAPs\n",
    "sc.pl.umap(combo, color=[\"modality\"], frameon=False, size=25.0)\n",
    "sc.pl.umap(combo, color=[celltype_key], frameon=False, size=25.0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec17afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rna_test_pp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e970ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pl.umap(combo, color=keys, ncols=4, frameon=False, size=75, wspace=0.25)\n",
    "#sc.pl.embedding(rna_test_pp, color='cell_type', ncols=4, frameon=False, basis='X_umap', size=75, wspace=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af484d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_markers = [\"IL7R\",\"CCR7\",\"NKG7\",\"GNLY\",\"MS4A1\",\"CD74\",\"LYZ\",\"S100A9\"]\n",
    "rna_markers = [g for g in rna_markers if g in rna_test_pp.var_names]\n",
    "\n",
    "for g in rna_markers:\n",
    "    j = rna_test_pp.var_names.get_loc(g)\n",
    "    rna_test_pp.obs[f\"RNA_{g}_obs\"] = X_rna_obs[:, j]\n",
    "    rna_test_pp.obs[f\"RNA_{g}_hat\"] = X_rna_hat[:, j]\n",
    "\n",
    "keys = []\n",
    "for g in rna_markers[:6]:\n",
    "    keys += [f\"RNA_{g}_obs\", f\"RNA_{g}_hat\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e8fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pl.umap(rna_test_pp, color=keys, ncols=4, frameon=False, size=75, wspace=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_per_feature(X, Y):\n",
    "    X = np.asarray(X, dtype=np.float32); Y = np.asarray(Y, dtype=np.float32)\n",
    "    Xc = X - X.mean(axis=0, keepdims=True)\n",
    "    Yc = Y - Y.mean(axis=0, keepdims=True)\n",
    "    num = (Xc * Yc).sum(axis=0)\n",
    "    den = np.sqrt((Xc**2).sum(axis=0) * (Yc**2).sum(axis=0)) + 1e-8\n",
    "    return num / den\n",
    "\n",
    "r_lsi = pearson_per_feature(X_atac_obs, X_atac_hat)\n",
    "r_rna = pearson_per_feature(X_rna_obs,  X_rna_hat)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(r_lsi, bins=50)\n",
    "plt.title(\"RNA→ATAC (LSI) per-dimension Pearson r\")\n",
    "plt.xlabel(\"r\"); plt.ylabel(\"# dims\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(r_rna, bins=50)\n",
    "plt.title(\"ATAC→RNA per-gene Pearson r\")\n",
    "plt.xlabel(\"r\"); plt.ylabel(\"# genes\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out many of each cell type are in the test set for level 2 cell annotations\n",
    "print(rna_test_pp.obs[\"cell_type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df3949",
   "metadata": {},
   "source": [
    "### All evaluation metrics beyond just the UMAP embeddings of the shared test set latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# ----------------------------\n",
    "# User settings\n",
    "# ----------------------------\n",
    "outdir = \"figures/Figure4_Multiome_eval_reproducibility\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "celltype_key = \"cell_type\"   # change to celltype.l1 / celltype.l3 as needed\n",
    "k_mix = 20                     # k for modality mixing\n",
    "k_lt  = 3                      # k for label transfer kNN\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PRE-FLIGHT CHECK + FIX (run once right before metrics/plots) ----------\n",
    "def _preflight_align_for_metrics(\n",
    "    rna_test_pp, adt_test_pp, Z_rna, Z_adt, celltype_key=\"cell_type\"\n",
    "):\n",
    "    import numpy as np\n",
    "\n",
    "    # 1) basic shape checks\n",
    "    print(\"rna_test_pp n_obs:\", rna_test_pp.n_obs)\n",
    "    print(\"adt_test_pp n_obs:\", adt_test_pp.n_obs)\n",
    "    print(\"Z_rna shape:\", np.asarray(Z_rna).shape)\n",
    "    print(\"Z_adt shape:\", np.asarray(Z_adt).shape)\n",
    "\n",
    "    # 2) enforce pairing by obs_names intersection (preserves RNA order)\n",
    "    common = rna_test_pp.obs_names.intersection(adt_test_pp.obs_names)\n",
    "    if len(common) != rna_test_pp.n_obs or len(common) != adt_test_pp.n_obs:\n",
    "        print(f\"[preflight] restricting to common paired cells: {len(common)}\")\n",
    "\n",
    "    rna_al = rna_test_pp[common].copy()\n",
    "    adt_al = adt_test_pp[common].copy()\n",
    "    adt_al = adt_al[rna_al.obs_names].copy()  # force identical order\n",
    "\n",
    "    # 3) slice Z arrays to match aligned AnnData order (assumes Z were computed in the same order)\n",
    "    # If your Z were computed from rna_test_pp/adt_test_pp directly, this is safe.\n",
    "    # If not, you *must* recompute Z after alignment.\n",
    "    if np.asarray(Z_rna).shape[0] != rna_al.n_obs or np.asarray(Z_adt).shape[0] != adt_al.n_obs:\n",
    "        raise ValueError(\n",
    "            \"[preflight] Z arrays do not match aligned AnnData n_obs. \"\n",
    "            \"Recompute Z_rna/Z_adt from rna_al/adt_al.\"\n",
    "        )\n",
    "\n",
    "    # 4) labels must come from the SAME objects you predict on\n",
    "    labels_rna = rna_al.obs[celltype_key].astype(str).to_numpy()\n",
    "    labels_adt = adt_al.obs[celltype_key].astype(str).to_numpy()\n",
    "\n",
    "    # 5) final asserts (this prevents your exact error)\n",
    "    assert rna_al.n_obs == adt_al.n_obs\n",
    "    assert (rna_al.obs_names == adt_al.obs_names).all()\n",
    "    assert len(labels_rna) == np.asarray(Z_rna).shape[0]\n",
    "    assert len(labels_adt) == np.asarray(Z_adt).shape[0]\n",
    "\n",
    "    print(\"[preflight] OK: paired, aligned, and lengths match.\")\n",
    "    return rna_al, adt_al, labels_rna, labels_adt\n",
    "\n",
    "\n",
    "# run it:\n",
    "rna_test_pp, atac_test_lsi, labels_rna, labels_atac = _preflight_align_for_metrics(\n",
    "    rna_test_pp, atac_test_lsi, Z_rna, Z_atac, celltype_key=celltype_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from univi.evaluation import encode_adata\n",
    "\n",
    "Z_rna = encode_adata(model, rna_test_pp, modality=\"rna\",\n",
    "                     latent=\"modality_mean\", device=device, batch_size=1024)\n",
    "Z_atac = encode_adata(model, atac_test_lsi, modality=\"atac\",\n",
    "                     latent=\"modality_mean\", device=device, batch_size=1024)\n",
    "\n",
    "key_rna = \"encode_adata(modality_mean)\"\n",
    "key_atac = \"encode_adata(modality_mean)\"\n",
    "\n",
    "rna_test_pp.obsm[\"X_univi_rna\"] = Z_rna\n",
    "atac_test_lsi.obsm[\"X_univi_atac\"] = Z_atac\n",
    "\n",
    "\n",
    "print(\"max|Z_rna-Z_atac|:\", float(np.max(np.abs(Z_rna - Z_atac))))\n",
    "print(\"mean L2(Z_rna-Z_atac):\", float(np.mean(np.linalg.norm(Z_rna - Z_atac, axis=1))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0dc341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Compute metrics (test model performance)\n",
    "# ----------------------------\n",
    "\n",
    "# 0) Fused latent (if you truly want it)\n",
    "#Z_fused = np.asarray(combo.obsm[\"X_univi\"])\n",
    "#mods_fused = combo.obs[\"modality\"].to_numpy()\n",
    "Z_fused = np.asarray(combo.obsm[\"X_univi\"])\n",
    "mods_fused = combo.obs[\"modality\"].to_numpy()\n",
    "\n",
    "# derive cell_ids that are identical for RNA+ADT copies\n",
    "# works with index_unique=\"-\" that produces \"<orig>-rna\" / \"<orig>-adt\"\n",
    "cell_ids = combo.obs_names.to_series().str.rsplit(\"-\", n=1).str[0].to_numpy()\n",
    "\n",
    "mix_fused = modality_mixing_score_excluding_pairs(Z_fused, mods_fused, cell_ids, k=k_mix)\n",
    "\n",
    "# 1) Modality-specific latents (Z_rna, Z_atac) already computed above\n",
    "\n",
    "\n",
    "# 2) FOSCTTM on modality-specific latents (subsample ok)\n",
    "n_total = int(rna_test_pp.n_obs)\n",
    "n_fos = int(min(20000, n_total))\n",
    "rng = np.random.default_rng(seed)\n",
    "sub = rng.choice(n_total, size=n_fos, replace=False)\n",
    "\n",
    "fos_rna_atac, fos_sem = foscttm_chunked(Z_rna[sub], Z_atac[sub], block=512)\n",
    "\n",
    "# 3) Modality mixing on modality-specific latents\n",
    "Z_concat = np.vstack([Z_rna, Z_atac])\n",
    "mods = np.array([\"rna\"] * Z_rna.shape[0] + [\"atac\"] * Z_atac.shape[0], dtype=object)\n",
    "mix_modality_specific = modality_mixing_score(Z_concat, mods, k=k_mix)\n",
    "\n",
    "# 4) Label transfer (modality-specific)\n",
    "# Make labels that match each embedding 1:1\n",
    "labels_rna = rna_test_pp.obs[celltype_key].astype(str).to_numpy()\n",
    "labels_atac = atac_test_lsi.obs[celltype_key].astype(str).to_numpy()\n",
    "\n",
    "assert Z_rna.shape[0] == labels_rna.shape[0], (Z_rna.shape, labels_rna.shape)\n",
    "assert Z_atac.shape[0] == labels_atac.shape[0], (Z_atac.shape, labels_atac.shape)\n",
    "\n",
    "pred_atac, acc_r2a, f1_r2a, cm_r2a, classes = knn_label_transfer(\n",
    "    Z_source=Z_rna, y_source=labels_rna,\n",
    "    Z_target=Z_atac, y_target=labels_atac,\n",
    "    k=k_lt\n",
    ")\n",
    "pred_rna, acc_a2r, f1_a2r, cm_a2r, _ = knn_label_transfer(\n",
    "    Z_source=Z_atac, y_source=labels_atac,\n",
    "    Z_target=Z_rna, y_target=labels_rna,\n",
    "    k=k_lt\n",
    ")\n",
    "\n",
    "metrics = {\n",
    "    \"embedding_keys\": {\"rna\": key_rna, \"atac\": key_atac, \"fused\": \"combo.obsm['X_univi']\"},\n",
    "    \"n_test\": n_total,\n",
    "    \"celltype_key\": celltype_key,\n",
    "\n",
    "    \"FOSCTTM_metric\": \"euclidean_sq\",\n",
    "    \"FOSCTTM_subsample_n\": n_fos,\n",
    "    \"FOSCTTM_rna_vs_atac_mean\": float(fos_rna_atac),\n",
    "    \"FOSCTTM_rna_vs_atac_sem\": float(fos_sem),\n",
    "\n",
    "    \"modality_mixing_k\": int(k_mix),\n",
    "    \"modality_mixing_fused\": float(mix_fused),\n",
    "    \"modality_mixing_modality_specific\": float(mix_modality_specific),\n",
    "\n",
    "    \"label_transfer_k\": int(k_lt),\n",
    "    \"label_transfer_rna_to_atac_acc\": float(acc_r2a),\n",
    "    \"label_transfer_rna_to_atac_macroF1\": float(f1_r2a),\n",
    "    \"label_transfer_atac_to_rna_acc\": float(acc_a2r),\n",
    "    \"label_transfer_atac_to_rna_macroF1\": float(f1_a2r),\n",
    "}\n",
    "\n",
    "print(json.dumps(metrics, indent=2))\n",
    "with open(os.path.join(outdir, \"figure4_metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "pd.DataFrame([metrics]).to_csv(os.path.join(outdir, \"figure4_metrics.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2197b057",
   "metadata": {},
   "source": [
    "### Peaks → Gene Activity (promoter-based) code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def build_promoters_from_gtf(\n",
    "    gtf_path,\n",
    "    *,\n",
    "    upstream=2000,\n",
    "    downstream=500,\n",
    "    use_feature=\"gene\",\n",
    "    gene_name_col=\"gene_name\",\n",
    "    gene_id_col=\"gene_id\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Load GTF via PyRanges and construct promoter intervals around TSS.\n",
    "    Uses '+' strand TSS=Start, '-' strand TSS=End.\n",
    "    Returns DataFrame with Chromosome, Start, End, Strand, gene_name, gene_id.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import pyranges as pr\n",
    "    except ImportError as e:\n",
    "        raise ImportError(\"Please `pip install pyranges` to use gene activity.\") from e\n",
    "\n",
    "    gr = pr.read_gtf(gtf_path)\n",
    "    df = gr.df\n",
    "\n",
    "    if \"Feature\" not in df.columns:\n",
    "        raise ValueError(\"Unexpected GTF columns; expected a 'Feature' column.\")\n",
    "    df = df[df[\"Feature\"] == use_feature].copy()\n",
    "\n",
    "    # keep only standard chromosomes if you want (optional)\n",
    "    # df = df[df[\"Chromosome\"].astype(str).str.match(r\"^chr(\\d+|X|Y|M)$\")]\n",
    "\n",
    "    if gene_name_col not in df.columns:\n",
    "        # fall back to gene_id as name if needed\n",
    "        df[gene_name_col] = df.get(gene_id_col, df[\"gene_id\"] if \"gene_id\" in df.columns else \"gene\")\n",
    "\n",
    "    # Compute TSS and promoter bounds\n",
    "    tss = np.where(df[\"Strand\"].values == \"+\", df[\"Start\"].values, df[\"End\"].values)\n",
    "    pstart = (tss - int(upstream)).astype(np.int64)\n",
    "    pend   = (tss + int(downstream)).astype(np.int64)\n",
    "    pstart[pstart < 0] = 0\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"Chromosome\": df[\"Chromosome\"].astype(str).values,\n",
    "        \"Start\": pstart,\n",
    "        \"End\": pend,\n",
    "        \"Strand\": df[\"Strand\"].astype(str).values,\n",
    "        \"gene_name\": df[gene_name_col].astype(str).values,\n",
    "        \"gene_id\": df[gene_id_col].astype(str).values if gene_id_col in df.columns else df[gene_name_col].astype(str).values,\n",
    "    })\n",
    "\n",
    "    # drop duplicate gene_name promoters (keep first) to avoid double counting\n",
    "    out = out.drop_duplicates(subset=[\"gene_name\"], keep=\"first\").reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "def make_peak_to_gene_map(\n",
    "    atac_adata,\n",
    "    promoters_df,\n",
    "    *,\n",
    "    prefer_nearest_tss=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a sparse peaks->genes mapping matrix M (n_peaks x n_genes).\n",
    "    If prefer_nearest_tss=True, assign each peak to the nearest overlapping promoter (by distance to TSS proxy),\n",
    "    otherwise a peak can contribute to multiple genes (not usually desired).\n",
    "    Returns: (M_csr, gene_names)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import pyranges as pr\n",
    "    except ImportError as e:\n",
    "        raise ImportError(\"Please `pip install pyranges` to use gene activity.\") from e\n",
    "\n",
    "    peaks_df = _parse_peak_varnames(atac_adata.var_names)\n",
    "    peaks_df[\"peak_idx\"] = np.arange(peaks_df.shape[0], dtype=np.int64)\n",
    "\n",
    "    prom = promoters_df.copy()\n",
    "    prom[\"gene_idx\"] = pd.Index(prom[\"gene_name\"]).factorize()[0]\n",
    "    # factorize above is stable but we want explicit ordering:\n",
    "    gene_names = prom[\"gene_name\"].to_numpy()\n",
    "    gene_to_idx = {g:i for i,g in enumerate(gene_names)}\n",
    "    prom[\"gene_idx\"] = prom[\"gene_name\"].map(gene_to_idx).astype(np.int64)\n",
    "\n",
    "    gr_peaks = pr.PyRanges(peaks_df[[\"Chromosome\",\"Start\",\"End\",\"peak_idx\"]])\n",
    "    gr_prom  = pr.PyRanges(prom[[\"Chromosome\",\"Start\",\"End\",\"Strand\",\"gene_name\",\"gene_idx\"]])\n",
    "\n",
    "    ov = gr_peaks.join(gr_prom).df\n",
    "    if ov.empty:\n",
    "        raise ValueError(\"No peak↔promoter overlaps found. Check genome build / chr naming / promoter window sizes.\")\n",
    "\n",
    "    # If desired: pick a single gene per peak among overlaps (nearest promoter midpoint as proxy)\n",
    "    if prefer_nearest_tss:\n",
    "        # promoter midpoint proxy\n",
    "        ov[\"prom_mid\"] = ((ov[\"Start_b\"].values + ov[\"End_b\"].values) / 2.0)\n",
    "        peak_mid = ((ov[\"Start\"].values + ov[\"End\"].values) / 2.0)\n",
    "        ov[\"dist\"] = np.abs(peak_mid - ov[\"prom_mid\"])\n",
    "        ov = ov.sort_values([\"peak_idx\",\"dist\"]).drop_duplicates(\"peak_idx\", keep=\"first\")\n",
    "\n",
    "    n_peaks = atac_adata.n_vars\n",
    "    n_genes = len(gene_names)\n",
    "\n",
    "    rows = ov[\"peak_idx\"].to_numpy(dtype=np.int64)\n",
    "    cols = ov[\"gene_idx\"].to_numpy(dtype=np.int64)\n",
    "    data = np.ones(rows.shape[0], dtype=np.float32)\n",
    "\n",
    "    M = sp.csr_matrix((data, (rows, cols)), shape=(n_peaks, n_genes))\n",
    "    return M, gene_names\n",
    "\n",
    "def compute_gene_activity_adata(\n",
    "    atac_adata,\n",
    "    peak_to_gene_map,\n",
    "    gene_names,\n",
    "    *,\n",
    "    counts_layer=\"counts\",\n",
    "    binarize=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute gene activity matrix (cells x genes) using sparse matmul:\n",
    "      GA = ATAC_counts (cells x peaks) @ M (peaks x genes)\n",
    "\n",
    "    Returns AnnData with X = GA (sparse), var_names = gene_names, obs copied.\n",
    "    \"\"\"\n",
    "    Xp = atac_adata.layers[counts_layer] if counts_layer in atac_adata.layers else atac_adata.X\n",
    "    if not sp.issparse(Xp):\n",
    "        Xp = sp.csr_matrix(Xp)\n",
    "\n",
    "    if binarize:\n",
    "        Xp = Xp.copy()\n",
    "        Xp.data[:] = 1.0\n",
    "\n",
    "    GA = Xp @ peak_to_gene_map  # (cells x genes) sparse\n",
    "    GA = GA.tocsr()\n",
    "\n",
    "    ga = ad.AnnData(\n",
    "        X=GA,\n",
    "        obs=atac_adata.obs.copy(),\n",
    "        var=pd.DataFrame(index=pd.Index(gene_names, name=\"gene\")),\n",
    "    )\n",
    "    return ga\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89335b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_peak_varnames(varnames):\n",
    "    \"\"\"\n",
    "    Parse ATAC peak names into (Chromosome, Start, End).\n",
    "\n",
    "    Expected *core* pattern somewhere in each name:\n",
    "        'chrX:123-456'\n",
    "\n",
    "    If a name can't be parsed, we assign dummy coordinates\n",
    "    'chrUn:0-1' so it won't overlap any promoters, but we keep\n",
    "    array length == n_peaks (so downstream matrices still align).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    peaks_df : DataFrame with columns ['Chromosome','Start','End']\n",
    "               length == len(varnames)\n",
    "    \"\"\"\n",
    "    chrom = []\n",
    "    start = []\n",
    "    end   = []\n",
    "    bad   = []\n",
    "\n",
    "    # regex that finds 'chr...:start-end' anywhere\n",
    "    pat = re.compile(r\"(chr[0-9XYM]+):(\\d+)-(\\d+)\")\n",
    "\n",
    "    for v in varnames:\n",
    "        m = pat.search(v)\n",
    "        if m:\n",
    "            c, s, e = m.groups()\n",
    "            chrom.append(c)\n",
    "            start.append(int(s))\n",
    "            end.append(int(e))\n",
    "        else:\n",
    "            bad.append(v)\n",
    "            # dummy coord that won't intersect any promoter\n",
    "            chrom.append(\"chrUn\")\n",
    "            start.append(0)\n",
    "            end.append(1)\n",
    "\n",
    "    if bad:\n",
    "        print(f\"[parse peaks] WARNING: could not parse {len(bad)} peaks; \"\n",
    "              \"assigned dummy coords 'chrUn:0-1'. Examples:\")\n",
    "        for b in bad[:10]:\n",
    "            print(\"   \", b)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\"Chromosome\": chrom, \"Start\": start, \"End\": end},\n",
    "        index=pd.Index(varnames, name=\"peak_id\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfbb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "GTF_PATH = \"/home/groups/precepts/ashforda/scOPE_github_stuff/data/reference/Homo_sapiens_GRCh38.p13.gencode.annotation.gtf\"\n",
    "\n",
    "# 1) build promoters from GTF\n",
    "promoters = build_promoters_from_gtf(\n",
    "    GTF_PATH,\n",
    "    upstream=2000,\n",
    "    downstream=500,\n",
    "    use_feature=\"gene\",   # typical\n",
    ")\n",
    "\n",
    "# 2) build peak→gene mapping using TRAIN peaks (assumes peaks identical across splits)\n",
    "M_peak_gene, gene_names = make_peak_to_gene_map(atac_train, promoters, prefer_nearest_tss=True)\n",
    "\n",
    "# 3) compute gene activity matrices for each split\n",
    "atac_train_ga = compute_gene_activity_adata(atac_train, M_peak_gene, gene_names, counts_layer=\"counts\", binarize=False)\n",
    "atac_val_ga   = compute_gene_activity_adata(atac_val,   M_peak_gene, gene_names, counts_layer=\"counts\", binarize=False)\n",
    "atac_test_ga  = compute_gene_activity_adata(atac_test,  M_peak_gene, gene_names, counts_layer=\"counts\", binarize=False)\n",
    "\n",
    "# pairing sanity\n",
    "assert (rna_train.obs_names == atac_train_ga.obs_names).all()\n",
    "assert (rna_val.obs_names   == atac_val_ga.obs_names).all()\n",
    "assert (rna_test.obs_names  == atac_test_ga.obs_names).all()\n",
    "\n",
    "print(atac_train_ga, atac_val_ga, atac_test_ga)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_gene_activity_gaussian(ga_adata, target_sum=1e4, log1p=True):\n",
    "    ga = ga_adata.copy()\n",
    "    # normalize_total works on .X if it's sparse\n",
    "    sc.pp.normalize_total(ga, target_sum=float(target_sum))\n",
    "    if log1p:\n",
    "        sc.pp.log1p(ga)\n",
    "    return ga\n",
    "\n",
    "atac_train_ga_pp = preprocess_gene_activity_gaussian(atac_train_ga, target_sum=1e4, log1p=True)\n",
    "atac_val_ga_pp   = preprocess_gene_activity_gaussian(atac_val_ga,   target_sum=1e4, log1p=True)\n",
    "atac_test_ga_pp  = preprocess_gene_activity_gaussian(atac_test_ga,  target_sum=1e4, log1p=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If dimensionality is too large, you can select top variable genes on train\n",
    "# and subset all splits (same as HVG):\n",
    "\n",
    "def subset_hvg_like(train_ga, val_ga, test_ga, n_top=5000):\n",
    "    tmp = train_ga.copy()\n",
    "    sc.pp.highly_variable_genes(tmp, n_top_genes=int(n_top), flavor=\"seurat\")\n",
    "    hv = tmp.var_names[tmp.var[\"highly_variable\"].to_numpy()]\n",
    "    return train_ga[:, hv].copy(), val_ga[:, hv].copy(), test_ga[:, hv].copy()\n",
    "\n",
    "atac_train_ga_pp, atac_val_ga_pp, atac_test_ga_pp = subset_hvg_like(\n",
    "    atac_train_ga_pp, atac_val_ga_pp, atac_test_ga_pp, n_top=5000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\"rna\": rna_train_pp, \"atac\": atac_train_ga_pp}\n",
    "val_dict   = {\"rna\": rna_val_pp,   \"atac\": atac_val_ga_pp}\n",
    "test_dict  = {\"rna\": rna_test_pp,  \"atac\": atac_test_ga_pp}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ba02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scanpy defaults (affects sc.pl.*)\n",
    "sc.set_figure_params(\n",
    "    figsize=(14, 12),   # bigger canvas\n",
    "    dpi=200,            # on-screen sharpness\n",
    "    dpi_save=600,       # saved file sharpness\n",
    "    fontsize=14,\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "# Matplotlib defaults (affects plt.*)\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (14, 12),\n",
    "    \"figure.dpi\": 200,\n",
    "    \"savefig.dpi\": 600,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"savefig.pad_inches\": 0.1,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"legend.fontsize\": 12,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37832a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the split you want to visualize\n",
    "ga = atac_test_ga_pp.copy()\n",
    "\n",
    "# bring over labels from RNA if GA doesn't already have them\n",
    "# (they should match by obs_names because you asserted pairing)\n",
    "if \"cell_type\" in rna_test.obs and \"cell_type\" not in ga.obs:\n",
    "    ga.obs[\"cell_type\"] = rna_test.obs[\"cell_type\"].astype(str).values\n",
    "\n",
    "# neighbors/umap on gene-activity\n",
    "ga.uns.pop(\"neighbors\", None)\n",
    "ga.uns.pop(\"umap\", None)\n",
    "for k in (\"connectivities\", \"distances\"):\n",
    "    if k in ga.obsp:\n",
    "        del ga.obsp[k]\n",
    "\n",
    "sc.pp.pca(ga, n_comps=50)\n",
    "sc.pp.neighbors(ga, use_rep=\"X_pca\", n_neighbors=15)\n",
    "sc.tl.umap(ga)\n",
    "\n",
    "sc.pl.umap(ga, color=[\"cell_type\"], frameon=False, size=75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024d5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PBMC-ish marker set (edit freely)\n",
    "ga_markers = [\n",
    "    \"MS4A1\", \"CD79A\", \"CD74\",     # B\n",
    "    \"NKG7\", \"GNLY\", \"PRF1\",       # NK / cytotoxic\n",
    "    \"LYZ\", \"S100A8\", \"S100A9\",    # mono\n",
    "    \"IL7R\", \"CCR7\", \"LTB\",        # CD4 naive/TCM-ish\n",
    "    \"FCGR3A\", \"LST1\",             # CD16 mono-ish\n",
    "]\n",
    "\n",
    "# keep only genes present\n",
    "ga_markers = [g for g in ga_markers if g in ga.var_names]\n",
    "print(\"GA markers present:\", ga_markers)\n",
    "'''\n",
    "sc.pl.umap(\n",
    "    ga,\n",
    "    color=ga_markers,\n",
    "    frameon=False,\n",
    "    ncols=4,\n",
    "    wspace=0.25,\n",
    "    size=75,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean gene activity per cell type (on your selected markers or top HVGs)\n",
    "genes_for_heatmap = ga_markers  # or use ga.var_names[:200] / etc.\n",
    "\n",
    "X = ga[:, genes_for_heatmap].X\n",
    "if not hasattr(X, \"toarray\"):\n",
    "    X_dense = np.asarray(X)\n",
    "else:\n",
    "    X_dense = X.toarray()\n",
    "\n",
    "df = pd.DataFrame(X_dense, index=ga.obs_names, columns=genes_for_heatmap)\n",
    "df[\"cell_type\"] = ga.obs[\"cell_type\"].astype(str).values\n",
    "\n",
    "pb = df.groupby(\"cell_type\")[genes_for_heatmap].mean()\n",
    "\n",
    "# z-score per gene for visualization\n",
    "pb_z = (pb - pb.mean(axis=0)) / (pb.std(axis=0) + 1e-8)\n",
    "\n",
    "plt.figure(figsize=(0.5 * len(genes_for_heatmap) + 4, 0.35 * pb_z.shape[0] + 3))\n",
    "plt.imshow(pb_z.values, aspect=\"auto\", interpolation=\"nearest\")\n",
    "plt.yticks(np.arange(pb_z.shape[0]), pb_z.index)\n",
    "plt.xticks(np.arange(pb_z.shape[1]), pb_z.columns, rotation=90)\n",
    "plt.colorbar(label=\"z-scored mean gene activity\")\n",
    "plt.title(\"Gene activity pseudo-bulk by cell type\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e331d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use paired test splits\n",
    "ga = atac_test_ga_pp\n",
    "rna = rna_test.copy()\n",
    "\n",
    "# make sure same order\n",
    "common = rna.obs_names.intersection(ga.obs_names)\n",
    "rna = rna[common].copy()\n",
    "ga  = ga[common].copy()\n",
    "ga  = ga[rna.obs_names].copy()\n",
    "\n",
    "# choose shared genes\n",
    "shared = np.intersect1d(rna.var_names.astype(str), ga.var_names.astype(str))\n",
    "shared = shared[:2000]  # keep it light; or pick markers\n",
    "print(\"n shared genes:\", len(shared))\n",
    "\n",
    "# pull matrices\n",
    "Xr = rna[:, shared].X\n",
    "Xg = ga[:, shared].X\n",
    "if hasattr(Xr, \"toarray\"): Xr = Xr.toarray()\n",
    "if hasattr(Xg, \"toarray\"): Xg = Xg.toarray()\n",
    "Xr = np.asarray(Xr, dtype=np.float32)\n",
    "Xg = np.asarray(Xg, dtype=np.float32)\n",
    "\n",
    "# per-gene Pearson (obs vs GA)\n",
    "Xr_c = Xr - Xr.mean(axis=0, keepdims=True)\n",
    "Xg_c = Xg - Xg.mean(axis=0, keepdims=True)\n",
    "num = (Xr_c * Xg_c).sum(axis=0)\n",
    "den = np.sqrt((Xr_c**2).sum(axis=0) * (Xg_c**2).sum(axis=0)) + 1e-8\n",
    "r = num / den\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(r, bins=60)\n",
    "plt.xlabel(\"Pearson r (RNA vs gene activity), per gene\")\n",
    "plt.ylabel(\"# genes\")\n",
    "plt.title(\"RNA↔Gene-activity agreement (paired test)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# show top genes\n",
    "top = np.argsort(r)[-20:][::-1]\n",
    "print(pd.DataFrame({\"gene\": shared[top], \"pearson_r\": r[top]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: use gene activity as atac modality adata in your UniVI pipeline\n",
    "atac_train_use = atac_train_ga_pp\n",
    "atac_val_use   = atac_val_ga_pp\n",
    "atac_test_use  = atac_test_ga_pp\n",
    "\n",
    "print(atac_train_use, atac_val_use, atac_test_use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949d7a96",
   "metadata": {},
   "source": [
    "### Other Figure 4/supplemental figures stuff for Multiome analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab82ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1) modality-specific latents (separate encoders)\n",
    "# ------------------------------------------------------\n",
    "Z_rna = encode_adata(\n",
    "    model, rna_test_pp,\n",
    "    modality=\"rna\",\n",
    "    latent=\"modality_mean\",   # <- RNA encoder mean\n",
    "    device=device,\n",
    "    batch_size=1024,\n",
    ")\n",
    "\n",
    "Z_atac = encode_adata(\n",
    "    model, atac_test_lsi,\n",
    "    modality=\"atac\",\n",
    "    latent=\"modality_mean\",   # <- ATAC encoder mean\n",
    "    device=device,\n",
    "    batch_size=1024,\n",
    ")\n",
    "\n",
    "assert Z_rna.shape == Z_atac.shape\n",
    "assert (rna_test_pp.obs_names == atac_test_lsi.obs_names).all()\n",
    "\n",
    "# (optional sanity: they should NOT be identical if truly modality-specific)\n",
    "print(\"mean L2(Z_rna - Z_adt):\", float(np.mean(np.linalg.norm(Z_rna - Z_atac, axis=1))))\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2) build combo and overlay the *two different* embeddings\n",
    "# ------------------------------------------------------\n",
    "rna_u = rna_test_pp.copy()\n",
    "atac_u = atac_test_lsi.copy()\n",
    "rna_u.obs[\"modality\"] = \"rna\"\n",
    "atac_u.obs[\"modality\"] = \"atac\"\n",
    "\n",
    "combo = ad.concat([rna_u, atac_u], join=\"outer\", index_unique=\"-\")\n",
    "\n",
    "# IMPORTANT: this is the embedding you’ll use for UMAP/plots\n",
    "combo.obsm[\"X_latent\"] = np.vstack([Z_rna, Z_atac])\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3) one UMAP on the stacked embedding\n",
    "# ------------------------------------------------------\n",
    "# clear stale graphs if re-running\n",
    "for key in (\"neighbors\", \"umap\"):\n",
    "    combo.uns.pop(key, None)\n",
    "for k in (\"connectivities\", \"distances\"):\n",
    "    if k in combo.obsp:\n",
    "        del combo.obsp[k]\n",
    "\n",
    "sc.pp.neighbors(combo, use_rep=\"X_latent\", n_neighbors=15)\n",
    "sc.tl.umap(combo, min_dist=0.5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check: do the two modalities overlay?\n",
    "sc.pl.umap(combo, color=[\"modality\"], frameon=False, size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check: do the two modalities overlay?\n",
    "sc.pl.umap(combo, color=[\"cell_type\"], frameon=False, size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1750389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import anndata as ad\n",
    "#import numpy as np\n",
    "#import scanpy as sc\n",
    "\n",
    "rna_u  = rna_test_pp.copy()\n",
    "atac_u = atac_test_lsi.copy()\n",
    "rna_u.obs[\"modality\"]  = \"rna\"\n",
    "atac_u.obs[\"modality\"] = \"atac\"\n",
    "\n",
    "combo = ad.concat([rna_u, atac_u], join=\"outer\", index_unique=\"-\")\n",
    "combo.obsm[\"X_latent\"] = np.vstack([Z_rna, Z_atac]).astype(np.float32)\n",
    "\n",
    "sc.pp.neighbors(combo, use_rep=\"X_latent\", n_neighbors=15)\n",
    "sc.tl.umap(combo, min_dist=0.5, random_state=0)\n",
    "\n",
    "# same embedding, different colorings:\n",
    "sc.pl.umap(combo, color=\"modality\", ncols=2, wspace=0.35, frameon=False, size=50)\n",
    "sc.pl.umap(combo, color=\"cell_type\", ncols=2, wspace=0.35, frameon=False, size=50)\n",
    "\n",
    "# RNA expression: plot only RNA rows (cleanest)\n",
    "#sc.pl.umap(combo[combo.obs[\"modality\"]==\"rna\"], color=[\"NKG7\",\"MS4A1\"], frameon=False, size=50)\n",
    "\n",
    "# ATAC programs/LSI: plot only ATAC rows (cleanest)\n",
    "#sc.pl.umap(combo[combo.obs[\"modality\"]==\"atac\"], color=[\"LSI_0\",\"LSI_1\"], frameon=False, size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c023062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def cross_modal_predict_all(\n",
    "    model,\n",
    "    adata_src,\n",
    "    src_mod,\n",
    "    tgt_mod,\n",
    "    *,\n",
    "    device=\"cpu\",\n",
    "    batch_size=512,\n",
    "    X_key=\"X\",\n",
    "    layer=None,\n",
    "    use_moe=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Predict target-modality features for ALL cells in adata_src using UniVI.\n",
    "    Returns a (n_cells, n_tgt_features) float32 numpy array.\n",
    "    \"\"\"\n",
    "    from univi.data import _get_matrix\n",
    "\n",
    "    model.eval()\n",
    "    dev = torch.device(device)\n",
    "\n",
    "    X = _get_matrix(adata_src, layer=layer, X_key=X_key)\n",
    "    if sp.issparse(X):\n",
    "        X = X.toarray()\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "\n",
    "    outs = []\n",
    "    for start in range(0, X.shape[0], int(batch_size)):\n",
    "        end = min(start + int(batch_size), X.shape[0])\n",
    "        xb = torch.as_tensor(X[start:end], dtype=torch.float32, device=dev)\n",
    "\n",
    "        mu_dict, logvar_dict = model.encode_modalities({src_mod: xb})\n",
    "\n",
    "        if use_moe and hasattr(model, \"mixture_of_experts\"):\n",
    "            mu_z, _ = model.mixture_of_experts(mu_dict, logvar_dict)\n",
    "        else:\n",
    "            mu_z = mu_dict[src_mod]\n",
    "\n",
    "        xhat = model.decode_modalities(mu_z)[tgt_mod]\n",
    "        outs.append(xhat.detach().cpu().numpy())\n",
    "\n",
    "    return np.vstack(outs).astype(np.float32, copy=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78397768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy.sparse as sp\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "# 0) assume paired + aligned\n",
    "assert (rna_test_pp.obs_names == atac_test_lsi.obs_names).all()\n",
    "\n",
    "# 1) make combo + embedding (use your existing Z_rna/Z_atac)\n",
    "rna_u = rna_test_pp.copy();  rna_u.obs[\"modality\"]  = \"rna\"\n",
    "atac_u = atac_test_lsi.copy(); atac_u.obs[\"modality\"] = \"atac\"\n",
    "\n",
    "combo = ad.concat([rna_u, atac_u], join=\"outer\", index_unique=\"-\")\n",
    "combo.obsm[\"X_latent\"] = np.vstack([Z_rna, Z_atac]).astype(np.float32)\n",
    "\n",
    "# compute 2D UMAP once (stored in combo.obsm[\"X_umap\"])\n",
    "sc.pp.neighbors(combo, use_rep=\"X_latent\", n_neighbors=15)\n",
    "sc.tl.umap(combo, min_dist=0.5, random_state=0)\n",
    "\n",
    "# 2) observed ATAC (LSI space)\n",
    "A_obs = atac_test_lsi.X\n",
    "if sp.issparse(A_obs): A_obs = A_obs.toarray()\n",
    "A_obs = np.asarray(A_obs, dtype=np.float32)\n",
    "\n",
    "# 3) predicted ATAC from RNA (same LSI dim count)\n",
    "A_hat = cross_modal_predict_all(\n",
    "    model, rna_test_pp, src_mod=\"rna\", tgt_mod=\"atac\",\n",
    "    device=device, batch_size=512\n",
    ").astype(np.float32)\n",
    "\n",
    "assert A_hat.shape == A_obs.shape\n",
    "\n",
    "# 4) write obs/hat scalars onto the correct modality rows in combo\n",
    "mods = combo.obs[\"modality\"].astype(str).to_numpy()\n",
    "is_rna  = (mods == \"rna\")\n",
    "is_atac = (mods == \"atac\")\n",
    "\n",
    "dims = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "#dims = [36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n",
    "\n",
    "for j in dims:\n",
    "    combo.obs[f\"ATAC_LSI_{j}_obs\"] = np.nan\n",
    "    combo.obs[f\"ATAC_LSI_{j}_hat\"] = np.nan\n",
    "    combo.obs.loc[combo.obs_names[is_atac], f\"ATAC_LSI_{j}_obs\"] = A_obs[:, j]\n",
    "    combo.obs.loc[combo.obs_names[is_rna],  f\"ATAC_LSI_{j}_hat\"] = A_hat[:, j]\n",
    "\n",
    "# 5) plot on SAME embedding\n",
    "for j in dims:\n",
    "    sc.pl.umap(\n",
    "        combo,\n",
    "        color=[f\"ATAC_LSI_{j}_obs\", f\"ATAC_LSI_{j}_hat\"],\n",
    "        ncols=2, wspace=0.35, size=50, frameon=False\n",
    "    )\n",
    "\n",
    "# also show the embedding itself\n",
    "sc.pl.umap(combo, color=[\"modality\", \"cell_type\"], ncols=2, wspace=0.35, size=50, frameon=False)\n",
    "\n",
    "# per-cell RMSE across chosen dims (on RNA rows)\n",
    "J = np.array(dims, dtype=int)\n",
    "rmse = np.sqrt(((A_hat[:, J] - A_obs[:, J])**2).mean(axis=1)).astype(np.float32)\n",
    "\n",
    "combo.obs[\"ATAC_LSI_rmse\"] = np.nan\n",
    "combo.obs.loc[combo.obs_names[is_rna], \"ATAC_LSI_rmse\"] = rmse\n",
    "\n",
    "sc.pl.umap(combo, color=[\"ATAC_LSI_rmse\"], frameon=False, size=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905db350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy.sparse as sp\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "# 0) assume paired + aligned\n",
    "assert (rna_test_pp.obs_names == atac_test_lsi.obs_names).all()\n",
    "\n",
    "# 1) make combo + embedding (use your existing Z_rna/Z_atac)\n",
    "rna_u = rna_test_pp.copy();   rna_u.obs[\"modality\"]  = \"rna\"\n",
    "atac_u = atac_test_lsi.copy(); atac_u.obs[\"modality\"] = \"atac\"\n",
    "\n",
    "combo = ad.concat([rna_u, atac_u], join=\"outer\", index_unique=\"-\")\n",
    "combo.obsm[\"X_latent\"] = np.vstack([Z_rna, Z_atac]).astype(np.float32)\n",
    "\n",
    "# 2D UMAP once (stored in combo.obsm[\"X_umap\"])\n",
    "sc.pp.neighbors(combo, use_rep=\"X_latent\", n_neighbors=15)\n",
    "sc.tl.umap(combo, min_dist=0.5, random_state=0)\n",
    "\n",
    "mods = combo.obs[\"modality\"].astype(str).to_numpy()\n",
    "is_rna  = (mods == \"rna\")\n",
    "is_atac = (mods == \"atac\")\n",
    "\n",
    "# 2) observed RNA (per cell x gene)\n",
    "R_obs = rna_test_pp.X\n",
    "if sp.issparse(R_obs): R_obs = R_obs.toarray()\n",
    "R_obs = np.asarray(R_obs, dtype=np.float32)\n",
    "\n",
    "# 3) predicted RNA from ATAC (same gene dim)\n",
    "R_hat = cross_modal_predict_all(\n",
    "    model, atac_test_lsi, src_mod=\"atac\", tgt_mod=\"rna\",\n",
    "    device=device, batch_size=512\n",
    ").astype(np.float32)\n",
    "\n",
    "assert R_hat.shape == R_obs.shape\n",
    "\n",
    "# 4) choose marker genes\n",
    "#marker_genes = [\"IL7R\",\"CCR7\",\"NKG7\",\"GNLY\",\"MS4A1\",\"CD74\",\"LYZ\",\"S100A9\"]\n",
    "marker_genes = [\"CD79A\", \"TRAC\"]\n",
    "marker_genes = [g for g in marker_genes if g in rna_test_pp.var_names]\n",
    "\n",
    "gene_idx = [rna_test_pp.var_names.get_loc(g) for g in marker_genes]\n",
    "\n",
    "# 5) write obs/hat scalars onto correct modality rows (obs on RNA rows, hat on ATAC rows)\n",
    "for g, j in zip(marker_genes, gene_idx):\n",
    "    combo.obs[f\"RNA_{g}_obs\"] = np.nan\n",
    "    combo.obs[f\"RNA_{g}_hat\"] = np.nan\n",
    "    combo.obs.loc[combo.obs_names[is_rna],  f\"RNA_{g}_obs\"] = R_obs[:, j]\n",
    "    combo.obs.loc[combo.obs_names[is_atac], f\"RNA_{g}_hat\"] = R_hat[:, j]\n",
    "\n",
    "# 6) plot on SAME embedding\n",
    "for g in marker_genes:\n",
    "    sc.pl.umap(\n",
    "        combo,\n",
    "        color=[f\"RNA_{g}_obs\", f\"RNA_{g}_hat\"],\n",
    "        ncols=2, wspace=0.35, size=50, frameon=False\n",
    "    )\n",
    "\n",
    "# also show embedding itself\n",
    "sc.pl.umap(combo, color=[\"modality\", \"cell_type\"], ncols=2, wspace=0.35, size=50, frameon=False)\n",
    "\n",
    "# 7) per-cell RMSE across marker genes (attach to ATAC rows, since hat lives there)\n",
    "J = np.array(gene_idx, dtype=int)\n",
    "rmse = np.sqrt(((R_hat[:, J] - R_obs[:, J])**2).mean(axis=1)).astype(np.float32)\n",
    "\n",
    "combo.obs[\"RNA_marker_rmse\"] = np.nan\n",
    "combo.obs.loc[combo.obs_names[is_atac], \"RNA_marker_rmse\"] = rmse\n",
    "\n",
    "sc.pl.umap(combo, color=[\"RNA_marker_rmse\"], frameon=False, size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49120576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import anndata as ad\n",
    "#import scanpy as sc\n",
    "#import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "def overlay_umap_with_pair_lines(\n",
    "    rna_adata,\n",
    "    z_rna_key=\"X_univi_rna_enc\",\n",
    "    z_atac_key=\"X_univi_atac_enc\",\n",
    "    label_key=None,\n",
    "    n_neighbors=15,\n",
    "    random_state=0,\n",
    "    point_size=8,\n",
    "    line_sample=300,        # None = all pairs (can get messy)\n",
    "    line_alpha=0.25,\n",
    "    line_lw=1.5,\n",
    "    line_color=\"k\",         # or \"gray\", \"tab:blue\", etc.\n",
    "):\n",
    "    assert z_rna_key in rna_adata.obsm, f\"Missing {z_rna_key}\"\n",
    "    assert z_atac_key in rna_adata.obsm, f\"Missing {z_atac_key}\"\n",
    "    assert rna_adata.obsm[z_rna_key].shape == rna_adata.obsm[z_atac_key].shape\n",
    "\n",
    "    # Two copies of same cells\n",
    "    a = rna_adata.copy()\n",
    "    b = rna_adata.copy()\n",
    "    a.obs = a.obs.copy()\n",
    "    b.obs = b.obs.copy()\n",
    "\n",
    "    cell_ids = rna_adata.obs_names.astype(str)\n",
    "    a.obs[\"cell_id\"] = cell_ids\n",
    "    b.obs[\"cell_id\"] = cell_ids\n",
    "    a.obs[\"modality\"] = \"rna_enc\"\n",
    "    b.obs[\"modality\"] = \"atac_enc\"\n",
    "\n",
    "    combo = ad.concat([a, b], join=\"outer\", axis=0, index_unique=\"-\")\n",
    "    combo.obsm[\"X_overlay\"] = np.vstack([rna_adata.obsm[z_rna_key], rna_adata.obsm[z_atac_key]])\n",
    "\n",
    "    # Fresh neighbors/umap state\n",
    "    combo.uns.pop(\"neighbors\", None)\n",
    "    combo.uns.pop(\"umap\", None)\n",
    "    for k in (\"connectivities\", \"distances\"):\n",
    "        if k in combo.obsp:\n",
    "            del combo.obsp[k]\n",
    "\n",
    "    sc.pp.neighbors(combo, use_rep=\"X_overlay\", n_neighbors=n_neighbors, random_state=random_state)\n",
    "    sc.tl.umap(combo, random_state=random_state)\n",
    "\n",
    "    # Table of coords\n",
    "    um = pd.DataFrame(combo.obsm[\"X_umap\"], columns=[\"umap1\", \"umap2\"], index=combo.obs_names)\n",
    "    df = combo.obs[[\"cell_id\", \"modality\"]].join(um)\n",
    "\n",
    "    # One row per cell_id with both modalities present\n",
    "    wide = df.pivot(index=\"cell_id\", columns=\"modality\", values=[\"umap1\", \"umap2\"]).dropna()\n",
    "\n",
    "    # Optional subsample lines\n",
    "    if line_sample is not None and wide.shape[0] > line_sample:\n",
    "        wide = wide.sample(n=line_sample, random_state=random_state)\n",
    "\n",
    "    x1 = wide[(\"umap1\", \"rna_enc\")].to_numpy()\n",
    "    y1 = wide[(\"umap2\", \"rna_enc\")].to_numpy()\n",
    "    x2 = wide[(\"umap1\", \"atac_enc\")].to_numpy()\n",
    "    y2 = wide[(\"umap2\", \"atac_enc\")].to_numpy()\n",
    "\n",
    "    # Build line segments for LineCollection: (n_lines, 2 points, 2 coords)\n",
    "    segs = np.stack(\n",
    "        [np.column_stack([x1, y1]), np.column_stack([x2, y2])],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), dpi=200)\n",
    "\n",
    "    for mod in [\"rna_enc\", \"atac_enc\"]:\n",
    "        sub = df[df[\"modality\"] == mod]\n",
    "        ax.scatter(sub[\"umap1\"], sub[\"umap2\"], s=point_size, alpha=0.7, label=mod)\n",
    "\n",
    "    lc = LineCollection(\n",
    "        segs,\n",
    "        colors=line_color,\n",
    "        linestyles=\":\",\n",
    "        linewidths=line_lw,\n",
    "        alpha=line_alpha,\n",
    "    )\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.set_xlabel(\"UMAP1\"); ax.set_ylabel(\"UMAP2\")\n",
    "    ax.legend(frameon=False, loc=\"best\")\n",
    "    ax.set_title(\"Overlay UMAP with paired-cell dotted links\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optional extra scanpy plots (no pair lines)\n",
    "    if label_key is not None and label_key in combo.obs:\n",
    "        sc.pl.umap(combo, color=[label_key, \"modality\"], frameon=False, wspace=0.4)\n",
    "\n",
    "    return combo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_key = 'cell_type'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8eca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d97d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "def build_combo_for_umaps(rna_test_pp, atac_test_lsi, Z_rna, Z_atac, celltype_key=\"cell_type\"):\n",
    "    # --- pairing sanity ---\n",
    "    assert (rna_test_pp.obs_names == atac_test_lsi.obs_names).all()\n",
    "    assert Z_rna.shape == Z_atac.shape\n",
    "    assert Z_rna.shape[0] == rna_test_pp.n_obs\n",
    "\n",
    "    # --- copies with clear metadata ---\n",
    "    r = rna_test_pp.copy()\n",
    "    a = atac_test_lsi.copy()\n",
    "    r.obs = r.obs.copy(); a.obs = a.obs.copy()\n",
    "\n",
    "    r.obs[\"modality\"] = \"rna\"\n",
    "    a.obs[\"modality\"] = \"atac\"\n",
    "    r.obs[\"cell_id\"]  = r.obs_names.astype(str)\n",
    "    a.obs[\"cell_id\"]  = a.obs_names.astype(str)\n",
    "\n",
    "    # --- concat (2N rows) ---\n",
    "    combo = ad.concat([r, a], join=\"outer\", axis=0, index_unique=\"-\")\n",
    "\n",
    "    # --- ONE clean rep for neighbors/UMAP (no NaNs) ---\n",
    "    combo.obsm[\"X_latent\"] = np.vstack([Z_rna, Z_atac]).astype(np.float32, copy=False)\n",
    "\n",
    "    # optional: stash fused/shared latent too, if you have it\n",
    "    if (\"X_univi\" in rna_test_pp.obsm) and (\"X_univi\" in atac_test_lsi.obsm):\n",
    "        combo.obsm[\"X_fused\"] = np.vstack([rna_test_pp.obsm[\"X_univi\"], atac_test_lsi.obsm[\"X_univi\"]]).astype(np.float32)\n",
    "\n",
    "    # final sanity: rep must be finite\n",
    "    X = combo.obsm[\"X_latent\"]\n",
    "    if not np.isfinite(X).all():\n",
    "        good = np.isfinite(X).all(axis=1)\n",
    "        combo = combo[good].copy()\n",
    "        combo.obsm[\"X_latent\"] = np.asarray(combo.obsm[\"X_latent\"], dtype=np.float32)\n",
    "\n",
    "    return combo\n",
    "\n",
    "\n",
    "def compute_umap_2d_and_3d(combo, rep_key=\"X_latent\", n_neighbors=15, random_state=0, min_dist=0.5):\n",
    "    # wipe stale state (safe if rerun)\n",
    "    for key in (\"neighbors\", \"umap\"):\n",
    "        combo.uns.pop(key, None)\n",
    "    for k in (\"connectivities\", \"distances\"):\n",
    "        if k in combo.obsp:\n",
    "            del combo.obsp[k]\n",
    "\n",
    "    # neighbors once\n",
    "    sc.pp.neighbors(combo, use_rep=rep_key, n_neighbors=n_neighbors, random_state=random_state)\n",
    "\n",
    "    # 2D\n",
    "    sc.tl.umap(combo, n_components=2, min_dist=min_dist, random_state=random_state)\n",
    "    combo.obsm[\"X_umap2\"] = combo.obsm[\"X_umap\"].copy()\n",
    "\n",
    "    # 3D (reuses same neighbor graph)\n",
    "    sc.tl.umap(combo, n_components=3, min_dist=min_dist, random_state=random_state)\n",
    "    combo.obsm[\"X_umap3\"] = combo.obsm[\"X_umap\"].copy()\n",
    "\n",
    "    # default back to 2D for scanpy plotting\n",
    "    combo.obsm[\"X_umap\"] = combo.obsm[\"X_umap2\"].copy()\n",
    "    return combo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da5bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = build_combo_for_umaps(rna_test_pp, atac_test_lsi, Z_rna, Z_atac, celltype_key=\"cell_type\")\n",
    "combo = compute_umap_2d_and_3d(combo, rep_key=\"X_latent\", n_neighbors=15, random_state=0)\n",
    "\n",
    "# scanpy 2D plots\n",
    "#sc.pl.umap(combo, color=[\"modality\", \"cell_type\"], frameon=False, size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2692eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "def overlay_pair_lines_2d(\n",
    "    combo,\n",
    "    *,\n",
    "    basis_key=\"X_umap2\",\n",
    "    id_key=\"cell_id\",\n",
    "    modality_key=\"modality\",\n",
    "    mod_a=\"rna\",\n",
    "    mod_b=\"atac\",\n",
    "\n",
    "    color_by=\"cell_type\",\n",
    "    cmap=\"tab20\",\n",
    "    show_legend=True,\n",
    "    legend_max=50,\n",
    "\n",
    "    line_sample=5000,\n",
    "    line_alpha=0.50,\n",
    "    line_lw=1.5,\n",
    "    line_color=\"k\",\n",
    "\n",
    "    point_size=75,\n",
    "    point_alpha=0.85,\n",
    "\n",
    "    figsize=(16, 14),\n",
    "    dpi=400,\n",
    "):\n",
    "    coords = np.asarray(combo.obsm[basis_key])\n",
    "    if coords.shape[1] != 2:\n",
    "        raise ValueError(f\"{basis_key} must be 2D for matplotlib overlay (got shape {coords.shape}).\")\n",
    "\n",
    "    df = combo.obs[[id_key, modality_key]].copy()\n",
    "    df[\"u1\"] = coords[:, 0]\n",
    "    df[\"u2\"] = coords[:, 1]\n",
    "\n",
    "    # -----------------------------\n",
    "    # Coloring\n",
    "    # -----------------------------\n",
    "    color_map = None\n",
    "    if color_by is None:\n",
    "        df[\"_color\"] = \"C0\"\n",
    "\n",
    "    else:\n",
    "        if color_by not in combo.obs.columns:\n",
    "            raise KeyError(f\"color_by='{color_by}' not found in combo.obs.\")\n",
    "        df[color_by] = combo.obs[color_by].astype(str).values\n",
    "\n",
    "        if color_by == modality_key or color_by == \"modality\":\n",
    "            # Force classic blue/orange\n",
    "            color_map = {str(mod_a): \"C0\", str(mod_b): \"C1\"}\n",
    "            df[\"_color\"] = df[color_by].map(color_map).fillna(\"0.7\")\n",
    "        else:\n",
    "            cats = pd.unique(df[color_by])\n",
    "            cmap_obj = plt.get_cmap(cmap, len(cats))\n",
    "            color_map = {c: cmap_obj(i) for i, c in enumerate(cats)}\n",
    "            df[\"_color\"] = df[color_by].map(color_map)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Pair lines\n",
    "    # -----------------------------\n",
    "    wide = df.pivot(index=id_key, columns=modality_key, values=[\"u1\", \"u2\"]).dropna()\n",
    "    if line_sample is not None and wide.shape[0] > int(line_sample):\n",
    "        wide = wide.sample(n=int(line_sample), random_state=0)\n",
    "\n",
    "    x1 = wide[(\"u1\", mod_a)].to_numpy()\n",
    "    y1 = wide[(\"u2\", mod_a)].to_numpy()\n",
    "    x2 = wide[(\"u1\", mod_b)].to_numpy()\n",
    "    y2 = wide[(\"u2\", mod_b)].to_numpy()\n",
    "    segs = np.stack([np.c_[x1, y1], np.c_[x2, y2]], axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "\n",
    "    for mod in [mod_a, mod_b]:\n",
    "        sub = df[df[modality_key].astype(str) == str(mod)]\n",
    "        ax.scatter(\n",
    "            sub[\"u1\"], sub[\"u2\"],\n",
    "            s=point_size,\n",
    "            c=sub[\"_color\"].tolist(),\n",
    "            alpha=point_alpha,\n",
    "            linewidths=0,\n",
    "            label=str(mod),\n",
    "        )\n",
    "\n",
    "    ax.add_collection(LineCollection(\n",
    "        segs, colors=line_color, linestyles=\":\", linewidths=line_lw, alpha=line_alpha\n",
    "    ))\n",
    "\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.set_xlabel(\"UMAP1\"); ax.set_ylabel(\"UMAP2\")\n",
    "    ax.set_title(f\"UMAP overlay + paired links (colored by {color_by})\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Legend\n",
    "    # -----------------------------\n",
    "    if show_legend and color_by is not None and color_map is not None:\n",
    "        cats = list(pd.unique(df[color_by]))\n",
    "        cats_show = cats[:int(legend_max)]\n",
    "        handles = [\n",
    "            plt.Line2D([0], [0], marker=\"o\", color=\"w\",\n",
    "                       markerfacecolor=color_map.get(c, \"0.7\"), markersize=7, label=c)\n",
    "            for c in cats_show\n",
    "        ]\n",
    "        ax.legend(\n",
    "            handles=handles,\n",
    "            title=color_by,\n",
    "            frameon=False,\n",
    "            loc=\"center left\",\n",
    "            bbox_to_anchor=(1.02, 0.5),\n",
    "            borderaxespad=0.0,\n",
    "        )\n",
    "        fig.subplots_adjust(right=0.72)\n",
    "    else:\n",
    "        ax.legend(frameon=False, loc=\"best\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #plt.show()\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5475b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_2d_umap = overlay_pair_lines_2d(combo, basis_key=\"X_umap2\", mod_a=\"rna\", mod_b=\"atac\", color_by=\"cell_type\", line_sample=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb44205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#celltype_2d_umap.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_2d_umap = overlay_pair_lines_2d(combo, basis_key=\"X_umap2\", mod_a=\"rna\", mod_b=\"atac\", color_by=\"modality\", line_sample=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a98f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modality_2d_umap.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def plot_umap3d_interactive(\n",
    "    adata,\n",
    "    *,\n",
    "    rep_key=\"X_latent\",           # representation to build neighbors/UMAP from (e.g., \"X_latent\")\n",
    "    umap_key=\"X_umap3\",           # where to store/read 3D coords\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.5,\n",
    "    random_state=0,\n",
    "\n",
    "    color_by=None,                # obs key (categorical/continuous). None -> no color\n",
    "    symbol_by=None,               # obs key (e.g., \"modality\")\n",
    "    hover_cols=(\"cell_id\", \"modality\", \"cell_type\"),\n",
    "\n",
    "    point_size=3,\n",
    "    opacity=0.85,\n",
    "\n",
    "    draw_pair_lines=True,\n",
    "    id_key=\"cell_id\",\n",
    "    modality_key=\"modality\",\n",
    "    mod_a=\"rna\",\n",
    "    mod_b=\"atac\",\n",
    "    line_sample=None,             # None=all\n",
    "    line_width=2.5,\n",
    "    line_opacity=0.45,\n",
    "    line_color=\"rgba(0,0,0,0.25)\",\n",
    "\n",
    "    width=950,\n",
    "    height=750,\n",
    "    title=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute (if needed) a 3D UMAP in `adata.obsm[umap_key]` and return a Plotly 3D scatter.\n",
    "    Optionally draws faint paired lines between modality copies using `id_key` and `modality_key`.\n",
    "\n",
    "    Requirements:\n",
    "      - `rep_key` exists in `adata.obsm` and is finite (no NaN/Inf)\n",
    "      - If draw_pair_lines=True: `id_key` and `modality_key` exist in `adata.obs`,\n",
    "        and each `id_key` appears twice (once per mod_a, once per mod_b).\n",
    "    \"\"\"\n",
    "    import scanpy as sc\n",
    "\n",
    "    # -----------------------\n",
    "    # 0) Validate rep\n",
    "    # -----------------------\n",
    "    if rep_key not in adata.obsm:\n",
    "        raise KeyError(f\"rep_key='{rep_key}' not found in adata.obsm. Available: {list(adata.obsm.keys())}\")\n",
    "\n",
    "    X = np.asarray(adata.obsm[rep_key], dtype=np.float32)\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(f\"adata.obsm['{rep_key}'] must be 2D; got shape {X.shape}\")\n",
    "    if not np.isfinite(X).all():\n",
    "        bad = (~np.isfinite(X).all(axis=1)).sum()\n",
    "        raise ValueError(f\"Input contains NaN/Inf in '{rep_key}'. Bad rows: {bad}/{X.shape[0]}\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 1) Compute 3D UMAP if missing/wrong\n",
    "    # -----------------------\n",
    "    need_umap = (umap_key not in adata.obsm) or (adata.obsm[umap_key].shape[1] != 3)\n",
    "    if need_umap:\n",
    "        # Clear stale scanpy state safely\n",
    "        for key in (\"neighbors\", \"umap\"):\n",
    "            adata.uns.pop(key, None)\n",
    "        for k in (\"connectivities\", \"distances\"):\n",
    "            if k in adata.obsp:\n",
    "                del adata.obsp[k]\n",
    "\n",
    "        sc.pp.neighbors(adata, use_rep=rep_key, n_neighbors=int(n_neighbors), random_state=int(random_state))\n",
    "        sc.tl.umap(adata, n_components=3, min_dist=float(min_dist), random_state=int(random_state))\n",
    "        adata.obsm[umap_key] = adata.obsm[\"X_umap\"].copy()\n",
    "\n",
    "    coords = np.asarray(adata.obsm[umap_key], dtype=np.float32)\n",
    "    if coords.shape[1] != 3:\n",
    "        raise ValueError(f\"{umap_key} must be 3D; got shape {coords.shape}\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 2) Build plotting DF\n",
    "    # -----------------------\n",
    "    df = adata.obs.copy()\n",
    "    df = df.assign(u1=coords[:, 0], u2=coords[:, 1], u3=coords[:, 2])\n",
    "\n",
    "    if color_by is not None and color_by not in df.columns:\n",
    "        raise KeyError(f\"color_by='{color_by}' not in adata.obs.\")\n",
    "    if symbol_by is not None and symbol_by not in df.columns:\n",
    "        raise KeyError(f\"symbol_by='{symbol_by}' not in adata.obs.\")\n",
    "\n",
    "    hover_data = {c: True for c in hover_cols if c in df.columns}\n",
    "    if color_by is not None:\n",
    "        hover_data[color_by] = True\n",
    "    if symbol_by is not None:\n",
    "        hover_data[symbol_by] = True\n",
    "\n",
    "    fig = px.scatter_3d(\n",
    "        df,\n",
    "        x=\"u1\", y=\"u2\", z=\"u3\",\n",
    "        color=color_by if color_by is not None else None,\n",
    "        symbol=symbol_by if symbol_by is not None else None,\n",
    "        hover_data=hover_data,\n",
    "        opacity=float(opacity),\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=float(point_size)))\n",
    "\n",
    "    # -----------------------\n",
    "    # 3) Optional paired lines\n",
    "    # -----------------------\n",
    "    if draw_pair_lines:\n",
    "        if id_key not in df.columns or modality_key not in df.columns:\n",
    "            raise KeyError(f\"Need '{id_key}' and '{modality_key}' in adata.obs to draw pair lines.\")\n",
    "\n",
    "        d2 = df[[id_key, modality_key, \"u1\", \"u2\", \"u3\"]].copy()\n",
    "        wide = d2.pivot(index=id_key, columns=modality_key, values=[\"u1\", \"u2\", \"u3\"]).dropna()\n",
    "\n",
    "        # ensure both modalities exist\n",
    "        need_cols = [(\"u1\", mod_a), (\"u2\", mod_a), (\"u3\", mod_a),\n",
    "                    (\"u1\", mod_b), (\"u2\", mod_b), (\"u3\", mod_b)]\n",
    "        missing = [c for c in need_cols if c not in wide.columns]\n",
    "        if missing:\n",
    "            raise KeyError(\n",
    "                f\"Missing required pivot columns for mod_a='{mod_a}', mod_b='{mod_b}'. \"\n",
    "                f\"Check values in adata.obs['{modality_key}'].\"\n",
    "            )\n",
    "\n",
    "        if line_sample is not None and wide.shape[0] > int(line_sample):\n",
    "            wide = wide.sample(n=int(line_sample), random_state=int(random_state))\n",
    "\n",
    "        # Build segments separated by NaNs (Plotly trick)\n",
    "        n = wide.shape[0]\n",
    "        x = np.empty(n * 3, dtype=float)\n",
    "        y = np.empty(n * 3, dtype=float)\n",
    "        z = np.empty(n * 3, dtype=float)\n",
    "\n",
    "        x[0::3] = wide[(\"u1\", mod_a)].to_numpy()\n",
    "        y[0::3] = wide[(\"u2\", mod_a)].to_numpy()\n",
    "        z[0::3] = wide[(\"u3\", mod_a)].to_numpy()\n",
    "\n",
    "        x[1::3] = wide[(\"u1\", mod_b)].to_numpy()\n",
    "        y[1::3] = wide[(\"u2\", mod_b)].to_numpy()\n",
    "        z[1::3] = wide[(\"u3\", mod_b)].to_numpy()\n",
    "\n",
    "        x[2::3] = np.nan\n",
    "        y[2::3] = np.nan\n",
    "        z[2::3] = np.nan\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=x, y=y, z=z,\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=float(line_width), color=line_color),\n",
    "                opacity=float(line_opacity),\n",
    "                hoverinfo=\"skip\",\n",
    "                showlegend=False,\n",
    "                name=f\"paired links ({mod_a}↔{mod_b})\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # -----------------------\n",
    "    # 4) Layout polish\n",
    "    # -----------------------\n",
    "    if title is None:\n",
    "        if color_by is None and symbol_by is None:\n",
    "            title = \"Interactive 3D UMAP\"\n",
    "        else:\n",
    "            title = f\"Interactive 3D UMAP (color={color_by}, symbol={symbol_by})\"\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=int(width),\n",
    "        height=int(height),\n",
    "        margin=dict(l=10, r=10, t=50, b=10),\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "            xaxis_title=\"UMAP1\",\n",
    "            yaxis_title=\"UMAP2\",\n",
    "            zaxis_title=\"UMAP3\",\n",
    "        ),\n",
    "        legend=dict(itemsizing=\"constant\"),\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default\n",
    "\n",
    "# Classic Jupyter Notebook:\n",
    "#pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "# JupyterLab:\n",
    "#pio.renderers.default = \"jupyterlab\"\n",
    "\n",
    "# VS Code notebooks:\n",
    "#pio.renderers.default = \"vscode\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_fig = plot_umap3d_interactive(\n",
    "    combo,\n",
    "    rep_key=\"X_latent\",\n",
    "    color_by=\"cell_type\",\n",
    "    symbol_by=\"modality\",\n",
    "    draw_pair_lines=True,\n",
    "    id_key=\"cell_id\",\n",
    "    modality_key=\"modality\",\n",
    "    mod_a=\"rna\",\n",
    "    mod_b=\"atac\",\n",
    "    line_sample=5000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21605f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"displayModeBar\": True,      # <- force modebar to always show\n",
    "    \"displaylogo\": False,\n",
    "    \"toImageButtonOptions\": {    # <- controls what the button exports\n",
    "        \"format\": \"png\",\n",
    "        \"filename\": \"umap3d\",\n",
    "        \"width\": 2000,\n",
    "        \"height\": 1600,\n",
    "        \"scale\": 9,              # higher = higher-res PNG from the button\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7982085",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65650f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_fig = plot_umap3d_interactive(\n",
    "    combo,\n",
    "    rep_key=\"X_latent\",\n",
    "    color_by=\"modality\",\n",
    "    symbol_by=\"modality\",\n",
    "    draw_pair_lines=True,\n",
    "    id_key=\"cell_id\",\n",
    "    modality_key=\"modality\",\n",
    "    mod_a=\"rna\",\n",
    "    mod_b=\"atac\",\n",
    "    line_sample=5000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0047b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7735ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1391844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45461b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b3fe7-e851-4954-a9ad-d103b72f8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94675a-b78a-46e9-911b-79a7ebc3fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909964b7-354c-4789-b32e-1991c4f978a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3767b-b18b-48bf-8d42-2e5fb2eaf0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d954e7-4742-4171-a3cb-65b770bf9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b57a36-d407-4802-a6e3-7eef8c56ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f124af-5fa2-463f-bc84-acc1a515881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (UniVI v0.2.3)",
   "language": "python",
   "name": "univi_v0.2.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
